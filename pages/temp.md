---
layout: page
title: Contemporary Trompe-l'œil, from PK, for Black Hole Club
permalink: /temp/
# category: menu
---

Examples from the [Prosthetic Knowledge](http://prostheticknowledge.tumblr.com/) archive of projects and experiences that employ [anamorphosis](https://en.wikipedia.org/wiki/Anamorphosis), an optical illusion of depth from flat surfaces dependent on viewing angle, with modern technological means such as positioning sensors or head tracking software.

The term '[Trompe-l'œil](https://en.wikipedia.org/wiki/Trompe-l'%C5%93il)' often refers to paintings in art history; a notabe example is [Holbein's _The Ambassadors_](https://en.wikipedia.org/wiki/The_Ambassadors_(Holbein)):

![](https://c10.patreonusercontent.com/3/eyJ2IjoiMSIsInciOjEyNDB9/patreon-media/post/18681055/e7c284171f6146d7b3fcadddb3f8903b?token-time=1527033600&token-hash=mBQaWQGGvXZeydpovHf5rxnSATeRqgJSeVoZdgwbuKk%3D)

The skull at the bottom of the piece can be seen correctly at a certain angle:

![](https://c10.patreonusercontent.com/3/eyJ2IjoiMSIsInciOjEyNDB9/patreon-media/post/18681055/70ca631233bd4dc8998849a59c526a77?token-time=1527033600&token-hash=hBndLcS3ZGUox5dtGpKNH8cFAv_bg5Dnhw7qjHdv6Mc%3D)

The work has even inspired a temporary tattoo from artist [Pablo Garcia](https://www.pablogarcia.org/):

![](https://c10.patreonusercontent.com/3/eyJ2IjoiMSIsInciOjEyNDB9/patreon-media/post/18681055/483a9b957dbd45a6a77964d492872a77?token-time=1527033600&token-hash=AfXkk-5I-HulhijAHX76J9QaVtYihJidP_g8mFKrQ_E%3D)

[[Source](https://www.kickstarter.com/projects/pgarcia/memento-mori-tattoo)]

Developments in the last decade have enabled this method to move from static images to realtime animated graphics for a variety of purposes. Some employ additional tracking sensors which have over time become more available or affordable, or use some kind of face tracking software to detect the observer via camera feed - both methods detect the position of the participant to calculate and accomodate the correct viewpoint.

The most common reference point to many of these projects is the work of [Johnny Chung Lee](http://johnnylee.net) and his work with the Nintendo Wii hardware. His 2007 project 'Head Tracking for Desktop VR Displays using the WiiRemote' presents an intelligent and creative way of producing a sense of depth through a standard display by placing the Wii's sensor bar onto a pair of glasses to be worn by the participant and a Wii controller near the display, which allows the calculation of their head position:

![](https://c10.patreonusercontent.com/3/eyJ2IjoiMSIsInciOjEyNDB9/patreon-media/post/18681055/922ef37fa1c8442e8054051869094d47?token-time=1527033600&token-hash=_MtuR0WPFyLlsb6ruf0SA04xQHWyZ_IUetKJbMo7o5w%3D)

Whilst realistic for the participant, the view from others outside the experience is different:

![](https://c10.patreonusercontent.com/3/eyJ2IjoiMSIsInciOjEyNDB9/patreon-media/post/18681055/19ab8306815d4107a0aae8b43ac26f39?token-time=1527033600&token-hash=b71AzmmnZRBLlbHEUI6avvTndDDdkqgGoM3ZYW9UKCk%3D)

Lee went on to work for Google to develop Project Tango. You can find out more about the projects he developed with the Wii controllers [here](http://johnnylee.net/projects/wii/). A good primer on how this works (and how the ideas related to the projects below), you can watch Lee's video [here](https://www.youtube.com/watch?v=Jd3-eiid-Uw).

Below is a list of related projects from the PK archive in chronological order, oldest first. The projects cover design, art performance, cinematography and hardware.

April 2012 - **AR 3D Hologram Coffee Table**

![](https://c10.patreonusercontent.com/3/eyJ2IjoiMSIsInciOjEyNDB9/patreon-media/post/18681055/cbe1dd066ad34f12b8b5877eeaab092f?token-time=1527033600&token-hash=efyNtiUCKeAFzqSKS1Im1drJsTnPpLtDmMDJc5iatm8%3D)

Project by Bastian Broecker employs Johnny Lee's ideas and places it onto a flat surface using a projector, using a Microsoft Kinect as a tracker.

A video of it in action can be found [**here**](https://www.youtube.com/watch?v=2CbiOikirrg) 

More details at PK page [here](http://prostheticknowledge.tumblr.com/post/22125389438/ar-3d-hologram-coffee-table-impressive-yet) 

April 2015 - **Perspective Tracking Demos**

![](https://c10.patreonusercontent.com/3/eyJ2IjoiMSIsInciOjEyNDB9/patreon-media/post/18681055/9956f22cb617483e905174c1f405cf44?token-time=1527033600&token-hash=AIyh_7_GRKFsWWSc7klwUDzocOfy53IyHlAhU1ZDSW0%3D)

![](https://c10.patreonusercontent.com/3/eyJ2IjoiMSIsInciOjEyNDB9/patreon-media/post/18681055/ee4f1409480f44808fdbb3848d26f02c?token-time=1527033600&token-hash=Kliih4LvVeEbCEA_d17qrKr99iHlb9I7zVHaq_4VMY4%3D)

Artist [Raven Kwok](http://ravenkwok.com/) explores positional tracking in a [CAVE environment](https://en.wikipedia.org/wiki/Cave_automatic_virtual_environment), using high end sensors and, interestingly, coded with creative coding language Processing:

> Each screen is attached perpendicularly to its neighbor(s), aligned with its corresponding rear projection. Four [Vicon Bonita](http://www.vicon.com/system/bonita)  cameras on top corners cover the central area surrounded by the  screens. The origin point locates at center of the central area.

> Data collected by Vicon is sent through [VRPN](https://en.wikipedia.org/wiki/VRPN) (Virtual-Reality Peripheral Network), then [OSC](http://opensoundcontrol.org/introduction-osc)  (Open Sound Control) protocol to Processing, and is mapped as frustum  parameters to compute three projection matrices, which coincide with the  screens’ position in reality.

A video demonstration can be found [here](https://vimeo.com/126332070), with more info at Raven's website [here](http://ravenkwok.com/perspective-tracking-in-triple-screens-cave/) 

[[PK Link](http://prostheticknowledge.tumblr.com/post/117689168371/perspective-tracking-demos-latest-from-ravenkwok)]

Februaru 2016 - **Doors**

![](https://c10.patreonusercontent.com/3/eyJ2IjoiMSIsInciOjEyNDB9/patreon-media/post/18681055/5c97ddc2891041ce84d5bfe993b8bc14?token-time=1527033600&token-hash=qr9P5vMfjfKX3h_LWdk5LkaJzPEnvNPHm_hTF_XT4l8%3D)

![](https://c10.patreonusercontent.com/3/eyJ2IjoiMSIsInciOjEyNDB9/patreon-media/post/18681055/c48c262b4f42426e807e85ee9f4dcacc?token-time=1527033600&token-hash=QP-NMnUXZXutVniuslATL1hvhG56E_U-Tthz41Dqylc%3D)

![](https://c10.patreonusercontent.com/3/eyJ2IjoiMSIsInciOjEyNDB9/patreon-media/post/18681055/4a886b4d66954b93833bdb263ffbc3e3?token-time=1527033600&token-hash=Hi_dV5GkRZG2i5U5-f-B2p_2LgROp11mBmHjO96fDzw%3D)

Interactive installation by [Theoriz](http://www.theoriz.com/) is a doorway that leads to virtual perceptions, utilizating head  tracking to provide convincing perspective to participating observer.

> Between reality and virtuality, we are playing with the feeling of  perception and infinite space. In this setup we had a real time  anamorphic custom software computing the perspective of the nearest  person.

> Through a 4 channel immersive and 3D spatialized sound, people  could experience and discover virtual audioreactive landscapes by simply  moving in space.

Video of the piece can be found [here](https://vimeo.com/154407574) 

[[PK Link](http://prostheticknowledge.tumblr.com/post/138816432351/doors-installation-by-theoriz-is-a-doorway-that)]

September 2016 - **Spending All My Time / Dynamic VR Display**

![](https://c10.patreonusercontent.com/3/eyJ2IjoiMSIsInciOjEyNDB9/patreon-media/post/18681055/c4829c3bd2ec4932a8089f0739f5ac27?token-time=1527033600&token-hash=0EB-_Gb2hz5zBSm6CydX6Wto45FCOQWI1blaD6eNXn4%3D)

![](https://c10.patreonusercontent.com/3/eyJ2IjoiMSIsInciOjEyNDB9/patreon-media/post/18681055/4189c1a143d04c7f9665b691202cc147?token-time=1527033600&token-hash=SQC8jTr-OOV52dexOv2sKOBnO3iRHg2VuIc-VPemgtI%3D)

![](https://c10.patreonusercontent.com/3/eyJ2IjoiMSIsInciOjEyNDB9/patreon-media/post/18681055/c7778d92bc844d9aa86bcfa6ca9eacc8?token-time=1527033600&token-hash=U2v5Yb17QPZaInAC6KnZpnNyCUftLJfG9Sk3bdasDhI%3D)

Production setup from [Rhizomatiks](https://rhizomatiks.com/) can provide sense of 3D depth to scene using trompe l'oeil motion tracking with robotic camera.

> Motion capture + Realtime 3D Scan + View dependent graphics rendering using camera tracking data.

A video demonstration can be found [here](https://www.youtube.com/watch?v=G7ZQ4KiX1JE). [[PK Link](http://prostheticknowledge.tumblr.com/post/155223976991/dynamic-vr-display-production-setup-from)]

The work was used in a live television performance by Japanese pop group [Perfume](http://www.perfume-global.com/) as part of a 30 year celebration of music television channel [Music Station](http://www.tv-asahi.co.jp/music/ultrafes2017/):

![](https://c10.patreonusercontent.com/3/eyJ2IjoiMSIsInciOjEyNDB9/patreon-media/post/18681055/5d14eaba506d42198da008518d3874b6?token-time=1527033600&token-hash=g0KwyyPXDOS3nhlkxgYl6irUzQQkOvWIUPV392Tn9n4%3D)

![](https://c10.patreonusercontent.com/3/eyJ2IjoiMSIsInciOjEyNDB9/patreon-media/post/18681055/ea85231dfed04907a3db4b5bde55d580?token-time=1527033600&token-hash=NdGIGgyPrDUYc3UX3TNs5Ih20LED88nsbOnvVvqtWJ4%3D)

A recording of the performance was thought to be lost, but I managed to find one [here](https://www.bilibili.com/video/av7707994/) [It is a Japanese video hosting site, but I wonder how long it will stay, so best to view it as soon as possible!] [[PK Link](http://prostheticknowledge.tumblr.com/post/150682133051/spending-all-my-time-j-pop-stage-performance-by)]

January 2017 - **HoloLamp**

![](https://c10.patreonusercontent.com/3/eyJ2IjoiMSIsInciOjEyNDB9/patreon-media/post/18681055/a93c4fc358ab41518dd4ad5f58b081f8?token-time=1527033600&token-hash=-XmVzgfEcvGBldpcg6Jsq5fI8ZVQ-a9p4JUlPLy4pE0%3D)

![](https://c10.patreonusercontent.com/3/eyJ2IjoiMSIsInciOjEyNDB9/patreon-media/post/18681055/db43ecbf0cc14430be804d01bef44098?token-time=1527033600&token-hash=YE1qfjvsxvTtSa9Zsa03uKBMNcPSC9CwyCpqvAFI534%3D)

![](https://c10.patreonusercontent.com/3/eyJ2IjoiMSIsInciOjEyNDB9/patreon-media/post/18681055/f0063876c2f54785a374d45b292cdb4a?token-time=1527033600&token-hash=VMt33yeZgXXd_mUUR3h8KD14IBIviEV1yi-E-4dN1P8%3D)

![](https://c10.patreonusercontent.com/3/eyJ2IjoiMSIsInciOjEyNDB9/patreon-media/post/18681055/1416d2034d7d4558ad613a0e893b4547?token-time=1527033600&token-hash=hlfl0A1sZ3PdPV6aAeSqFht1mEgRsjS_qzjEPmLc5Zg%3D)

Hardware which combines projection with headtracking to present  3D perspective on flat surface using facial recognition to calculate viewing angles.

More from the official website [**here**](http://hololamp.tech/) [[PK Link](http://prostheticknowledge.tumblr.com/post/156049041031/hololamp-augmented-reality-product-uses-projection)]

April 2017 - **Picture Window**

![](https://c10.patreonusercontent.com/3/eyJ2IjoiMSIsInciOjEyNDB9/patreon-media/post/18681055/2c41fafdcbe041e1b3d763f93505109b?token-time=1527033600&token-hash=4_hwhW8JpY7vzDRTBu0Bl9Sf-HOxOoJRReBh2vr1CNE%3D)

![](https://c10.patreonusercontent.com/3/eyJ2IjoiMSIsInciOjEyNDB9/patreon-media/post/18681055/f692ad14f3f74a3bb6930da38f70b6c0?token-time=1527033600&token-hash=TVW7kmpEo6BWY0UMNOjDRb5t46D3PfbGNy5zdlUBtWk%3D)

Coding project from [Ryan Sullivan](http://smirkingcat.software/) takes Johnny Lee's idea with the Wii controller and applies it to the controllers of the HTC Vive:

> This is a Unity asset that allows you to turn your display (whether  that’s a monitor, tv, or projected image) into a window that looks into  the virtual space from the perspective of a tracked object.

A video demonstration can be found [here](https://www.youtube.com/watch?v=O5ZMjA3gVRw). Code for the project can be found [here](http://smirkingcat.software/picturewindow/) [[PK Link](http://prostheticknowledge.tumblr.com/post/159303547921/picture-window-code-from-ryan-sullivan-can-provide)]

June 2017 - **No-Logram**

![](https://c10.patreonusercontent.com/3/eyJ2IjoiMSIsInciOjEyNDB9/patreon-media/post/18681055/634b93f3c2d849dbb88d8ce56476a908?token-time=1527033600&token-hash=n7wqglnZ7x4TaXydlqTYhzI1nOtkw8EA8YAxO76d_2s%3D)

![](https://c10.patreonusercontent.com/3/eyJ2IjoiMSIsInciOjEyNDB9/patreon-media/post/18681055/eec65b1517104af4b25db2cc1631e95f?token-time=1527033600&token-hash=wCKzwdWIgI2hM5a1YKCU0zy3iUeeCyTzsMlx2MU01t8%3D)

![](https://c10.patreonusercontent.com/3/eyJ2IjoiMSIsInciOjEyNDB9/patreon-media/post/18681055/e218157464cd4800a97800d186b75e7b?token-time=1527033600&token-hash=MGxL8_8u4Nr7IKD-24vsvvJ6X29627VXSke_RheJfsI%3D)

![](https://c10.patreonusercontent.com/3/eyJ2IjoiMSIsInciOjEyNDB9/patreon-media/post/18681055/16b821f05a3c4536b308056093ca2196?token-time=1527033600&token-hash=ZVTwEFQzbXVCtT0epB43KmxYFWr-eb_VWXpUysU8N90%3D)

Art installation project from Joanie Lemercier employs projections on a transparent screen with positional tracking to give impression of objects floating in mid-air. It isn't clear what tech is being used for the effect.

> - This is a video projection that appears to float in the air.  
> - The user is tracked to adjust perspective so objects appears in 3D.  
> - Unlike AR and VR, no headset, device or screen is required.  
> - You can control the projection with your hands.  
> - There is no limitation in scale.  
> - I’m developping this as an art installation  
> - It’s also available for special commissions.   
> THIS IS NOT A HOLOGRAM !  
> Holograms are still images captured on photographic plate with a laser, and were invented in 1971.  
> THIS IS A VIDEO PROJECTION appearing to float in the air and  following the viewers perspective, overlayed with the real world. Unlike  AR and VR, no headset, device or screen is required.

You can find out more about the series [here](http://joanielemercier.com/no-logram/) [[PK Link](http://prostheticknowledge.tumblr.com/post/162399812716/floating-projections-latest-from-joanielemercier)]

February 2018 - **The Parallax View**

![](https://c10.patreonusercontent.com/3/eyJ2IjoiMSIsInciOjEyNDB9/patreon-media/post/18681055/9c96703e3f0d4d63b86f7b23812af313?token-time=1527033600&token-hash=1jaljhkR3vWuVCZfJfV9BYJXYKJZo3NyNpPxc-CcyM8%3D)

![](https://c10.patreonusercontent.com/3/eyJ2IjoiMSIsInciOjEyNDB9/patreon-media/post/18681055/ef0142ece55c45409416bfb93cbfc980?token-time=1527033600&token-hash=pUgA37vBgfBIpRFKlpNtYAAZ-qoFv9JKzBZEC3wQIxU%3D)

![](https://c10.patreonusercontent.com/3/eyJ2IjoiMSIsInciOjEyNDB9/patreon-media/post/18681055/fa9beed6ca094562a5b426cc4c359114?token-time=1527033600&token-hash=q0o3iVMXfhvYrKm2j02KSrGIfuqEsxdTvf0QdNDrSf8%3D)

![](https://c10.patreonusercontent.com/3/eyJ2IjoiMSIsInciOjEyNDB9/patreon-media/post/18681055/88b392b288894c7f9af99d4f59b3a29b?token-time=1527033600&token-hash=0i-E5l6twZxx5nv0tcg0oyjhv4RVzrMnUT7K8KE-018%3D)

Project from [Peder Norrby](http://www.anxious-bored.com/) brings ideas illustrated above to the IphoneX using TrueDepth facetracking and Unity to produce a_Trompe-l'œil_ effect of depth from the position of your head.

> Illusion of depth by 3D head tracking using ARKit and iPhone X. For best results, only one eye should be open (the app allows selecting which eye to track, or can try to select eye automatically).

The app is available from the App Store [here](https://itunes.apple.com/gb/app/theparallaxview/id1352818700?mt=8&ign-mpt=uo%3D4) 

[[PK Link](http://prostheticknowledge.tumblr.com/post/171379375686/the-parallax-view-project-from-peder-norrby-is-an)]

April 2018 - **How We Killed The Green Screen**

![](https://c10.patreonusercontent.com/3/eyJ2IjoiMSIsInciOjEyNDB9/patreon-media/post/18681055/12ddd35301ed4ba4a7046f372a237ab8?token-time=1527033600&token-hash=DLzWxQ__-P70bZzHkKPoJYLX0lHcfdcrqWN27u-rY-4%3D)

![](https://c10.patreonusercontent.com/3/eyJ2IjoiMSIsInciOjEyNDB9/patreon-media/post/18681055/cbdae8bbb66448cf8e83d7602ff2dfa1?token-time=1527033600&token-hash=bl5nUNRjT6a69HXaAjWSd7flhM7FYbIfIQ6SsfTr6aI%3D)

![](https://c10.patreonusercontent.com/3/eyJ2IjoiMSIsInciOjEyNDB9/patreon-media/post/18681055/527d4cdbdbc4488fa15e96f5a7b89572?token-time=1527033600&token-hash=Tzk2VfpSuw5QLj1RzrWol-1Ks-3K9KTdw1A-b9W_jgQ%3D)

![](https://c10.patreonusercontent.com/3/eyJ2IjoiMSIsInciOjEyNDB9/patreon-media/post/18681055/69d8d12122ed400d966c19cf9f14c533?token-time=1527033600&token-hash=_JBmbvJH0YOJxPI8PzaY9VHFrdK8wnXlQIRRKJIlb_E%3D)

Film director [Michael Plescia](https://vimeo.com/user8222183) presents updated method of SFX trick, the rear projection, incorporating realtime trompe l'oeil camera position tracking for convincing backdrops, called WallAR, in a similar way to the Rhizomatiks method above. I maybe wrong, but I may have caught the use of an HTC Vive controller attached to the camera.

> This piece delves into the inception, development process, and shows the  production test footage of the first ever real-time, in-camera,  real-light, real-lens, perspective-adapting, mixed-reality, rear-screen,  compositing technique.

The video explaining the method can be found [here](https://vimeo.com/264282403) [[PK Link](http://prostheticknowledge.tumblr.com/post/173041569001/how-we-killed-the-green-screen-film-director)]

