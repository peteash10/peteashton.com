---
layout: page
title: Speculative Cameras notes
permalink: /speculative_cameras_notes_2017/
# category: menu
---

I ran a [Speculative Cameras workshop](https://www.developedinbirmingham.com/programme/speculative-cameras-workshop/) for [Developed in Birmingham](https://www.developedinbirmingham.com) on August 19th 2017 at [Birmingham Museum & Art Gallery](http://www.birminghammuseums.org.uk/bmag). These are notes for the participants. 

The course is indebted to [Golan Levin's Experimental Capture course](https://github.com/golanlevin/ExperimentalCapture) for CMU which I attended the summer school version of in 2016. Golan has put all the course notes and materials [online](https://github.com/golanlevin/ExperimentalCapture) and you are encouraged to dig deep. 

Other inspiration comes from [James George](http://jamesgeorge.org)'s talk [Imaging The Future](https://vimeo.com/134973504) and his work with [Alexander Porter](http://alexanderporter.net) at [Scatter](http://scatter.nyc).

Speculative Cameras was the title of my work-in-progress while I was a fellow at Birmingham Open Media. [I gave a talk on the subject](https://vimeo.com/159868781) in 2016. This has now morphed into [Instructions for Humans](http://art.peteashton.com/instructions-for-humans/). 

## Pete's Work

At the beginning of the slides I showed a bit of my work. Most of it is archived at [art.peteashton.com](http://art.peteashton.com). 

[How to do Focus Stacking](http://blog.peteashton.com/art/2017/01/03/stacking/)

[Live Sonification of Photography](http://art.peteashton.com/live-sonification-photography/) 

[Koyaanisqatsi Slitscanned](http://art.peteashton.com/koyaanisqatsi-slitscanned/)

[Sitting In Stagram](http://art.peteashton.com/sitting-in-stagram/)

[648 Members of Parliament](http://art.peteashton.com/648-MPs/)

[Cross City Walks](http://xcw.org.uk)

[A Portrait of Birmingham](http://art.peteashton.com/portrait-bham)

[Instructions for Humans](http://art.peteashton.com/instructions-for-humans/) which open at [Birmingham Open Media next month](http://www.bom.org.uk/event/instructions-for-humans/).

# Camera Obscura

[Wikipedia's history](https://en.wikipedia.org/wiki/Camera_obscura)

[David Hockney's thesis](https://en.wikipedia.org/wiki/Hockney–Falco_thesis) that Renaissance artists uses optical aids in their paintings. The BBC documentary [Secret Knowledge](https://www.youtube.com/watch?v=X97bhjx4EaI) is on YouTube in depressingly low quality but is well worth a watch. 

[Birmingham Camera Obscura](http://bhamobscura.com), the project run by Jenny Duffin and myself. 

[Abelardo Morell](http://www.abelardomorell.net/project/camera-obscura/) pioneered the development of the "turn a whole room into a camera" technique and has a great archive of rooms overlooking landmarks. 

[Chris Dury's cloud chambers](http://chrisdrury.co.uk)

[Sam at Light Play](https://light-play.org) produces beautiful portraits from his camera obscura tent. 

# Junk Lenses

[Miroslav Tichý](https://en.wikipedia.org/wiki/Miroslav_Tichý) and his [home made camera](http://tichyocean.com/artist/miroslav-tichy).  

The [2000 Through the Viewfinder photos](https://www.flickr.com/photos/peteashton/sets/72157594253244021) I made during my lens-hacking period. 

# Photogrammetry 

I've finished a couple of our scans from the workshop. 

- [Here's Simon](https://skfb.ly/6tnNU) who stood still so magnificently. 
- [This is the octagon kiosk outside BMAG](https://skfb.ly/6tnQH).

<div class="sketchfab-embed-wrapper"><iframe width="640" height="480" src="https://sketchfab.com/models/500e4061685e4ccaaa819765a3f2aff6/embed" frameborder="0" allowvr allowfullscreen mozallowfullscreen="true" webkitallowfullscreen="true" onmousewheel=""></iframe>
</div>

[Golan Levin's brief history.](https://github.com/golanlevin/ExperimentalCapture/blob/master/docs/Photogrammetry-and-3D-scanning.md)

[The Shining in 360](https://www.youtube.com/watch?v=AupAFblRwgY) (best viewed in the Chrome browser)

[Mannequin Challenge](http://prostheticknowledge.tumblr.com/post/153566351806/mannequinchallenge-structure-from-motion-a)

[Agisoft Photoscan](http://www.agisoft.com) is the application I recommended. You can get a 30 day trial license and the basic license is US $179. I have not found any cheaper or open source alternatives that have this level of quality. (Later: There's [Colmap](https://demuc.de/colmap/) which is free but I haven't looked at it. Seems to need a powerful computer but the [tutorial](https://www.youtube.com/watch?v=P-EC0DzeVEU) is very interesting.)

[PDF of the guide to using Photoscan.](https://github.com/golanlevin/ExperimentalCapture/blob/master/workshop/pdf/photogrammetry_from_video_with_photoscan.pdf)

There are of course many other ways to capture 3D and depth information. Kinect sensors are popular with artists (see work by [Scatter](http://scatter.nyc) and some phones are coming with dual cameras. Photogrammetry's main requirement is processing power so look for new developments as this increases. 

# Infrared

This is a subset of [Multispectral Imaging](https://en.wikipedia.org/wiki/Multispectral_image) and I based it on [Golan Levin's introduction to the subject](https://github.com/golanlevin/ExperimentalCapture/blob/master/docs/hyperspectral.md). 

There's been lots of work made with Infrared, to the point where the aesthetic was getting a little tired, but [Richard Mosse](http://www.richardmosse.com) seems to have found a new way to use it which is why I showed you so much of his work. 

# Artificial Intelligence

Such a broad subject and so much to cover. This is the basis of my show [Instructions for Humans at Birmingham Open Media](http://www.bom.org.uk/event/instructions-for-humans/) next month where I'll be in the gallery every day (Wed - Sat, 12-5) so if you'd like to discuss it further please come visit. I will also be gathering more resources at [instructionsforhumans.com](http://instructionsforhumans.com) once the show starts.

[Deep Dream Generator](https://deepdreamgenerator.com) is the tool we used to turn the group portrait into slugs and puppies. There are also options for "Style Transfer" which we didn't look at. [Wikipedia](https://en.wikipedia.org/wiki/DeepDream)

![](http://peteashton.com/images/dream_qviki86p1q0.jpg)

[Gene Kogan](http://genekogan.com) is the go-to guy for using AI and machine learning for art. His book-in-progress with Francis Tseng is online with lots of examples at [ml4a.github.io](http://ml4a.github.io). Here's the short presentation I played you: [What Neural Networks See](https://experiments.withgoogle.com/ai/what-neural-nets-see).

<iframe width="640" height="360" src="https://www.youtube-nocookie.com/embed/Gu0MkmynWkw?rel=0" frameborder="0" allowfullscreen></iframe>

[Kyle Macdonald's walk through the streets with an object-recognition system running on his laptop.](https://vimeo.com/146492001)  

[Memo Akten](http://www.memo.tv) currently developing new work using AI systems and is worth keeping an eye on. Something good will emerge from his brain, I'm sure. 

## And that's it! 

Thank you again for coming and hope to see you at BOM in the Autumn. 

[Pete Ashton](http://peteashton.com)   
*Last updated 21th August 2017*