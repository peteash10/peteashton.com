In one of the key scenes in Alfonso Cuarón’s 2006 film Children of Men, Clive Owen’s character, Theo, visits a friend at Battersea Power Station, which is now some combination of government building and private collection. Cultural treasures – Michelangelo’s David, Picasso’s Guernica, Pink Floyd’s inflatable pig – are preserved in a building that is itself a refurbished heritage artifact. This is our only glimpse into the lives of the elite, holed up against the effects of a catastrophe which has caused mass sterility: no children have been born for a generation. Theo asks the question, ‘how all this can matter if there will be no-one to see it?’ The alibi can no longer be future generations, since there will be none. The response is nihilistic hedonism: ‘I try not to think about it’.

What is unique about the dystopia in Children of Men is that it is specific to late capitalism. This isn’t the familiar totalitarian scenario routinely trotted out in cinematic dystopias (see, for example, James McTeigue’s 2005 V for Vendetta). In the PD. James novel on which the film is based, democracy is suspended and the country is ruled over by a self-appointed Warden, but, wisely, the film downplays all this. For all that we know, the authoritarian measures that are everywhere in place could have been implemented within a political structure that remains, notionally, democratic. The War on Terror has prepared us for such a development: the normalization of crisis produces a situation in which the repealing of measures brought in to deal with an emergency becomes unimaginable (when will the war be over?)

Watching Children of Men, we are inevitably reminded of the phrase attributed to Fredric Jameson and Slavoj Žižek, that it is easier to imagine the end of the world than it is to imagine the end of capitalism. That slogan captures precisely what I mean by ‘capitalist realism’: the widespread sense that not only is capitalism the only viable political and economic system, but also that it is now impossible even to imagine a coherent alternative to it. Once, dystopian films and novels were exercises in such acts of imagination – the disasters they depicted acting as narrative pretext for the emergence of different ways of living. Not so in Children of Men. The world that it projects seems more like an extrapolation or exacerbation of ours than an alternative to it. In its world, as in ours, ultra-authoritarianism and Capital are by no means incompatible: internment camps and franchise coffee bars co-exist. In Children of Men, public space is abandoned, given over to uncollected garbage and stalking animals (one especially resonant scene takes place inside a derelict school, through which a deer runs). Neoliberals, the capitalist realists par excellence, have celebrated the destruction of public space but, contrary to their official hopes, there is no withering away of the state in Children of Men, only a stripping back of the state to its core military and police functions (I say ‘official’ hopes since neoliberalism surreptitiously relied on the state even while it has ideologically excoriated it. This was made spectacularly clear during the banking crisis of 2008, when, at the invitation of neoliberal ideologues, the state rushed in to shore up the banking system.)

The catastrophe in Children of Men is neither waiting down the road, nor has it already happened. Rather, it is being lived through. There is no punctual moment of disaster; the world doesn’t end with a bang, it winks out, unravels, gradually falls apart. What caused the catastrophe to occur, who knows; its cause lies long in the past, so absolutely detached from the present as to seem like the caprice of a malign being: a negative miracle, a malediction which no penitence can ameliorate. Such a blight can only be eased by an intervention that can no more be anticipated than was the onset of the curse in the first place. Action is pointless; only senseless hope makes sense. Superstition and religion, the first resorts of the helpless, proliferate.

But what of the catastrophe itself? It is evident that the theme of sterility must be read metaphorically, as the displacement of another kind of anxiety. I want to argue this anxiety cries out to be read in cultural terms, and the question the film poses is: how long can a culture persist without the new? What happens if the young are no longer capable of producing surprises?

Children of Men connects with the suspicion that the end has already come, the thought that it could well be the case that the future harbors only reiteration and re-permutation. Could it be that there are no breaks, no ‘shocks of the new’ to come? Such anxieties tend to result in a bi-polar oscillation: the ‘weak messianic’ hope that there must be something new on the way lapses into the morose conviction that nothing new can ever happen. The focus shifts from the Next Big Thing to the last big thing – how long ago did it happen and just how big was it?

T.S. Eliot looms in the background of Children of Men, which, after all, inherits the theme of sterility from The Waste Land. The film’s closing epigraph ‘shantih shantih shantih’ has more to do with Eliot’s fragmentary pieces than the Upanishads’ peace. Perhaps it is possible to see the concerns of another Eliot – the Eliot of ‘Tradition and the Individual Talent’ – ciphered in Children of Men. It was in this essay that Eliot, in anticipation of Harold Bloom, described the reciprocal relationship between the canonical and the new. The new defines itself in response to what is already established; at the same time, the established has to reconfigure itself in response to the new. Eliot’s claim was that the exhaustion of the future does not even leave us with the past. Tradition counts for nothing when it is no longer contested and modified. A culture that is merely preserved is no culture at all. The fate of Picasso’s Guernica in the film – once a howl of anguish and outrage against Fascist atrocities, now a wall-hanging – is exemplary. Like its Battersea hanging space in the film, the painting is accorded ‘iconic’ status only when it is deprived of any possible function or context. No cultural object can retain its power when there are no longer new eyes to see it.

We do not need to wait for Children of Men’s near-future to arrive to see this transformation of culture into museum pieces. The power of capitalist realism derives in part from the way that capitalism subsumes and consumes all of previous history: one effect of its ‘system of equivalence’ which can assign all cultural objects, whether they are religious iconography, pornography, or Das Kapital, a monetary value. Walk around the British Museum, where you see objects torn from their lifeworlds and assembled as if on the deck of some Predator spacecraft, and you have a powerful image of this process at work. In the conversion of practices and rituals into merely aesthetic objects, the beliefs of previous cultures are objectively ironized, transformed into artifacts. Capitalist realism is therefore not a particular type of realism; it is more like realism in itself. As Marx and Engels themselves observed in The Communist Manifesto,

[Capital] has drowned the most heavenly ecstasies of religious fervor, of chivalrous enthusiasm, of philistine sentimentalism, in the icy water of egotistical calculation. It has resolved personal worth into exchange value, and in place of the numberless indefeasible chartered freedoms, has set up that single, unconscionable freedom — Free Trade. In one word, for exploitation, veiled by religious and political illusions, it has substituted naked, shameless, direct, brutal exploitation.

Capitalism is what is left when beliefs have collapsed at the level of ritual or symbolic elaboration, and all that is left is the consumer-spectator, trudging through the ruins and the relics.

Yet this turn from belief to aesthetics, from engagement to spectatorship, is held to be one of the virtues of capitalist realism. In claiming, as Badiou puts it, to have ‘delivered us from the “fatal abstractions” inspired by the “ideologies of the past”’, capitalist realism presents itself as a shield protecting us from the perils posed by belief itself. The attitude of ironic distance proper to postmodern capitalism is supposed to immunize us against the seductions of fanaticism. Lowering our expectations, we are told, is a small price to pay for being protected from terror and totalitarianism. ‘We live in a contradiction,’ Badiou has observed:

a brutal state of affairs, profoundly inegalitarian – where all existence is evaluated in terms of money alone – is presented to us as ideal. To justify their conservatism, the partisans of the established order cannot really call it ideal or wonderful. So instead, they have decided to say that all the rest is horrible. Sure, they say, we may not live in a condition of perfect Goodness. But we’re lucky that we don’t live in a condition of Evil. Our democracy is not perfect. But it’s better than the bloody dictatorships. Capitalism is unjust. But it’s not criminal like Stalinism. We let millions of Africans die of AIDS, but we don’t make racist nationalist declarations like Milosevic. We kill Iraqis with our airplanes, but we don’t cut their throats with machetes like they do in Rwanda, etc.

The ‘realism’ here is analogous to the deflationary perspective of a depressive who believes that any positive state, any hope, is a dangerous illusion.

In their account of capitalism, surely the most impressive since Marx’s, Deleuze and Guattari describe capitalism as a kind of dark potentiality which haunted all previous social systems. Capital, they argue, is the ‘unnamable Thing’, the abomination, which primitive and feudal societies ‘warded off in advance’. When it actually arrives, capitalism brings with it a massive desacralization of culture. It is a system which is no longer governed by any transcendent Law; on the contrary, it dismantles all such codes, only to re-install them on an ad hoc basis. The limits of capitalism are not fixed by fiat, but defined (and redefined) pragmatically and improvisationally. This makes capitalism very much like the Thing in John Carpenter’s film of the same name: a monstrous, infinitely plastic entity, capable of metabolizing and absorbing anything with which it comes into contact. Capital, Deleuze and Guattari says, is a ‘motley painting of everything that ever was’; a strange hybrid of the ultra-modern and the archaic. In the years since Deleuze and Guattari wrote the two volumes of their Capitalism And Schizophrenia, it has seemed as if the deterritorializing impulses of capitalism have been confined to finance, leaving culture presided over by the forces of reterritorialization.

This malaise, the feeling that there is nothing new, is itself nothing new of course. We find ourselves at the notorious ‘end of history’ trumpeted by Francis Fukuyama after the fall of the Berlin Wall. Fukuyama’s thesis that history has climaxed with liberal capitalism may have been widely derided, but it is accepted, even assumed, at the level of the cultural unconscious. It should be remembered, though, that even when Fukuyama advanced it, the idea that history had reached a ‘terminal beach’ was not merely triumphalist. Fukuyama warned that his radiant city would be haunted, but he thought its specters would be Nietzschean rather than Marxian. Some of Nietzsche’s most prescient pages are those in which he describes the ‘oversaturation of an age with history’. ‘It leads an age into a dangerous mood of irony in regard to itself, he wrote in Untimely Meditations, ‘and subsequently into the even more dangerous mood of cynicism’, in which ‘cosmopolitan fingering’, a detached spectatorialism, replaces engagement and involvement. This is the condition of Nietzsche’s Last Man, who has seen everything, but is decadently enfeebled precisely by this excess of (self) awareness.

Fukuyama’s position is in some ways a mirror image of Fredric Jameson’s. Jameson famously claimed that postmodernism is the ‘cultural logic of late capitalism’. He argued that the failure of the future was constitutive of a postmodern cultural scene which, as he correctly prophesied, would become dominated by pastiche and revivalism. Given that Jameson has made a convincing case for the relationship between postmodern culture and certain tendencies in consumer (or post-Fordist) capitalism, it could appear that there is no need for the concept of capitalist realism at all. In some ways, this is true. What I’m calling capitalist realism can be subsumed under the rubric of postmodernism as theorized by Jameson. Yet, despite Jameson’s heroic work of clarification, postmodernism remains a hugely contested term, its meanings, appropriately but unhelpfully, unsettled and multiple. More importantly, I would want to argue that some of the processes which Jameson described and analyzed have now become so aggravated and chronic that they have gone through a change in kind.

Ultimately, there are three reasons that I prefer the term capitalist realism to postmodernism. In the 1980s, when Jameson first advanced his thesis about postmodernism, there were still, in name at least, political alternatives to capitalism. What we are dealing with now, however, is a deeper, far more pervasive, sense of exhaustion, of cultural and political sterility. In the 80s, ‘Really Existing Socialism’ still persisted, albeit in its final phase of collapse. In Britain, the fault lines of class antagonism were fully exposed in an event like the Miners’ Strike of 1984-1985, and the defeat of the miners was an important moment in the development of capitalist realism, at least as significant in its symbolic dimension as in its practical effects. The closure of pits was defended precisely on the grounds that keeping them open was not ‘economically realistic’, and the miners were cast in the role of the last actors in a doomed proletarian romance. The 80s were the period when capitalist realism was fought for and established, when Margaret Thatcher’s doctrine that ‘there is no alternative’ – as succinct a slogan of capitalist realism as you could hope for – became a brutally self-fulfilling prophecy.

Secondly, postmodernism involved some relationship to modernism. Jameson’s work on postmodernism began with an interrogation of the idea, cherished by the likes of Adorno, that modernism possessed revolutionary potentials by virtue of its formal innovations alone. What Jameson saw happening instead was the incorporation of modernist motifs into popular culture (suddenly, for example, Surrealist techniques would appear in advertising). At the same time as particular modernist forms were absorbed and commodified, modernism’s credos – its supposed belief in elitism and its monological, top-down model of culture – were challenged and rejected in the name of ‘difference’, ‘diversity’ and ‘multiplicity’. Capitalist realism no longer stages this kind of confrontation with modernism. On the contrary, it takes the vanquishing of modernism for granted: modernism is now something that can periodically return, but only as a frozen aesthetic style, never as an ideal for living.

Thirdly, a whole generation has passed since the collapse of the Berlin Wall. In the 1960s and 1970s, capitalism had to face the problem of how to contain and absorb energies from outside. It now, in fact, has the opposite problem; having all-too successfully incorporated externality, how can it function without an outside it can colonize and appropriate? For most people under twenty in Europe and North America, the lack of alternatives to capitalism is no longer even an issue. Capitalism seamlessly occupies the horizons of the thinkable. Jameson used to report in horror about the ways that capitalism had seeped into the very unconscious; now, the fact that capitalism has colonized the dreaming life of the population is so taken for granted that it is no longer worthy of comment. It would be dangerous and misleading to imagine that the near past was some prelapsarian state rife with political potentials, so it’s as well to remember the role that commodification played in the production of culture throughout the twentieth century. Yet the old struggle between detournement and recuperation, between subversion and incorporation, seems to have been played out. What we are dealing with now is not the incorporation of materials that previously seemed to possess subversive potentials, but instead, their precorporation: the pre-emptive formatting and shaping of desires, aspirations and hopes by capitalist culture. Witness, for instance, the establishment of settled ‘alternative’ or ‘independent’ cultural zones, which endlessly repeat older gestures of rebellion and contestation as if for the first time. ‘Alternative’ and ‘independent’ don’t designate something outside mainstream culture; rather, they are styles, in fact the dominant styles, within the mainstream. No-one embodied (and struggled with) this deadlock more than Kurt Cobain and Nirvana. In his dreadful lassitude and objectless rage, Cobain seemed to give wearied voice to the despondency of the generation that had come after history, whose every move was anticipated, tracked, bought and sold before it had even happened. Cobain knew that he was just another piece of spectacle, that nothing runs better on MTV than a protest against MTV; knew that his every move was a cliché scripted in advance, knew that even realizing it is a cliché. The impasse that paralyzed Cobain is precisely the one that Jameson described: like postmodern culture in general, Cobain found himself in ‘a world in which stylistic innovation is no longer possible, [where] all that is left is to imitate dead styles, to speak through the masks and with the voices of the styles in the imaginary museum’. Here, even success meant failure, since to succeed would only mean that you were the new meat on which the system could feed. But the high existential angst of Nirvana and Cobain belongs to an older moment; what succeeded them was a pastiche-rock which reproduced the forms of the past without anxiety.

Cobain’s death confirmed the defeat and incorporation of rock’s utopian and promethean ambitions. When he died, rock was already being eclipsed by hip hop, whose global success has presupposed just the kind of precorporation by capital which I alluded to above. For much hip hop, any ‘naïve’ hope that youth culture could change anything has been replaced by the hard-headed embracing of a brutally reductive version of ‘reality’. ‘In hip hop’, Simon Reynolds pointed out in a 1996 essay in The Wire magazine,

‘real’ has two meanings. First, it means authentic, uncompro-mised music that refuses to sell out to the music industry and soften its message for crossover. ‘Real’ also signifies that the music reflects a ‘reality’ constituted by late capitalist economic instability, institutionalized racism, and increased surveillance and harassment of youth by the police. ‘Real’ means the death of the social: it means corporations who respond to increased profits not by raising pay or improving benefits but by …. downsizing (the laying-off the permanent workforce in order to create a floating employment pool of part-time and freelance workers without benefits or job security).

In the end, it was precisely hip hop’s performance of this first version of the real – ‘the uncompromising’ – that enabled its easy absorption into the second, the reality of late capitalist economic instability, where such authenticity has proven highly marketable. Gangster rap neither merely reflects pre-existing social conditions, as many of its advocates claim, nor does it simply cause those conditions, as its critics argue – rather the circuit whereby hip hop and the late capitalist social field feed into each other is one of the means by which capitalist realism transforms itself into a kind of anti-mythical myth. The affinity between hip hop and gangster movies such as Scarface, The Godfather films, Reservoir Dogs, Goodfellas and Pulp Fiction arises from their common claim to have stripped the world of sentimental illusions and seen it for ‘what it really is’: a Hobbesian war of all against all, a system of perpetual exploitation and generalized criminality. In hip hop, Reynolds writes, ‘To “get real” is to confront a state-of-nature where dog eats dog, where you’re either a winner or a loser, and where most will be losers’.

The same neo-noir worldview can be found in the comic books of Frank Miller and in the novels of James Ellroy. There is a kind of machismo of demythologization in Miller and Ellroy’s works. They pose as unflinching observers who refuse to prettify the world so that it can be fitted into the supposedly simple ethical binaries of the superhero comic and the traditional crime novel. The ‘realism’ here is somehow underscored, rather than undercut, by their fixation on the luridly venal – even though the hyperbolic insistence on cruelty, betrayal and savagery in both writers quickly becomes pantomimic. ‘In his pitch blackness’, Mike Davis wrote of Ellroy in 1992, ‘there is no light left to cast shadows and evil becomes a forensic banality. The result feels very much like the actual moral texture of the Reagan-Bush era: a supersaturation of corruption that fails any longer to outrage or even interest’. Yet this very desensitization serves a function for capitalist realism: Davis hypothesized that ‘the role of L.A. noir’ may have been ‘to endorse the emergence of homo reaganus’.

In the cases of gangster rap and Ellroy, capitalist realism takes the form of a kind of super-identification with capital at its most pitilessly predatory, but this need not be the case. In fact, capitalist realism is very far from precluding a certain anti-capitalism. After all, and as Žižek has provocatively pointed out, anti-capitalism is widely disseminated in capitalism. Time after time, the villain in Hollywood films will turn out to be the ‘evil corporation’. Far from undermining capitalist realism, this gestural anti-capitalism actually reinforces it. Take Disney/ Pixar’s Wall-E (2008). The film shows an earth so despoiled that human beings are no longer capable of inhabiting it. We’re left in no doubt that consumer capitalism and corporations – or rather one mega-corporation, Buy n Large – is responsible for this depredation; and when we see eventually see the human beings in offworld exile, they are infantile and obese, interacting via screen interfaces, carried around in large motorized chairs, and supping indeterminate slop from cups. What we have here is a vision of control and communication much as Jean Baudrillard understood it, in which subjugation no longer takes the form of a subordination to an extrinsic spectacle, but rather invites us to interact and participate. It seems that the cinema audience is itself the object of this satire, which prompted some right wing observers to recoil in disgust, condemning Disney/Pixar for attacking its own audience. But this kind of irony feeds rather than challenges capitalist realism. A film like Wall-E exemplifies what Robert Pfaller has called ‘interpassivity’: the film performs our anti-capitalism for us, allowing us to continue to consume with impunity. The role of capitalist ideology is not to make an explicit case for something in the way that propaganda does, but to conceal the fact that the operations of capital do not depend on any sort of subjectively assumed belief. It is impossible to conceive of fascism or Stalinism without propaganda – but capitalism can proceed perfectly well, in some ways better, without anyone making a case for it. Žižek’s counsel here remains invaluable. ‘If the concept of ideology is the classic one in which the illusion is located in knowledge’, he argues,

then today’s society must appear post-ideological: the prevailing ideology is that of cynicism; people no longer believe in ideological truth; they do not take ideological propositions seriously. The fundamental level of ideology, however, is not of an illusion masking the real state of things but that of an (unconscious) fantasy structuring our social reality itself. And at this level, we are of course far from being a post-ideological society. Cynical distance is just one way … to blind ourselves to the structural power of ideological fantasy: even if we do not take things seriously, even if we keep an ironical distance, we are still doing them.

Capitalist ideology in general, Žižek maintains, consists precisely in the overvaluing of belief – in the sense of inner subjective attitude – at the expense of the beliefs we exhibit and externalize in our behavior. So long as we believe (in our hearts) that capitalism is bad, we are free to continue to participate in capitalist exchange. According to Žižek, capitalism in general relies on this structure of disavowal. We believe that money is only a meaningless token of no intrinsic worth, yet we act as if it has a holy value. Moreover, this behavior precisely depends upon the prior disavowal – we are able to fetishize money in our actions only because we have already taken an ironic distance towards money in our heads.

Corporate anti-capitalism wouldn’t matter if it could be differentiated from an authentic anti-capitalist movement. Yet, even before its momentum was stalled by the September 11th attacks on the World Trade Center, the so called anti-capitalist movement seemed also to have conceded too much to capitalist realism. Since it was unable to posit a coherent alternative political-economic model to capitalism, the suspicion was that the actual aim was not to replace capitalism but to mitigate its worst excesses; and, since the form of its activities tended to be the staging of protests rather than political organization, there was a sense that the anti-capitalism movement consisted of making a series of hysterical demands which it didn’t expect to be met. Protests have formed a kind of carnivalesque background noise to capitalist realism, and the anti-capitalist protests share rather too much with hyper-corporate events like 2005’s Live 8, with their exorbitant demands that politicians legislate away poverty.

Live 8 was a strange kind of protest; a protest that everyone could agree with: who is it who actually wants poverty? And it is not that Live 8 was a ‘degraded’ form of protest. On the contrary, it was in Live 8 that the logic of the protest was revealed in its purest form. The protest impulse of the 60s posited a malevolent Father, the harbinger of a reality principle that (supposedly) cruelly and arbitrarily denies the ‘right’ to total enjoyment. This Father has unlimited access to resources, but he selfishly – and senselessly – hoards them. Yet it is not capitalism but protest itself which depends upon this figuration of the Father; and one of the successes of the current global elite has been their avoidance of identification with the figure of the hoarding Father, even though the ‘reality’ they impose on the young is substantially harsher than the conditions they protested against in the 60s. Indeed, it was of course the global elite itself – in the form of entertainers such as Richard Curtis and Bono – which organized the Live 8 event. To reclaim a real political agency means first of all accepting our insertion at the level of desire in the remorseless meat-grinder of Capital. What is being disavowed in the abjection of evil and ignorance onto fantasmatic Others is our own complicity in planetary networks of oppression. What needs to be kept in mind is both that capitalism is a hyper-abstract impersonal structure and that it would be nothing without our co-operation. The most Gothic description of Capital is also the most accurate. Capital is an abstract parasite, an insatiable vampire and zombie-maker; but the living flesh it converts into dead labor is ours, and the zombies it makes are us. There is a sense in which it simply is the case that the political elite are our servants; the miserable service they provide from us is to launder our libidos, to obligingly re-present for us our disavowed desires as if they had nothing to do with us.

The ideological blackmail that has been in place since the original Live Aid concerts in 1985 has insisted that ‘caring individuals’ could end famine directly, without the need for any kind of political solution or systemic reorganization. It is necessary to act straight away, we were told; politics has to be suspended in the name of ethical immediacy. Bono’s Product Red brand wanted to dispense even with the philanthropic intermediary. ‘Philanthropy is like hippy music, holding hands’, Bono proclaimed. ‘Red is more like punk rock, hip hop, this should feel like hard commerce’. The point was not to offer an alternative to capitalism – on the contrary, Product Red’s ‘punk rock’ or ‘hip hop’ character consisted in its ‘realistic’ acceptance that capitalism is the only game in town. No, the aim was only to ensure that some of the proceeds of particular transactions went to good causes. The fantasy being that western consumerism, far from being intrinsically implicated in systemic global inequalities, could itself solve them. All we have to do is buy the right products.

‘Capitalist realism’ is not an original coinage. It was used as far back as the 1960s by a group of German Pop artists and by Michael Schudson in his 1984 book Advertising, The Uneasy Persuasion, both of whom were making parodic references to socialist realism. What is new about my use of the term is the more expansive – even exorbitant – meaning that I ascribe to it. Capitalist realism as I understand it cannot be confined to art or to the quasi-propagandistic way in which advertising functions. It is more like a pervasive atmosphere, conditioning not only the production of culture but also the regulation of work and education, and acting as a kind of invisible barrier constraining thought and action.

If capitalist realism is so seamless, and if current forms of resistance are so hopeless and impotent, where can an effective challenge come from? A moral critique of capitalism, emphasizing the ways in which it leads to suffering, only reinforces capitalist realism. Poverty, famine and war can be presented as an inevitable part of reality, while the hope that these forms of suffering could be eliminated easily painted as naive utopianism. Capitalist realism can only be threatened if it is shown to be in some way inconsistent or untenable; if, that is to say, capitalism’s ostensible ‘realism’ turns out to be nothing of the sort.

Needless to say, what counts as ‘realistic’, what seems possible at any point in the social field, is defined by a series of political determinations. An ideological position can never be really successful until it is naturalized, and it cannot be naturalized while it is still thought of as a value rather than a fact. Accordingly, neoliberalism has sought to eliminate the very category of value in the ethical sense. Over the past thirty years, capitalist realism has successfully installed a ‘business ontology’ in which it is simply obvious that everything in society, including healthcare and education, should be run as a business. As any number of radical theorists from Brecht through to Foucault and Badiou have maintained, emancipatory politics must always destroy the appearance of a ‘natural order’, must reveal what is presented as necessary and inevitable to be a mere contingency, just as it must make what was previously deemed to be impossible seem attainable. It is worth recalling that what is currently called realistic was itself once ‘impossible’: the slew of privatizations that took place since the 1980s would have been unthinkable only a decade earlier, and the current political-economic landscape (with unions in abeyance, utilities and railways denationalized) could scarcely have been imagined in 1975. Conversely, what was once eminently possible is now deemed unrealistic. ‘Modernization’, Badiou bitterly observes, ‘is the name for a strict and servile definition of the possible. These ‘reforms’ invariably aim at making impossible what used to be practicable (for the largest number), and making profitable (for the dominant oligarchy) what did not used to be so’.

At this point, it is perhaps worth introducing an elementary theoretical distinction from Lacanian psychoanalysis which Žižek has done so much to give contemporary currency: the difference between the Real and reality. As Alenka Zupancic explains, psychoanalysis’s positing of a reality principle invites us to be suspicious of any reality that presents itself as natural. ‘The reality principle’, Zupancic writes,

is not some kind of natural way associated with how things are ... The reality principle itself is ideologically mediated; one could even claim that it constitutes the highest form of ideology, the ideology that presents itself as empirical fact (or biological, economic...) necessity (and that we tend to perceive as non-ideological). It is precisely here that we should be most alert to the functioning of ideology.

For Lacan, the Real is what any ‘reality’ must suppress; indeed, reality constitutes itself through just this repression. The Real is an unrepresentable X, a traumatic void that can only be glimpsed in the fractures and inconsistencies in the field of apparent reality. So one strategy against capitalist realism could involve invoking the Real(s) underlying the reality that capitalism presents to us.

Environmental catastrophe is one such Real. At one level, to be sure, it might look as if Green issues are very far from being ‘unrepresentable voids’ for capitalist culture. Climate change and the threat of resource-depletion are not being repressed so much as incorporated into advertising and marketing. What this treatment of environmental catastrophe illustrates is the fantasy structure on which capitalist realism depends: a presupposition that resources are infinite, that the earth itself is merely a husk which capital can at a certain point slough off like a used skin, and that any problem can be solved by the market (In the end, Wall-E presents a version of this fantasy – the idea that the infinite expansion of capital is possible, that capital can proliferate without labor – on the off world ship, Axiom, all labor is performed by robots; that the burning up of Earth’s resources is only a temporary glitch, and that, after a suitable period of recovery, capital can terraform the planet and recolonize it). Yet environmental catastrophe features in late capitalist culture only as a kind of simulacra, its real implications for capitalism too traumatic to be assimilated into the system. The significance of Green critiques is that they suggest that, far from being the only viable political-economic system, capitalism is in fact primed to destroy the entire human environment. The relationship between capitalism and eco-disaster is neither coincidental nor accidental: capital’s ‘need of a constantly expanding market’, its ‘growth fetish’, mean that capitalism is by its very nature opposed to any notion of sustainability.

But Green issues are already a contested zone, already a site where politicization is being fought for. In what follows, I want to stress two other aporias in capitalist realism, which are not yet politicized to anything like the same degree. The first is mental health. Mental health, in fact, is a paradigm case of how capitalist realism operates. Capitalist realism insists on treating mental health as if it were a natural fact, like weather (but, then again, weather is no longer a natural fact so much as a political-economic effect). In the 1960s and 1970s, radical theory and politics (Laing, Foucault, Deleuze and Guattari, etc.) coalesced around extreme mental conditions such as schizophrenia, arguing, for instance, that madness was not a natural, but a political, category. But what is needed now is a politicization of much more common disorders. Indeed, it is their very commonness which is the issue: in Britain, depression is now the condition that is most treated by the NHS. In his book The Selfish Capitalist, Oliver James has convincingly posited a correlation between rising rates of mental distress and the neoliberal mode of capitalism practiced in countries like Britain, the USA and Australia. In line with James’s claims, I want to argue that it is necessary to reframe the growing problem of stress (and distress) in capitalist societies. Instead of treating it as incumbent on individuals to resolve their own psychological distress, instead, that is, of accepting the vast privatization of stress that has taken place over the last thirty years, we need to ask: how has it become acceptable that so many people, and especially so many young people, are ill? The ‘mental health plague’ in capitalist societies would suggest that, instead of being the only social system that works, capitalism is inherently dysfunctional, and that the cost of it appearing to work is very high.

The other phenomenon I want to highlight is bureaucracy. In making their case against socialism, neoliberal ideologues often excoriated the top-down bureaucracy which supposedly led to institutional sclerosis and inefficiency in command economies. With the triumph of neoliberalism, bureaucracy was supposed to have been made obsolete; a relic of an unlamented Stalinist past. Yet this is at odds with the experiences of most people working and living in late capitalism, for whom bureaucracy remains very much a part of everyday life. Instead of disappearing, bureaucracy has changed its form; and this new, decentralized, form has allowed it to proliferate. The persistence of bureaucracy in late capitalism does not in itself indicate that capitalism does not work – rather, what it suggests is that the way in which capitalism does actually work is very different from the picture presented by capitalist realism.

In part, I have chosen to focus on mental health problems and bureaucracy because they both feature heavily in an area of culture which has becoming increasingly dominated by the imperatives of capitalist realism: education. Through most of the current decade, I worked as a lecturer in a Further Education college, and in what follows, I will draw extensively on my experiences there. In Britain, Further Education colleges used to be places which students, often from working class backgrounds, were drawn to if they wanted an alternative to more formal state educational institutions. Ever since Further Education colleges were removed from local authority control in the early 1990s, they have become subject both to ‘market’ pressures and to government-imposed targets. They have been at the vanguard of changes that would be rolled out through the rest of the education system and public services – a kind of lab in which neoliberal ‘reforms’ of education have been trialed, and as such, they are the perfect place to begin an analysis of the effects of capitalist realism.

By contrast with their forebears in the 1960s and 1970s, British students today appear to be politically disengaged. While French students can still be found on the streets protesting against neoliberalism, British students, whose situation is incomparably worse, seem resigned to their fate. But this, I want to argue, is a matter not of apathy, nor of cynicism, but of reflexive impotence. They know things are bad, but more than that, they know they can’t do anything about it. But that ‘knowledge’, that reflexivity, is not a passive observation of an already existing state of affairs. It is a self-fulfilling prophecy.

Reflexive impotence amounts to an unstated worldview amongst the British young, and it has its correlate in widespread pathologies. Many of the teenagers I worked with had mental health problems or learning difficulties. Depression is endemic. It is the condition most dealt with by the National Health Service, and is afflicting people at increasingly younger ages. The number of students who have some variant of dyslexia is astonishing. It is not an exaggeration to say that being a teenager in late capitalist Britain is now close to being reclassified as a sickness. This pathologization already forecloses any possibility of politicization. By privatizing these problems – treating them as if they were caused only by chemical imbalances in the individual’s neurology and/or by their family background – any question of social systemic causation is ruled out.

Many of the teenage students I encountered seemed to be in a state of what I would call depressive hedonia. Depression is usually characterized as a state of anhedonia, but the condition I’m referring to is constituted not by an inability to get pleasure so much as it by an inability to do anything else except pursue pleasure. There is a sense that ‘something is missing’ – but no appreciation that this mysterious, missing enjoyment can only be accessed beyond the pleasure principle. In large part this is a consequence of students’ ambiguous structural position, stranded between their old role as subjects of disciplinary institutions and their new status as consumers of services. In his crucial essay ‘Postscript on Societies of Control’, Deleuze distinguishes between the disciplinary societies described by Foucault, which were organized around the enclosed spaces of the factory, the school and the prison, and the new control societies, in which all institutions are embedded in a dispersed corporation.

Deleuze is right to argue that Kafka is the prophet of distributed, cybernetic power that is typical of Control societies. In The Trial, Kafka importantly distinguishes between two types of acquittal available to the accused. Definite acquittal is no longer possible, if it ever was (‘we have only legendary accounts of ancient cases [which] provide instances of acquittal’). The two remaining options, then, are (1) ‘Ostensible acquittal’, in which the accused is to all and intents and purposes acquitted, but may later, at some unspecified time, face the charges in full, or (2) ‘Indefinite postponement’, in which the accused engages in (what they hope is an infinitely) protracted process of legal wrangling, so that the dreaded ultimate judgment is unlikely to be forthcoming. Deleuze observes that the Control societies delineated by Kafka himself, but also by Foucault and Burroughs, operate using indefinite postponement: Education as a lifelong process... Training that persists for as long as your working life continues... Work you take home with you… Working from home, homing from work. A consequence of this ‘indefinite’ mode of power is that external surveillance is succeeded by internal policing. Control only works if you are complicit with it. Hence the Burroughs figure of the ‘Control Addict’: the one who is addicted to control, but also, inevitably, the one who has been taken over, possessed by Control.

Walk into almost any class at the college where I taught and you will immediately appreciate that you are in a post-disciplinary framework. Foucault painstakingly enumerated the way in which discipline was installed through the imposition of rigid body postures. During lessons at our college, however, students will be found slumped on desk, talking almost constantly, snacking incessantly (or even, on occasions, eating full meals). The old disciplinary segmentation of time is breaking down. The carceral regime of discipline is being eroded by the technologies of control, with their systems of perpetual consumption and continuous development.

The system by which the college is funded means that it literally cannot afford to exclude students, even if it wanted to. Resources are allocated to colleges on the basis of how successfully they meet targets on achievement (exam results), attendance and retention of students. This combination of market imperatives with bureaucratically-defined ‘targets’ is typical of the ‘market Stalinist’ initiatives which now regulate public services. The lack of an effective disciplinary system has not, to say the least, been compensated for by an increase in student self-motivation. Students are aware that if they don’t attend for weeks on end, and/or if they don’t produce any work, they will not face any meaningful sanction. They typically respond to this freedom not by pursuing projects but by falling into hedonic (or anhedonic) lassitude: the soft narcosis, the comfort food oblivion of Playstation, all-night TV and marijuana.

Ask students to read for more than a couple of sentences and many – and these are A-level students mind you – will protest that they can’t do it. The most frequent complaint teachers hear is that it’s boring. It is not so much the content of the written material that is at issue here; it is the act of reading itself that is deemed to be ‘boring’. What we are facing here is not just time–honored teenage torpor, but the mismatch between a post-literate ‘New Flesh’ that is ‘too wired to concentrate’ and the confining, concentrational logics of decaying disciplinary systems. To be bored simply means to be removed from the communicative sensation-stimulus matrix of texting, YouTube and fast food; to be denied, for a moment, the constant flow of sugary gratification on demand. Some students want Nietzsche in the same way that they want a hamburger; they fail to grasp – and the logic of the consumer system encourages this misapprehension – that the indigestibility, the difficulty is Nietzsche.

An illustration: I challenged one student about why he always wore headphones in class. He replied that it didn’t matter, because he wasn’t actually playing any music. In another lesson, he was playing music at very low volume through the headphones, without wearing them. When I asked him to switch it off, he replied that even he couldn’t hear it. Why wear the headphones without playing music or play music without wearing the headphones? Because the presence of the phones on the ears or the knowledge that the music is playing (even if he couldn’t hear it) was a reassurance that the matrix was still there, within reach. Besides, in a classic example of interpassivity, if the music was still playing, even if he couldn’t hear it, then the player could still enjoy it on his behalf. The use of headphones is significant here – pop is experienced not as something which could have impacts upon public space, but as a retreat into private ‘OedIpod’ consumer bliss, a walling up against the social.

The consequence of being hooked into the entertainment matrix is twitchy, agitated interpassivity, an inability to concentrate or focus. Students’ incapacity to connect current lack of focus with future failure, their inability to synthesize time into any coherent narrative, is symptomatic of more than mere demotivation. It is, in fact, eerily reminiscent of Jameson’s analysis in ‘Postmodernism and Consumer Society’. Jameson observed there that Lacan’s theory of schizophrenia offered a ‘suggestive aesthetic model’ for understanding the fragmenting of subjectivity in the face of the emerging entertainment-industrial complex. ‘With the breakdown of the signifying chain’, Jameson summarized, ‘the Lacanian schizophrenic is reduced to an experience of pure material signifiers, or, in other words, a series of pure and unrelated presents in time’. Jameson was writing in the late 1980s – i.e. the period in which most of my students were born. What we in the classroom are now facing is a generation born into that ahistorical, anti-mnemonic blip culture – a generation, that is to say, for whom time has always come ready-cut into digital micro-slices.

If the figure of discipline was the worker-prisoner, the figure of control is the debtor-addict. Cyberspatial capital operates by addicting its users; William Gibson recognized that in Neuromancer when he had Case and the other cyberspace cowboys feeling insects-under-the-skin strung out when they unplugged from the matrix (Case’s amphetamine habit is plainly the substitute for an addiction to a far more abstract speed). If, then, something like attention deficit hyperactivity disorder is a pathology, it is a pathology of late capitalism – a consequence of being wired into the entertainment-control circuits of hyperme-diated consumer culture. Similarly, what is called dyslexia may in many cases amount to a post-lexia. Teenagers process capital’s image-dense data very effectively without any need to read –slogan-recognition is sufficient to navigate the net-mobile-magazine informational plane. ‘Writing has never been capitalism’s thing. Capitalism is profoundly illiterate’, Deleuze and Guattari argued in Anti-Oedipus. ‘Electric language does not go by way of the voice or writing: data processing does without them both’. Hence the reason that many successful business people are dyslexic (but is their post-lexical efficiency a cause or effect of their success?)

Teachers are now put under intolerable pressure to mediate between the post-literate subjectivity of the late capitalist consumer and the demands of the disciplinary regime (to pass examinations etc). This is one way in which education, far from being in some ivory tower safely inured from the ‘real world’, is the engine room of the reproduction of social reality, directly confronting the inconsistencies of the capitalist social field. Teachers are caught between being facilitator-entertainers and disciplinarian-authoritarians. Teachers want to help students to pass the exams; they want us to be authority figures who tell them what to do. Teachers being interpellated by students as authority figures exacerbates the ‘boredom’ problem, since isn’t anything that comes from the place of authority a priori boring? Ironically, the role of disciplinarian is demanded of educators more than ever at precisely the time when disciplinary structures are breaking down in institutions. With families buckling under the pressure of a capitalism which requires both parents to work, teachers are now increasingly required to act as surrogate parents, instilling the most basic behavioral protocols in students and providing pastoral and emotional support for teenagers who are in some cases only minimally socialized.

It is worth stressing that none of the students I taught had any legal obligation to be at college. They could leave if they wanted to. But the lack of any meaningful employment opportunities, together with cynical encouragement from government means that college seems to be the easier, safer option. Deleuze says that Control societies are based on debt rather than enclosure; but there is a way in which the current education system both indebts and encloses students. Pay for your own exploitation, the logic insists – get into debt so you can get the same McJob you could have walked into if you’d left school at sixteen…

Jameson observed that ‘the breakdown of temporality suddenly releases [the] present of time from all the activities and intentionalities that might focus it and make it a space of praxis’. But nostalgia for the context in which the old types of praxis operated is plainly useless. That is why French students don’t in the end constitute an alternative to British reflexive impotence. That the neoliberal Economist would deride French opposition to capitalism is hardly surprising, yet its mockery of French ‘immobilization’ had a point. ‘Certainly the students who kicked off the latest protests seemed to think they were re-enacting the events of May 1968 their parents sprang on Charles de Gaulle’, it wrote in its lead article of March 30, 2006.

They have borrowed its slogans (‘Beneath the cobblestones, the beach!’) and hijacked its symbols (the Sorbonne university). In this sense, the revolt appears to be the natural sequel to [2005]’s suburban riots, which prompted the government to impose a state of emergency. Then it was the jobless, ethnic underclass that rebelled against a system that excluded them. Yet the striking feature of the latest protest movement is that this time the rebellious forces are on the side of conservatism. Unlike the rioting youths in the banlieues, the objective of the students and public-sector trade unions is to prevent change, and to keep France the way it is.

It’s striking how the practice of many of the immobilizers is a kind of inversion of that of another group who also count themselves heirs of 68: the so called ‘liberal communists’ such as George Soros and Bill Gates who combine rapacious pursuit of profit with the rhetoric of ecological concern and social responsibility. Alongside their social concern, liberal communists believe that work practices should be (post) modernized, in line with the concept of ‘being smart’. As Žižek explains,

Being smart means being dynamic and nomadic, and against centralized bureaucracy; believing in dialogue and cooperation as against central authority; in flexibility as against routine; culture and knowledge as against industrial production; in spontaneous interaction and autopoiesis as against fixed hierarchy.

Taken together, the immobilizers, with their implicit concession that capitalism can only be resisted, never overcome, and the liberal communists, who maintain that the amoral excesses of capitalism must be offset by charity, give a sense of the way in which capitalist realism circumscribes current political possibilities. Whereas the immobilizers retain the form of 68-style protest but in the name of resistance to change, liberal communists energetically embrace newness. Žižek is right to argue that, far from constituting any kind of progressive corrective to official capitalist ideology, liberal communism constitutes the dominant ideology of capitalism now. ‘Flexibility’, ‘nomadism’ and ‘spontaneity’ are the very hallmarks of management in a post-Fordist, Control society. But the problem is that any opposition to flexibility and decentralization risks being self-defeating, since calls for inflexibility and centralization are, to say the least, not likely to be very galvanizing.

In any case, resistance to the ‘new’ is not a cause that the left can or should rally around. Capital thought very carefully about how to break labor; yet there has still not yet been enough thought about what tactics will work against capital in conditions of post-Fordism, and what new language can be innovated to deal with those conditions. It is important to contest capitalism’s appropriation of ‘the new’, but to reclaim the ‘new’ can’t be a matter of adapting to the conditions in which we find ourselves –we’ve done that rather too well, and ‘successful adaptation’ is the strategy of managerialism par excellence.

The persistent association of neoliberalism with the term ‘Restoration’, favored by both Badiou and David Harvey, is an important corrective to the association of capital with novelty. For Harvey and Badiou, neoliberal politics are not about the new, but a return of class power and privilege. ‘[I]n France,’ Badiou has said, ‘‘Restoration’ refers to the period of the return of the King, in 1815, after the Revolution and Napoleon. We are in such a period. Today we see liberal capitalism and its political system, parliamentarianism, as the only natural and acceptable solutions’. Harvey argues that neoliberalization is best conceived of as a ‘political project to re-establish the conditions for capital accumulation and to restore the power of economic elites’. Harvey demonstrates that, in an era popularly described as ‘post-political’, class war has continued to be fought, but only by one side: the wealthy. ‘After the implementation of neoliberal policies in the late 1970s,’ Harvey reveals,

the share of national income of the top 1 per cent of income earners soared, to reach 15 per cent ... by the end of the century. The top 0.1 per cent of income earners in the US increased their share of the national income from 2 per cent in 1978 to over 6 per cent by 1999, while the ratio of the median compensation of workers to the salaries of CEOs increased from just over 30 to 1 in 1970 to nearly 500 to 1 by 2000.... The US is not alone in this: the top 1 per cent of income earners in Britain have doubled their share of the national income from 6.5 per cent to 13 per cent since 1982.

As Harvey shows, neoliberals were more Leninist than the Leninists, using think-tanks as the intellectual vanguard to create the ideological climate in which capitalist realism could flourish.

The immobilization model – which amounts to a demand to retain the Fordist/disciplinary regime – could not work in Britain or the other countries in which neoliberalism has already taken a hold. Fordism has definitively collapsed in Britain, and with it the sites around which the old politics were organized. At the end of the control essay, Deleuze wonders what new forms an anti-control politics might take:

One of the most important questions will concern the ineptitude of the unions: tied to the whole of their history of struggle against the disciplines or within the spaces of enclosure, will they be able to adapt themselves or will they give way to new forms of resistance against the societies of control? Can we already grasp the rough outlines of the coming forms, capable of threatening the joys of marketing? Many young people strangely boast of being “motivated”; they re-request apprenticeships and permanent training. It’s up to them to discover what they’re being made to serve, just as their elders discovered, not without difficulty, the telos of the disciplines.

What must be discovered is a way out of the motivation/demotivation binary, so that disidentification from the control program registers as something other than dejected apathy. One strategy would be to shift the political terrain – to move away from the unions’ traditional focus on pay and onto forms of discontent specific to post-Fordism. Before we analyse that further, we must consider in more depth what post-Fordism actually is.

‘A guy told me one time’, says organized crime boss Neil McCauley in Michael Mann’s 1995 film Heat, ’Don’t let yourself get attached to anything you are not willing to walk out on in 30 seconds flat if you feel the heat around the corner’. One of the easiest ways to grasp the differences between Fordism and post-Fordism is to compare Mann’s film with the gangster movies made by Francis Ford Coppola and Martin Scorsese between 1971 and 1990. In Heat, the scores are undertaken not by Families with links to the Old Country, but by rootless crews, in an LA of polished chrome and interchangeable designer kitchens, of featureless freeways and late-night diners. All the local color, the cuisine aromas, the cultural idiolects which the likes of The Godfather and Goodfellas depended upon have been painted over and re-fitted. Heat’s Los Angeles is a world without landmarks, a branded Sprawl, where markable territory has been replaced by endlessly repeating vistas of replicating franchises. The ghosts of Old Europe that stalked Scorsese and Coppola’s streets have been exorcised, buried with the ancient beefs, bad blood and burning vendettas somewhere beneath the multinational coffee shops. You can learn a great deal about the world of Heat from considering the name ‘Neil McCauley’. It is an anonymous name, a fake passport name, a name that is bereft of history (even as, ironically, it echoes the name of British historian, Lord McCaulay). Compare ‘Corleone’, and remember that the Godfather was named after a village. McCauley is perhaps the part that De Niro played that is closest to the actor’s own personality: a screen, a cipher, depthless, icily professional, stripped down to pure preparation, research, Method (‘I do what I do best’). McCauley is no mafia Boss, no puffed-up chief perched atop a baroque hierarchy governed by codes as solemn and mysterious as those of the Catholic Church and written in the blood of a thousand feuds. His Crew are professionals, hands-on entrepreneur-speculators, crime-technicians, whose credo is the exact opposite of Cosa Nostra family loyalty. Family ties are unsustainable in these conditions, as McCauley tells the Pacino character, the driven detective, Vincent Hanna. ‘Now, if you’re on me and you gotta move when I move, how do you expect to keep a marriage?’ Hanna is McCauley’s shadow, forced to assume his insubstantiality, his perpetual mobility. Like any group of shareholders, McCauley’s crew is held together by the prospect of future revenue; any other bonds are optional extras, almost certainly dangerous. Their arrangement is temporary, pragmatic and lateral – they know that they are interchangeable machine parts, that there are no guarantees, that nothing lasts. Compared to this, the goodfellas seem like sedentary sentimentalists, rooted in dying communities, doomed territories.

The ethos espoused by McCauley is the one which Richard Sennett examines in The Corrosion of Character: The Personal Consequences of Work in the New Capitalism, a landmark study of the affective changes that the post-Fordist reorganization of work has brought about. The slogan which sums up the new conditions is ‘no long term’. Where formerly workers could acquire a single set of skills and expect to progress upwards through a rigid organizational hierarchy, now they are required to periodically re-skill as they move from institution to institution, from role to role. As the organization of work is decentralized, with lateral networks replacing pyramidal hierarchies, a premium is put on ‘flexibility’. Echoing McCauley’s mockery of Hanna in Heat (‘How do you expect to keep a marriage?’), Sennett emphasizes the intolerable stresses that these conditions of permanent instability put on family life. The values that family life depends upon – obligation, trustworthiness, commitment – are precisely those which are held to be obsolete in the new capitalism. Yet, with the public sphere under attack and the safety nets that a ‘Nanny State’ used to provide being dismantled, the family becomes an increasingly important place of respite from the pressures of a world in which instability is a constant. The situation of the family in post-Fordist capitalism is contradictory, in precisely the way that traditional Marxism expected: capitalism requires the family (as an essential means of reproducing and caring for labor power; as a salve for the psychic wounds inflicted by anarchic social-economic conditions), even as it undermines it (denying parents time with children, putting intolerable stress on couples as they become the exclusive source of affective consolation for each other).

According to Marxist economist Christian Marazzi, the switch from Fordism to post-Fordism can be given a very specific date: October 6, 1979. It was on that date that the Federal Reserve increased interest rates by 20 points, preparing the way for the ‘supply-side economics’ that would constitute the ‘economic reality’ in which we are now enmeshed. The rise in interest rates not only contained inflation, it made possible a new organization of the means of production and distribution. The ‘rigidity’ of the Fordist production line gave way to a new ‘flexibility’, a word that will send chills of recognition down the spine of every worker today. This flexibility was defined by a deregulation of Capital and labor, with the workforce being casualized (with an increasing number of workers employed on a temporary basis), and outsourced.

Like Sennett, Marazzi recognizes that the new conditions both required and emerged from an increased cybernetization of the working environment. The Fordist factory was crudely divided into blue and white collar work, with the different types of labor physically delimited by the structure of the building itself. Laboring in noisy environments, watched over by managers and supervisors, workers had access to language only in their breaks, in the toilet, at the end of the working day, or when they were engaged in sabotage, because communication interrupted production. But in post-Fordism, when the assembly line becomes a ‘flux of information’, people work by communicating. As Norbert Wiener taught, communication and control entail one another.

Work and life become inseparable. Capital follows you when you dream. Time ceases to be linear, becomes chaotic, broken down into punctiform divisions. As production and distribution are restructured, so are nervous systems. To function effectively as a component of just-in-time production you must develop a capacity to respond to unforeseen events, you must learn to live in conditions of total instability, or ‘precarity’, as the ugly neologism has it. Periods of work alternate with periods of unemployment. Typically, you find yourself employed in a series of short-term jobs, unable to plan for the future.

Both Marazzi and Sennett point out that the disintegration of stable working patterns was in part driven by the desires of workers – it was they who, quite rightly, did not wish to work in the same factory for forty years. In many ways, the left has never recovered from being wrong-footed by Capital’s mobilization and metabolization of the desire for emancipation from Fordist routine. Especially in the UK, the traditional representatives of the working class – union and labor leaders – found Fordism rather too congenial; its stability of antagonism gave them a guaranteed role. But this meant that it was easy for the advocates of post-Fordist Capital to present themselves as the opponents of the status quo, bravely resisting an inertial organized labor ‘pointlessly’ invested in fruitless ideological antagonism which served the ends of union leaders and politicians, but did little to advance the hopes of the class they purportedly represented. Antagonism is not now located externally, in the face-off between class blocs, but internally, in the psychology of the worker, who, as a worker, is interested in old-style class conflict, but, as someone with a pension fund, is also interested in maximizing the yield from his or her investments. There is no longer an identifiable external enemy. The consequence is, Marazzi argues, that post-Fordist workers are like the Old Testament Jews after they left the ‘house of slavery’: liberated from a bondage to which they have no wish to return but also abandoned, stranded in the desert, confused about the way forward.

The psychological conflict raging within individuals cannot but have casualties. Marazzi is researching the link between the increase in bi-polar disorder and post-Fordism and, if, as Deleuze and Guattari argue, schizophrenia is the condition that marks the outer edges of capitalism, then bi-polar disorder is the mental illness proper to the ‘interior’ of capitalism. With its ceaseless boom and bust cycles, capitalism is itself fundamentally and irreducibly bi-polar, periodically lurching between hyped-up mania (the irrational exuberance of ‘bubble thinking’) and depressive come-down. (The term ‘economic depression’ is no accident, of course). To a degree unprecedented in any other social system, capitalism both feeds on and reproduces the moods of populations. Without delirium and confidence, capital could not function.

It seems that with post-Fordism, the ‘invisible plague’ of psychiatric and affective disorders that has spread, silently and stealthily, since around 1750 (i.e. the very onset of industrial capitalism) has reached a new level of acuteness. Here, Oliver James’s work is important. In The Selfish Capitalist, James points to significant rises in the rates of ‘mental distress’ over the last 25 years. ‘By most criteria’, James reports,

rates of distress almost doubled between people born in 1946 (aged thirty-six in 1982) and 1970 (aged thirty in 2000). For example, 16 per cent of thirty-six-year-old women in 1982 reported having ‘trouble with nerves, feeling low, depressed or sad’, whereas 29 per cent of thirty year-olds reported this in 2000 (for men it was 8 per cent in 1982, 13 per cent in 2000).

Another British study James cites compared levels of psychiatric morbidity (which includes neurotic symptoms, phobias and depression) in samples of people in 1977 and 1985. ‘Whereas 22 per cent of the 1977 sample reported psychiatric morbidity, this had risen to almost a third of the population (31 per cent) by 1986’. Since these rates are much higher in countries that have implemented what James calls ‘selfish’ capitalism than in other capitalist nations, James hypothesizes that it is selfish (i.e. neoliberalized) capitalist policies and culture that are to blame. Specifically, James points to the way in which selfish capitalism stokes up

both aspirations and the expectations that they can be fulfilled. ... In the entrepreneurial fantasy society, the delusion is fostered that anyone can be Alan Sugar or Bill Gates, never mind that the actual likelihood of this occurring has diminished since the 1970s – a person born in 1958 was more likely than one born in 1970 to achieve upward mobility through education, for example. The Selfish Capitalist toxins that are most poisonous to well-being are the systematic encouragement of the ideas that material affluence is they key to fulfillment, that only the affluent are winners and that access to the top is open to anyone willing to work hard enough, regardless of their familial, ethnic or social background – if you do not succeed, there is only one person to blame.

James’s conjectures about aspirations, expectations and fantasy fit with my own observations of what I have called ‘hedonic depression’ in British youth.

It is telling, in this context of rising rates of mental illness, that New Labour committed itself, early in its third term in government, to removing people from Incapacity Benefit, implying that many, if not most, claimants are malingerers. In contrast with this assumption, it doesn’t seem unreasonable to infer that most of the people claiming Incapacity Benefit – and there are well in excess of two million of them – are casualties of Capital. A significant proportion of claimants, for instance, are people psychologically damaged as a consequence of the capitalist realist insistence that industries such as mining are no longer economically viable. (Even considered in brute economic terms, though, the arguments about ‘viability’ seem rather less than convincing, especially once you factor in the cost to taxpayers of incapacity and other benefits.) Many have simply buckled under the terrifyingly unstable conditions of post-Fordism.

The current ruling ontology denies any possibility of a social causation of mental illness. The chemico-biologization of mental illness is of course strictly commensurate with its de-politicization. Considering mental illness an individual chemico-biological problem has enormous benefits for capitalism. First, it reinforces Capital’s drive towards atomistic individualization (you are sick because of your brain chemistry). Second, it provides an enormously lucrative market in which multinational pharmaceutical companies can peddle their pharmaceuticals (we can cure you with our SSRIs). It goes without saying that all mental illnesses are neurologically instantiated, but this says nothing about their causation. If it is true, for instance, that depression is constituted by low serotonin levels, what still needs to be explained is why particular individuals have low levels of serotonin. This requires a social and political explanation; and the task of repoliticizing mental illness is an urgent one if the left wants to challenge capitalist realism.

It does not seem fanciful to see parallels between the rising incidence of mental distress and new patterns of assessing workers’ performance. We will now take a closer look at this ‘new bureaucracy’.

Mike Judge’s unjustly undercelebrated film Office Space (1999) is as acute an account of the 90s/00s workplace as Schrader’s Blue Collar (1978) was of 70s labor relations. Instead of the confrontation between trade union officials and management in a factory, Judge’s film shows a corporation sclerotized by administrative ‘anti-production’: workers receive multiple memos from different managers saying the exact same thing. Naturally, the memo concerns a bureaucratic practice: it aims to induce compliance with a new procedure of putting ‘cover sheets’ on reports. In keeping with the ‘being smart’ ethos, the management style in Office Space is a mixture of shirtsleeves-informality and quiet authoritarianism. Judge shows this same managerialism presides in the corporate coffee chains where the office workers go to relax. Here, staff are required to decorate their uniforms with ‘seven pieces of flair’, (i.e. badges or other personal tokens) to express their ‘individuality and creativity’: a handy illustration of the way in which ‘creativity’ and ‘self-expression’ have become intrinsic to labor in Control societies; which, as Paolo Virno, Yann Moulier Boutang and others have pointed out, now makes affective, as well as productive demands, on workers. Furthermore, the attempt to crudely quantify these affective contributions also tells us a great deal about the new arrangements. The flair example also points to another phenomenon: hidden expectations behind official standards. Joanna, a waitress at the coffee chain, wears exactly seven pieces of flair, but it is made clear to her that, even though seven is officially enough, it is actually inadequate – the manager asks if she wants to look the sort of person ‘who only does the bare minimum.’

‘You know what, Stan, if you want me to wear 37 pieces of flair,’ Joanna complains, ‘why don’t you just make the minimum 37 pieces of flair?’

‘Well,’ the manager replies, ‘I thought I remembered you saying that you wanted to express yourself.’ Enough is no longer enough. This syndrome will be familiar to many workers who may find that a ‘satisfactory’ grading in a performance evaluation is no longer satisfactory. In many educational institutions, for instance, if after a classroom observation a teacher is graded as ‘satisfactory’, they will be required to undertake training prior to a reassessment.

Initially, it might appear to be a mystery that bureaucratic measures should have intensified under neoliberal governments that have presented themselves as anti-bureaucratic and anti-Stalinist. Yet new kinds of bureaucracy – ‘aims and objectives’, ‘outcomes’, ‘mission statements’ – have proliferated, even as neoliberal rhetoric about the end of top-down, centralized control has gained pre-eminence. It might seem that bureaucracy is a kind of return of the repressed, ironically re-emerging at the heart of a system which has professed to destroy it. But the resurgence of bureaucracy in neoliberalism is more than an atavism or an anomaly.

As I have already indicated, there is no contradiction between ‘being smart’ and the increase of administration and regulation: they are two sides of labor in Control societies. Richard Sennett has argued that the flattening of pyramidal hierarchies has actually led to more surveillance of workers. ‘One of the claims made for the new organization of work is that it decentralizes power, that is, gives people in the lower ranks of organization more control over their own activities’, Sennett writes. ‘Certainly this claim is false in terms of the techniques employed for taking apart the old bureaucratic behemoths. The new information systems provide a comprehensive picture of the organization to top managers in ways which give individuals anywhere in the network little room to hide’. But it isn’t only that information technology has granted managers more access to data; it is that the data itself has proliferated. Much of this ‘information’ is provided by workers themselves. Massimo De Angelis and David Harvie describe some of the bureaucratic measures with which a lecturer must comply when putting together a module for an undergraduate degree in British universities. ‘For each module’, De Angelis and Harvie write,

the ‘module leader’ (ML, i.e., lecturer) must complete various paperwork, in particular a ‘module specification’ (at the module’s start) which lists the module’s ‘aims and objectives’, ILOs, ‘modes and methods of assessment’, amongst other information; and a ‘module review’ document (at the end of the module), in which the ML reports their own assessment of the module’s strengths and weaknesses and their suggested changes for the following year; a summary of student feedback; and average marks and their dispersion.

This is only the beginning, however. For the degree program as a whole, academics must prepare a ‘program specification’, as well as producing ‘annual program reports’, which record student performance according to ‘progression rates’, ‘withdrawal rates’, location and spread of marks. All students’ marks have to be graded against a ‘matrix’. This auto-surveillance is complemented by assessments carried out by external authorities. The marking of student assignments is monitored by ‘external examiners’ who are supposed to maintain consistency of standards across the university sector. Lecturers have to be observed by their peers, while departments are subject to periodic three or four day inspections by the Quality Assurance Agency for Higher Education (QAA). If they are ‘research active’, lecturers must submit their ‘best four publications’ every four or five years to be graded by panel as part of the Research Assessment Exercise (replaced in 2008 by the equally controversial Research Excellence Framework). De Angelis and Harvie are clear that these are only very sketchy accounts of only some of the bureaucratic tasks that academics have to perform, all of which have funding implications for institutions. This battery of bureaucratic procedures is by no means confined to universities, nor to education: other public services, such as the National Health Service and the police force, find themselves enmeshed in similar bureaucratic metastases.

This is in part a consequence of the inherent resistance of certain processes and services to marketization. (The supposed marketization of education, for instance, rests on a confused and underdeveloped analogy: are students the consumers of the service or its product?) The idealized market was supposed to deliver ‘friction free’ exchanges, in which the desires of consumers would be met directly, without the need for intervention or mediation by regulatory agencies. Yet the drive to assess the performance of workers and to measure forms of labor which, by their nature, are resistant to quantification, has inevitably required additional layers of management and bureaucracy. What we have is not a direct comparison of workers’ performance or output, but a comparison between the audited representation of that performance and output. Inevitably, a short-circuiting occurs, and work becomes geared towards the generation and massaging of representations rather than to the official goals of the work itself. Indeed, an anthropological study of local government in Britain argues that ‘More effort goes into ensuring that a local authority’s services are represented correctly than goes into actually improving those services’. This reversal of priorities is one of the hallmarks of a system which can be characterized without hyperbole as ‘market Stalinism’. What late capitalism repeats from Stalinism is just this valuing of symbols of achievement over actual achievement. As Marshall Berman explained, describing Stalin’s White Sea Canal project of 1931-33:

Stalin seems to have been so intent on creating a highly visible symbol of development that he pushed and squeezed the project in ways that only retarded the development of the project. Thus the workers and the engineers were never allowed the time, money or equipment necessary to build a canal that would be deep enough and safe enough to carry twentieth-century cargoes; consequently, the canal has never played any significant role in Soviet commerce or industry. All the canal could support, apparently, were tourist steamers, which in the 1930s were abundantly stocked with Soviet and foreign writers who obligingly proclaimed the glories of the work. The canal was a triumph of publicity; but if half the care that went into the public relations campaign had been devoted to the work itself, there would have been far fewer victims and far more real developments – and the project would have been a genuine tragedy, rather than a brutal farce in which real people were killed by pseudo-events.

In a strange compulsion to repeat, the ostensibly anti-Stalinist neoliberal New Labour government has shown the same tendency to implement initiatives in which real world effects matter only insofar as they register at the level of (PR) appearance. The notorious ‘targets’ which the New Labour government was so enthusiastic in imposing are a case in point. In a process that repeats itself with iron predictability everywhere that they are installed, targets quickly cease to be a way of measuring performance and become ends in themselves. Anxiety about falling standards in school examinations is now a regular feature of the summertime in Britain. Yet if students are less skilled and knowledgeable than their predecessors, this is due not to a decline in the quality of examinations per se, but to the fact that all of the teaching is geared towards passing the exams. Narrowly focused ‘exam drill’ replaces a wider engagement with subjects. Similarly, hospitals perform many routine procedures instead of a few serious, urgent operations, because this allows them to hit the targets they are assessed on (operating rates, success rates and reduction in waiting time) more effectively.

It would be a mistake to regard this market Stalinism as some deviation from the ‘true spirit’ of capitalism. On the contrary, it would be better to say that an essential dimension of Stalinism was inhibited by its association with a social project like socialism and can only emerge in a late capitalist culture in which images acquire an autonomous force. The way value is generated on the stock exchange depends of course less on what a company ‘really does’, and more on perceptions of, and beliefs about, its (future) performance. In capitalism, that is to say, all that is solid melts into PR, and late capitalism is defined at least as much by this ubiquitous tendency towards PR-production as it is by the imposition of market mechanisms.

Here, Žižek’s elaboration of Lacan’s concept of the ‘big Other’ is crucial. The big Other is the collective fiction, the symbolic structure, presupposed by any social field. The big Other can never be encountered in itself; instead, we only ever confront its stand-ins. These representatives are by no means always leaders. In the example of the White Sea Canal above, for instance, it wasn’t Stalin himself who was the representative of the big Other so much as the Soviet and foreign writers who had to be persuaded of the glories of the project. One important dimension of the big Other is that it does not know everything. It is this constitutive ignorance of the big Other that allows public relations to function. Indeed, the big Other could be defined as the consumer of PR and propaganda, the virtual figure which is required to believe even when no individual can. To use one of Žižek’s examples: who was it, for instance, who didn’t know that Really Existing Socialism (RES) was shabby and corrupt? Not any of the people, who were all too aware of its shortcomings; nor any of the government administrators, who couldn’t but know. No, it was the big Other who was the one deemed not to know – who wasn’t allowed to know – the quotidian reality of RES. Yet the distinction between what the big Other knows, i.e. what is officially accepted, and what is widely known and experienced by actual individuals, is very far from being ‘merely’ emptily formal; it is the discrepancy between the two that allows ‘ordinary’ social reality to function. When the illusion that the big Other did not know can no longer be maintained, the incorporeal fabric holding the social system together disintegrates. This is why Khrushchev’s speech in 1965, in which he ‘admitted’ the failings of the Soviet state, was so momentous. It is not as if anyone in the party was unaware of the atrocities and corruption carried out in its name, but Khrushchev’s announcement made it impossible to believe any more that the big Other was ignorant of them.

So much for Really Existing Socialism – but what of Really Existing Capitalism? One way to understand the ‘realism’ of capitalist realism is in terms of the claim to have given up belief in the big Other. Postmodernism can be construed as the name for the complex of crises that the decline in the belief in the big Other has triggered, as Lyotard’s famous formulation of the postmodern condition – ‘incredulity towards metanarratives’ –suggests. Jameson, of course, would argue that the ‘incredulity towards metanarratives’ is one expression of the ‘cultural logic of late capitalism’, a consequence of the switch into the post-Fordist mode of capital accumulation. Nick Land gives one of the most euphoric accounts of the ‘postmodern meltdown of culture into the economy’. In Land’s work, a cybernetically upgraded invisible hand is progressively eliminating centralized state power. Land’s 90s texts synthesized cybernetics, complexity theory, cyberpunk fiction and neoliberalism to construct a vision of capital planetary artificial intelligence: a vast, supple, endlessly fissile system which renders human will obsolete. In his manifesto for nonlinear, decentered Capital, ‘Meltdown’, Land invokes a ‘massively distributed matrix-networked tendency oriented to disabling ROM command-control programs sustaining all macro- and micro-governmental entities, globally concentrating themselves as the Human Security System’. This is capitalism as a shattering Real, in which (viral, digital) signals circulate on self-sustaining networks which bypass the Symbolic, and therefore do not require the big Other as guarantor. It is Deleuze and Guattari’s Capital as ‘Unnamable Thing’, but without the forces of reterritorialization and anti-production which they argued were constitutive of capitalism. One of the problems of Land’s position is also what is most interesting about it: precisely that it posits a ‘pure’ capitalism, a capitalism which is only inhibited and blocked by extrinsic, rather than internal, elements (according to Land’s logic, these elements are atavisms that will eventually be consumed and metabolized by Capital). Yet capitalism cannot be ‘purified’ in this way; strip away the forces of anti-production and capitalism disappears with them. Similarly, there is no progressive tendency towards an ‘unsheathing’ of capitalism, no gradual unmasking of Capital as it ‘really’ is: rapacious, indifferent, inhuman. On the contrary, the essential role of the ‘incorporeal transformations’ effectuated by PR, branding and advertising in capitalism suggests that, in order to operate effectively, capitalism’s rapacity depends upon various forms of sheathing. Really Existing Capitalism is marked by the same division which characterized Really Existing Socialism, between, on the one hand, an official culture in which capitalist enterprises are presented as socially responsible and caring, and, on the other, a widespread awareness that companies are actually corrupt, ruthless, etc. In other words, capitalist postmodernity is not quite as incredulous as it would appear to be, as the jeweler Gerald Ratner famously found to his cost. Ratner precisely tried to circumvent the Symbolic and ‘tell it how it is’, describing the inexpensive jewelry his shops sold as ‘crap’ in an after-dinner speech. But the consequence of Ratner making this judgment official were immediate, and serious - £500m was wiped off the value of the company and he lost his job. Customers might previously have known that the jewelry Ratners sold was poor quality, but the big Other didn’t know; as soon as it did, Ratners collapsed.

Vernacular postmodernism has dealt with the ‘crisis of symbolic efficiency’ in a far less intense way than Nick Land, through metafictional anxieties about the function of the author, and in television programs or films which expose the mechanisms of their own productions and reflexively incorporate discussions of their own status as commodities. But postmod-ernism’s supposed gestures of demystification do not evince sophistication so much as a certain naivety, a conviction that there were others, in the past, who really believed in the Symbolic. In fact, of course, ‘symbolic efficiency’ was achieved precisely by maintaining a clear distinction between a material-empirical causality, and another, incorporeal causality proper to the Symbolic. Žižek gives the example of a judge: ‘I know very well that things are the way I see them, that this person is a corrupted weakling, but I nonetheless treat him respectfully, since he wears the insignia of a judge, so that when he speaks, it is the Law itself which speaks through him’. However, postmodernism’s

cynical reduction to reality ... falls short: when a judge speaks, there is in a way more truth in his words (the words of the Institution of law) than in the direct reality of the person of judge if one limits oneself to what one sees, one simply misses the point. Lacan aims at this paradox with his ‘les non-dupes errent’: those who do not allow themselves to be caught in the symbolic deception/fiction, who continue to believe their eyes, are the ones who err most. A cynic who ‘believes only his eyes’ misses the efficiency of the symbolic fiction, and how it structures our experience of reality.

Much of Baudrillard’s work was a commentary on this same effect: the way in which the abolition of the Symbolic led not to a direct encounter with the Real, but to a kind of hemorrhaging of the Real. For Baudrillard, phenomena such as fly on the wall documentaries and political opinion polls – both of which claimed to present reality in an unmediated way – would always pose an insoluble dilemma. Did the presence of the cameras affect the behavior of those being filmed? Would the publication of poll results affect the future behavior of voters? Such questions were undecidable, and therefore ‘reality’ would always be elusive: at the very moment when it seemed that it was being grasped in the raw, reality transformed into what Baudrillard, in a much misunderstood neologism, called ‘hyperreality’. Uncannily echoing Baudrillard’s fixations, the most successful reality television programs ended up fusing fly on the wall documentary elements with interactive polling. In effect, there are two levels of ‘reality’ in these shows: the unscripted behavior of the ‘real life’ participants onscreen, and the unpredictable responses of the audience at home, which in turn affect the behavior of the onscreen participants. Yet reality TV is continually haunted by questions about fiction and illusion: are the participants acting, suppressing certain aspects of their personality in order to appear more appealing to us, the audience? And have the audience’s votes been accurately registered, or is there some kind of a fix? The slogan that the Big Brother TV show uses – ‘You decide’ – captures perfectly the mode of control by feedback that, according to Baudrillard, has replaced old centralized forms of power. We ourselves occupy the empty seat of power, phoning and clicking in our responses. TV’s Big Brother had superseded Orwell’s Big Brother. We the audience are not subjected to a power that comes from outside; rather, we are integrated into a control circuit that has our desires and preferences as its only mandate – but those desires and preferences are returned to us, no longer as ours, but as the desires of the big Other. Clearly, these circuits are not confined to television: cybernetic feedback systems (focus groups, demographic surveys) are now integral to the delivery of all ‘services’, including education and government.

This returns us to the issue of post-Fordist bureaucracy. There is of course a close relationship between bureaucracy – the discourse of officialdom – and the big Other. Witness two of Žižek’s own examples of the big Other at work: a low-level official who, having not been informed of a promotion, says ‘Sorry, I have not yet been properly informed about this new measure, so I can’t help you...’; a woman who believed that she was suffering bad luck because of the number of her house, who could not be satisfied by simply repainting a different number herself , because ‘it has to be done properly, by the responsible state institution...’ We are all familiar with bureaucratic libido, with the enjoyment that certain officials derive from this position of disavowed responsibility (‘it’s not me, I’m afraid, it’s the regulations’). The frustration of dealing with bureaucrats often arises because they themselves can make no decisions; rather, they are permitted only to refer to decisions that have always-already been made (by the big Other). Kafka was the greatest writer on bureaucracy because he saw that this structure of disavowal was inherent to bureaucracy. The quest to reach the ultimate authority who will finally resolve K’s official status can never end, because the big Other cannot be encountered in itself: there are only officials, more or less hostile, engaged in acts of interpretation about what the big Other’s intentions. And these acts of interpretation, these deferrals of responsibility, are all that the big Other is.

If Kafka is valuable as a commentator on totalitarianism, it is by revealing that there was a dimension of totalitarianism which cannot be understood on the model of despotic command. Kafka’s purgatorial vision of a bureaucratic labyrinth without end chimes with Žižek’s claim that the Soviet system was an ‘empire of signs’, in which even the Nomenklatura themselves –including Stalin and Molotov – were engaged in interpreting a complex series of social semiotic signals. No-one knew what was required; instead, individuals could only guess what particular gestures or directives meant. What happens in late capitalism, when there is no possibility of appealing, even in principle, to a final authority which can offer the definitive official version, is a massive intensification of that ambiguity. As an example of this syndrome, let us turn once more to Further Education. At a meeting between Trade Union officials, college Principals and Members of Parliament, the Learning and Skills Council (LSC), the quango at the heart of the FE funding labyrinth, came in for particular attack. Neither the teachers, nor the Principals, nor the MPs could determine how particular directives had generated themselves, since they are not there in government policy itself. The answer was that the LSC ‘interpreted’ the instructions issued by the Department for Education and Skills. These interpretations then achieve the strange autonomy peculiar to bureaucracy. On the one hand, bureaucratic procedures float freely, independent of any external authority; but that very autonomy means that they assume a heavy implacability, a resistance to any amendment or questioning.

The proliferation of auditing culture in post Fordism indicates that the demise of the big Other has been exaggerated. Auditing can perhaps best be conceived of as fusion of PR and bureaucracy, because the bureaucratic data is usually intended to fulfill a promotional role: in the case of education, for example, exam results or research ratings augment (or diminish) the prestige of particular institutions. The frustration for the teacher is that it seems as if their work is increasingly aimed at impressing the big Other which is collating and consuming this ‘data’. ‘Data’ has been put in inverted commas here, because much of the so-called information has little meaning or application outside the parameters of the audit: as Eeva Berglund puts it, ‘the information that audit creates does have consequences even though it is so shorn of local detail, so abstract, as to be misleading or meaningless - except, that is, by the aesthetic criteria of audit itself.

New bureaucracy takes the form not of a specific, delimited function performed by particular workers but invades all areas of work, with the result that – as Kafka prophesied – workers become their own auditors, forced to assess their own performance. Take, for example, the ‘new system’ that OFSTED (Office for Standards in Education) uses to inspect Further Education colleges. Under the old system, a college would have a ‘heavy’ inspection once every four years or so, i.e. one involving many lesson observations and a large number of inspectors present in the college. Under the new, ‘improved’ system, if a college can demonstrate that its internal assessment systems are effective, it will only have to undergo a ‘light’ inspection. But the downside of this ‘light’ inspection is obvious – surveillance and monitoring are outsourced from OFSTED to the college and ultimately to lecturers themselves, and become a permanent feature of the college structure (and of the psychology of individual lecturers). The difference between the old/heavy and new/light inspection system corresponds precisely to Kafka’s distinction between ostensible acquittal and indefinite postponement, outlined above. With ostensible acquittal, you petition the lower court judges until they grant you a non-binding reprieve. You are then free from the court, until the time when your case is re-opened. Indefinite postponement, meanwhile, keeps your case at the lowest level of the court, but at the cost of an anxiety that has never ends. (The changes in OFSTED inspections are mirrored by in the change from the Research Assessment Exercise to the Research Excellence Framework in higher education: periodic assessment will be superseded by a permanent and ubiquitous measurement which cannot help but generate the same perpetual anxiety.)

In any case, it is not as if the ‘light’ inspection is in any sense preferable for staff than the heavy one. The inspectors are in the college for the same amount of time as they were under the old system. The fact that there are fewer of them does nothing to alleviate the stress of the inspection, which has far more to do with the extra bureaucratic window-dressing one has to do in anticipation of a possible observation than it has to do with any actual observation itself. The inspection, that is to say, corresponds precisely to Foucault’s account of the virtual nature of surveillance in Discipline And Punish. Foucault famously observes there that there is no need for the place of surveillance to actually be occupied. The effect of not knowing whether you will be observed or not produces an introjection of the surveillance apparatus. You constantly act as if you are always about to be observed. Yet, in the case of school and university inspections, what you will be graded on is not primarily your abilities as a teacher so much as your diligence as a bureaucrat. There are other bizarre effects. Since OFSTED is now observing the college’s self-assessment systems, there is an implicit incentive for the college to grade itself and its teaching lower than it actually deserves. The result is a kind of postmodern capitalist version of Maoist confessionalism, in which workers are required to engage in constant symbolic self-denigration. At one point, when our line manager was extolling the virtues of the new, light inspection system, he told us that the problem with our departmental log-books was that they were not sufficiently self-critical. But don’t worry, he urged, any self-criticisms we make are purely symbolic, and will never be acted upon; as if performing self-flagellation as part of a purely formal exercise in cynical bureaucratic compliance were any less demoralizing.

In the post-Fordist classroom, the reflexive impotence of the students is mirrored by reflexive impotence of the teachers. De Angelis and Harvie report that

practices and requirements of standardisation and surveillance obviously impose a huge burden of work on academics and few are happy about it. There have been a number of responses. Managers have frequently suggested there is no alternative (TINA) and have perhaps suggested that what we need to do is ‘work smarter, not harder’. This seductive slogan, introduced to dampen staff resistance to further change which in their (our) experience has a devastating effects on working conditions, attempts to couple the need for ‘change’ (restructuring and innovation) in order to meet the budget pressure and increase ‘competitiveness’, with staff’s resistance not only to worsening of their condition of work, but also to the educational and academic ‘meaninglessness’ of the ‘changes’.

The invocation of the idea that ‘there is no alternative’, and the recommendation to ‘work smarter, not harder’, shows how capitalist realism sets the tone for labor disputes in post-Fordism. Ending the inspection regime, one lecturer sardonically remarked, seems more impossible than ending slavery was. Such fatalism can only be challenged if a new (collective) political subject emerges.

‘Being realistic’ may once have meant coming to terms with of a reality experienced as solid and immovable. Capitalist realism, however, entails subordinating oneself to a reality that is infinitely plastic, capable of reconfiguring itself at any moment. We are confronted with what Jameson, in his essay ‘The Antimonies Of The Postmodern’, calls ‘a purely fungible present in which space and psyches alike can be processed and remade at will’. The ‘reality’ here is akin to the multiplicity of options available on a digital document, where no decision is final, revisions are always possible, and any previous moment can be recalled at any time. The middle manager I referred to above turned adaptation to this ‘fungible’ reality it into a fine art. He asserted with full confidence a story about the college and its future one day – what the implications of the inspection were likely to be; what senior management was thinking; then literally the next day would happily propound a story that directly contradicted what he previously said. There was never a question of his repudiating the previous story; it was as if he, only dimly remembered there ever being another story. This, I suppose, is ‘good management’. It is, also, perhaps the only way to stay healthy amidst capitalism’s perpetual instability. On the face of it, this manager is a model of beaming mental health, his whole being radiating a hail-fellow-well-met bonhomie. Such cheerfulness can only be maintained if one has a near-total absence of any critical reflexivity and a capacity, as he had, to cynically comply with every directive from bureaucratic authority. The cynicism of the compliance is essential, of course; the preservation of his 60s liberal self-image depended upon his ‘not really believing’ in the auditing processes he so assiduously enforced. What this disavowal depends upon is the distinction between inner subjective attitude and outward behavior I discussed above: in terms of his inner subjective attitude, the manager is hostile, even contemptuous, towards, the bureaucratic procedures he supervises; but in terms of his outward behavior, he is perfectly compliant. Yet it is precisely workers’ subjective disinvestment from auditing tasks which enables them to continue to perform labor that is pointless and demoralizing.

The manager’s capacity to smoothly migrate from one reality to another reminded me of nothing so much as Ursula Le Guin’s The Lathe of Heaven. It is a novel about George Orr, a man whose dreams literally come true. In time-honored fairy tale fashion, however, the acts of wish fulfillment quickly become traumatic and catastrophic. When, for instance, Orr is induced by his therapist, Dr Haber, into dreaming that the problem of overpopulation is solved, he wakes to find himself in a world in which billions have been wiped out by a plague; a plague that, as Jameson put it in his discussion of the novel, was ‘a hitherto nonexistent event which rapidly finds its place in our chronological memory of the recent past’. Much of the power of the novel consists in its rendering of these retrospective confabulations, whose mechanics are at once so familiar – because we perform them every night when we dream – and so odd. How could it ever be possible for us to believe successive or even co-extensive stories that so obviously contradict one another? Yet we know from Kant, Nietzsche and psychoanalysis that waking, as much as dreaming, experience, depends upon just such screening narratives. If the Real is unbearable, any reality we construct must be a tissue of inconsistencies. What differentiates Kant, Nietzsche and Freud from the tiresome cliché that ‘life is but a dream’ is the sense that the confabulations we live are consensual. The idea that the world we experience is a solipsistic delusion projected from the interior of our mind consoles rather than disturbs us, since it conforms with our infantile fantasies of omnipotence; but the thought that our so-called interiority owe its existence to a fictionalized consensus will always carry an uncanny charge. This extra level of uncanniness is registered in The Lathe of Heaven when Le Guin has Orr’s reality-warping dreams witnessed by others – the therapist, Haber, who seeks to manipulate and control Orr’s ability, and the lawyer, Heather Lelache. What, then, is it like to live through someone else’s dream coming true?

[Haber] could not go on talking. He felt it: the shift, the arrival, the change.

The woman felt it too. She looked frightened. Holding the brass necklace up close to her throat like a talisman, she was staring in dismay, shock, terror, out of the window at the view.

[...] What would it do to the woman? Would she understand, would she go mad, what would she do? Would she keep both memories, as he did, the true one and the new one, the old one and the true one?

Does she ‘go crazy’? No, not at all: after a few moments of bewildered fugue, Heather Lelache accepts the ‘new’ world as the ‘true’ world, editing out the point of suture. This strategy – of accepting the incommensurable and the senseless without question – has always been the exemplary technique of sanity as such, but it has a special role to play in late capitalism, that ‘motley painting of everything that ever was’, whose dreaming up and junking of social fictions is nearly as rapid as its production and disposal of commodities.

In these conditions of ontological precarity, forgetting becomes an adaptive strategy. Take the example of Gordon Brown, whose expedient reinvention of his political identity involved an attempt to induce a collective forgetting. In an article in International Socialism, John Newsinger remembers how

Brown told the Confederation of British Industry conference that ‘business is in my blood’. His mother had been a company director and ‘I was brought up in an atmosphere where I knew exactly what was happening as far as business was concerned’. He was, indeed he had always been, one of them. The only problem is that it was not true. As his mother subsequently admitted, she would never have called herself ‘a business woman’: she had only ever done some ‘light administrative duties’ for ‘a small family firm’ and had given up the job when she married, three years before young Gordon was even born. While there have been Labor politicians who have tried to invent working class backgrounds for themselves before, Brown is the first to try and invent a capitalist background.

Newsinger contrasts Brown with his rival and predecessor as British prime minister, Tony Blair, a very different case. While Blair – who presented the strange spectacle of a postmodern messianism – never had any beliefs that he had to recant on, Brown’s move from Presbyterian socialist to New Labour supremo was a long, arduous and painful process of repudiation and denial. ‘Whereas, for Blair, the embrace of neoliberalism involved no great personal struggle because he had no previous beliefs to dispose of, Newsinger writes, ‘for Brown it involved a deliberate decision to change sides. The effort, one suspects, damaged his personality’. Blair was the Last Man by nature and inclination; Brown has become the Last Man, the dwarf at the End of History, by force of will.

Blair was the man without a chest, the outsider the party needed in order to get into power, his joker hysterical face salesman-smooth; Brown’s implausible act of self-reinvention is what the party itself had to go through, his fake-smile grimace the objective correlative of Labour’s real state now that it has completely capitulated to capitalist realism: gutted, and gutless, its insides replaced by simulacra which once looked lustrous but now possess all the allure of decade-old computer technology.

In conditions where realities and identities are upgraded like software, it is not surprising that memory disorders should have become the focus of cultural anxiety – see, for instance, the Bourne films, Memento, Eternal Sunshine Of the Spotless Mind. In the Bourne films, Jason Bourne’s quest to regain his identity goes alongside a continual flight from any settled sense of self. ‘Try to understand me... ,’ says Bourne in the original novel by Robert Ludlum,

I have to know certain things ... enough to make a decision... but maybe not everything. A part of me has to be able to walk away, disappear. I have to be able to say to myself, what was isn’t any longer, and there’s a possibility that it never was because I have no memory of it. What a person can’t remember didn’t exist.... for him.

In the films, Bourne’s transnational nomadism is rendered in an ultra-fast cutting style which functions as a kind of anti-memory, pitching the viewer into the vertiginous ‘continuous present’ which Jameson argues is characteristic of postmodern temporality. The complex plotting of Ludlum’s novels is transformed into a series of evanescent event-ciphers and action set pieces which barely cohere into an intelligible narrative. Bereft of personal history, Bourne lacks narrative memory, but retains what we might call formal memory: a memory – of techniques, practices, actions – that is literally embodied in a series of physical reflexes and tics. Here, Bourne’s damaged memory echoes the postmodern nostalgia mode as described by Fredric Jameson, in which contemporary or even futuristic reference at the level of content obscure a reliance on established or antiquated models at the level of form. On the one hand, this is a culture that privileges only the present and the immediate – the extirpation of the long term extends backwards as well as forwards in time (for example, media stories monopolize attention for a week or so then are instantly forgotten); on the other hand, it is a culture that is excessively nostalgic, given over to retrospection, incapable of generating any authentic novelty. It may be that Jameson’s identification and analysis of this temporal antimony is his most important contribution to our understanding of postmodern/post-Fordist culture. ‘[T]he paradox from which we must set forth,’ he argues in ‘Antimonies Of The Postmodern’,

is the equivalence between an unparalleled rate of change on all the levels of social life and an unparalleled standardization of everything – feelings along with consumer goods, language along with built space – that would seem incompatible with such mutability... What then dawns is the realization that no society has ever been as standardized as this one, and that the stream of human, social and historical temporality has never flowed quite so homogenously. ... What we now begin to feel, therefore – and what begins to emerge as some deeper and more fundamental constitution of postmodernity itself, at least in its temporal dimension – is henceforth, where everything now submits to the perpetual change of fashion and media image, that nothing can change any longer.

No doubt this is another example of the struggle between the forces of deterritorialization and reterritorialization which Deleuze and Guattari argue is constitutive of capitalism as such. It wouldn’t be surprising if profound social and economic instability resulted in a craving for familiar cultural forms, to which we return in the same way that Bourne reverts to his core reflexes. The memory disorder that is the correlative of this situation is the condition which afflicts Leonard in Memento, theoretically pure anterograde amnesia. Here, memories prior to the onset of the condition are left intact, but sufferers are unable to transfer new memories into long term memory; the new therefore looms up as hostile, fleeting, un-navigable, and the sufferer is drawn back to the security of the old. The inability to make new memories: a succinct formulation of the postmodern impasse....

If memory disorder provides a compelling analogy for the glitches in capitalist realism, the model for its smooth functioning would be dreamwork. When we are dreaming, we forget, but immediately forget that we have done so; since the gaps and lacunae in our memories are Photoshopped out, they do not trouble or torment us. What dreamwork does is to produce a confabulated consistency which covers over anomalies and contradictions, and it is this which Wendy Brown picked up on when she argued that it was precisely dreamwork which provided the best model for understanding contemporary forms of power. In her essay ‘American Nightmare: Neoconservatism, Neoliberalism, and De-democratization’, Brown unpicked the alliance between neoconservatism and neoliberalism which constituted the American version of capitalist realism up until 2008. Brown shows that neoliberalism and neoconservatism operated from premises which are not only inconsistent, but directly contradictory. ‘How’, Brown asks,

does a rationality that is expressly amoral at the level of both ends and means (neoliberalism) intersect with one that is expressly moral and regulatory (neoconservatism)? How does a project that empties the world of meaning, that cheapens and deracinates life and openly exploits desire, intersect one centered on fixing and enforcing meanings, conserving certain ways of life, and repressing and regulating desire? How does support for governance modeled on the firm and a normative social fabric of self-interest marry or jostle against support for governance modeled on church authority and a normative social fabric of self-sacrifice and long-term filial loyalty, the very fabric shredded by unbridled capitalism?

But incoherence at the level of what Brown calls ‘political rationality’ does nothing to prevent symbiosis at the level of political subjectivity, and, although they proceeded from very different guiding assumptions, Brown argues that neoliberalism and neoconservatism worked together to undermine the public sphere and democracy, producing a governed citizen who looks to find solutions in products, not political processes. As Brown claims,

the choosing subject and the governed subject are far from opposites ... Frankfurt school intellectuals and, before them, Plato theorized the open compatibility between individual choice and political domination, and depicted democratic subjects who are available to political tyranny or authoritarianism precisely because they are absorbed in a province of choice and need-satisfaction that they mistake for freedom.

Extrapolating a little from Brown’s arguments, we might hypothesize that what held the bizarre synthesis of neoconservatism and neoliberalism together was their shared objects of abomination: the so called Nanny State and its dependents. Despite evincing an anti-statist rhetoric, neoliberalism is in practice not opposed to the state per se – as the bank bail-outs of 2008 demonstrated – but rather to particular uses of state funds; meanwhile, neoconservatism’s strong state was confined to military and police functions, and defined itself against a welfare state held to undermine individual moral responsibility.

Although excoriated by both neoliberalism and neoconserva-tivism, the concept of the Nanny State continues to haunt capitalist realism. The specter of big government plays an essential libidinal function for capitalist realism. It is there to be blamed precisely for its failure to act as a centralizing power, the anger directed at it much like the fury Thomas Hardy supposedly spat at God for not existing. ‘Time and again’, James Meek observed in an LRB piece on water privatization in Britain, ‘Conservative and Labor governments have discovered that when they give powers to private companies, and those private companies screw up, voters blame the government for giving the powers away, rather than the companies for misusing them’. Meek was visiting Tewkesbury, one of the British towns that was the victim of serious flooding in 2007, a year after the disaster. On the face of it, the flooding and the consequent failure of services was the fault of privatized water companies and house builders, yet Meek found that this was not the way that most of the local residents saw it. ‘In Tewkesbury’, Meeks wrote,

in general there is more hostility towards the government, the council and the Environment Agency for not stopping house builders than there is towards house builders for building houses, or buyers for buying them. When insurers raise their premiums, more blame is directed at the government for not spending enough on flood defences than at insurers for raising the premiums, or at people who choose to live in a flood-prone valley but don’t like paying extra for it.

This syndrome was repeated on a much grander scale with a disaster of a different kind –the bank crisis of 2008. The media focus was on the excesses of individual bankers and on the government’s handling of the crisis, not on the systemic causes of the crisis. I don’t for a moment want to excuse New Labour for its part in such disasters, but it has to be recognized that focus on government, like the focus on immoral individuals, is an act of deflection. Scapegoating an impotent government (running around to clean up the messes made by its business friends) arises from bad faith, from a continuing hostility to the Nanny State that nevertheless goes alongside a refusal to accept the consequences of the sidelining of government in global capitalism – a sign, perhaps, that, at the level of the political unconscious, it is impossible to accept that there are no overall controllers, that the closest thing we have to ruling powers now are nebulous, unaccountable interests exercising corporate irresponsibility. A case of fetishist disavowal, perhaps – ‘we know perfectly well that the government is not pulling the strings, but nevertheless...’ The disavowal happens in part because the centerlessness of global capitalism is radically unthinkable. Although people are interpellated now as consumers – and, as Wendy Brown and others have pointed out, government itself is presented as a kind of commodity or service – they still cannot help but think of themselves as (if they were) citizens.

The closest that most of us come to a direct experience of the centerlessness of capitalism is an encounter with the call center. As a consumer in late capitalism, you increasingly exist in two, distinct realities: the one in which the services are provided without hitch, and another reality entirely, the crazed Kafkaesque labyrinth of call centers, a world without memory, where cause and effect connect together in mysterious, unfathomable ways, where it is a miracle that anything ever happens, and you lose hope of ever passing back over to the other side, where things seem to function smoothly. What exemplifies the failure of the neoliberal world to live up to its own PR better than the call center? Even so, the universality of bad experiences with call centers does nothing to unsettle the operating assumption that capitalism is inherently efficient, as if the problems with call centers weren’t the systemic consequences of a logic of Capital which means organizations are so fixated on making profits that they can’t actually sell you anything.

The call center experience distils the political phenomenology of late capitalism: the boredom and frustration punctuated by cheerily piped PR, the repeating of the same dreary details many times to different poorly trained and badly informed operatives, the building rage that must remain impotent because it can have no legitimate object, since – as is very quickly clear to the caller –there is no-one who knows, and no-one who could do anything even if they could. Anger can only be a matter of venting; it is aggression in a vacuum, directed at someone who is a fellow victim of the system but with whom there is no possibility of communality. Just as the anger has no proper object, it will have no effect. In this experience of a system that is unresponsive, impersonal, centerless, abstract and fragmentary, you are as close as you can be to confronting the artificial stupidity of Capital in itself.

Call center angst is one more illustration of the way that Kafka is poorly understood as exclusively a writer on totalitarianism; a decentralized, market Stalinist bureaucracy is far more Kafkaesque than one in which there is a central authority. Read, for instance, the bleak farce of K’s encounter with the telephone system in the Castle, and it is hard not to see it as uncannily prophetic of the call center experience.

There’s no fixed exchange with the Castle, no central exchange which transmits our calls further. When anybody calls up the Castle from here the instruments in all the subordinate departments ring, or rather they would ring if practically all the departments – I know this for a certainty – didn’t leave their receivers off. Now and then, however, a fatigued official may feel the need of a little distraction, especially in the evenings and at night and may hang the receiver on. Then we get an answer, but of course an answer that’s a practical joke. And that’s very understandable too. For who would take the responsibility of interrupting, in the middle of the night, the extremely important work that goes on furiously the whole time, with a message about his own private troubles? I can’t comprehend how even a stranger can imagine that when he calls up Sordini, for example, it’s Sordini that answers.

K’s response anticipates the bewildered frustration of the individual in the call center labyrinth. Although many of the conversations with call center operatives appear Dadaistically nonsensical, they cannot be treated as such, cannot be dismissed as being of no significance.

‘I didn’t know it was like that, certainly,’ said K. ‘I couldn’t know of all these peculiarities, but I didn’t put much confidence in those telephone conversations and I was always aware that the only things of any importance were those that happened in the Castle itself.’

‘No,’ said the Superintendent, holding firmly onto the word, ‘these telephone replies from the Castle certainly have a meaning, why shouldn’t they? How could a message given by an official from the Castle not be important?’

The supreme genius of Kafka was to have explored the negative atheology proper to Capital: the centre is missing, but we cannot stop searching for it or positing it. It is not that there is nothing there – it is that what is there is not capable of exercising responsibility.

This problem is addressed from another angle in a paper by Campbell Jones entitled ‘The Subject Supposed To Recycle’. In posing the question, ‘who is the subject supposed to recycle?’ Jones denaturalizes an imperative that is now so taken for granted that resisting it seems senseless, never mind unethical. Everyone is supposed to recycle; no-one, whatever their political persuasion, ought to resist this injunction. The demand that we recycle is precisely posited as a pre- or post-ideological imperative; in other words, it is positioned in precisely the space where ideology always does its work. But the subject supposed to recycle, Jones argued, presupposed the structure not supposed to recycle: in making recycling the responsibility of ‘everyone’, structure contracts out its responsibility to consumers, by itself receding into invisibility. Now, when the appeal to individual ethical responsibility has never been more clamorous – in her book Frames Of War, Judith Butler uses the term ‘responsibi-lization’ to refer to this phenomenon – it is necessary to wager instead on structure at its most totalizing. Instead of saying that everyone – i.e. every one – is responsible for climate change, we all have to do our bit, it would be better to say that no-one is, and that’s the very problem. The cause of eco-catastrophe is an impersonal structure which, even though it is capable of producing all manner of effects, is precisely not a subject capable of exercising responsibility. The required subject – a collective subject - does not exist, yet the crisis, like all the other global crises we’re now facing, demands that it be constructed. Yet the appeal to ethical immediacy that has been in place in British political culture since at least 1985 – when the consensual sentimentality of Live Aid replaced the antagonism of the Miners Strike – permanently defers the emergence of such a subject.

Similar issues are touched on in a paper by Armin Beverungen on Alan Pakula’s 1974 film The Parallax View, which sees The Parallax View as providing a kind of diagram of the way in which a certain model of (business) ethics goes wrong. The problem is that the model of individual responsibility assumed by most versions of ethics have little purchase on the behavior of Capital or corporations. The Parallax View is in a sense a meta-conspiracy film: a film not only about conspiracies but about the impotence of attempts to uncover them; or, much worse than that, about the way in which particular kinds of investigation feed the very conspiracies they intend to uncover. It is not only that the Warren Beatty character is framed/killed for the crime he is investigating, neatly eliminating him and undermining his investigations with one pull of a corporate assassins trigger; it’s that, as Jameson noted in his commentary on the film in The Geopolitical Aesthetic, his very tenacity, quasi-sociopathic individualism, make him eminently frameable.

The terrifying climactic moment of The Parallax View – when the silhouette of Beatty’s anonymous assassin appears against migraine-white space – for me now rhymes with the open door at the end of a very different film, Peter Weir’s The Truman Show. But where the door in the horizon opening onto black space at the end of Weir’s film connotes a break in a universe of total determinism, the nothingness on which existentialist freedom depends, The Parallax View’s ‘final open door ... opens onto a world conspiratorially organized and controlled as far as the eye can see’ (Jameson). This anonymous figure with a rifle in a doorway is the closest we get to seeing the conspiracy (as) itself. The conspiracy in The Parallax View never gives any account of itself. It is never focalised through a single malign individual. Although presumably corporate, the interests and motives of the conspiracy in The Parallax View are never articulated (perhaps not even to or by those actually involved in it). Who knows what the Parallax Corporation really wants? It is itself situated in the parallax between politics and economy. Is it a commercial front for political interests, or is the whole machinery of government a front for it? It’s not clear if the Corporation really exists – more than that, it is not clear if its aim is to pretend that it doesn’t exist, or to pretend that it does.

There are certainly conspiracies in capitalism, but the problem is that they are themselves only possible because of deeper level structures that allow them to function. Does anyone really think, for instance, that things would improve if we replaced the whole managerial and banking class with a whole new set of (‘better’) people? Surely, on the contrary, it is evident that the vices are engendered by the structure, and that while the structure remains, the vices will reproduce themselves. The strength of Pakula’s film is precisely to invoke the shadowy, centerless impersonality proper to a corporate conspiracy. As Jameson observes, what Pakula captures so well in The Parallax View is a particular kind of corporate affective tonality:

For the agents of conspiracy, Sorge [conern] is a matter of smiling confidence, and the preoccupation is not personal but corporate, concern for the vitality of the network or the institution, a disembodied distraction or inattentiveness engaging the absent space of the collective organization itself without the clumsy conjectures that sap the energies of the victims. These people know, and are therefore able to invest their presence as characters in an intense yet complacent attention whose centre of gravity is elsewhere: a rapt intentness which is at the same time disinterest. Yet this very different type of concern, equally depersonalised, carries its own specific anxiety with it, as it were unconsciously and corporately, without any consequences for the individual villains.

... without any consequences for the individual villains... How that phrase resonates just now – after the deaths of Jean Charles De Menezes and Ian Tomlinson and after the banking fiasco. And what Jameson is describing here is the mortifying cocoon of corporate structure – which deadens as it protects, which hollows out, absents, the manager, ensures that their attention is always displaced, ensures that they cannot listen. The delusion that many who enter into management with high hopes is precisely that they, the individual, can change things, that they will not repeat what their managers had done, that things will be different this time; but watch someone step up into management and it’s usually not very long before the grey petrification of power starts to subsume them. It is here that structure is palpable – you can practically see it taking people over, hear its deadened/ deadening judgements speaking through them.

For this reason, it is a mistake to rush to impose the individual ethical responsibility that the corporate structure deflects. This is the temptation of the ethical which, as Žižek has argued, the capitalist system is using in order to protect itself in the wake of the credit crisis – the blame will be put on supposedly pathological individuals, those ‘abusing the system’, rather than on the system itself. But the evasion is actually a two step procedure – since structure will often be invoked (either implicitly or openly) precisely at the point when there is the possibility of individuals who belong to the corporate structure being punished. At this point, suddenly, the causes of abuse or atrocity are so systemic, so diffuse, that no individual can be held responsible. This was what happened with the Hillsborough football disaster, the Jean Charles De Menezes farce and so many other cases. But this impasse – it is only individuals that can be held ethically responsible for actions, and yet the cause of these abuses and errors is corporate, systemic – is not only a dissimulation: it precisely indicates what is lacking in capitalism. What agencies are capable of regulating and controlling impersonal structures? How is it possible to chastise a corporate structure? Yes, corporations can legally be treated as individuals – but the problem is that corporations, whilst certainly entities, are not like individual humans, and any analogy between punishing corporations and punishing individuals will therefore necessarily be poor. And it is not as if corporations are the deep-level agents behind everything; they are themselves constrained by/ expressions of the ultimate cause-that-is-not-a-subject: Capital.

Nothing could be a clearer illustration of what Žižek has identified as the failure of the Father function, the crisis of the paternal superego in late capitalism, than a typical edition of Supernanny. The program offers what amounts to a relentless, although of course implicit, attack on postmodernity’s permissive hedonism. Supernanny is a Spinozist insofar as, like Spinoza, she takes it for granted that children are in a state of abjection. They are unable to recognize their own interests, unable to apprehend either the causes of their actions or their (usually deleterious) effects. But the problems that Supernanny confronts do not arise from the actions or character of the children – who can only be expected to be idiotic hedonists – but with the parents. It is the parents’ following of the trajectory of the pleasure principle, the path of least resistance, that causes most of the misery in the families. In a pattern that quickly becomes familiar, the parents’ pursuit of the easy life leads them to accede to their children’s every demand, which become increasingly tyrannical.

Rather like many teachers or other workers in what used to be called ‘public service’, Supernanny has to sort out problems of socialization that the family can no longer resolve. A Marxist Supernanny would of course turn away from the troubleshooting of individual families to look at the structural causes which produce the same repeated effect.

The problem is that late capitalism insists and relies upon the very equation of desire with interests that parenting used to be based on rejecting. In a culture in which the ‘paternal’ concept of duty has been subsumed into the ‘maternal’ imperative to enjoy, it can seem that the parent is failing in their duty if they in any way impede their children’s absolute right to enjoyment. Partly this is an effect of the increasing requirement that both parents work; in these conditions, when the parent sees the child very little, the tendency will often be to refuse to occupy the ‘oppressive’ function of telling the child what to do. The parental disavowal of this role is doubled at the level of cultural production by the refusal of ‘gatekeepers’ to do anything but give audiences what they already (appear to) want. The concrete question is: if a return to the paternal superego – the stern father in the home, Reithian superciliousness in broadcasting – is neither possible nor desirable, then how are we to move beyond the culture of monotonous moribund conformity that results from a refusal to challenge or educate? A question as massive as this cannot of course be finally answered in a short book such as this, and what follows here will amount to a few starting points and suggestions. In brief, though, I believe that it is Spinoza who offers the best resources for thinking through what a ‘paternalism without the father’ might look like.

In Tarrying with the Negative, Žižek famously argues that a certain Spinozism is the ideology of late capitalism. Žižek believes that Spinoza’s rejection of deontology for an ethics based around the concept of health is allegedly flat with capitalism’s amoral affective engineering. The famous example here is Spinoza’s reading of the myth of the Fall and the foundation of Law. On Spinoza’s account, God does not condemn Adam for eating the apple because the action is wrong; he tells him that he should not consume the apple because it will poison him. For Žižek, this dramatizes the termination of the Father function. An act is wrong not because Daddy says so; Daddy only says it is ‘wrong’ because performing the act will be harmful to us. In Žižek’s view, Spinoza’s move both deprives the grounding of Law in a sadistic act of scission (the cruel cut of castration), at the same time as it denies the ungrounded positing of agency in an act of pure volition, in which the subject assumes responsibility for everything. In fact, Spinoza has immense resources for analyzing the affective regime of late capitalism, the video-drome-control apparatus described by Burroughs, Philip K. Dick and David Cronenberg in which agency is dissolved in a phantasmagoric haze of psychic and physical intoxicants. Like Burroughs, Spinoza shows that, far from being an aberrant condition, addiction is the standard state for human beings, who are habitually enslaved into reactive and repetitive behaviors by frozen images (of themselves and the world). Freedom, Spinoza shows, is something that can be achieved only when we can apprehend the real causes of our actions, when we can set aside the ‘sad passions’ that intoxicate and entrance us.

There’s no doubt that late capitalism certainly articulates many of its injunctions via an appeal to (a certain version of) health. The banning of smoking in public places, the relentless monstering of working class diet on programs like You Are What You Eat, do appear to indicate that we are already in the presence of a paternalism without the Father. It is not that smoking is ‘wrong’, it is that it will lead to our failing to lead long and enjoyable lives. But there are limits to this emphasis on good health: mental health and intellectual development barely feature at all, for instance. What we see instead is a reductive, hedonic model of health which is all about ‘feeling and looking good’. To tell people how to lose weight, or how to decorate their house, is acceptable; but to call for any kind of cultural improvement is to be oppressive and elitist. The alleged elitism and oppression cannot consist in the notion that a third party might know someone’s interest better than they know it themselves, since, presumably smokers are deemed either to be unaware of their interests or incapable of acting in accordance with them. No: the problem is that only certain types of interest are deemed relevant, since they reflect values that are held to be consensual. Losing weight, decorating your house and improving your appearance belong to the ‘consentimental’ regime.

In an excellent interview at the Register.com, the documentary film-maker Adam Curtis identifies the contours of this regime of affective management.

TV now tells you what to feel.

It doesn’t tell you what to think any more. From EastEnders to reality format shows, you’re on the emotional journey of people – and through the editing, it gently suggests to you what is the agreed form of feeling. “Hugs and Kisses”, I call it.

I nicked that off Mark Ravenhill who wrote a very good piece which said that if you analyse television now it’s a system of guidance – it tells you who is having the Bad Feelings and who is having the Good Feelings. And the person who is having the Bad Feelings is redeemed through a “hugs and kisses” moment at the end. It really is a system not of moral guidance, but of emotional guidance.

Morality has been replaced by feeling. In the ‘empire of the self everyone ‘feels the same’ without ever escaping a condition of solipsism. ‘What people suffer from,’ Curtis claims,

is being trapped within themselves - in a world of individualism everyone is trapped within their own feelings, trapped within their own imaginations. Our job as public service broadcasters is to take people beyond the limits of their own self, and until we do that we will carry on declining.

The BBC should realize that. I have an idealistic view, but if the BBC could do that, taking people beyond their own selves, it will renew itself in a way that jumps over the competition. The competition is obsessed by serving people in their little selves. And in a way, actually, Murdoch for all his power, is trapped by the self. That’s his job, to feed the self.

In the BBC, it’s the next step forward. It doesn’t mean we go back to the 1950s and tell people how to dress, what we do is say “we can free you from yourself” – and people would love it.

Curtis attacks the internet because, in his view, it facilitates communities of solipsists, interpassive networks of like-minds who confirm, rather than challenge, each others’ assumptions and prejudices. Instead of having to confront other points of view in a contested public space, these communities retreat into closed circuits. But, Curtis claims, the impact of internet lobbies on Old Media is disastrous, since, not only does its reactive pro-activity allow the media class to further abnegate its function to educate and lead, it also allows populist currents on both the left and the right to ‘bully’ media producers into turning out programming that is anodyne and mediocre.

Curtis’s critique has a point, but it misses important dimensions of what is happening on the net. Contrary to Curtis’s account of blogging, blogs can generate new discourse networks that have no correlate in the social field outside cyberspace. As Old Media increasingly becomes subsumed into PR and the consumer report replaces the critical essay, some zones of cyberspace offer resistance to a ‘critical compression’ that is elsewhere depressingly pervasive. Nevertheless, the interpassive simulation of participation in postmodern media, the network narcissism of MySpace and Facebook, has, in the main, generated content that is repetitive, parasitic and conformist. In a seeming irony, the media class’s refusal to be paternalistic has not produced a bottom-up culture of breathtaking diversity, but one that is increasingly infantilized. By contrast, it is paternalistic cultures that treat audiences as adults, assuming that they can cope with cultural products that are complex and intellectually demanding. The reason that focus groups and capitalist feedback systems fail, even when they generate commodities that are immensely popular, is that people do not know what they want. This is not only because people’s desire is already present but concealed from them (although this is often the case). Rather, the most powerful forms of desire are precisely cravings for the strange, the unexpected, the weird. These can only be supplied by artists and media professionals who are prepared to give people something different from that which already satisfies them; by those, that is to say, prepared to take a certain kind of risk. The Marxist Supernanny would not only be the one who laid down limitations, who acted in our own interests when we are incapable of recognizing them ourselves, but also the one prepared to take this kind of risk, to wager on the strange and our appetite for it. It is another irony that capitalism’s ‘society of risk’ is much less likely to take this kind of risk than was the supposedly stodgy, centralized culture of the postwar social consensus. It was the public service-oriented BBC and Channel 4 that perplexed and delighted me with the likes of Tinker, Tailor, Soldier Spy, Pinter plays and Tarkovsky seasons; it was this BBC that also funded the popular avant gardism of the BBC Radiophonic Workshop, which embedded sonic experimentalism into everyday life. Such innovations are unthinkable now that the public has been displaced by the consumer. The effect of permanent structural instability, the ‘cancellation of the long term’, is invariably stagnation and conservatism, not innovation. This is not a paradox. As Adam Curtis’s remarks above make clear, the affects that predominate in late capitalism are fear and cynicism. These emotions do not inspire bold thinking or entrepreneurial leaps, they breed conformity and the cult of the minimal variation, the turning out of products which very closely resemble those that are already successful. Meanwhile, films such as the aforementioned Tarkovsky’s Solaris and Stalker -plundered by Hollywood since as far back as Alien and Blade Runner – were produced in the ostensibly moribund conditions of the Brezhnevite Soviet state, meaning that the USSR acted as a cultural entrepreneur for Hollywood. Since it is now clear that a certain amount of stability is necessary for cultural vibrancy, the question to be asked is: how can this stability be provided, and by what agencies?

It’s well past time for the left to cease limiting its ambitions to the establishing of a big state. But being ‘at a distance from the state’ does not mean either abandoning the state or retreating into the private space of affects and diversity which Žižek rightly argues is the perfect complement to neoliberalism’s domination of the state. It means recognizing that the goal of a genuinely new left should be not be to take over the state but to subordinate the state to the general will. This involves, naturally, resuscitating the very concept of a general will, reviving – and modernizing – the idea of a public space that is not reducible to an aggregation of individuals and their interests. The ‘methodological individualism’ of the capitalist realist worldview presupposes the philosophy of Max Stirner as much as that of Adam Smith or Hayek in that it regards notions such as the public as ‘spooks’, phantom abstractions devoid of content. All that is real is the individual (and their families). The symptoms of the failures of this worldview are everywhere – in a disintegrated social sphere in which teenagers shooting each other has become commonplace, in which hospitals incubate aggressive superbugs – what is required is that effect be connected to structural cause. Against the postmodernist suspicion of grand narratives, we need to reassert that, far from being isolated, contingent problems, these are all the effects of a single systemic cause: Capital. We need to begin, as if for the first time, to develop strategies against a Capital which presents itself as ontologically, as well as geographically, ubiquitous.

Despite initial appearances (and hopes), capitalist realism was not undermined by the credit crisis of 2008. The speculations that capitalism might be on the verge of collapsing soon proved to be unfounded. It quickly became clear that, far from constituting the end of capitalism, the bank bail-outs were a massive re-assertion of the capitalist realist insistence that there is no alternative. Allowing the banking system to disintegrate was held to be unthinkable, and what ensued was a vast hemor-rhaging of public money into private hands. Nevertheless, what did happen in 2008 was the collapse of the framework which has provided ideological cover for capitalist accumulation since the 1970s. After the bank bail-outs neoliberalism has, in every sense, been discredited. That is not to say that neoliberalism has disappeared overnight; on the contrary, its assumptions continue to dominate political economy, but they do so now no longer as part of an ideological project that has a confident forward momentum, but as inertial, undead defaults. We can now see that, while neoliberalism was necessarily capitalist realist, capitalist realism need not be neoliberal. In order to save itself, capitalism could revert to a model of social democracy or to a Children of Men–like authoritarianism. Without a credible and coherent alternative to capitalism, capitalist realism will continue to rule the political-economic unconscious.

But even if it is now evident that the credit crisis will not lead to the end of capitalism all by itself, the crisis has led to the relaxing of a certain kind of mental paralysis. We are now in a political landscape littered with what Alex Williams called ‘ideological rubble’ – it is year zero again, and a space has been cleared for a new anti-capitalism to emerge which is not necessarily tied to the old language or traditions. One of the left’s vices is its endless rehearsal of historical debates, its tendency to keep going over Kronsdadt or the New Economic Policy rather than planning and organizing for a future that it really believes in. The failure of previous forms of anti-capitalist political organization should not be a cause for despair, but what needs to be left behind is a certain romantic attachment to the politics of failure, to the comfortable position of a defeated marginality. The credit crisis is an opportunity – but it needs to be treated as a tremendous speculative challenge, a spur for a renewal that is not a return. As Badiou has forcefully insisted, an effective anti-capitalism must be a rival to Capital, not a reaction to it; there can be no return to pre-capitalist territorialities. Anti-capitalism must oppose Capital’s globalism with its own, authentic, universality.

It is crucial that a genuinely revitalized left confidently occupy the new political terrain I have (very provisionally) sketched here. Nothing is inherently political; politicization requires a political agent which can transform the taken-for-granted into the up-for-grabs. If neoliberalism triumphed by incorporating the desires of the post 68 working class, a new left could begin by building on the desires which neoliberalism has generated but which it has been unable to satisfy. For example, the left should argue that it can deliver what neoliberalism signally failed to do: a massive reduction of bureaucracy. What is needed is a new struggle over work and who controls it; an assertion of worker autonomy (as opposed to control by management) together with a rejection of certain kinds of labor (such as the excessive auditing which has become so central feature of work in post-Fordism). This is a struggle that can be won – but only if a new political subject coalesces; it is an open question as to whether the old structures (such as the trade unions) will be capable of nurturing that subjectivity, or whether it will entail the formation of wholly new political organizations. New forms of industrial action need to be instituted against managerialism. For instance, in the case of teachers and lecturers, the tactic of strikes (or even of marking bans) should be abandoned, because they only hurt students and members (at the college where I used to work, one-day strikes were pretty much welcomed by management because they saved on the wage bill whilst causing negligible disruption to the college). What is needed is the strategic withdrawal of forms of labor which will only be noticed by management: all of the machineries of self-surveillance that have no effect whatsoever on the delivery of education, but which managerialism could not exist without. Instead of the gestural, spectacular politics around (noble) causes like Palestine, it’s time that teaching unions got far more immanent, and take the opportunity opened up by the crisis to begin to rid public services of business ontology. When even businesses can’t be run as businesses, why should public services?

We must convert widespread mental health problems from medicalized conditions into effective antagonisms. Affective disorders are forms of captured discontent; this disaffection can and must be channeled outwards, directed towards its real cause, Capital. Furthermore, the proliferation of certain kinds of mental illness in late capitalism makes the case for a new austerity, a case that is also made by the increasing urgency of dealing with environmental disaster. Nothing contradicts capitalism’s constitutive imperative towards growth more than the concept of rationing goods and resources. Yet it is becoming uncomfortably clear that consumer self-regulation and the market will not by themselves avert environmental catastrophe. There is a libidinal, as well as a practical case, to be made for this new ascesis. If, as Oliver James, Žižek and Supernanny have shown, unlimited license leads to misery and disaffection, then limitations placed on desire are likely to quicken, rather than deaden, it. In any case, rationing of some sort is inevitable. The issue is whether it will be collectively managed, or whether it will be imposed by authoritarian means when it is already too late. Quite what forms this collective management should take is, again, an open question, one that can only be resolved practically and experimentally.

The long, dark night of the end of history has to be grasped as an enormous opportunity. The very oppressive pervasiveness of capitalist realism means that even glimmers of alternative political and economic possibilities can have a disproportionately great effect. The tiniest event can tear a hole in the grey curtain of reaction which has marked the horizons of possibility under capitalist realism. From a situation in which nothing can happen, suddenly anything is possible again.

Where did the future go? For much of the twentieth century, the future held sway over our dreams. On the horizons of the political left a vast assortment of emancipatory visions gathered, often springing from the conjunction of popular political power and the liberating potential of technology. From predictions of new worlds of leisure, to Soviet-era cosmic communism, to afro-futurist celebrations of the synthetic and diasporic nature of black culture, to post-gender dreams of radical feminism, the popular imagination of the left envisaged societies vastly superior to anything we dream of today.1 Through popular political control of new technologies, we would collectively transform our world for the better. Today, on one level, these dreams appear closer than ever. The technological infrastructure of the twenty-first century is producing the resources by which a very different political and economic system could be achieved. Machines are accomplishing tasks that were unimaginable a decade ago. The internet and social media are giving a voice to billions who previously went unheard, bringing global participative democracy closer than ever to existence. Open-source designs, copyleft creativity, and 3D printing all portend a world where the scarcity of many products might be overcome. New forms of computer simulation could rejuvenate economic planning and give us the ability to direct economies rationally in unprecedented ways. The newest wave of automation is creating the possibility for huge swathes of boring and demeaning work to be permanently eliminated. Clean energy technologies make possible virtually limitless and environmentally sustainable forms of power production. And new medical technologies not only enable a longer, healthier life, but also make possible new experiments with gender and sexual identity. Many of the classic demands of the left – for less work, for an end to scarcity, for economic democracy, for the production of socially useful goods, and for the liberation of humanity – are materially more achievable than at any other point in history.

Yet, for all the glossy sheen of our technological era, we remain bound by an old and obsolete set of social relations. We continue to work long hours, commuting further, to perform tasks that feel increasingly meaningless. Our jobs have become more insecure, our pay has stagnated, and our debt has become overwhelming. We struggle to make ends meet, to put food on the table, to pay the rent or mortgage, and as we shuffle from job to job, we reminisce about pensions and struggle to find affordable childcare. Automation renders us unemployed and stagnant wages devastate the middle class, while corporate profits surge to new heights. The glimmers of a better future are trampled and forgotten under the pressures of an increasingly precarious and demanding world. And each day, we return to work as normal: exhausted, anxious, stressed and frustrated.

At a planetary level, things appear even more ominous. The breakdown of the global climate continues unabated, and the ongoing fallout from the economic crisis has led governments to embrace the paralysing death-spiral of austerity. Buffeted by imperceptible and abstract powers, we feel incapable of evading or controlling the tidal pulsions of economic, social and environmental forces. But how are we to change this? All around us, it seems that the political systems, movements and processes that dominated the last hundred years are no longer able to bring about genuinely transformative change. Instead, they have forced us onto an endless treadmill of misery. Electoral democracy lies in remarkable disrepair. Centre-left political parties have been hollowed out and sapped of any popular mandate. Their corpses stumble on as vehicles for careerist ambitions. Radical political movements bloom promisingly but are quickly snuffed out by exhaustion and repression. Organised labour has seen its power systematically taken apart, leaving it sclerotic and incapable of anything more than feeble resistance. Yet, in the face of these calamities, today’s politics remains stubbornly beset by a lack of new ideas. Neoliberalism has held sway for decades, and social democracy exists largely as an object of nostalgia. As crises gather force and speed, politics withers and retreats. In this paralysis of the political imaginary, the future has been cancelled.2

This book is about how we got here, and where we might go next. Using an idea we call ‘folk politics’, we offer a diagnosis of how and why we lost the capacity to build a better future. Under the sway of folk-political thinking, the most recent cycle of struggles – from anti-globalisation to anti-war to Occupy Wall Street – has involved the fetishisation of local spaces, immediate actions, transient gestures, and particularisms of all kinds. Rather than undertake the difficult labour of expanding and consolidating gains, this form of politics has focused on building bunkers to resist the encroachments of global neoliberalism. In so doing, it has become a politics of defence, incapable of articulating or building a new world. For any movement that struggles to escape neoliberalism and build something better, these folk-political approaches are insufficient. In their place, this book sets out an alternative politics – one that seeks to take back control over our future and to foster the ambition for a world more modern than capitalism will allow. The utopian potentials inherent in twenty-first-century technology cannot remain bound to a parochial capitalist imagination; they must be liberated by an ambitious left alternative. Neoliberalism has failed, social democracy is impossible, and only an alternative vision can bring about universal prosperity and emancipation. Articulating and achieving this better world is the fundamental task of the left today.

Today it appears that the greatest amount of effort is needed to achieve the smallest degree of change. Millions march against the Iraq War, yet it goes ahead as planned. Hundreds of thousands protest austerity, but unprecedented budget cuts continue. Repeated student protests, occupations and riots struggle against rises in tuition fees, but they continue their inexorable advance. Around the world, people set up protest camps and mobilise against economic inequality, but the gap between the rich and the poor keeps growing. From the alter-globalisation struggles of the late 1990s, through the antiwar and ecological coalitions of the early 2000s, and into the new student uprisings and Occupy movements since 2008, a common pattern emerges: resistance struggles rise rapidly, mobilise increasingly large numbers of people, and yet fade away only to be replaced by a renewed sense of apathy, melancholy and defeat. Despite the desires of millions for a better world, the effects of these movements prove minimal.

A FUNNY THING HAPPENED ON THE WAY TO THE PROTEST

Failure permeates this cycle of struggles, and as a result, many of the tactics on the contemporary left have taken on a ritualistic nature, laden with a heavy dose of fatalism. The dominant tactics – protesting, marching, occupying, and various other forms of direct action – have become part of a well-established narrative, with the people and the police each playing their assigned roles. The limits of these actions are particularly visible in those brief moments when the script changes. As one activist puts it, of a protest at the 2001 Summit of the Americas:

On April 20, the first day of the demonstrations, we marched in our thousands towards the fence, behind which 34 heads of state had gathered to hammer out a hemispheric trade deal. Under a hail of catapult-launched teddy bears, activists dressed in black quickly removed the fence’s supports with bolt cutters and pulled it down with grapples as onlookers cheered them on. For a brief moment, nothing stood between us and the convention centre. We scrambled atop the toppled fence, but for the most part we went no further, as if our intention all along had been simply to replace the state’s chain-link and concrete barrier with a human one of our own making.

We see here the symbolic and ritualistic nature of the actions, combined with the thrill of having done something – but with a deep uncertainty that appears at the first break with the expected narrative. The role of dutiful protestor had given these activists no indication of what to do when the barriers fell. Spectacular political confrontations like the Stop the War marches, the now-familiar melees against the G20 or World Trade Organization and the rousing scenes of democracy in Occupy Wall Street all give the appearance of being highly significant, as if something were genuinely at stake. Yet nothing changed, and long-term victories were traded for a simple registration of discontent.

To outside observers, it is often not even clear what the movements want, beyond expressing a generalised discontent with the world. The contemporary protest has become a melange of wild and varied demands. The 2009 G20 summit in London, for instance, featured protestors marching for issues that spanned from grandiose anti-capitalist stipulations to modest goals centred on more local issues. When demands can be discerned at all, they usually fail to articulate anything substantial. They are often nothing more than empty slogans – as meaningful as calling for world peace. In more recent struggles, the very idea of making demands has been questioned. The Occupy movement infamously struggled to articulate meaningful goals, worried that anything too substantial would be divisive. And a broad range of student occupations across the Western world has taken up the mantra of ‘no demands’ under the misguided belief that demanding nothing is a radical act.

When asked what the ultimate upshot of these actions has been, participants differ between admitting to a general sense of futility and pointing to the radicalisation of those who took part. If we look at protests today as an exercise in public awareness, they appear to have had mixed success at best. Their messages are mangled by an unsympathetic media smitten by images of property destruction – assuming that the media even acknowledges a form of contention that has become increasingly repetitive and boring. Some argue that, rather than trying to achieve a certain end, these movements, protests and occupations in fact exist only for their own sake. The aim in this case is to achieve a certain transformation of the participants, and create a space outside of the usual operations of power. While there is a degree of truth to this, things like protest camps tend to remain ephemeral, small-scale and ultimately unable to challenge the larger structures of the neoliberal economic system. This is politics transmuted into pastime – politics-as-drug-experience, perhaps – rather than anything capable of transforming society. Such protests are registered only in the minds of their participants, bypassing any transformation of social structures. While these efforts at radicalisation and awareness-raising are undoubtedly important to some degree, there still remains the question of exactly when these sequences might pay off. Is there a point at which a critical mass of consciousness-raising will be ready for action? Protests can build connections, encourage hope and remind people of their power. Yet, beyond these transient feelings, politics still demands the exercise of that power, lest these affective bonds go to waste. If we will not act after one of the largest crises of capitalism, then when?

The emphasis on the affective aspects of protests plays into a broader trend that has come to privilege the affective as the site of real politics. Bodily, emotional and visceral elements come to replace and stymie (rather than complement and enhance) more abstract analysis. The contemporary landscape of social media, for example, is littered with the bitter fallout from an endless torrent of outrage and anger. Given the individualism of current social media platforms – premised on the maintenance of an online identity – it is perhaps no surprise to see online ‘politics’ tend towards the self-presentation of moral purity. We are more concerned to appear right than to think about the conditions of political change. Yet these daily outrages pass as rapidly as they emerge, and we are soon on to the next vitriolic crusade. In other places, public demonstrations of empathy with those suffering replace more finely tuned analysis, resulting in hasty or misplaced action – or none at all. While politics always has a relationship to emotion and sensation (to hope or anger, fear or outrage), when taken as the primary mode of politics, these impulses can lead to deeply perverse results. In a famous example, 1985’s Live Aid raised huge amounts of money for famine relief through a combination of heartstring-tugging imagery and emotionally manipulative celebrity-led events. The sense of emergency demanded urgent action, at the expense of thought. Yet the money raised actually extended the civil war causing the famine, by allowing rebel militias to use the food aid to support themselves. While viewers at home felt comforted they were doing something rather than nothing, a dispassionate analysis revealed that they had in fact contributed to the problem. These unintended outcomes become even more pervasive as the targets of action grow larger and more abstract. If politics without passion leads to cold-hearted, bureaucratic technocracy, then passion bereft of analysis risks becoming a libidinally driven surrogate for effective action. Politics comes to be about feelings of personal empowerment, masking an absence of strategic gains.

Perhaps most depressing, even when movements have some successes, they are in the context of overwhelming losses. Residents across the UK, for example, have successfully mobilised in particular cases to stop the closure of local hospitals. Yet these real successes are overwhelmed by larger plans to gut and privatise the National Health Service. Similarly, recent anti-fracking movements have been able to stop test drilling in various localities – but governments nevertheless continue to search for shale gas resources and provide support for companies to do so. In the United States, various movements to stop evictions in the wake of the housing crisis have made real gains in terms of keeping people in their homes. Yet the perpetrators of the subprime mortgage debacle continue to reap the profits, waves of foreclosures continue to sweep across the country, and rents continue to surge across the urban world. Small successes – useful, no doubt, for instilling a sense of hope – nevertheless wither in the face of overwhelming losses. Even the most optimistic activist falters in the face of struggles that continue to fail. In other cases, well-intentioned projects like Rolling Jubilee strive to escape the spell of neoliberal common sense. The ostensibly radical aim of crowdsourcing money to pay the debts of the underprivileged means buying into a system of voluntary charity and redistribution, as well as accepting the legitimacy of the debt in the first place. In this respect, the initiative is one among a larger group of projects that act simply as crisis responses to the faltering of state services. These are survival mechanisms, not a desirable vision for the future.

What can we conclude from all of this? The recent cycle of struggles has to be identified as one of overarching failure, despite a multitude of small-scale successes and moments of large-scale mobilisation. The question that any analysis of the left today must grapple with is simply: What has gone wrong? It is undeniable that heightened repression by states and the increased power of corporations have played a significant role in weakening the power of the left. Still, it remains debatable whether the repression faced by workers, the precarity of the masses and the power of capitalists is any greater than it was in the late nineteenth century. Workers then were still struggling for basic rights, often against states more than willing to use lethal violence against them. But whereas that period saw mass mobilisation, general strikes, militant labour and radical women’s organisations all achieving real and lasting successes, today is defined by their absence. The recent weakness of the left cannot simply be chalked up to increased state and capitalist repression: an honest reckoning must accept that problems also lie within the left. One key problem is a widespread and uncritical acceptance of what we call ‘folk-political’ thinking.

What is folk politics? Folk politics names a constellation of ideas and intuitions within the contemporary left that informs the common-sense ways of organising, acting and thinking politics. It is a set of strategic assumptions that threatens to debilitate the left, rendering it unable to scale up, create lasting change or expand beyond particular interests. Leftist movements under the sway of folk politics are not only unlikely to be successful – they are in fact incapable of transforming capitalism. The term itself draws upon two senses of ‘folk’. First, it evokes critiques of folk psychology which argue that our intuitive conceptions of the world are both historically constructed and often mistaken. Secondly, it refers to ‘folk’ as the locus of the small-scale, the authentic, the traditional and the natural. Both of these dimensions are implied in the idea of folk politics.

As a first approximation, we can therefore define folk politics as a collective and historically constructed political common sense that has become out of joint with the actual mechanisms of power. As our political, economic, social and technological world changes, tactics and strategies which were previously capable of transforming collective power into emancipatory gains have now become drained of their effectiveness. As the common sense of today’s left, folk politics often operates intuitively, uncritically and unconsciously. Yet common sense is also historical and mutable. It is worth recalling that today’s familiar forms of organisation and tactics, far from being natural or pre-given, have instead been developed over time in response to specific political problems. Petitions, occupations, strikes, vanguard parties, affinity groups, trade unions: all arose out of particular historical conditions. Yet the fact that certain ways of organising and acting were once useful does not guarantee their continued relevance. Many of the tactics and organisational structures that dominate the contemporary left are responses to the experience of state communism, exclusionary trade unions, and the collapse of social democratic parties. Yet the ideas that made sense in the wake of those moments no longer present effective tools for political transformation. Our world has moved on, becoming more complex, abstract, nonlinear and global than ever before.

Against the abstraction and inhumanity of capitalism, folk politics aims to bring politics down to the ‘human scale’ by emphasising temporal, spatial and conceptual immediacy. At its heart, folk politics is the guiding intuition that immediacy is always better and often more authentic, with the corollary being a deep suspicion of abstraction and mediation. In terms of temporal immediacy, contemporary folk politics typically remains reactive (responding to actions initiated by corporations and governments, rather than initiating actions); ignores long-term strategic goals in favour of tactics (mobilising around single-issue politics or emphasising process); prefers practices that are often inherently fleeting (such as occupations and temporary autonomous zones); chooses the familiarities of the past over the unknowns of the future (for instance, the repeated dreams of a return to ‘good’ Keynesian capitalism); and expresses itself as a predilection for the voluntarist and spontaneous over the institutional (as in the romanticisation of rioting and insurrection).

In terms of spatial immediacy, folk politics privileges the local as the site of authenticity (as in the 100-miles diet or local currencies); habitually chooses the small over the large (as in the veneration of small-scale communities or local businesses); favours projects that are un-scalable beyond a small community (for instance, general assemblies and direct democracy); and often rejects the project of hegemony, valuing withdrawal or exit rather than building a broad counter-hegemony. Likewise, folk politics prefers that actions be taken by participants themselves – in its emphasis on direct action, for example – and sees decision-making as something to be carried out by each individual rather than by any representative. The problems of scale and extension are either ignored or smoothed over in folk-political thinking.

Finally, in terms of conceptual immediacy, there is a preference for the everyday over the structural, valorising personal experience over systematic thinking; for feeling over thinking, emphasising individual suffering, or the sensations of enthusiasm and anger experienced during political actions; for the particular over the universal, seeing the latter as intrinsically totalitarian; and for the ethical over the political – as in ethical consumerism, or moralising critiques of greedy bankers. Organisations and communities are to be transparent, rejecting in advance any conceptual mediation, or even modest amounts of complexity. The classic images of universal emancipation and global change have been transformed into a prioritisation of the suffering of the particular and the authenticity of the local. As a result, any process of constructing a universal politics is rejected from the outset.

Understood in these ways, we can detect traces of folk politics in organisations and movements like Occupy, Spain’s 15M, student occupations, left communist insurrectionists like Tiqqun and the Invisible Committee, most forms of horizontalism, the Zapatistas, and contemporary anarchist-tinged politics, as well as a variety of other trends like political localism, the slow-food movement, and ethical consumerism, among many others. But no single position embodies all of these dispositions, which leads us to a first qualification: as an uncritical and often unconscious common sense, folk politics comes to be instantiated to varying degrees in concrete political positions. That is to say, folk politics does not name an explicit position, but only an implicit tendency. The ideas that characterise this tendency are widely dispersed throughout the contemporary left, but some positions are more folk-political than others. This brings us to a second important qualification: the problem with folk politics is not that it starts from the local; all politics begins from the local. The problem is rather that folk-political thinking is content to remain at (and even privileges) that level – of the transient, the small-scale, the unmediated and the particular. It takes these to be sufficient rather than simply necessary moments. Therefore, the point is not simply to reject folk politics. Folk politics is a necessary component of any successful political project, but it can only be a starting point. A third qualification is that folk politics is only a problem for particular types of projects: those that seek to move beyond capitalism. Folk-political thinking can be perfectly well adapted to other political projects: projects aimed solely at resistance, movements organised around local issues, and small-scale projects. Political movements based around keeping a hospital open or preventing evictions are all admirable, but they are importantly different from movements trying to challenge neoliberal capitalism. The idea that one organisation, tactic or strategy applies equally well to any sort of struggle is one of the most pervasive and damaging beliefs among today’s left. Strategic reflection – on means and ends, enemies and allies – is necessary before approaching any political project. Given the nature of global capitalism, any postcapitalist project will require an ambitious, abstract, mediated, complex and global approach – one that folk-political approaches are incapable of providing.

Combining these qualifications, we can therefore say that folk politics is necessary but insufficient for a postcapitalist political project. By emphasising and remaining at the level of the immediate, folk politics lacks the tools to transform neoliberalism into something else. While folk politics can undoubtedly make important interventions in local struggles, we deceive ourselves when we think these are turning the tide against global capitalism. They represent, at best, temporary respite against its onslaught. The project of this book is to begin outlining an alternative – a way for the left to navigate from the local to the global, and synthesise the particular with the universal. Such an alternative cannot simply be a conservative reversion to the working-class politics of the last century. It must instead combine an updated way of thinking politics (a shift from immediacy to structural analysis) with an upgraded means of doing politics (which directs action towards building platforms and expanding scales).

Why did folk politics arise in the first place? Why is it that folk political tendencies, for all their manifest flaws, are so seductive and appealing to the movements of today? At least three answers present themselves. The first explanation is to see folk politics as a response to the problem of how to interpret and act within an ever more complex world. The second, related explanation involves situating folk politics as a reaction to the historical experiences of the communist and social democratic left. Finally, folk politics is a more immediate response to the empty spectacle of contemporary party politics.

Increasingly, multipolar global politics, economic instability, and anthropogenic climate change outpace the narratives we use to structure and make sense of our lives. Each of these is an example of what is termed a complex system, which features nonlinear dynamics, where marginally different inputs can cause dramatically divergent outputs, intricate sets of causes feedback on one another in unexpected ways, and which characteristically operates on scales of space and time that go far beyond any individual’s unaided perception. Globalisation, international politics, and climate change: each of these systems shapes our world, but their effects are so extensive and complicated that it is difficult to place our own experience within them. The global economy is a good example of this. In simple terms, the economy is not an object amenable to direct perception; it is distributed across time and space (you will never meet ‘the economy’ in person); it incorporates a wide array of elements, from property laws to biological needs, natural resources to technological infrastructures, market stalls and supercomputers; and it involves an enormous and intricately interacting set of feedback loops, all of which produce emergent effects that are irreducible to its individual components. In other words, the interaction of an economy’s parts produces effects that cannot be understood just by knowing how those parts work in isolation – it is only in grasping the relations between them that the economy can be made sense of. While we might have an idea of what an economy consists of, we will never be able to experience it directly in the same way as other phenomena. It can only be observed symptomatically through key statistical indexes (charting changes in inflation or interest rates, stock indexes, GDP, and so on), but can never be seen, heard or touched in its totality.

As a result, despite everything that has been written about capitalism, we still struggle to understand its dynamics and its mechanisms. Most importantly, we lack a ‘cognitive map’ of our socioeconomic system: a mental picture of how individual and collective human action can be situated within the unimaginable vastness of the global economy. Recent decades have seen an increasing complexity in the dynamics that impinge upon politics. We might consider the imminent threat of anthropogenic climate change as a new kind of problem – one that is unamenable to any simple solution and that involves such intricately woven effects that it is hard to even know where to intervene. Equally, the global economy today appears significantly more complex in terms of the mobility of capital, the intricacies of global finance and the multiplicity of actors involved. How well do our traditional political images of the world map onto these changes? For the left at least, an analysis premised on the industrial working class was a powerful way to interpret the totality of social and economic relations in the nineteenth and early twentieth centuries, thereby articulating clear strategic objectives. Yet the history of the global left over the course of the twentieth century attests to the ways in which this analysis failed to attend to both the range of possible liberating struggles (based in gender, race or sexuality) and the ability of capitalism to restructure itself – through the creation of the welfare state, or the neoliberal transformations of the global economy. Today, the old models often falter in the face of new problems; we lose the capacity to understand our position in history and in the world at large.

This separation between everyday experience and the system we live within results in increased alienation: we feel adrift in a world we do not understand. The cultural theorist Fredric Jameson notes that the proliferation of conspiracy theories is partly a response to this situation. Conspiracy theories act by narrowing the agency behind our world to a single figure of power (the Bilderberg Group, the Freemasons or some other convenient scapegoat). Despite the extraordinary complexity of some of these theories, they nevertheless provide a reassuringly simple answer to ‘who is behind it all’, and what our own role is in the situation. In other words, they act precisely as a (faulty) cognitive map.

Folk politics presents itself as another possible response to the problems of overwhelming complexity. If we do not understand how the world operates, the folk-political injunction is to reduce complexity down to a human scale. Indeed, folk-political writing is saturated with calls for a return to authenticity, to immediacy, to a world that is ‘transparent’, ‘human-scaled’, ‘tangible’, ‘slow’, ‘harmonious’, ‘simple’, and ‘everyday’. Such thinking rejects the complexity of the contemporary world, and thereby rejects the possibility of a truly postcapitalist world. It attempts to give a human face to power; whereas what is truly terrifying is the generally asubjective nature of the system. The faces are interchangeable; the power remains the same. The turn towards localism, temporary moments of resistance, and the intuitive practices of direct action all effectively attempt to condense the problems of global capitalism into concrete figures and moments.

In this process, folk politics often reduces politics to an ethical and individual struggle. There is a tendency sometimes to imagine that we simply need ‘good’ capitalists, or a ‘responsible’ capitalism. At the same time, the imperative to ‘make it local’ leads folk politics to fetishise immediate results and the concrete appearance of action. Delaying a corporate attack on the environment, for instance, is lauded as a success – even if the company simply waits out public attention before returning once again. Moreover, as Rosa Luxemburg pointed out long ago, the fetishisation of ‘immediate results’ leads to an empty pragmatism that struggles to maintain the present balance of power, rather than seeking to change structural conditions. Without the necessary abstraction of strategic thought, tactics are ultimately fleeting gestures. Finally, the abjuring of complexity dovetails with the neoliberal case for markets. One of the primary arguments made against planning has been that the economy is simply too complex to be guided. The only alternative is therefore to leave the distribution of resources to the market and reject any attempt to guide it rationally. Considered in all these ways, folk politics appears as an attempt to make global capitalism small enough to be thinkable – and at the same time, to articulate how to act upon this restricted image of capitalism. By contrast, the argument of this book is that folk-political tendencies are mistaken. If complexity presently outstrips humanity’s capacities to think and control, there are two options: one is to reduce complexity down to a human scale; the other is to expand humanity’s capacities. We endorse the latter position. Any postcapitalist project will necessarily require the creation of new cognitive maps, political narratives, technological interfaces, economic models, and mechanisms of collective control to be able to marshal complex phenomena for the betterment of humanity.

While the response to increasing complexity goes some way towards explaining the rise of folk-political thinking, it must also be situated in terms of the particular history of left politics in the twentieth century. In many respects, folk-political tendencies are understandable (if inadequate) responses to the challenges faced in the last fifty years – challenges that have emerged both within the left and in competition with conservative and capitalist forces. In particular, folk politics emerged as a response to the collapse of the postwar social democratic complex that knitted together working-class institutions, social democratic parties, and the hegemony of embedded liberalism. The breakdown of this social democratic bloc occurred across multiple lines of conflict and in various spheres: in the emergence of new forms of work, associated with the affective and cognitive; in the emergence of energy crises that disrupted geopolitical certainties; in the increasing difficulties capitalist enterprises faced in achieving profitability; in the proliferation of neoliberal ideology through the institutional networks of think tanks and university departments; in the explosion of new forms of political subjectivities, projects and demands; and in the widespread discrediting of nominally communist states. Each of these factors served to disrupt the foundation of the postwar social system in Europe and America. In this process, there was both an outdating of old left paradigms and an outmanoeuvring of the new ones.

Perhaps the most significant point in this destabilisation of the postwar settlement was in the late 1960s and early 1970s. The global revolts of 1968 gave both new prominence and new inspiration to a series of left movements that rejected the coordinates of struggle articulated by labour unions and political parties. These movements were driven partly by the emerging history of Stalinist repression, and when combined with the Soviet regime’s suppression of democratising currents in Eastern Europe, this meant that communist parties were increasingly discredited in the eyes of young European leftists. This called into question the strategic validity of the Leninist programme of state-takeover by a revolutionary party leading a coalition of forces centred on the industrial working class. If even ‘successful’ revolutions led to sclerotic technocracy and political repression in the long term, what then was to be the properly emancipatory course of action? Hierarchy and vanguardism in the communist party increasingly appeared opposed to the aims of the emerging social movements.

Beyond the difficulties of transitioning to postcapitalism under a communist administration, the prospects for state-takeover in the developed nations in the 1960s and 1970s seemed slight, especially given the divisions emerging on the left. The uprisings in France in May 1968, in which the French Communist Party notably failed to back the unionists and student groups, seemingly brought to an end any prospect of a political revolution. In addition, social democracy and its Keynesian-corporatist solutions to social inequity appeared increasingly content with the existing order, and unable or unwilling to move towards an emancipatory socialism. Though social democracy was capable of offering significant gains to certain groups, it retained an authoritarian establishment and a paternalistic cast, generally exclusive of women and ethnic minorities, and was dependent upon a mode of capitalist organisation (Fordism) that generated unusual levels of social cohesion. It was this social cohesion that was eroded in the late 1960s and early 1970s by the emergence of new mass desires (for increased flexibility in work, for example) and newly insistent demands (for racial and gender equality, for nuclear disarmament, for sexual freedoms, and against Western imperialism). By the late 1960s, these new problems could no longer be resolved with the existing set of leftist political agents, and electoral pressures were beginning to transform the social democratic party from a mass party of the working class into an increasingly coalition-based party of the middle class. The remaining radical elements of social democratic parties were being slowly hollowed out.

The ongoing decline of the party form can be traced partly to the disastrous realities of rule in the nominally communist states and the disappointment of social democracy. At the same time, a series of well-founded critiques were marshalled from within the new left, prompted partly by the experiences of women in activist groups, who found their voices continued to be marginalised even in allegedly radical organisations. More hierarchical organisational forms, such as parties or traditional union organisations, continued to entrench the predominant patriarchal and sexist social relations prevalent in broader society. Considerable experimentation was therefore conducted to produce new organisational forms that could work against this social repression. This included the use of consensus decision-making and horizontal debating structures that would later come to worldwide fame with the Occupy Wall Street movement. Outside of feminist groups, the new student left of the university campuses, while diverse in its manifestations, was often explicitly anti-authoritarian, anti-bureaucratic, and even anti-organisational. Many of the tactics espoused by these groups emphasised the benefits of direct action and drew their influences from African-American civil rights movements and earlier student movements, as well as from the ideas of European Situationism, anarchist political currents, and the incipient environmental movement. Here we can see the emergence of folk politics’ basic strategic orientation and the modes of action that characterise it: from the occupation, sit-in, or squatted commune through to carnivalesque street protests and ‘happenings’. Each of these tactics emerged in this period as a way to disrupt the functioning of everyday power, suspend the ‘normal’ forms of social regulation and promote egalitarian spaces for discussion. Beyond trying to change society, these interventions aimed at transforming the participants themselves and embodying the new forms of sociality to come.

The movements that crystallised in the period were therefore diverse in their makeup and outlook, operating across various subjectivities, territorial locations, and tactical and strategic forms. But each of them, in its own way, articulated new desires that could not readily be accommodated within the old forms of left-wing politics. One way to consider these movements is as part of a generalised ‘antisystemic’ political phenomenon of the time. Across the globe, there was a tendency towards challenging and taking apart the power of bureaucratic hierarchies in favour of new modes of direct action, extending from the student, feminist and black power movements of the United States, through to the Situationist movement, student and allied labour movements of Europe, Prague’s anti-Stalinists, the student revolts of Mexico and Tokyo, and China’s Cultural Revolution. At its most extreme, however, this antisystemic politics led towards the identification of political power as inherently tainted by oppressive, patriarchal and domineering tendencies. This leaves something of a paradox. On the one hand, it could choose some form of negotiation or accommodation with existing power structures, which would tend towards the corruption or co-optation of the new left. But on the other hand, it could choose to remain marginal, and thereby unable to transform those elements of society not already convinced of its agenda. The critiques many of these antisystemic movements made of established forms of state, capitalist and old-left bureaucratic power were largely accurate. Yet antisystemic politics offered few resources to build a new movement capable of contending against capitalist hegemony.

The legacy of these social movements was therefore two-sided. The ideas, values and new desires articulated by them had a significant impact on a global level; the dissemination of feminist, anti-racist, gay-rights and anti-bureaucratic demands remains their strongest achievement. In this, they represented an absolutely necessary moment of self-critique by the left, and the legacy of folk-political tactics finds its appropriate historical conditions here. Simultaneously, however, an inability or lack of desire to turn the more radical sides of these projects into hegemonic ones also had important consequences for the period of destabilisation that followed. While capable of generating an array of new and powerful ideas of human freedom, the new social movements were generally unable to replace the faltering social democratic order.

Just as the new social movements were on the rise, the economic basis of the social democratic consensus was beginning to fall apart. The 1970s saw surging energy prices, the collapse of the Bretton Woods system, the growth of global capital flows, persistent stagflation and falling capitalist profits. This effectively ended the basic political settlement that had supported the postwar era: that unique nexus of Keynesian economic policy, Fordist–corporatist industrial production and the broadly social democratic consensus that returned a part of the social surplus back to workers. Across the world, the structural crisis presented an opportunity for the forces of both the broad left and the broad right to generate a new hegemony that could resolve it.

For the right, the challenge was to restore capital accumulation and profitability. This challenge was eventually answered by the emergence of neoliberal thought on the global stage; but even before that, right-wing forces in the UK and the United States were experimenting with new ways to outmanoeuvre both the old and new left. One particularly important approach was a political-economic strategy to link the crisis of capitalism to union power. The subsequent defeat of organised labour throughout the core capitalist nations has perhaps been neoliberalism’s most important achievement, significantly changing the balance of power between labour and capital. The means by which this was achieved were diverse, from physical confrontation and combat, to using legislation to undermine solidarity and industrial action, to embracing shifts in production and distribution that compromised union power (such as disaggregating supply chains), to re-engineering public opinion and consent around a broadly neoliberal agenda of individual freedom and ‘negative solidarity’. The latter denotes more than mere indifference to worker agitations – it is the fostering of an aggressively enraged sense of injustice, committed to the idea that, because I must endure increasingly austere working conditions (wage freezes, loss of benefits, a declining pension pot), then everyone else must as well. The result of these combined shifts was a hollowing-out of unions and the defeat of the working class in the developed world.

While the right successfully faced the structural crisis by consolidating its political and economic power, the movements of the old and new left were unable to confront this new configuration of forces. In the 1970s, socialist and even communist political parties were gradually able to gain increasing ground in elections in Western Europe; but the old left simply tried to resolve the crisis by doubling down on the traditional corporatist agenda. But the old Keynesian policy formulations were unable to kick-start growth, restrain unemployment or reduce inflation under these new economic conditions. As a result, left-wing governments coming to power in the 1970s, such as the British Labour Party, often ended up having to implement proto-neoliberal policies in frustrated attempts to foster a recovery. The traditional labour movement, decrepit and stagnant, was by now being bested and co-opted by the forces of the right. In this context, the new left was a necessary critique that was essential to the left’s revitalisation and progress. Yet, as we saw in the previous section, if the old labour organisations were in many senses bereft of ideas, the new left was unable to institutionalise itself and articulate a counter-hegemony. The result was a left that became increasingly marginalised.

As neoliberalism expanded and consolidated its common sense, the remaining social democratic parties increasingly came to accept neoliberalism’s terms. With most major parties effectively signed up to its political and economic programme, and increasing numbers of public services being taken into private hands, the ability to achieve significant change at the ballot box was dramatically reduced. Widespread cynicism began to accompany a hollowed-out party politics that came to resemble the public relations industry, with politicians being reduced to the role of shopkeepers hawking undesirable wares. Mass participation in electoral politics declined in tandem with the gradual acceptance of the neoliberal coordinates, and the age of post-politics was upon us. Mass voter disaffection is the result today, with voter turnout routinely at historic lows. Under these circumstances, the folk-political insistence on immediate results and small-scale participatory democracy has an obvious allure.

The position of the new social movements in this context was more ambiguous. By the 1990s, the positioning of the working class as privileged political subject had been fully broken down, and a much wider array of social identities, desires and oppressions had gained recognition. Increasingly sophisticated attempts were made to develop the analysis of interacting power structures, giving rise to ideas of intersectional oppressions. As a result of cultural dissemination and mainstream political endorsement, large parts of the programmes of feminist, anti-racist and queer political movements had become enshrined in law and embraced on a social level. But despite these successes, there had been a rollback from the kind of radical demands outlined in the 1970s, which envisaged a much more thorough transformation of society. Feminists, for example, have made significant gains in terms of pay equality, abortion rights and childcare policies, but these pale in comparison to projects for the total abolition of gender. Similarly, for many black liberation movements, while anti-racist employment policies and antidiscrimination laws were widely enacted, they had not been accompanied by other radical programmes espoused by earlier movements. Much of the success seen by the new social movements today is confined within the hegemonic terms established by neoliberalism – articulated around market-centred claims, liberal rights and a rhetoric of choice. What have been sidelined in the process are the more radical and anti-capitalist elements of these projects.

Looking back, we have the collapse of the traditional organisations of the left, and the simultaneous rise of an alternative new left predicated upon critiques of bureaucracy, verticality, exclusion and institutionalisation, combined with an incorporation of some of the new desires into the apparatus of neoliberalism. It was against this backdrop that folk-political intuitions increasingly sedimented as a new common sense and came to be expressed in the alter-globalisation movements. These movements emerged in two phases. The first, appearing from the mid 1990s through to the early 2000s, consisted of groups such as the Zapatistas, anti-capitalists, alter-globalisers, and participants in the World Social Forum and global anti-war protests. A second phase began immediately after the 2007–09 financial crisis and featured various groups united by their similar organisational forms and ideological positions, including the Occupy movement, Spain’s 15M and various national-level student movements. Both phases of the newest social movements sought to counter neoliberalism and its national and corporate avatars, with the first phase targeting global trade and governance organizations, and the latter focusing more on financialisation, inequality and debt. Drawing influence from the earlier social movements, this latest cycle of struggles comprises groups that tend to privilege the local and the spontaneous, the horizontal and the anti-state. The apparent plausibility of folk politics rests on the collapse of traditional modes of organisation on the left, of the co-optation of social democratic parties into a choice-less neoliberal hegemony, and the broad sense of disempowerment engendered by the insipidness of contemporary party politics. In a world where the most serious problems we face seem intractably complex, folk politics presents an alluring way to prefigure egalitarian futures in the present. On its own, however, this kind of politics is unable to give rise to long-lasting forces that might supersede, rather than merely resist, global capitalism.

The critique of folk politics advanced in this book is as much a warning as it is a diagnosis. The existing tendencies in the mainstream and radical left are moving towards the folk-political pole, and we seek to reverse this trend. The aim of the first half of the book is therefore to disrupt an increasingly dogmatic set of principles about how to strategise and do politics today. Beginning with a critical take on existing politics, Chapter 2 seeks to diagnose and outline the limits of contemporary folk-political thinking. While the left has rejected the project of hegemony and expansion, Chapter 3 shows how neoliberalism successfully took the opposite path. In the place of folk politics, the second half will suggest an alternative leftist project organised around global and universal emancipation. Chapter 4 argues that a future-orientated left needs to reclaim the initiative for modernisation and its emphasis on progress and universal emancipation. Chapter 5 sets out an analysis of the tendencies of contemporary capitalism, emphasising the crisis of work and social reproduction. These tendencies demand a response, and our argument is that the left should begin mobilising a political project to direct these forces in a progressive manner. In contrast to today’s dominant focus on debt and inequality, Chapter 6 envisions a post-work world. Chapters 7 and 8 examine some of the steps that will need to be taken to achieve this vision, which include building a counter-hegemonic movement and rebuilding the capacities of the left. Finally, the Conclusion takes a step back to examine the project of modernity from the perspective of a future-orientated left guided by the goal of universal emancipation. This book is predicated on a simple belief – that a modern left can neither continue with the current system nor return to an idealised past, but must instead face up to the task of building a new future.

A key challenge facing the left today is to reckon with the disappointments and failures of the most recent cycle of struggles. From the anti-globalisation to the Occupy movements, we have seen a high point of folk-political practice. Why, despite a considerable mobilisation of people and passions, did these movements fail to achieve any significant change in the political status quo? Some writers have argued that the incapacity of contemporary leftist movements can be explained by their class basis, such as their alleged lack of a working-class component, or the infiltration of reformist liberal interests. Others have argued that the problem lies with the nature of the system and the hurdles placed in front of any transformative project. Yet as we argued last chapter, this only partly explains the recent failures. By contrast, the argument of this chapter is that the problems lie more with the folk-political assumptions that shape the strategic horizon of recent left politics. We seek here to diagnose the limits posed by contemporary folk politics.

As was argued in Chapter 1, folk politics emerges at the junction between a generalised reaction to increasing social complexity and a specific history of leftist movements in the twentieth century. This chapter examines how the folk-political intuitions that were formed in the process have come to shape some of the dominant strands of contemporary leftist politics. We make no claim to cover the entire field of social movements here, but simply focus on what have been the most politically popular and significant moments of the radical left in the past fifteen years. We also do not claim that any of the particular political tactics used by these movements are inherently problematic. The merits of particular tactics are only legible when seen in the context of both the broader historical horizon and the strategy aimed at transforming it. It is in our current setting – of a world overwhelmingly determined by the imperatives of global capitalism, combined with folk-political strategies focused on the local and the spontaneous – that we locate the fundamental weakness of the contemporary left. We begin by examining one of the most popular political tendencies of the past fifteen years – horizontalism – before turning to widespread ideas centred on localism, and the general reactive thrust of most mainstream and radical leftist politics.

Crystallising in 1970s US social movements and thrust into prominence by the Zapatistas, alter-globalisation activists and the movement of the squares, horizontalism has become the dominant strand of today’s radical left. Responding to the twentieth-century failures of state-led political change, horizontalist movements instead advocate changing the world by changing social relations from below. They draw upon a long tradition of theory and practice in anarchism, council communism, libertarian communism and autonomism, in order to – in the words of one proponent – ‘change the world without taking power’. At the heart of these movements lies a rejection of the state and other formal institutions, and a privileging of society as the space from which radical change will emerge. Horizontalism rejects the project of hegemony as intrinsically domineering, putting forth an affinity-based politics in its stead. Rather than advocating an appeal to or takeover of the vertical power of the state, horizontalism argues for freely associating individuals to come together, create their own autonomous communities and govern their own lives. In broad terms, we can summarise these ideas in terms of four major commitments:

1.A rejection of all forms of domination

2.An adherence to direct democracy and/or consensus decision-making

3.A commitment to prefigurative politics

4.An emphasis on direct action

Embedded within this set of commitments is a series of problems that constrain and limit their potential in the struggle against global capitalism.

Horizontalism’s focus on domination in all its forms is perhaps its signal contribution. Moving beyond the old left’s traditional focus on the state and capital, it emphasises the various ways in which other types of domination continue to structure society (racial, patriarchal, sexual, ableist, and so on). It is a significant advance that many of today’s radical left have adopted these ideas and centred their practice upon the complete removal of all forms of oppression – a commitment that we believe any serious leftist politics must adopt. Yet the means by which horizontalist movements attempt to overcome domination and oppression often end up being bound by the limits of folk politics. In seeking the direct and unmediated cancellation of social relations of domination, these movements either tend to ignore the more subtle forms of domination that persist, or else fail to construct persistent political structures able to maintain the new social relations in the long term.

The commitment to avoiding all forms of domination is closely tied to a critique of representation – both conceptual and political. In practice, this has led to a rejection of the more hierarchical structures that characterise representative politics. Having experienced the history of corrupt trade unions and rapidly eroded liberal democracies, representation is seen as inevitably leading to self-serving and dominant elites. These structures are to be replaced by direct forms of democracy that privilege immediacy over mediation, invoking a more personal sense of politics. The idea here is that a ‘face-to-face democracy’ is presumably more natural and authentic, and less prone to the emergence of hierarchies. Political decisions are to be made not by representatives, but instead by individuals representing themselves in person. Direct democracy ends up being taken as a basic value, underpinned by the folk-political intuition that what is immediate is better than what is mediated. Rather than majority rule, parliamentary procedure, or dictates from a central committee, it is consensus that is often the major aim of discussions. Debate and governance should therefore be maximally inclusive, and the process of deliberation itself, as opposed to just its outcomes, is something to be valued. Participatory democracy is understandably a major attraction for many people, particularly in light of the empty, ritualistic gestures of contemporary representative democracies. Many participants speak of the feelings of empowerment they derive from participating in consensus decision-making processes. Maximal inclusivity and consensus are therefore valorised, and the importance of tactics and process is placed above strategic objectives.

Direct democracy, consensus and inclusivity all form part of horizontalism’s commitments to prefigurative politics, which aims to create in the here-and-now the world they would like to see. Prefigurative politics is a longstanding tradition on the left, from the anarchism of Kropotkin and Bakunin onwards, but it has only recently come to characterise the leading edges of left-wing politics. The earlier promise that, after the revolution, hierarchies and exclusions would evaporate was little consolation to the women and people of colour whose concerns were ignored by yet another white male leader. Rather than wait for a purported revolution, prefigurative politics attempts to instantiate a new world immediately – again relying on an implicit sense that immediacy is inherently superior to more mediated approaches. At its best, prefigurative politics attempts to embody utopian impulses in bringing the future into concrete existence today. Yet at its worst, an insistence on prefiguration becomes a dogmatic assertion that the means must match the ends, accompanied by ignorance of the structural forces set against it.

If the aim is to create the world we want in the here-and-now, and if recourse to mediating institutions is forbidden (or at least disavowed), then the appropriate form of practice has to be direct action. This is a form of practice that encompasses a wide range of possible tactics, ranging from theatrical protests in the vein of the Situationists, to wildcat strikes, to blockading ports, to burning down luxury housing developments. In these practices we can again see hints of folk politics – the privileging of the direct, the immediate and the intuitive. To be sure, direct action can sometimes be more effective and useful than protests – such as pouring concrete to destroy anti-homeless spikes, or using slow-down methods in workplace struggles. Yet, as we will see, direct action often remains insufficient to secure longstanding change, and in isolation, is typically only a temporary impediment to the powers of state and capital.

Direct democracy, prefigurative politics and direct action are not, we hasten to add, intrinsically flawed. Rather than being denounced in themselves, their utility needs to be judged relative to particular historical situations and particular strategic objectives – in terms of their ability to exert real power to create genuine lasting transformation. The reality of complex, globalised capitalism is that small interventions consisting of relatively non-scalable actions are highly unlikely to ever be able to reorganise our socioeconomic system. As we suggest in the second half of this book, the tactical repertoire of horizontalism can have some use, but only when coupled with other more mediated forms of political organisation and action. Following this broad overview of horizontalism’s theoretical commitments and the general issues associated with them, we can now turn to two important sequences in twenty-first-century politics to highlight both the practical possibilities and the strong folk-political limits built into these models. In what follows, we examine two of the strongest cases for horizontalism: the Occupy movement emerging after the 2008 financial crisis and the Argentinean experience in the wake of the country’s 2001 default. In each case, we can see both the real successes and the palpable limits of these approaches.

The most significant recent embodiment of horizontalist principles occurred in the ‘movement of the squares’. While occupations do not require horizontalist governance (indeed, the precursors to the tactic originally came from the military), the vast majority of post-2008 occupations have been organised along such lines. This wave of occupations of public spaces spread rapidly to over 950 cities worldwide in 2011, each inflected with local political, economic, cultural and class concerns. Here we want to examine the failure of the Occupy movement in the Western world, in particular because it highlights the deficiencies of folk-political thinking in the core capitalist countries. Notably, this failure occurred despite the vast range of approaches subsumed under the name of Occupy. In the United States, for example, from Occupy Wall Street to Occupy Oakland, this movement ranged from the dogmatically non-violent to the openly antagonistic, between an often confused liberalism and a militant libertarian communism. Adding to this regional variation was the mixed ideological make-up of the participants, which spanned the political spectrum and included reformist liberals, anti-capitalists, insurrectionist anarchists, anti-state communists and union activists, along with a smattering of anti–Federal Reserve libertarians. In addition to this diversity, there was widespread resistance to the articulation of political demands, making the unity of the movement even more difficult to discern.

It is relatively easy to see why so many were motivated to join the movement. The horizontalist nature of Occupy gave people a means to express themselves in the face of societies that barely registered their voices. Particularly in America, the structure of electoral democracy around two large parties has meant the window of political discourse has become incredibly narrow. The assortment of slogans and causes associated with Occupy testifies to an explosion of suppressed anger and a proliferation of political demands that otherwise went unheard. Even among those who did not directly participate in the occupations, Occupy provided a platform for the excluded in websites such as the ‘We are the 99 Percent’ Tumblr, with a chorus of voices protesting against economic immiseration and social exclusion. Beyond any direct political result, the opportunity for the frustrations of the excluded to be publicly aired was inspiring and empowering for many.

Occupy also worked to disrupt the ordinary lives of both participants and observers, and allowed people to participate together in a shared political project. In the words of one observer, ‘the practice of autonomy provides a lesson in one’s own power’. In places such as Oakland, activists frequently pushed towards more radical politics than the usual mediating organisations (such as non-profits) would have allowed. Occupy functioned, like many protest movements, as a way to radicalise those who were involved, especially when they were faced with disproportionately brutal police responses. Occupations were purported to prefigure a new world; but even if that new world has yet to emerge, the movements certainly showed participants what was possible with political solidarity.

Beyond these internal benefits, occupied spaces functioned as bases for actions against the political system (as in protest camps against the G8). The majority of these actions consisted of protest marches and rallies, with the spaces also operating as physical locations for collective decision-making. In relation to external actions, occupied spaces also worked as headquarters for skills training – for example, carrying out acts of civil disobedience, dealing with police repression or providing information on legal rights. In a general sense, occupations worked as the most obvious real-world manifestation of the infrastructure for the overall movement. The occupations were also (though not always) a place for supporting the most marginal sections of society, particularly the homeless. Perhaps most importantly, the occupations provided an insistent focal point for media attention – particularly the Zuccotti Park occupation in New York – and brought many otherwise sidelined issues to the attention of the government and the wider public. At least for a limited time, Occupy was able to draw significant mainstream press and television news attention to issues of economic justice – a real achievement in a heavily neoliberalised media environment.

But despite these successes, there are important ways in which the occupations failed. Numerous commentators from within the movement have already noted a number of these, including the ways in which Occupy’s rhetoric of inclusivity hid a series of exclusions based on race, gender, income and free time. Folk-political constraints were contained in the practices and ideas of the movement, and it was these tendencies that ultimately left it incapable of expanding spatially, consolidating temporally or universalising itself. To be sure, some of the movements that made up Occupy had no intention of scaling up, persisting in time or universalising themselves. Many (though not all) horizontalist thinkers place an emphasis on the particular dynamism of relatively short-lived, spontaneous politics, holding that ‘relative permanence is not necessarily a virtue’. But whether intended or not, the movement’s tendency in practice to prioritise spatial, temporal and conceptual immediacy weakened it collectively, leaving it unable to persist long enough to have a chance of seriously pursuing its basic objectives.

Drawing upon horizontalist principles, the Occupy movement was characterised chiefly by its adherence to direct democracy. While direct democracy can exist in a variety of different forms – from workers’ councils to Swiss-style canton democracy – under Occupy it took the general assembly as the dominant organisational form. In an era of declining democratic effectiveness, a new way of doing democracy was one of the most common aspirations articulated by participants in these protests. Still, when fetishised as an end in itself, direct democracy inexorably imposes significant constraints. In the first place, the level of effort and involvement in politics that direct democracy demands leads to problems of sustainability. The participatory economics (Parecon) project, for instance, envisions direct democracy at every level of society; but this vision for a postcapitalist world translates into endlessly ramifying staff meetings over every detail of life – hardly the inspiring stuff of utopian visions. Under Occupy, many general assemblies devolved into similar situations in which even the most mundane of issues had to be painstakingly addressed by a collective. The acrimonious debates over drummers making too much noise in the Zuccotti Park occupation are just one particularly farcical example of this. The more general point is that direct democracy requires a significant amount of participation and effort – in other words, it entails increasing amounts of work. During brief moments of revolutionary enthusiasm, this extra work can become inconsequential; yet after the return to normality it is simply added to the ordinary pressures of everyday life. The extra work of direct democracy is problematic especially because of the constitutive exclusions it entails – particularly for those who are unable to attend physically, those who do not feel comfortable in large groups and those who lack public speaking skills (with all the gendered and racialised biases inherent to these factors). As the Occupy movement went on, the general assemblies simply collapsed, often under the weight of exhaustion and boredom. The conclusion to be drawn from this is that the problem of democracy today is not that people want a say over every single aspect of their lives. The real issue of democratic deficit is that the most significant decisions of society are out of the hands of the average person. Direct democracy responds to this problem, but attempts to solve it by making democracy an immediate and bodily experience that rejects mediation. Similar preferences for immediacy in democracy also hold back its spatial scalability. To put it simply, direct democracy requires small communities. It is notable that the hundreds of thousands in Tahrir Square in Egypt did not have a general assembly, and that even at Occupy Wall Street, the general assembly consisted of only a small proportion of the total number of participants. The very mechanisms and ideals of direct democracy (face-to-face discussion) make it difficult for it to exist beyond small communities, and make it virtually impossible to respond to problems of national, regional and global democracy. The spatial constraints of direct democracy also overlook the regressive aspects of small communities. These ‘intimate’ communities are often home to the most virulent forms of xenophobia, homophobia, racism, pernicious gossip, and all other varieties of backward thinking. Small communities of the kind required by direct democracy are not a suitable goal for a modern left movement. Moreover, participative democracy might well be constructed without them, particularly using the communications technologies available today.

Another folk-political constraint emerged with the emphasis on consensus as a basic goal of the process. The aim of consensus is to reach a decision that is acceptable to everyone, again reliant upon spatial immediacy. As anarchist David Graeber notes, ‘It is much easier, in a face-to-face community, to figure out what most members of that community want to do, than to figure out how to convince those who do not to go along with it.’ Yet what works well on one scale (the face-to-face community) is much more difficult to make work on larger ones. Perhaps inevitably in the case of a relatively diffuse movement such as Occupy, consensus decision-making led to a lowest-common-denominator set of demands, where they emerged at all. There was also much rhetoric glorifying the absence of determinate demands as somehow radical. These arguments from within the movement identified the making of demands as alienating and divisive, as potentially reducing the role of the movement by appealing to outside powers – such as the state – and hence liable to lead towards the co-optation of the movement. As critics of such views have argued, however, the divisive nature of demands is also a positive: while putting some participants off, they may equally mobilise those committed to achieving the demand in question. Moreover, they work to clarify the real political differences contained in the movement – differences often elided in practice, even where they might prove to be insurmountable.

Further problems with Occupy emerged with its nominal rejection of any forms of organisational verticality. Most notably, this led to problems emerging in the relations between the movement and other similarly minded groups. Whereas the movement of the squares in Egypt and Tunisia built strong connections with existing labour movements, the Western world’s Occupy movement largely rejected such associations. This led to three tendencies. The first was a frequently paralysing decisional structure. When actions were taken by Occupy, they often came from a sub-group acting on their own, rather than from the general assembly making a consensus decision. Actions, in other words, did not come from horizontalism. Second, evidence shows that hierarchical organisations are crucial in defending movements against the state. In Occupy, the maintenance of the occupied space against police repression was the result, not of horizontalism, but of vertical institutions that mobilised their members to support the occupation. Similarly, in Egypt, football supporters and religious organisations were central to the defence of Tahrir Square against the violence of the state and reactionaries. Finally, the rejection of verticality in all its forms meant a key mechanism for spatially and temporally expanding the movement was abandoned. Links to labour, social justice, and even political parties would have provided an infrastructure for Occupy to move beyond folk-political parameters. Organised workers, for instance, were crucial in Egypt for turning the general protest into a near general strike, shutting down the country as a result and providing the final blow to the Mubarak regime. Links to political parties have also helped occupations in Iceland, Greece and Spain produce much broader successes. In the end, despite the clear desire to spread Occupy’s ideas – and the real success in garnering public attention – the moves necessary to transform the social fabric were never taken.

More fundamentally, though, Occupy constrained itself by enforcing a rigidly prefigurative politics. The basic prefigurative gesture is to embody the future world immediately – to change our ways of relating to each other in order to live the postcapitalist future in the present. The role of occupations is a classic example of this: they often self-consciously aim to enact the space of a non-capitalist world through mutual aid, rejections of hierarchy and rigorous direct democracy. Yet these spaces are understood and built as explicitly temporary – not spaces for sustained change or the working-out of concrete alternatives, let alone ambitious competitors to global capitalism. Instead they are short-term spaces containing the transitory experiences of an immediate community. A pamphlet from a precursor to the Occupy movement makes this particularly clear:

[Students who insisted on no demands] saw the point of occupation as the creation of a momentary opening in capitalist time and space, a rearrangement that sketched the contours of a new society. We side with this anti-reformist position. While we know these free zones will be partial and transitory, the tensions they expose between the real and the possible can push the struggle in a more radical direction.

The acknowledgement that the occupation will be temporary is here combined with a naive belief that maybe this time it will spark a radical change. Prefigurative spaces face a continuous struggle against dissolution for good reasons. First, they require a variety of logistical supports, including housing, food, sanitation, healthcare, defence and legal advice. Most of this does not come from within the prefigurative community, but instead relies upon existing capitalist networks. The social reproduction of encampments is difficult even under the most favourable conditions, and even established utopian communities (often religious in nature) typically find it impossible to remain independent and self-sustaining. Second, prefigurative spaces are often subject to state and corporate repression – and if they are not, it is typically because they pose no threat to the existing social order. The Zapatistas, for example, are permitted to exist in relative freedom simply because the state and capital do not see them as a threat. The moment a prefigurative space becomes a threat is the moment when repression weighs down on it, and when its fetishisation of horizontalism becomes a serious liability. Prefigurative politics, at its worst, therefore ignores the forces aligned against the creation and expansion of a new world. The simple positing and practising of a new world is insufficient to overcome these forces, as the repression faced by Occupy demonstrated.

The immediate question that must be asked of any prefigurative politics is therefore: How can it be expanded and scaled up? Even granting the problematic assumption that most people would want to live as the Occupy camps did, what efforts might be possible to physically and socially expand these spaces? When theorists face up to this question, vague hand-waving usually ensues: moments will purportedly ‘resonate’ with each other; small everyday actions will somehow make a qualitative shift to ‘crack open’ society; riots and blockades will ‘spread and multiply’; experiences will ‘contaminate’ participants and expand; pockets of prefigurative resistance will just ‘spontaneously erupt’. In any case, the difficult task of traversing from the particular to the universal, from the local to the global, from the temporary to the permanent, is elided by wishful thinking. The strategic imperatives to expand, extend and universalise are left unfulfilled.

If Occupy was unsuccessful in expanding prefigurative spaces beyond the margins of society, these protest camps could still be useful as launching pads for direct action. Indeed, one of the most notable achievements of the Occupy movement was to establish a social and physical infrastructure that could act as a foundation for direct actions. In countries like Greece and Spain, debt strikes have been organised and picket lines formed for workers without the right to strike. Other Occupy movements supported squatters, provided food for the homeless, set up pirate media, mobilised to prevent evictions, protested against government cuts and provided humanitarian relief after natural disasters. But the influence of Occupy should not be overstated. For instance, many of the successful eviction and foreclosure movements have been extensions of pre-existing work done by movements such as the black activist–led Take Back the Land. More broadly, the problem is that direct actions generally act on surface effects, patching the wounds of capitalism but leaving the underlying problems and structures intact. Foreclosures continue apace, consumer debt rises to new heights, workers are thrown out into the streets, and the homeless population surges. In the case of Occupy, what became apparent was the limits of a propaganda of the deed. While direct action can have real successes, it remains localised and temporary, and in this it remains folk-political. Direct action can be effective in mitigating the worst excesses of capitalism, but it can never address the difficult problem of attacking a globally dispersed abstraction, often focusing instead on intuitive targets. The project of an expansive left – a left aiming to transform capitalism in fundamental ways – remains absent.

The image of Occupy that emerges here is of a movement that was wedded to certain assumptions about the benefits of local spaces, small communities, direct democracy and temporary autonomy at the margins of society. In turn, these beliefs rendered the movement incapable of expanding spatially, establishing sustainable transformations and universalising itself. The Occupy movements achieved real victories in creating solidarity, giving a voice to disenchanted and marginalised people, and raising public awareness. But they nevertheless remained an archipelago of prefigurative islands, surrounded by an implacably hostile capitalist environment. The proximate cause for the movement’s failure was state repression, in the form of police clad in riot gear ruthlessly clearing the occupied spaces across the United States. But the structural causes were built into the assumptions and practices of the movement. Without the central focus of the occupied spaces, the movement dispersed and fragmented. Ultimately, the organisational form of these movements could not overcome the problems of scalability and construct a form of persistent power capable of effectively resisting the inevitable reaction from the state. What may work quite well on one scale – perhaps up to a hundred people – becomes increasingly difficult to operate effectively when extended beyond that. If a truly ambitious left politics is to take on global actors – the neoliberal capitalist system and its governing institutions, leading governments and their armies and police forces, and an entire planet’s worth of corporations and financial entities – then operating beyond the merely local is essential. While there is certainly much to learn from these movements, it is our contention that, on their own, they will remain ineffective at bringing about large-scale change.

If any case from recent history offers hope for the sufficiency of horizontalism, it would appear to be Argentina, which achieved a large-scale national turn towards horizontalism and expansive worker control over factories. Yet a brief look at the Argentinean experience actually reveals new dimensions to the limits of folk-political approaches. In Argentina’s circumstances, the immediate imperative for new social organisations came from the collapse of the national economy. Struck by a massive recession in 1998, the economy buckled and lost over a quarter of its GDP by 2002. Tensions reached a peak in December 2001, with government restrictions and financial chaos provoking the people into mass protests. The result was the collapse of the government and an eventual default on their debts. With the government both unable and unwilling to help its population, people were forced to find new ways to provide for themselves.

In the wake of these challenges, many of the Argentinean people took it upon themselves to self-organise and create new political and economic structures. To a significant degree, these responses were organised around explicitly horizontalist principles. As with Occupy, there are a variety of benefits that can be identified in the horizontalist organising of Argentina. Perhaps most importantly, these movements were able to disrupt the common-sense norms of neoliberal society, moving beyond market individualism and negative solidarity. The fostering of bonds between individuals helped to overcome the antagonism that most protests and strikes often face from other parts of society. Like Occupy, but on a broader scale, Argentina’s horizontal movements were also quickly able to provide the means for social reproduction under crisis conditions.

But while these experiments with horizontalism brought about a number of achievements, its experience also revealed several further problems. Principal among these is the limitations faced by neighbourhood assemblies as an organisational form. Modelled on horizontalist principles, the neighbourhood assemblies arose in response to the immediate needs and possibilities opened up by the crisis. Like the general assembly of Occupy, they enabled people to have a newfound voice. But even when joined together in inter-neighbourhood assemblies, they never approached the point of replacing the state, or of being able to present themselves as a viable alternative. The functions of the state – welfare, healthcare, redistribution, education, and so on – were not about to be replaced by the horizontalist movement, even at its height of participation. It thus remained a localised response to the crisis. Further limitations surfaced as these assemblies could only function by either rejecting organised – which is to say, collective – interests, or incorporating them, and thus being overwhelmed. Collective interests were incapable of being brought into the decision-making process without breaking it, since they often took control over discussion and debate. Problematically, these assemblies operated best on an individualistic basis.

Other organisational experiments in Argentina involved the spread of worker-controlled factories. In the wake of the economic crisis, some shuttered businesses were taken over and maintained by their employees. These factories helped to keep workers in jobs, and there is some evidence that they provided better pay for their workers. Unfortunately, despite the attention given to them, the total number of people involved was relatively small: in the most optimistic estimates, there were around 250 factories incorporating just under 10,000 workers. With a labour force of over 18 million, this means far less than 0.1 per cent of the economy was participating in worker-controlled factories. Not only were these factories a minor part of the overall economy, but they also remained necessarily embedded within capitalist social relations. The dream of escape is just that: a dream. Tied to the imperative to create a profit, worker-controlled businesses can be just as oppressive and environmentally damaging as any large-scale business, but without the efficiencies of scale. Such problems are widespread across the worker-cooperative experience, having arisen not only in Argentina, but also in the Zapatista model and across America.

Beyond these organisational limits, the key problem with Argentina as a model for postcapitalism is that it was simply a salve for the problems of capitalism, not an alternative to it. As the economy started to improve, participation in the neighbourhood assemblies and alternative economies drastically declined. The post-crisis horizontalist movements in Argentina were built as an emergency response to the collapse of the existing order, not as a competitor to a relatively well-functioning order. Indeed, the more widespread problem with contemporary horizontalism is that it often sees emergency situations – in the wake of a hurricane, earthquake or economic meltdown – as representative of a better world. It is a struggle, to say the least, to see how post-disaster conditions are an improvement for the vast majority of the world’s population. A politics that finds its best expression in the breakdown of social and economic order is not an alternative, so much as a knee-jerk survival instinct. Equally problematic is the tendency for horizontalists to find political potential in the mundane ways we organise horizontally in everyday life – friends gathering together, parties, festivals, and so on. The problem is that such modes of organising are not scalable beyond a small community – and, more to the point, are not useful for certain political goals. As the Argentinean example shows, these modes of organising can be valuable for basic neighbourhood survival and for creating a sense of solidarity between people. But horizontalism struggles to compete against more organised interests, to sustain itself once a base level of normality returns, and to achieve long-term and large-scale political goals such as providing universal healthcare, high-level education and social security. These approaches remain useful in exceptional circumstances and for a small range of goals, but they will neither revolutionise society nor genuinely threaten global capitalism.

In the case of both neighbourhood assemblies and worker-controlled factories, we see that the primary organisational models of horizontalism are insufficient. They are often reactive tactics that fail to compete in the antagonistic environment of global capitalism. On a theoretical level, and in the actual experiences of Occupy and Argentina, the limits of horizontalism have repeatedly been made clear over the past decade. While recognising the important capacity of horizontalist tactics to provide small-scale support to communities and to temporarily disrupt certain exploitative practices, the commitment to fetishised versions of consensus, direct action, and particularly prefigurative politics, constrains the possibilities of expanding and overtaking existing social systems.

Less politically radical than horizontalism, though no less ubiquitous, is localism. As an ideology, localism extends far beyond the left, inflecting the politics of pro-capitalists, anti-capitalists, radicals and mainstream culture alike, as a new kind of political common sense. Shared between all of these is a belief that the abstraction and sheer scale of the modern world is at the root of our present political, ecological and economic problems, and that the solution therefore lies in adopting a ‘small is beautiful’ approach to the world. Small-scale actions, local economies, immediate communities, face-to-face interaction – all of these responses characterise the localist worldview. In a time when most of the political strategies and tactics developed in the nineteenth and twentieth centuries appear blunted and ineffectual, localism has a seductive logic to it. In all its diverse variants, from centre-right communitarianism to ethical consumerism, developmental microloans, and contemporary anarchist practice, the promise it offers to do something concrete, enabling political action with immediately noticeable effects, is empowering on an individual level. But this sense of empowerment can be misleading. The problem with localism is that, in attempting to reduce large-scale systemic problems to the more manageable sphere of the local community, it effectively denies the systemically interconnected nature of today’s world. Problems such as global exploitation, planetary climate change, rising surplus populations, and the repeated crises of capitalism are abstract in appearance, complex in structure, and non-localised. Though they touch upon every locality, they are never fully manifested in any particular region. Fundamentally, these are systemic and abstract problems, requiring systemic and abstract responses.

While much of the populist localism on the right can easily be dismissed as regressive macho fantasy (for example, secessionist libertarianism), sinister ideological cover for austerity economics (the UK Conservative Party’s ‘Big Society’) or downright racist (the nationalist or fascist blaming of immigrants for structural economic problems), the localism of the left has been less thoroughly scrutinised. Though undoubtedly well-meaning, both the radical and mainstream left partake in localist politics and economics to their detriment. In what follows we will critically examine two of the more popular variants – local food and economic localism – which in very different areas exemplify the problematic dynamics of localism in general.

With a cachet that reaches far beyond typical political circles, localism has recently come to dominate discussions of the production, distribution and consumption of food. Most influential here have been the interlinked movements known as ‘slow food’ and ‘locavorism’ (eating locally). The slow-food movement began in the mid 1980s in Italy, partly as a protest against the ever-increasing encroachment of fast-food chains. Slow food, as its name suggests, stands for everything McDonald’s does not: local food, traditional recipes, slow eating and highly skilled production. It is food that offers the most visceral embodiment of the benefits of the slow lifestyle, overcoming the vicissitudes of fast-paced capitalism by returning to an older culture of savouring meals and traditional production techniques. But even its proponents admit that there are difficulties involved in living the slow-food lifestyle: ‘Few of us have the time, money, energy or discipline to be a model Slow Foodie.’

Without an assessment of how our lives are structured by social, political and economic pressures that make it easier to eat pre-prepared food than embrace the slow-food lifestyle, the end result is a variant of ethical consumerism with a hedonistic twist. It is patently correct that taking one’s time to enjoy a well-prepared meal can be a pleasurable experience. Paying attention to a meal recasts the experience from one of pure utility into a more social and aesthetic experience. But there are structural reasons why we do not choose to do this often – reasons that are not the result of any individual moral failing. The structure of work, for example, is a primary reason why many of us are unable to enjoy slow eating, or meals prepared according to the ideals of the slow-food movement. Slow food might not always require money, but it always requires time. For those who have to work multiple jobs to support their families, time is at a premium. What is more, the gender politics of slow food are problematic, given that we live in patriarchal societies where the majority of food preparation is still presumed to be the task of wives and mothers. While ‘fast’ food or pre-prepared meals might be unhealthy, their popularity enables the freeing up of women to live lives that are less marked by the everyday drudgery of feeding their families. As innocent as it may at first seem, the slow-food movement, like many other forms of ethical consumerism, fails to think in large-scale terms about how its ideas might work within the broader context of rapacious capitalism.

Closely linked to the slow-food movement are locavorism and the ‘100-mile diet’ – a food politics that emphasises eating locally. Locavorism holds that locally sourced food is not only more likely to be healthy, but is also a vital component of our efforts to reduce carbon outputs, and hence our impact on the environment. It situates itself, therefore, as a response to a global issue. Moreover, locavorism claims to be one way to overcome the alienation of our relationship to food under capitalism. By eating food grown or produced in our locality, so this logic runs, we will be able to get back in touch with the production of our food and reclaim it from the dead hands of a capitalism that has run amok. Compared to the slow-food movement, locavorism positions itself more explicitly, and politically, against globalisation. In doing so, it appeals to a constellation of folk-political ideas relating to the primacy of the local as a horizon of political action, and of the virtues of the local over the global, the immediate over the mediated, the simple over the complex.

These ideas condense often complex environmental issues into questions of individual ethics. One of the most serious (and intrinsically collective) crises of our times is thus effectively privatised. This personalised environmental ethic is exemplified in localist food politics – in particular, in the moral (and price) premium placed on locally grown food. Here we find ecologically motivated arguments (for reducing energy expenditure by reducing the distances over which food is transported, for example) combined with class differentiation (in the form of marketing designed to promote identification with organic food). Similarly, complex problems are condensed into poorly formulated shorthand. For instance, the idea of ‘food miles’ – identifying the distances that food products have travelled, so as to reduce carbon outputs – appears a reasonable one. The problem is that it is all too often taken to be sufficient on its own as a guide to ethical action. As a 2005 report by the UK’s Department of Agriculture and Food found, while the environmental impacts of transporting food were indeed considerable, a single indicator based on total food miles was inadequate as a measure of sustainability. Most notably, the food-miles metric emphasises an aspect of food production that contributes a relatively small amount to overall carbon outputs. When it is simply assumed that ‘small is beautiful’, we can all too easily ignore the fact that the energy costs associated with producing food locally may well exceed the total costs of transporting it from a more suitable climate. Even for the purpose of assessing the contribution of food transportation, food miles are a poor metric. Air freight, for example, makes up a relatively small portion of total food miles, but it makes up a disproportionately large slice of total food-related CO2 emissions. The energy consumption involved in putting food on our plates is important, but it cannot be captured in anything as simple as food miles, or in the idea that ‘local is best’. Indeed, highly inefficient local food production techniques may be more costly than efficiently grown globally sourced foodstuffs. The bigger question here relates to the priorities we place on the types of food we produce, how that production is controlled, who consumes that food and at what cost.

Localist food politics flattens the complexities it is trying to resolve into a simplistic binary: global, bad; local, good. What is needed, by contrast, are less simplistic ways of looking at complex problems – an analysis that takes into account the global food system as a whole, rather than intuitive shorthand formulae such as food miles, or ‘organic’ versus non-‘organic’ foods. It is likely that the ideal method of global food production will be some complex mixture of local initiatives, industrial farming practices, and global systems of distribution. It is equally likely that an analysis capable of calculating the best means to grow and distribute food lies outside the grasp of any individual consumer, requiring significant technical knowledge, collective effort and global coordination. None of this is well served by a culture that simply values the local.

Localism, in all its forms, represents an attempt to abjure the problems and politics of scale involved in large systems such as the global economy, politics and the environment. Our problems are increasingly systemic and global, and they require an equally systemic response. Action must always to some extent occur at the local level – and indeed some localist ideas, such as resiliency, can be useful. But localism-as-ideology goes much further, rejecting the systemic analysis that might guide and coordinate instances of local action to confront, oppose and potentially supplant oppressive instances of global power or looming planetary threats. Nowhere is the inability of localist solutions to challenge complex global problems more apparent than in movements towards localised business, banking and economics. Since the 2008 financial crisis, there have been a number of trends on the broad left towards reforming our economic and monetary systems. While much of this work is useful, one prominent strand has focused on transforming economic systems through localisation. The problem with big business, so the thinking goes, is not so much its inherently exploitative nature but the scale of the enterprises involved. Smaller businesses and banks would supposedly be more reflective of the local community’s needs.

One popular recent campaign, the ‘move your money’ movement, centred on the idea that, if it was the scale of banks that was to blame for the financial crisis, then customers ought to move their funds collectively to smaller, more virtuous institutions. Ethical-consumerist campaigns like this offer a semblance of effective action – they provide a meaningful narrative about the problems of the system and indicate the simple and pain-free action necessary to resolve it. As with most folk-political actions, it has all the appearances and feeling of having done something. Major banks are positioned as the bad guys, and individuals can supposedly produce significant effects just by moving their money into smaller, local banks and credit unions. What this model neglects is the complex abstractions of the modern banking system. Money circulates as immediately global and immediately interconnected with every other market. In any situation where a small bank or credit union has more deposits than it is able to profitably reinvest within its locality, it will inevitably seek investments within the broader financial system. Indeed, a reading of the accounts of smaller banks in the United States reveals that they partake in and contribute to the same global financial markets as everyone else – investing in Treasury, mortgage or corporate bonds while often participating in socially destructive lending practices that equal those of the major banks. While clearly a reformist measure, ‘move your money’ might at least have been expected to lead to some transformations in the composition of the US banking system. However, as of September 2013, total assets held by the six largest US banks had increased by 37 per cent since the financial crisis. Indeed, by every available measure the big US banks are larger today than at the beginning of the crisis, holding 67 per cent of all assets in the US banking system. And while legislative efforts across the world have made some attempts to impose restraints on the activities that led to the crisis (requiring increased capital asset ratios and regular ‘stress tests’ designed to avoid further bailouts), risky lending continues, and risky derivatives holdings remain at staggeringly high levels.

If localist efforts to constrain the size of the largest banks appear doomed to failure, what are we to make of alternative campaigns to replicate some of the local banks that make up much of the continental European banking system? For example, 70 per cent of the German banking sector consists of community or smaller-sized banks. German and Swiss community banks, their proponents argue, pool risks collectively and are mutually owned, with high degrees of autonomy to take advantage of local knowledge, and as a result generally remained profitable throughout the financial crisis. It is also argued that local banks of this type are more likely to lend to small businesses than the larger institutions that are more common in the United States and the UK. There are advantages to some local banking models, but their stability is often overstated. For example, despite being highly localised and under community control, Spain’s community banks (the cajas) took significant risks in the property market and other speculative investments in the 2000s, necessitating thoroughgoing financial restructuring after the 2008 crisis. Though under the alleged control of boards with community representation, investment decisions were effectively taken with little proper oversight. Localisation here meant the politicisation of allegedly disinterested governance boards, turning some cajas into platforms for local government investment in speculative property schemes, as a culture of cronyism took hold. With the worst of Spain’s banking crisis centred on the local banks, restructuring meant the merging of local banks to form larger institutions. Even in Germany, often touted as having the best localised banking system in the world, there were issues with some regional banks. The Landesbanken, for example, were heavily invested in structured credit products that performed particularly poorly during the financial crisis. The lesson to draw from this is that there is nothing inherent in smaller institutions that will enable them to resist the worst excesses of contemporary finance – and that the idea of cleanly separating the local from the global is today impossible. Political capture, the need to seek profitable investments beyond those available in the local area, and simply the high returns of more risky investments, are all factors leading local banks to participate in the broader financial system. Even mutual ownership is no guarantee of financial probity, as demonstrated by the recent travails of the UK’s Co-operative Bank, which almost collapsed entirely following an ill-conceived takeover of a building society in 2009. The systemic problems of the financial system can only be properly dealt with by taking apart financial power, whether by means of broad regulation (as was briefly achieved under postwar Keynesianism) or more revolutionary methods. Fetishising the small and the local seems to be a means of simply ignoring the more significant ways in which the system could be transformed for the better.

A folk-political sentiment has manifested itself in both radical horizontalist and more moderate localist movements, yet similar intuitions underpin a broad range of the contemporary left. Across these groups, a series of judgments are widely accepted: small is beautiful, the local is ethical, simpler is better, permanence is oppressive, progress is over. These kinds of ideas are favoured over any counter-hegemonic project – a politics that might contend with capitalist power at the largest scales. At its heart, much of contemporary folk politics therefore expresses a ‘deep pessimism: it assumes we can’t make large-scale, collective social change’. This defeatist attitude runs amok on the left – and perhaps with good reason, considering the continued failures of the past thirty years.

For centre-left political parties, nostalgia for a lost past is the best that can be hoped for. The most radical content to be found here consists of dreams of social democracy and the so-called ‘golden age’ of capitalism. Yet the very conditions which once made social democracy possible no longer exist. The capitalist ‘golden age’ was predicated on the production paradigm of the orderly factory environment, where (white, male) workers received security and a basic standard of living in return for a lifetime of stultifying boredom and social repression. Such a system depended on an international hierarchy of empires, colonies and an underdeveloped periphery; a national hierarchy of racism and sexism; and a rigid family hierarchy of female subjugation. Moreover, social democracy relied on a particular balance of forces between classes (and a willingness for compromise between them), and even this was only possible in the wake of the unprecedented destruction caused by the Great Depression and World War II, and in the face of external threats from communism and fascism. For all the nostalgia many may feel, this regime is both undesirable and impossible to recover. But the more pertinent point is that even if we could go back to social democracy, we should not. We can do better, and the social democratic adherence to jobs and growth means it will always err on the side of capitalism and at the expense of the people. Rather than modelling our future on a nostalgic past, we should aim to create a future for ourselves. The move beyond the constraints of the present will not be achieved through a return to a more humanised capitalism reconstructed from a misty-eyed recollection of the past.

While nostalgia for a lost past is clearly not an adequate response, neither is today’s widespread glorification of resistance. Resistance always means resistance against another active force. In other words, it is a defensive and reactive gesture, rather than an active movement. We do not resist a new world into being; we resist in the name of an old world. The contemporary emphasis on resistance therefore belies a defensive stance towards the encroachments of expansionary capitalism. Trade unions, for instance, position themselves as resisting neoliberalism with demands to ‘save our health system’ or ‘stop austerity’; but these demands simply reveal a conservative disposition at the heart of the movement. According to these demands, the best one can hope for is small impediments in the face of a predatory capitalism. We can only struggle to keep what we already have, as limited and crisis-ridden as it may be. Even in left-leaning Latin America this trend is visible, with the most significant successes largely around efforts to impede transnational corporations, particularly in relation to mining. In many circles resistance has come to be glorified, obscuring the conservative nature of such a stance behind a veil of radical rhetoric. Resistance is seen to be all that is possible, while constructive projects are nothing but a dream. While it can be important in some circumstances, in the task of building a new world, resistance is futile.

Other movements argue for an approach of withdrawal, whereby individuals exit from existing social institutions. Horizontalism is closely linked to this approach, being predicated on the rejection of existing institutions and the creation of autonomous forms of community. Indeed, the recent history of activism has tended towards such approaches. Often these approaches are explicitly opposed to complex societies, meaning that the ultimate implied destination is some form of communitarianism or anarcho-primitivism. Others suggest making oneself invisible in order to evade detection and repression by the state. At the extreme, some argue for what amounts to a left-wing survivalism: civilisation is in catastrophe, and we should therefore become invisible, retreat to small communes, and learn how to grow food, hunt, heal and defend ourselves. If left at the level of survivalism, these kinds of positions, while perhaps unappealing, would at least have some consistency. They at least have the virtue of being open about their implications. However, arguments for withdrawal and exit too easily confuse the idea of a social logic separate from capitalism with a social logic that is antagonistic to capitalism – or, in an even stronger claim, that poses a threat to capitalist logics. Yet capitalism has been and will continue to be compatible with a wide range of different practices and autonomous spaces. The Spanish town of Marinaleda offers a useful example of this. Over the course of three decades, this small community (pop. 2,700) has built up a ‘communist utopia’ that has expropriated land, built its own housing and co-operatives, kept living costs low, and provided work for everyone. Yet the limits of such an approach for transforming capitalism are quickly revealed: housing materials are provided by the regional government, agricultural subsidies come from the European Union, jobs are sustained by the rejection of labour-saving devices, income still comes from selling goods on wider capitalist markets, and businesses remain subjected to capitalist competition and the global financial crisis. Marinaleda is but one example of how the project of withdrawing, escaping or exiting from capitalism is still contained within a folk-political horizon, within which defending small bunkers of autonomy against the onslaught of capitalism is the best that can be hoped for. Yet we would argue not only that more can be hoped for (and achieved), but that, in the absence of broad and systematic contention, even those small pockets of resistance are likely to be swiftly eradicated.

Horizontalism, localism, nostalgia, resistance and withdrawal all embody, to greater or lesser degrees, folk-political intuitions about how to do politics. And they all remain inadequate for the task of transforming capitalism. But this is not to say that they should be rejected in their entirety. As the rest of the book will make clear, there are a number of important elements to retain from these approaches. Rather than being intrinsically malign, folk politics is simply partial, temporary and insufficient. Various horizontalist approaches, for example, have raised important questions about power, domination and hierarchy – but they have not developed adequate responses to them. Folk politics as a tendency retreats from the difficulty of these problems by attempting to dispel them from the outset. Yet, in a world where dominance, power, hierarchy and exploitation are imposed upon us, such questions must be confronted directly, rather than retreated from. Likewise, in a banal sense, all politics is local. We act upon things in our immediate vicinity in order to change larger political structures. We cannot simply reject the local. But today’s folk-political tendencies invoke a stronger sense of local politics: a retreat into the local in order to avoid the problems of a complex and abstract society; an assumption about the authenticity and naturalness of the local; and a neglect of scalable and sustainable practices that might go beyond the local. While all politics begins within the local, folk politics remains local.

In the end, a significant part of the problem with folk politics lies less in the particular tactics and practices it tends to adhere to than in the overarching strategic vision into which it is placed. Protests, marches, occupations, sit-ins and blockades all have their place: none of these tactics in themselves are fundamentally folk-political. But when they are marshalled by a strategic vision that sees temporary and small-scale changes as the horizon of success, or when they are extrapolated beyond the particular conditions that made them effective, they are inevitably going to be bound up within folk-political thinking. If the tactic of occupation, for example, is employed in order to create exemplars and temporary spaces of non-capitalist social relations, it will inevitably fail to achieve substantial change. If, on the other hand, it is understood as a mechanism to produce solidarity networks and mobilise them for further action, then it may still have use within broader counter-hegemonic strategies. But this sort of strategic reflection about the virtues and limits of any particular action is what is absent from too much of the left today. The numerous protests and marches and occupations typically operate without any sense of strategy, simply acting as dispersed and independent blips of resistance. There is far too little thought given to how to combine these various actions, and how they might function together to collectively build a better world. Instead we are left with actions that sometimes succeed but which rarely have an overarching eye to how this contributes to medium-and long-term goals. In the next chapter, we look at how the right undertook such strategic reflection and orchestrated a situation in which neoliberalism became the dominant common sense of our time.

If our era is dominated by one hegemonic ideology, it is that of neoliberalism. It is widely assumed that the most effective away to produce and distribute goods and services is by allowing instrumentally rational individuals to exchange via the market. State regulations and national industries are, by contrast, seen as distortions and inefficiencies holding back the productive dynamics inherent to free markets. Today, this vision of how economies should operate is what both its critics and proponents take as a baseline. Neoliberalism sets the agenda for what is realistic, necessary and possible. While the economic crisis of 2008 has upset the blind belief in neoliberalism, it nevertheless remains an entrenched part of our worldview – so much so that it is difficult even for its critics to picture coherent alternatives. Yet this ideology of neoliberalism did not emerge fully formed from the minds of Milton Friedman or Friedrich Hayek, or even the Chicago School, and its global hegemony did not arise inevitably from capitalism’s logic.

In its origins, neoliberalism was a fringe theory. Its adherents found it difficult to gain employment, were often untenured, and were mocked by the Keynesian mainstream. Neoliberalism was far from being the world-dominating ideology it would eventually become. The question this chapter will focus on is: How did a small band of neoliberals manage to reshape the world so radically? Neoliberalism was never a given, never a necessary endpoint of capitalist accumulation. Rather, it was a political project from the beginning, and a massively successful one in the end. It succeeded by skilfully constructing an ideology and the infrastructure to support it, and by operating in a non–folk-political manner. This chapter aims to show that neoliberalism functioned as an expansive universal ideology. From humble beginnings, the universalising logic of neoliberalism made it capable of spreading across the world, infiltrating the media, the academy, the policy world, education, labour practices, and the affects, feelings and identities of everyday people. This chapter therefore focuses primarily on how neoliberal hegemony was constructed, rather than on the specific content of neoliberalism. What is of greatest interest is how it was able to transform the ideological and material fabric of global society.

What standard histories of neoliberalism often neglect is the ways in which the main components of this ideological architecture were systematically and painstakingly set in place in the decades prior to the 1970s. It is in this prehistory of the neoliberal era that we can discern an alternative mode of political action – one that evades the limits of folk politics. This is not to say that this prehistory provides a model for any future leftist programme simply to copy; rather, it is an instructive case study in how the right was able to move beyond folk politics and create a new hegemony. The history of neoliberalism has been one of contingencies, struggle, concentrated action, patience and grand-scale strategic thinking. It has been a flexible idea, actualised in various ways according to the specific circumstances it encountered: from Germany in the 1940s, Chile in the 1970s and the UK in the 1980s, to post-Hussein Iraq in the 2000s. This versatility has made neoliberalism a sometimes contradictory project, but one that succeeds precisely by transforming these contradictions into productive tensions.

These tensions and variations have led some to believe that the term ‘neoliberalism’ is meaningless and should be relegated to polemics. But the term has some validity, even if it is often used loosely. In popular perception, neoliberalism is usually identified with a glorification of free markets – a position that also entails a commitment to free trade, private property rights and the free movement of capital. Defining neoliberalism as the veneration of free markets is problematic, however, because many ostensibly neoliberal states do not adhere to free-market policies. Others have argued that neoliberalism is predicated upon instilling competition wherever possible. This makes sense of the drive towards privatisation, but it fails to explain the debates within neoliberalism about whether competition is an ultimate good or not. Some take into account these tensions within neoliberalism and recognise it as the political, rather than economic, project of a particular class. There is certainly some truth to this claim, but, taken at face value, it cannot explain why neoliberal ideology was rejected for so long by the capitalist classes that purportedly benefit from it.

Our view is that, contrary to its popular presentation, neoliberalism differs from classical liberalism in ascribing a significant role to the state. A major task of neoliberalism has therefore been to take control of the state and repurpose it. Whereas classical liberalism advocated respect for a naturalised sphere supposedly beyond state control (the natural laws of man and the market), neoliberals understand that markets are not ‘natural’. Markets do not spontaneously emerge as the state backs away, but must instead be consciously constructed, sometimes from the ground up. For instance, there is no natural market for the commons (water, fresh air, land), or for healthcare, or for education. These and other markets must be built through an elaborate array of material, technical and legal constructs. Carbon markets required years to be built; volatility markets exist in large part as a function of abstract financial models; and even the most basic markets require intricate design. Under neoliberalism, the state therefore takes on a significant role in creating ‘natural’ markets. The state also has an important role in sustaining these markets – neoliberalism demands that the state defend property rights, enforce contracts, impose anti-trust laws, repress social dissent and maintain price stability at all costs. This latter demand, in particular, has greatly expanded in the wake of the 2008 crisis into the full-spectrum management of monetary issues through central banks. We therefore make a grave mistake if we think the neoliberal state is intended simply to step back from markets. The unprecedented interventions by central banks into financial markets are symptomatic not of the neoliberal state’s collapse, but of its central function: to create and sustain markets at all costs. Yet it has been an arduous and winding path from neoliberalism’s origins to the present, in which its ideas hold sway over those injecting trillions of dollars into the market.

The origins of neoliberalism are disparate, both geographically and intellectually. Elements of what would become the neoliberal project can be found in 1920s Vienna, 1930s Chicago and London, and 1930s and 1940s Germany. Throughout these decades, national movements worked on the margins of academia to maintain liberal ideas. It was not until 1938 that these independent movements were to gain their first transnational organisation, resulting from the Walter Lippmann Colloquium held in Paris just before the eruption of World War II. For the first time, this event brought together the classical liberal theorists, the new German ordoliberals, the British LSE liberals, and Austrian economists such as Friedrich Hayek and Ludwig von Mises. It focused on the historical ebbing of classical liberalism in the face of rising collectivism, and it was here that the first steps were made in consolidating a group of new liberal thinkers. Out of this event a new organisation – Centre International d’Études pour la Rénovation du Libéralisme – arose with the explicit aim of developing and spreading a new liberalism. The outbreak of World War II quickly put an end to the ambitious aims of this organisation, but the network of people involved would continue to work towards developing a neoliberalism. The seeds of the global neoliberal infrastructure had been planted.

It was an idea of Hayek’s that ultimately mobilised this infrastructure into a ‘neoliberal thought collective’ and inaugurated the slow rise of the new hegemony. Since the Walter Lippmann Colloquium had been buried in the onslaught of World War II, the transnational infrastructure of an incipient neoliberalism had to be reconstructed. A chance meeting with a Swiss businessman in 1945 gave Hayek the financial means to put his ideas into action. Thus was born the Mont Pelerin Society (MPS): a closed intellectual network that provided the basic ideological infrastructure for neoliberalism to ferment. It is no exaggeration to say that almost all of the important figures in the postwar creation of neoliberalism were in attendance at its first meeting in 1947, including the Austrian economists, the UK liberals, the Chicago School, the German ordoliberals and a French contingent.

From its beginnings, the MPS was consciously focused on changing political common sense and sought to develop a liberal utopia. It explicitly understood that this intellectual framework would then be actively filtered down through think tanks, universities and policy documents, in order to institutionalise and eventually monopolise the ideological terrain. In a letter to those he had invited, Hayek wrote that the purpose of the MPS was

to enlist the support of the best minds in formulating a programme which has a chance of gaining general support. Our effort therefore differs from any political task in that it must be essentially a long-run effort, concerned not so much with what would be immediately practicable, but with the beliefs which must gain ascendance if the dangers are to be averted which at the moment threaten individual freedom.

The Society thus made a ‘commitment to a long-run war of position in the “battle of ideas” … Privatized, strategic, elite deliberation was therefore established as the modus operandi.’ Opening the ten-day event, Hayek diagnosed the problem of the new liberals: a lack of alternatives to the existing (Keynesian) order. There was no ‘consistent philosophy of the opposition groups’ and no ‘real programme’ for change. As a result of this diagnosis, Hayek defined the central goal of the MPS as changing elite opinion in order to establish the parameters within which public opinion could then be formed. Contrary to a common assumption, capitalists did not initially see neoliberalism as being in their interests. A major task of the MPS was therefore to educate capitalists as to why they should become neoliberals. In order to achieve these goals, the vision of effective action was one of operating on the invisible framework of political common sense that was formed by the ideas circulating in elite networks. From its origins, the MPS eschewed folk politics by working with a global horizon, by working abstractly (outside the parameters of existing possibilities) and by formulating a clear strategic conception of the terrain to be occupied – namely, elite opinion – in order to change political common sense.

Behind this set of goals there lay a consistent but highly flexible account of what was new about neoliberalism. Divisions arose, in particular, over the role of the state in maintaining a competitive order; some argued that intervention was necessary to sustain competition, and others that intervention was the source of monopolies and centralisation. There were less divisive arguments over other particular policy positions, indicating that this was far from a homogeneous or unified group. In many ways, the common element was simply the social network itself, with its commitment to building a new liberalism. Yet this inbuilt plurality allowed neoliberalism to foster and mutate as it spread around the world, giving it hegemonic strength in its adaptations to the particularity of each space. Its flexibility as an ideology allowed it to excel in carrying out its hegemonic function of incorporating different groups into an overarching consensus.

These debates also extended to questions of strategy. Many members and financiers of Mont Pelerin were impatient with Hayek’s long-term approach and wanted to start producing books and other publications immediately, in order to influence the public. In the midst of Keynesian dominance, stable growth and low unemployment, Hayek keenly recognised the unlikelihood of changing public opinion. The Society’s strategy was self-consciously long-term, and Hayek’s view eventually won out within its meetings. Outside these meetings, the networks surrounding the MPS began actively to construct an extensive transnational infrastructure of ideological diffusion. Hayek had been planning since at least the mid 1940s to establish a system of think tanks propounding neoliberal ideas, while at the same time working to place Society members in government positions (a strategy that eventually produced three heads of state and a large number of cabinet ministers). It was the 1950s, in particular, that saw the proliferation of think tanks allied to the Society, and the subsequent diffusion of neoliberal ideas into the academic and policy worlds.

In the UK, the aims of the MPS were pursued by a network of think tanks and other organisations, such as the Institute of Economic Affairs, the Adam Smith Institute, the Centre for Policy Studies, and an array of smaller groups. Members of the MPS were to enter into US politics, first via think tanks like the American Enterprise Institute, and then through more formal positions such as Milton Friedman’s role as economic advisor to Barry Goldwater in his presidential run. Yet it was in Germany that neoliberalism would first achieve both organisational and policy success.

In the wake of World War II, the world was primed for significant changes in economic ideas. Yet it was Germany that faced a unique set of economic difficulties – both the well-known hyperinflation problems of the Weimar Republic and the arduous post–World War II reconstruction effort. While most of the world adopted Keynesian policies, Germany took a different pathway, guided by some of the same neoliberals who had convened at the Walter Lippmann Colloquium. Given the utter collapse of the German state, the problem facing postwar reconstruction planners was how to reconstitute the state – specifically, how to produce legitimacy without having a functional state infrastructure already in place. The answer was found in the ideas propounded by the early ordoliberals: establish a space of economic freedom. This in turn generated a web of connections between individuals which produced the legitimacy of a nascent postwar German state. Rather than a legal legitimacy, the state was seen to derive its legitimacy from a well-functioning economy. It was this idea that would provide the grounding for neoliberalism’s first policy experiments.

Following World War II, the ordoliberals began to move into government positions and implement their ideas, establishing the material and institutional foothold from which to shape economic ideology. The first, and perhaps most historically significant position, was the appointment of Ludwig Erhard to the directorate of economics in the postwar administrative zone of the British and US militaries. With the support of a fellow ordoliberal, Wilhelm Röpke, Erhard simultaneously eliminated all existing price and wage controls, and drastically cut income and capital taxes. This was a radical deregulatory move, and one that compelled the Soviet Union to establish a blockade on Berlin and inaugurate the Cold War. In the decades that followed, ordoliberals would come increasingly to populate significant positions in the German Ministry of Economics, with Erhard himself becoming Chancellor in 1963. But despite their intentions, the ordoliberals lacked a principled distinction between legitimate and illegitimate government interventions – an ambiguity which facilitated the German economy’s transformation into increasingly Keynesian forms. Interventions to maintain competition shaded into interventions to provide welfare, and by the 1970s Germany had become a standard social democratic state. The difficulties encountered in the policy world did not stop neoliberalism from innovating on other terrains, though – in particular, the space of the so-called ‘second-hand dealers’ in ideas.

Neoliberals had long emphasised the importance of using a variety of venues to influence elites and construct a new common sense. In the postwar era, this approach spanned academia, the media and the policy world. But one of the primary innovations for neoliberal consolidation of the ideological sphere was the use of think tanks. While they had existed for over a hundred years, the extensive use made of them by the MPS was a novelty. It involved developing policy arguments, building policy solutions and homing in on economic culprits. An informal division of labour was established, with some think tanks focusing on the large philosophical ideas, targeting the very assumptions and rationale of the orthodox Keynesian position – this was the task adopted by the Manhattan Institute for Policy Research (MIPR) in the 1970s, for example – while others aimed to produce more immediate public policy proposals. These were explicit attempts to unhinge the dominant worldview in order to subsequently introduce specific policy solutions that were grounded upon the neoliberal view.

The figure of Antony Fisher was vital in the building of neoliberalism’s ideological hegemony. One of the founders of the UK’s first neoliberal think tank – the Institute of Economic Affairs (IEA) – Fisher explicitly argued that the most difficult part of changing ideas lay not in their production, but in their diffusion. As a result of this belief, Fisher would be heavily involved in establishing conservative think tanks not only in the UK, but also in Canada (the Fraser Institute) and the United States (the MIPR). The IEA itself was focused on ‘those whom Hayek had called the “second-hand dealers” in ideas, the journalists, academics, writers, broadcasters, and teachers who dictate the long-term intellectual thinking of the nation’. The explicit intention was to change the ideological fabric of the British elite, infiltrating and subtly altering the terms of discourse. This also extended shrewdly to the mission of the IEA itself, which maintained a deceptive position on its own aims, presenting itself as an apolitical organisation focusing on research into markets in general. In line with this vision of ideological takeover, the IEA produced short pamphlets intended to be as accessible as possible to a mainstream audience. Moreover, these texts were written in a somewhat utopian fashion, without regard for whether a policy was capable of being implemented at that moment. The goal, as always, was the long-term redefinition of the possible. Over the course of decades, these various interventions developed a wide-ranging neoliberal worldview. More than just single-issue responses to the fashionable problems of the day, what the IEA and its associates had constructed was a systematic and coherent economic perspective. Think tanks instilled this worldview by educating and socialising rising members of political parties. Numerous members of what would become Thatcher’s administration passed through the IEA during the 1960s and 1970s. The outcome of the IEA’s efforts was not only to subtly transform the economic discourse in Britain, but also to naturalise two particular policies: the necessity of attacking trade union power, and the imperative of monetary stability. The former would purportedly let markets freely adapt to changing economic circumstances, while the latter would provide the basic price stability needed for a healthy capitalist economy.

In the United States, too, think tanks and academic research groups were built to push for a broadly neoliberal agenda, the Heritage Foundation and the Hoover Institute being two of the most notable. The MIPR aimed to redefine political common sense by writing books on neoliberal economics that were intended for a popular audience, some of which eventually sold over 500,000 copies. Other books, such as Charles Murray’s Losing Ground, laid the foundations for the policy shift which today identifies welfare dependency rather than poverty itself as the central social problem. Numerous other widespread policy ideas, such as zero-tolerance policing and workfare, stemmed from the policy factory of the MIPR. Its books succeeded in their objective of changing the common sense of the political classes and the public. The think tank, as an organisational form, was so integral to neoliberalism’s ideological success that the very process of creating think tanks was itself institutionalised. The Atlas Economic Research Foundation, founded in 1981 by Fisher, declared as its explicit aim ‘to institutionalise this process of helping start up new think tanks’. Atlas today boasts of having helped create or connect over 400 neoliberal think tanks in more than eighty countries. The sheer scale of the neoliberal ideological infrastructure is made fully transparent here.

Beyond think tanks, a variety of other mechanisms were used to build up a hegemonic discourse. In working to install the Chicago brand of neoliberalism as the dominant alternative, Milton Friedman wrote extensive op-eds and newspaper columns, and made use of television interviews in a way that was unprecedented for an academic. Businesses funded projects to turn his work into popular television shows, taking the media terrain by storm. These technological tools were the essential means he used to diffuse his economic vision to policymakers and the public. Newspapers such as the Wall Street Journal, Daily Telegraph and Financial Times paralleled this effort, shaping the public’s perspective by invoking neoliberal policies at every opportunity. Business schools and management consultancies also began to adopt and spread neoliberal ideas about corporate forms, and the Chicago School became a global beacon of neoliberal thought. Such institutions were crucial for the spread of neoliberal hegemony, since they were often the training grounds of the global elite. Individuals would come to these neoliberal US schools and then return to their own countries with the neoliberal ideology inculcated in them. By the 1970s, therefore, a full-spectrum infrastructure had developed to promulgate neoliberal ideas. Think tanks and utopian proclamations organised long-term thinking; public-facing speeches, pamphlets and media efforts framed the general outlines of the neoliberal common sense; and politicians and policy proposals made tactical interventions into the political terrain. Yet, despite their increasingly hegemonic potential, a mere decade prior to the arrival in office of Thatcher and Reagan, Keynesianism still reflected the most widely accepted approach to organising states and markets. The ideas of this group of neoliberal intellectuals were still often seen as senseless throwbacks to the failed policies of the pre–Great Depression era. But this would all change by the 1980s – a decade that would leave Keynesianism in disarray and enshrine neoliberalism as the preeminent model for economic modernisation.

Having made national inroads, neoliberalism first gained serious international prominence in the 1970s, as a response to the combined pressures of high unemployment and high inflation – both of which had originated in oil shocks, general commodity price rises, wage increases and the expansion of credit. The dominant Keynesian approach to the economy had argued that governments should stimulate the economy by putting money into it when unemployment was rising, but, when inflation was rising, take money out of the economy, to slow down price rises. In the 1970s, however, both problems arose simultaneously – rising inflation and rising unemployment, or ‘stagflation’. The traditional Keynesian policy solutions were incapable of dealing with this conjunction, thus seemingly dictating a turn to alternative theories. It is important to be clear that, at this point, multiple interpretations of the economic problem were possible. The production of inflation through wage rigidities and trade union power was not the only possible framing of the problem, and neoliberalism was not the only possible solution. Alternative interpretations were available, alternative answers possible; in the moment, no one knew what the way out would be. The neoliberal narrative of the crisis, for instance, plays down the role of banking deregulation by UK Chancellor Anthony Barber in the early 1970s and the breakdown of the Bretton Woods system. These deregulations sparked a surge in the monetary base and a subsequent surge in price inflation, and then wage inflation. In other words, an alternative narrative was possible in which the problem was not strong unions, but rather deregulated finance.

That the neoliberal story won out is in no small measure because of the ideological infrastructure that adherents to its ideas had constructed over decades. The neoliberals found themselves well placed, since they had routinely argued that inflation was a necessary outcome of the welfare state’s unwillingness to break wage and price rigidities. They had both a diagnosis of the problem and a solution. Government officials who were uncertain about what to do in the face of crisis found a plausible story in neoliberalism. It was thus the long-term construction of intellectual hegemony by the neoliberal thought collective that left them well positioned to leverage their ideas into power. As Milton Friedman famously put it, ‘Only a crisis – actual or perceived – produces real change. When that crisis occurs, the actions that are taken depend on the ideas that are lying around. That, I believe, is our basic function: to develop alternatives to existing policies, to keep them alive and available until the politically impossible becomes the politically inevitable.’ This programme spells out exactly what happened in the 1970s crisis. If alternative analyses of the crisis had been accepted, it would have entailed a policy response different from that of neoliberalism. Rather than attacking the power of labour, for example, politicians could have responded by re-regulating credit creation. In other words, neoliberalism was not a necessary outcome, but a political construction.

While Keynesian approaches were eventually able to develop an explanation of stagflation, by then it was too late, and the neoliberal approach had taken over academic economics and the policy world. In short, neoliberalism had become hegemonic. The decade after 1979 saw Margaret Thatcher elected as the British prime minister, Paul Volcker appointed as chairman of the Federal Reserve, and Ronald Reagan elected president of the United States. The IMF and World Bank, facing identity crises after the breakdown of the Bretton Woods system, were rapidly infiltrated and converted into crucibles of the true neoliberal faith by the 1980s. France undertook a neoliberal turn during the Mitterrand administration in the early 1980s, and the major economies of Europe became bound by the neoliberal policies embodied in the constitution of the European Union. In the United States and UK, a wave of systematic attacks were launched against the power of labour. Piece by piece, trade unions were demolished and labour regulations dismantled. Capital controls were loosened, finance was deregulated, and the welfare state began to be scavenged for profitable parts.

Outside Europe and North America, neoliberalism had already been forced on Chile and Argentina in the aftermath of military coups in the 1970s. The developing world debt crisis of the 1980s acted as a key moment to break traditional proto-socialist hegemonies and institute a turn to neoliberalism across the world. Moreover, with the breakdown of the USSR, Eastern Europe saw a wave of neoliberalising trends that were spurred on by Western economic advisors. It is estimated that these privatising policies in former Soviet nations led to a million deaths, proving that privatisation could be just as deadly as collectivisation, and that the expansion of neoliberalism was a far from bloodless affair. Misery, death and dictatorships lay in the wake of its advances across the globe. This was a normative regime that had forced itself into the everyday psychic and bodily reality of the world’s population. By the mid 1990s, with the collapse of the USSR, neoliberalism’s extension via IMF structural adjustment policies, its consolidation in the UK’s New Labour and Clinton’s US administration, and its ubiquity in the academic field of economics, neoliberalism had reached its hegemonic peak. The novel conjunctural moment of the 1970s was quickly forgotten by the public, and neoliberalism took on the universal and natural qualities that Thatcher’s doctrine of ‘there is no alternative’ had espoused. Neoliberalism had become a new common sense, accepted by every party in power. It mattered little whether the left or right won; neoliberalism had stacked the deck.

As we have seen, neoliberalism propagated its ideology through a division of labour – academics shaping education, think tanks influencing policy, and popularisers manipulating the media. The inculcation of neoliberalism involved a full-spectrum project of constructing a hegemonic worldview. A new common sense was built that came to co-opt and eventually dominate the terminology of ‘modernity’ and ‘freedom’ – terminology that fifty years ago would have had very different connotations. Today, it is nearly impossible to speak these words without immediately invoking the precepts of neoliberal capitalism.

We all know today that ‘modernisation’ translates into job cuts, the slashing of welfare and the privatisation of government services. To modernise, today, simply means to neoliberalise. The term ‘freedom’ has suffered a similar fate, reduced to individual freedom, freedom from the state, and the freedom to choose between consumer goods. Liberal ideas of individual freedom played an important role in the ideological struggle with the USSR, priming the population of the Western world to mobilise behind any ideology that purported to value individual freedoms. With its emphasis on individual freedoms, neoliberalism was able to co-opt elements of movements organised around ‘libertarianism, identity politics, [and] multiculturalism’. Likewise, by emphasising freedom from the state, neoliberalism was able to appeal to anarcho-capitalists and the movements of desire that exploded in May 1968. Lastly, with the idea of freedom being limited to a freedom of the market, the ideology could co-opt consumerist desires. At the level of production, neoliberal freedom could also recruit emerging desires among workers for flexible labour – desires that were soon turned against them. In struggling for and successfully seizing the ideological terrain of modernity and freedom, neoliberalism has managed to wind its way inexorably into our very self-conceptions. In arrogating the meaning of terms such as modernisation and freedom, neoliberalism has proved itself to be the single most successful hegemonic project of the last fifty years.

Neoliberalism has thus become ‘the form of our existence – the way in which we are led to conduct ourselves, to relate to others and to ourselves’. It is, in other words, not just politicians, business leaders, the media elite and academics who have been enrolled into this vision of the world, but also workers, students, migrants – and everyone else. In other words, neoliberalism creates subjects. Paradigmatically, we are constructed as competitive subjects – a role that encompasses and surpasses industrial capitalism’s productive subject. The imperatives of neoliberalism drive these subjects to constant self-improvement in every aspect of their lives. Perpetual education, the omnipresent requirement to be employable, and the constant need for self-reinvention are all of a piece with this neoliberal subjectivity. The competitive subject, moreover, straddles the divide between the public and the private. One’s personal life is as bound to competition as one’s work life. Under these conditions, it is no surprise that anxiety proliferates in contemporary societies. Indeed, an entire battery of psychopathologies has been exacerbated under neoliberalism: stress, anxiety, depression and attention deficit disorders are increasingly common psychological responses to the world around us. Crucially, the construction of everyday neoliberalism has also been a primary source of political passivity. Even if you do not buy into the ideology, its effects nevertheless force you into increasingly precarious situations and increasingly entrepreneurial inclinations. We need money to survive, so we market ourselves, do multiple jobs, stress and worry about how to pay rent, pinch pennies at the grocery store, and turn socialising into networking. Given these effects, political mobilisation becomes a dream that is perpetually postponed, driven away by the anxieties and pressures of everyday life.

At the same time, we should recognise that this production of subjectivity was not simply an external imposition. Hegemony, in all its forms, operates not as an illusion, but as something that builds on the very real desires of the population. Neoliberal hegemony has played upon ideas, yearnings and drives already existing within society, mobilising and promising to fulfil those that could be aligned with its basic agenda. The worship of individual freedom, the value ascribed to hard work, freedom from the rigid work week, individual expression through work, the belief in meritocracy, the bitterness felt at corrupt politicians, unions and bureaucracies – these beliefs and desires pre-exist neoliberalism and find expression in it. Bridging the left–right divide, many people today are simply angry at what they see as others taking advantage of the system. Hatred for the rich tax evader combines easily with disgust for the poor welfare cheat; anger at the oppressive employer becomes indistinguishable from anger at all politicians. This is linked with the spread of middle-class identities and aspirations – desires for home ownership, self-reliance and entrepreneurial spirit were fostered and extended into formerly working-class social spaces. Neoliberal ideology has a grounding in lived experience and does not exist simply as an academic puzzle. Neoliberalism has become parasitical on everyday experience, and any critical analysis that misses this is bound to misrecognise the deep roots of neoliberalism in today’s society. Over the course of decades, neoliberalism has therefore come to shape not only elite opinions and beliefs, but also the normative fabric of everyday life itself. The particular interests of neoliberals have become universalised, which is to say, hegemonic. Neoliberalism constitutes our collective common sense, making us its subjects whether we believe in it or not.

It has often been argued that neoliberalism succeeded (and continues to succeed in spite of its failures) because it is supported by a series of overlapping and powerful interests – the transnational elite, the financiers, the major stockholders of the largest corporations. While these interests have certainly assisted the potency of the neoliberal ideology, such an explanation nevertheless leaves certain questions unanswered. If elite support was sufficient for ideological success, and if neoliberalism was clearly beneficial to elites, there would not have been a forty-year delay between the initial formulation of the ideas and their implementation. Instead, the embedded liberalism of Keynesianism remained ideologically dominant even as it constrained powerful interests. In particular, financial interests were sidelined for a long period after the 1929 crash and ensuing Great Depression. The power dynamics maintaining the Keynesian consensus needed to be taken apart piecemeal. Equally, an explanation of neoliberalism’s success that relies solely on its compatibility with particular elite interests also leaves unexplained why other possible responses to the problems of the 1970s were never implemented. An important element of neoliberalism’s eventual ideological success is that there was both a crisis and a readily available solution. The crisis (stagflation) was one that no government knew how to deal with at the time, while the solution was the preconceived neoliberal ideas that had been fermenting for decades in its ideological ecology. It was not that neoliberals presented a better argument for their position (the myth of rational political discourse); rather, an institutional infrastructure was constructed to project their ideas and establish them as the new common sense of the political elite.

In all of this there are important lessons to be learned, which have led some to call for a Mont Pelerin of the left. On the broadest level, this history of neoliberalism serves to demonstrate that the greatest recent success of the right – installing a neoliberal hegemony on a global scale – was accomplished through non–folk-political means. This means, in the first place, that the neoliberals thought in long-term visions. This was a different temporality from both election cycles and the boom-and-bust of individual protests. Instead, what the left can learn from is how the MPS patiently set out explicit objectives and analysed the terrain of their historical conjunction, all in order to propose specific and effective means to alter that terrain. It set its sights on long-term change, waiting forty years for the crisis of Keynesianism and the emergence of Reagan and Thatcher. In taking this approach, the intellectuals of neoliberalism thought abstractly in terms of possibilities: what was impossible during their own time became possible later, partly through their actions and preparations. Secondly, they sought to build a counter-hegemonic project that would overturn the consensus around social democracy and Keynesian policies. They took a full-spectrum approach to changing hegemonic conditions and built up an entire ideological infrastructure that was capable of insinuating itself into every political issue and every fibre of political common sense. It overthrew the hegemonic ideas of its time. As Philip Mirowski writes, their strategic genius was

to appreciate that it is not enough to dangle a utopian vision just beyond reach as eventual motivation for political action; the cadre that triumphs is the side that can simultaneously mount a full set of seemingly unrelated political proposals that deal with the short-, medium-, and long-term horizons of action, combining regimes of knowledge and interim outcomes, so that the end result is the inexorable movement of the polis ever closer to the eventual goal. The shrewd strategy of simultaneously conducting both a short game and a long game, superficially appearing to the uninformed to be in mutual conflict but united behind the scenes by overarching theoretical aims, is probably the single most significant explanation of the triumph of neoliberal policies during a conjuncture where their opponents had come to expect utter refutation.

The third major lesson for the left to learn is that the loose collective of MPS also thought expansively in spatial terms – aiming to spread the network globally, through key nodes. In the think tank, they found an organisational form adapted to the task of global intellectual hegemony. They established networks between think tanks, politicians, journalists, the media and teachers – building a consistency between these disparate groups that did not require a unity of purpose or organisational form. This entailed an admirable flexibility in their project. While neoliberalism is often denounced as being too empirically disparate to make sense as a coherent project, it is in fact the willingness to modify its ideas in light of conditions on the ground that has made it particularly powerful as an ideology.

The call for a Mont Pelerin of the left should therefore not be taken as an argument to simply copy its mode of operation. The argument is rather that the left can learn from the long-term vision, the methods of global expansion, the pragmatic flexibility and the counter-hegemonic strategy that united an ecology of organisations with a diversity of interests. The demand for a Mont Pelerin of the left is ultimately a call to build anew the hegemony of the left.

This chapter marks a turning point. From the negative task of diagnosing the strategic limitations of the contemporary left, this chapter begins the positive project of elaborating an escape route from our current condition. In the following chapters, we argue that the contemporary left should reclaim modernity, build a populist and hegemonic force, and mobilise towards a post-work future. Folk-political attempts at prefiguration, direct action and relentless horizontalism are unlikely to achieve this, partly because they misrecognise the nature of their opponent. Capitalism is an aggressively expansive universal, from which efforts to segregate a space of autonomy are bound to fail. Withdrawal, resistance, localism and autonomous spaces represent a defensive game against an uncompromising and incessantly encroaching capitalism. Moreover, particularisms can easily coexist with capitalist universalism. The innumerable cultural and political variants of capitalism do little to stifle the expansion of commodification, the creation of proletariats, and the imperative of accumulation. The much-lamented capacity of capitalism to incorporate resistance more often than not simply reveals that particularisms are, in themselves, incapable of competing against a universalism. Indeed, given neoliberalism’s inherently expansionary nature, only an alternative expansionary and inclusive universal of some kind will be able to combat and supersede capitalism on a global scale. With the dynamics of accumulation at the heart of capital, a non-expansionary capitalism is an oxymoron. An ambitious leftist politics therefore cannot be satisfied with measures to defend localities. It must seek instead to construct a new future-oriented politics capable of challenging capitalism at the largest scales. It must unmask the pseudo-universality of capitalist social relations and recapture the meaning of the future.

This chapter takes a step back from the empirical and historical focus of the earlier chapters, and seeks to elaborate a philosophical ground for the chapters that follow. We argue that a key element of any future-oriented left must be to contest the idea of ‘modernity’. Whereas folk-political approaches lack an enticing vision of the future, struggles over modernity have always been struggles over what the future should look like: from the communist modernism of the early Soviet Union to the scientific socialism of postwar social democracy, and on to the sleek neoliberal efficiency of Thatcher and Reagan. What it means to be modern is not pre-established, but is instead a highly ‘contested field’. Yet, in the face of capitalism’s success at universalising itself, this term has been almost fully ceded to the right. ‘Modernisation’ has come to signify simply some dread combination of privatisation, heightened exploitation, rising inequality and inept managerialism. Likewise, notions of the future tend to revolve around ideas of ecological apocalypse, the dismantling of the welfare state, or corporate-led dystopia, rather than anything bearing the mark of utopia or universal emancipation. For many, therefore, modernity is simply a cultural expression of capitalism. From this accepted wisdom, the necessary conclusion follows: only the cancellation of modernity can bring about the end of capitalism. The result has been an anti-modern tendency within numerous social movements from the 1970s onward. Yet this mistaken conflation of modernity with the institutions of capitalism overlooks the alternative forms it can take, and the ways in which many anti-capitalist struggles rely upon its ideals. Modernity presents both a narrative for popular mobilisation and a philosophical framework for understanding the arc of history. As the term that indexes the direction of society, it must be a key discursive battleground for any leftist politics invested in creating a better world. This chapter sets out the broad philosophical stakes of such a project by examining three factors that would help to elaborate a left modernity: an image of historical progress, a universalist horizon and a commitment to emancipation.

In discussing ‘modernity’, we face the immediate problem of clarifying what it means. It can refer to a chronological period, typically filtered through European history with a variety of events having been posited as its origin: the Renaissance, the Enlightenment, the French Revolution, the Industrial Revolution. For others, modernity is defined by a distinct set of practices and institutions: widespread bureaucratisation, a basic framework of liberal democracy, the differentiation of social functions, the colonisation of the non-European world, and the expansion of capitalist social relations. Yet modernity also refers to a repertoire of conceptual innovations revolving around universal ideals of progress, reason, freedom and democracy. This chapter emphasises these latter aspects: modernity names a set of concepts that have been independently developed in numerous cultures across the world, but which took on a particular resonance in Europe. These are the elements of modernity that cannot be renounced, and that form the well-spring from which more popular discourses around modernisation are generated. The conceptual ideals – such as freedom, democracy and secularism – are the source of both capitalist modernity and the struggles against it. Ideas associated with modernity animated the work of abolitionists, formed the basis of numerous African trade union struggles, and continue today in ‘those thousands of campaigns for wages, land rights, basic health, and security, dignity, self-determination, autonomy, and so forth’. In broad terms, then, whether it is explicitly recognised or not, the political struggles of today are struggles within the space of modernity and its ideals. Modernity must be contested, not rejected.

To invoke modernity is ultimately to raise the question of the future. What should the future look like? What courses should we set? What does it mean to be contemporary? And whose future is it? Since the emergence of the term, modernity has been concerned with unravelling a circular or retrospective notion of time and introducing a rupture between the present and the past. With this break, the future is projected as being potentially different from and better than the past. Modernity is tantamount to ‘the discovery of the future’ and has therefore found itself intimately linked with notions such as ‘progress, advance, development, emancipation, liberation, growth, accumulation, Enlightenment, embetterment, [and the] avant-garde’. Suggesting that history can progress through deliberate human action, it is the nature of this progress that competing definitions of modernity have struggled over. Historically, the left has found its natural home in being oriented towards the future. From early communist visions of technological progress, to Soviet space utopias, to the social democratic rhetoric of the ‘white heat of technology’, what set the left apart from the right was its unambiguous embrace of the future. The future was to be an improvement over the present in material, social and political terms. By contrast, the forces of the political right were, with a few notable exceptions, defined by their defence of tradition and their essentially reactionary nature.

This situation was reversed during the rise of neoliberalism, with politicians like Thatcher commanding the rhetoric of modernisation and the future to great effect. Co-opting these terms and mobilising them into a new hegemonic common sense, neoliberalism’s vision of modernity has held sway ever since. Consequently, discussions of the left in terms of the future now seem aberrant, even absurd. With the postmodern moment, the seemingly intrinsic links between the future, modernity and emancipation were prized apart. Philosophers like Simon Critchley can now confidently assert that ‘we have to resist the idea and ideology of the future, which is always the ultimate trump card of capitalist ideas of progress’. Such folk-political sentiments blindly accept the neoliberal common sense, preferring to shy away from grand visions and replace them with a posturing resistance. From the radical left’s discomfort with technological modernity to the social democratic left’s inability to envision an alternative world, everywhere today the future has largely been ceded to the right. A skill that the left once excelled at – building enticing visions for a better world – has deteriorated after years of neglect.

If the left is to recover a sense of progress, however, it cannot simply adopt the classic images of history headed towards a singular destination. Progress, for these approaches, was not only possible, but in fact woven as a necessity into the very fabric of history. Human societies were thought to travel along a pre-defined pathway towards a single outcome modelled after Europe. The nations of Europe were deemed to have developed capitalist modernity independently, and their historical experiences of development were considered to be both necessary and superior to those of other cultures. Such ideas dominated traditional European philosophy and continued on in the influential modernisation literature of the 1950s and 1960s, with their attempts to naturalise capitalism against a Soviet opponent. Partly endorsed by both early Marxism and later Keynesian and neoliberal capitalisms, a one-size-fits-all model of historical progress positioned non-Western societies as lacking and in need of development – a position that served to justify colonial and imperial practices.

From the standpoint of their philosophical critics, these notions of progress were disparaged precisely for their belief in preconceived destinations – whether in the liberal progression towards capitalist democracy or in the Marxist progression towards communism. The complex and often disastrous record of the twentieth century demonstrated conclusively that history could not be relied upon to follow any predetermined course. Regression was as likely as progress, genocide as possible as democratisation. In other words, there was nothing inherent in the nature of history, the development of economic systems, or sequences of political struggle that could guarantee any particular outcome. From a broadly left perspective, for example, even those limited but not insignificant political gains that have been achieved – such as welfare provision, women’s rights and worker protections – can be rolled back. Moreover, even in states where nominally communist governments took power, it proved far more difficult than expected to transition from a capitalist system of production to a fully communist one. This series of historical experiences fuelled an internal critique of European modernity by way of psychoanalysis, critical theory and poststructuralism. For the thinkers of postmodernism, modernity came to be associated with a credulous naivety. In Jean-François Lyotard’s epochal definition, postmodernity was identified as the era that has grown to be suspicious of the grand metanarrative. On this account, postmodernity is a cultural condition of disillusionment with the kinds of grandiose narratives represented by capitalist, liberal and communist accounts of progress.

To be sure, these critiques capture something important about the chronological texture of our time. And yet, the announcement of the end of grand narratives has often been viewed by those outside Europe as being absolutely of a piece with modernity. Further, with the benefit of thirty years’ hindsight, the broader impact of the cultural condition diagnosed by Lyotard has not been the decline of belief in metanarratives per se, but rather a broad disenchantment with those offered by the left. The association between capitalism and modernisation remains, while properly progressive notions of the future have wilted under postmodern critique and been quashed beneath the social wreckage of neoliberalism. Most significantly, with the collapse of the Soviet Union and the rise of globalisation, history does appear to have a grand narrative. Throughout the world, markets, wage labour, commodities and productivity-enhancing technologies have all expanded under the systemic imperative to accumulate. Capitalism has become the destiny of contemporary societies, happily coexisting with national differences and paying little heed to clashes between civilisations. But we can draw a distinction here between the endpoint (capitalism) and the pathway towards it. Indeed, the mutual entanglement of countries means that the European pathway (heavily reliant on exploiting colonies and slavery) is barred for many of the newly developing countries. While there are broad paradigms of development, each country has had to find its own unique way to respond to the imperatives of global capitalism. The path of capitalist modernisation is therefore instantiated in different cultures, following different trajectories and with different rhythms of development. Uneven and combined development is the order of the day. Progress is therefore not bound to a single European path, but is instead filtered through a variety of political and cultural constellations, all directed towards instantiating capitalist relations. Today, modernisers simply fight over which variant of capitalism to install.

Recuperating the idea of progress under such circumstances means, first and foremost, contesting the dogma of this inevitable endpoint. Capitalist modernity was never a necessary outcome, but instead a successful project driven by various classes and a systemic imperative towards accumulation and expansion. Various modernities are possible, and new visions of the future are essential for the left. Such images are a necessary supplement to any transformative political project. They give a direction to political struggles and generate a set of criteria to adjudicate which struggles to support, which movements to resist, what to invent, and so on. In the absence of images of progress, there can only be reactivity, defensive battles, local resistance and a bunker mentality – what we have characterised as folk politics. Visions of the future are therefore indispensable for elaborating a movement against capitalism. Contra the earlier thinkers of modernity, there is no necessity to progress, nor a singular pathway from which to adjudicate the extent of development. Instead, progress must be understood as hyperstitional: as a kind of fiction, but one that aims to transform itself into a truth. Hyperstitions operate by catalysing dispersed sentiment into a historical force that brings the future into existence. They have the temporal form of ‘will have been’. Such hyperstitions of progress form orienting narratives with which to navigate forward, rather than being an established or necessary property of the world. Progress is a matter of political struggle, following no pre-plotted trajectory or natural tendency, and with no guarantee of success. If the supplanting of capitalism is impossible from the standpoint of one or even many defensive stances, it is because any form of prospective politics must set out to construct the new. Pathways of progress must be cut and paved, not merely travelled along in some pre-ordained fashion; they are a matter of political achievement rather than divine or earthly providence.

Any elaboration of an alternative image of progress must inevitably face up to the problem of universalism – the idea that certain values, ideas and goals may hold across all cultures. Capitalism, as we have argued, is an expansionary universal that weaves itself through multiple cultural fabrics, reworking them as it goes along. Anything less than a competing universal will end up being smothered by an all-embracing series of capitalist relations. Various particularisms – localised, specific forms of politics and culture – cohabitate with ease in the world of capitalism. The list of possibilities continues to grow as capitalism differentiates into Chinese capitalism, American capitalism, Brazilian capitalism, Indian capitalism, Nigerian capitalism, and so on. If defending a particularism is insufficient, it is because history shows us that the global space of universalism is a space of conflict, with each contender requiring the relative provincialisation of its competitors. If the left is to compete with global capitalism, it needs to rethink the project of universalism.

But to invoke such an idea is to call forth a number of fundamental critiques directed against universalism in recent decades. While a universal politics must move beyond any local struggles, generalising itself at the global scale and across cultural variations, it is for these very reasons that it has been criticised. As a matter of historical record, European modernity was inseparable from its ‘dark side’ – a vast network of exploited colonial dominions, the genocide of indigenous peoples, the slave trade, and the plundering of colonised nations’ resources. In this conquest, Europe presented itself as embodying the universal way of life. All other peoples were simply residual particulars that would inevitably come to be subsumed under the European way – even if this required ruthless physical violence and cognitive assault to guarantee the outcome. Linked to this was a belief that the universal was equivalent to the homogeneous. Differences between cultures would therefore be erased in the process of particulars being subsumed under the universal, creating a culture modelled in the image of European civilisation. This was a universalism indistinguishable from pure chauvinism. Throughout this process, Europe dissimulated its own parochial position by deploying a series of mechanisms to efface the subjects who made these claims – white, heterosexual, property-owning males. Europe and its intellectuals abstracted away from their location and identity, presenting their claims as grounded in a ‘view from nowhere’. This perspective was taken to be untarnished by racial, sexual, national or any other particularities, providing the basis for both the alleged universality of Europe’s claims and the illegitimacy of other perspectives. While Europeans could speak and embody the universal, other cultures could only be represented as particular and parochial. Universalism has therefore been central to the worst aspects of modernity’s history.

Given this heritage, it might seem that the simplest response would be to rescind the universal from our conceptual arsenal. But, for all the difficulties with the idea, it nevertheless remains necessary. The problem is partly that one cannot simply reject the concept of the universal without generating other significant problems. Most notably, giving up on the category leaves us with nothing but a series of diverse particulars. There appears no way to build meaningful solidarity in the absence of some common factor. The universal also operates as a transcendent ideal – never satisfied with any particular embodiment, and always open to striving for better. It contains the conceptual impulse to undo its own limits. Rejecting this category also risks Orientalising other cultures, transforming them into an exotic Other. If there are only particularisms, and provincial Europe is associated with reason, science, progress and freedom, then the unpleasant implication is that non-Western cultures must be devoid of these. The old Orientalist divides are inadvertently sustained in the name of a misguided anti-universalism. On the other hand, one risks licensing all sorts of oppressions as simply the inevitable consequence of plural cultural forms. All the problems of cultural relativism reappear if there are no criteria to discern which global knowledges, politics and practices support a politics of emancipation. Given all of this, it is unsurprising to see aspects of universalism pop up throughout history and across cultures, to see even its critics begrudgingly accept its necessity, and to see a variety of attempts to revise the category.

To maintain this necessary conceptual tool, the universal must be identified not with an established set of principles and values, but rather with an empty placeholder that is impossible to fill definitively. Universals emerge when a particular comes to occupy this position through hegemonic struggle: the particular (‘Europe’) comes to represent itself as the universal (‘global’). It is not simply a false universal, though, as there is a mutual contamination: the universal becomes embodied in the particular, while the particular loses some of its specificities in functioning as the universal. Yet there can never be a fully achieved universalism, and universals are therefore always open to contestation from other universals. This is what we will later outline in politico-strategic terms as counter-hegemony – a project aimed at subverting an existing universalism in favour of a new order. This leads us to our second point – as counter-hegemonic, universals can have a subversive and liberating strategic function. On the one hand, a universal makes an unconditional demand – everything must be placed under its rule. Yet, on the other hand, universalism is never an achieved project (even capitalism remains incomplete). This tension renders any established hegemonic structure open to contestation and enables universals to function as insurrectionary vectors against exclusions. For example, the concept of universal human rights, problematic as it may be, has been put to use by numerous movements, ranging from local housing struggles to international justice for war crimes. Its universal and unconditional demand has been mobilised in order to highlight those who are left out of its protections and rights. Similarly, feminists have criticised certain concepts as exclusionary of women and mobilised universal claims against their constraints, as in the use of the universal idea that ‘all humans are equal’. In such cases, the particular (‘woman’) becomes a way to prosecute a critique against an existing universal (‘humanity’). Meanwhile, the previously established universal (‘humanity’) becomes revealed as a particular (‘man’). These examples show that universals can be revitalised by the struggles that both challenge and elucidate them. In this regard, ‘to appeal to universalism as a way of asserting the superiority of Western culture is to betray universality, but to appeal to universalism as a way of dismantling the superiority of the West is to realize it’. Universalism, on this account, is the product of politics, not a transcendent judge standing above the fray.

We can turn now to one final aspect of universalism, which is its heterogeneous nature. As capitalism makes clear, universalism does not entail homogeneity – it does not necessarily involve converting diverse things into the same kind of thing. In fact, the power of capitalism is precisely its versatility in the face of changing conditions on the ground and its capacity to accommodate difference. A similar prospect must also hold for any leftist universal – it must be one that integrates difference rather than erasing it. What then does all of this mean for the project of modernity? It means that any particular image of modernity must be open to co-creation, and further transformation and alteration. And in a globalised world where different peoples necessarily co-exist, it means building systems to live in common despite the plurality of ways of life. Contrary to Eurocentric accounts and classic images of universalism, it must recognise the agency of those outside Europe, and the necessity of their voices in building truly planetary and universal futures. The universal, then, is an empty placeholder that hegemonic particulars (specific demands, ideals and collectives) come to occupy. It can operate as a subversive and emancipatory vector of change with respect to established universalisms, and it is heterogeneous and includes differences, rather than eliminating them.

While the left has traditionally been associated with ideals of equality (manifested today in the focus on income and wealth inequalities), we believe that freedom is an equally essential principle of left modernity. This concept has been central to the political battles fought throughout the twentieth century, with the United States routinely posing as ‘the free world’ against a totalitarian enemy (in the figure of the USSR, and then the increasingly incoherent images of ‘Islamofascism’). In these hegemonic battles, capitalism has repeatedly asserted its superiority by upholding an idea of negative freedom. This is the freedom of individuals from arbitrary interference by other individuals, collectives and institutions (paradigmatically, the state). Negative freedom’s insistence on the absence of interference has made it an ideal tool to wield against purportedly totalitarian opponents, yet it is a woefully emaciated concept of freedom. In practice, it translates into a modicum of political freedom from the state (ever less so in an age of digital spying and the war on terror) and the economic freedoms to sell our labour power and to choose between shiny new consumer goods. Under negative freedom, the rich and the poor are considered equally free, despite the obvious differences in their capacities to act. Negative freedom is entirely compatible with mass poverty, starvation, homelessness, unemployment and inequality. It is also entirely compatible with our desires being manufactured and designed by pervasive advertising. Against this limited concept of freedom, we argue for a much more substantial version.

Whereas negative freedom is concerned with assuring the formal right to avoid interference, ‘synthetic freedom’ recognises that a formal right without a material capacity is worthless. Under a democracy, for example, we are all formally free to run for political leadership. But without the financial and social resources to run a campaign, this is a meaningless freedom. Equally, we are all formally free to not take a job, but most of us are nevertheless practically forced into accepting whatever is on offer. In either case, various options may be theoretically available, but for all practical purposes are off the table. This reveals the significance of having the means to realise a formal right, and it is this emphasis on the means and capacities to act that is crucial for a leftist approach to freedom. As Marx and Engels wrote, ‘it is possible to achieve real liberation only in the real world and by real means’. Understood in this way, freedom and power become intertwined. If power is the basic capacity to produce intended effects in someone or something else, then an increase in our ability to carry out our desires is simultaneously an increase in our freedom. The more capacity we have to act, the freer we are. One of the biggest indictments of capitalism is that it enables the freedom to act for only a vanishingly small few. A primary aim of a postcapitalist world would therefore be to maximise synthetic freedom, or in other words, to enable the flourishing of all of humanity and the expansion of our collective horizons. Achieving this involves at least three different elements: the provision of the basic necessities of life, the expansion of social resources, and the development of technological capacities. Taken together, these form a synthetic freedom that is constructed rather than natural, a collective historical achievement rather than the result of simply leaving people be. Emancipation is thus not about detaching from the world and liberating a free soul, but instead a matter of constructing and cultivating the right attachments.

In the first place, synthetic freedom entails the maximal provision of the basic resources needed for a meaningful life: things like income, time, health and education. Without these resources, most people are left formally but not really free. Understood in this way, rising global inequality is revealed as an equally massive disparity in freedom. One initial step in resolving this is the classic social democratic goal of providing the common goods of society, such as healthcare, housing, childcare, education, transport and internet access. The liberal idea in which these basic necessities of life are supposedly enhanced by freedom of choice in the market ignores the actual (financial and cognitive) burdens involved in making such choices. In a world of synthetic freedom, high-quality public goods would be provided for us, leaving us to get on with our lives rather than worrying about which healthcare provider to go with. Beyond the social democratic imagination, however, lie two further essentials of existence: time and money. Free time is the basic condition for self-determination and the development of our capacities. Equally, synthetic freedom demands the provision of a basic income to all in order for them to be fully free. Such a policy not only provides the monetary resources for living under capitalism, but also makes possible an increase in free time. It provides us with the capacity to choose our lives: we can experiment and build unconventional lives, choosing to foster our cultural, intellectual and physical sensibilities instead of blindly working to survive. Time and money therefore represent key components of freedom in any substantive sense.

A full image of synthetic freedom must also seek to expand our capacities beyond what is currently possible. If it is to avoid the problem of manipulating people into contentment with the status quo, synthetic freedom must be open to whatever people might desire. That is to say, freedom cannot simply be equated with making existing options viable, but instead must be open to the largest possible set of options. In this, collective resources are essential. Processes of social reasoning, for instance, can enable common understandings of the world, creating a ‘we’ in the process that has much greater powers to act than individuals alone. Equally, language is effectively cognitive scaffolding that enables us to leverage symbolic thought to expand our horizons. The development, deepening and expansion of knowledge enable us to imagine and achieve capacities that are otherwise unattainable. As we acquire technical knowledge of our built environment and scientific knowledge of the natural world, and come to understand the fluid tendencies of the social world, we gain greater powers to act. As Louis Althusser put it,

Just as knowledge of the laws of light has never prevented men from seeing … so knowledge of the laws that govern the development of societies does not prevent men from living, or take the place of labour, love and struggle. On the contrary: knowledge of the laws of light has produced the glasses which have transformed men’s sight, just as knowledge of the laws of social development has given rise to endeavours which have transformed and enlarged the horizon of human existence.

The anti-intellectualism that permeates the political right, and increasingly infects the critical left, is therefore a retrogression of the worst kind. Healthy scepticism is transformed into an abdication of our commitments to expand freedom. This retrogression in relation to knowledge also occurs in the fantasies of immediate and unbound freedoms in practice. The voluntaristic image that sees mediations, institutions and abstractions as opposed to freedom simply confuses the absence of artifice with the full expression of freedom. Needless to say, this is misguided. Collective action, with its expansion of synthetic freedom, is more often than not carried out through complex divisions of labour, mediated chains of engagement and abstract institutional structures. The social aspect of synthetic freedom is therefore not a return to some human desire for face-to-face sociality and simple cooperation, but instead a call for collective, complex and mediated self-determination.

Finally, if we are to expand our capacities to act, the development of technology must play a central role. As has always been the case, ‘technology is the source of our options [and] options are the basis of a future that keeps us above the level of pawn’. Our level of freedom is highly dependent upon the historical conditions of scientific and technological development. The artifices that emerge from these fields both expand existing capacities for action and create entirely new ones in the process. The full development of synthetic freedom therefore requires a reconfiguration of the material world in accordance with the drive to expand our capacities for action. It demands experimentation with collective and technological augmentation, and a spirit that refuses to accept any barrier as natural and inevitable. Cyborg augmentations, artificial life, synthetic biology and technologically mediated reproduction are all examples of this elaboration. The overall aim must therefore be picked out as an unrelenting project to unbind the necessities of this world and transform them into materials for the further construction of freedom. Such an image of emancipation can never be satisfied with or condensed into a static society, but will instead continually strain beyond any limitations. Freedom is a synthetic enterprise, not a natural gift.

Underlying this idea of emancipation is a vision of humanity as a transformative and constructible hypothesis: one that is built through theoretical and practical experimentation and elaboration. There is no authentic human essence to be realised, no harmonious unity to be returned to, no unalienated humanity obscured by false mediations, no organic wholeness to be achieved. Alienation is a mode of enablement, and humanity is an incomplete vector of transformation. What we are and what we can become are open-ended projects to be constructed in the course of time. As Sadie Plant puts it,

It’s always been problematic to talk about the liberation of women because that presupposes that we know what women are. If both women and men have been organised into the forms we currently take, then we don’t want to liberate what we are now, if you see what I mean … It’s not a question of liberation so much as a question of evolution – or engineering. There’s a gradual re-engineering of what it can be to be a woman and we don’t yet know what it is. We have to find out.

What must therefore be articulated is a humanism that is not defined in advance. This is a project of self-realisation, but one without a pre-established endpoint. It is only through undergoing the process of revision and construction that humanity can come to know itself. This means revising the human both theoretically and practically, engaging in new modes of being and new forms of sociality as practical ramifications of making ‘the human’ explicit. It is to undertake an interventionist approach to the human that is opposed to those humanisms that protect a parochial image of the human at all costs. These interventions range from individual bodily experimentation to collective political mobilisations against restricted images of the human, and everything in between. It means liberating ourselves from the decrepit economic image of humanity that capitalist modernity has installed, and inventing a new humanity. Emancipation, under this vision, would therefore mean increasing the capacity of humanity to act according to whatever its desires might become. And universal emancipation would be the insistent and maximal extension of this goal to the entirety of our species. It is in this sense that universal emancipation lies at the heart of a modern left.

We have seen that, without a conception of the future, the left becomes bound to a defence of tradition, and to protecting bunkers of resistance. What, then, would a left modernity look like? It would be one that offered enticing and expansive visions of a better future. It would operate with a universal horizon, mobilise a substantial concept of freedom, and make use of the most advanced technologies in order to achieve its emancipatory goals. Rather than a Eurocentric view of the future, it would rely upon a global set of voices articulating and negotiating in practice what a common and plural future might be. Whether operating through slave revolts, workers’ struggles, anti-colonial uprisings or women’s movements, the critics of sedimented universalisms have always been essential agents in modernity’s construction of the future; they are the ones who have continually revised, revolted and created a ‘universalism from below’. Yet to truly enable the liberation of futures in the plural, the current global order premised on waged labour and capitalist accumulation will need to be transcended first. A left modernity will, in other words, require building a postcapitalist and post-work platform upon which multiple ways of living could emerge and flourish. The next two chapters will set out both the necessity and desirability of this particular vision of the future.

We have so far argued that the contemporary left tends towards a folk politics that is incapable of turning the tide against global capitalism. In its place, the left needs to reclaim the contested legacy of modernity and advance visions for a new future. It is imperative, however, that its vision of a new future be grounded upon actually existing tendencies. This chapter sets out a conjunctural analysis of contemporary capitalism, viewed through the lens of work. On the basis of this analysis, the next chapter will argue for the desirability of a future without work. What does it mean to call for the end of work? By ‘work’, we mean our jobs – or wage labour: the time and effort we sell to someone else in return for an income. This is time that is not under our control, but under our bosses’, managers’ and employers’ control. A full one-third of our adult lives is spent in submission to them. Work can be framed in contrast to ‘leisure’, typically associated with the weekend and holidays. But leisure should not be confused with idleness, as many of the things we enjoy most involve immense amounts of effort. Learning a musical instrument, reading literature, socialising with friends and playing sports all involve varying degrees of effort – but these are things that we freely choose to do. A post-work world is therefore not a world of idleness; rather, it is a world in which people are no longer bound to their jobs, but free to create their own lives. Such a project draws upon a long line of thinkers – Marxists, Keynesians, feminists, black nationalists and anarchists alike – who have rejected the centrality of work. These thinkers have, each in their own way, sought to liberate humanity from the drudgery of work, the dependence on wage labour, and the submission of our lives to a boss. They have struggled to open up the ‘realm of freedom’ from which humanity can continue its project of emancipation.

While the broad aims of this project have a long series of precedents, recent developments in capitalism give renewed urgency to these issues. Rapid automation, expanding surplus populations and the continued imposition of austerity all heighten the need to rethink work and prepare for the new crises of capitalism. Just as the Mont Pelerin Society foreshadowed the crisis of Keynesianism and prepared a full-spectrum set of responses, so too should the left prepare for the coming crisis of work and surplus populations. While the effects of the 2008 crisis continue to reverberate throughout the world, it is too late to take advantage of that moment; all around us we can see that capital has recovered and consolidated itself in a renewed and sharpened form. The left must instead prepare for the next opportunity.

This chapter explains why a post-work world is an increasingly pressing option. The first section outlines the emerging crisis of work – the breakdown of stable jobs in developed countries, the rise of unemployment and surplus populations, and the collapse of ‘work’ as a disciplinary measure holding society together. We then turn to the various symptoms of this crisis as it is manifested not only in unemployment figures, but also in increased precarity, jobless recoveries, growing slums and expanding urban marginality. All around us we can see the effects of this shift bubbling up in new social conflicts and problems. Finally, we look at the various ways in which capitalism’s tendency to produce surplus populations has been managed by the state. Today, the crisis of work threatens to overrun these traditional tools of control, laying the social conditions for the shift to a post-work world.

While work is common to every society, under capitalism it takes on historically unique qualities. In pre-capitalist societies, work was necessary, but people had shared access to land, subsistence farming and the necessary means of survival. Peasants were poor but self-sufficient, and survival was not dependent on working for someone else. Capitalism changed all this. Through the process called primitive accumulation, pre-capitalist workers were uprooted from their land and dispossessed of their means of subsistence. Peasants struggled against this and continued to survive on the margins of the emerging capitalist world, and it eventually took violent force and harsh new legal systems to impose wage labour on the population. Peasants, in other words, had to be made into a proletariat. This new figure of the proletariat was defined by its lack of access to the means of production or subsistence, and its requirement for wage labour in order to survive. This means that the ‘proletariat’ is not just the ‘working class’ nor is it defined by an income level, profession or culture. Rather, the proletariat is simply that group of people who must sell their labour power to live – whether they are employed or not. And the history of capitalism is the history of the world’s population being transformed into proletarian existence through the advancing dispossession of the peasantry. With the recent integration of post-communist countries and the rise of China and India, the global proletariat has seen a ‘great doubling’, with 1.5 billion more people now reliant upon waged work for survival. But with the emergence of the proletariat, there also comes a new form of unemployment. In fact, unemployment as we understand it today was an invention of capitalism. Having been torn away from their means of subsistence, for the first time in history a new ‘surplus population’ emerges that is unable to find waged work. While capitalism may exploit the employed working class, as Joan Robinson once wrote, ‘The misery of being exploited by capitalists is nothing compared to the misery of not being exploited at all.’

For the most part, the size of this surplus expands and contracts in tandem with economic cycles. All things being equal, as economies grow, workers are drawn from the surplus and into waged labour, the unemployment level decreases, and the labour market tightens. At a certain point, however, economic demand stalls, wages begin to cut into profitability, or workers become too politically bold. For reasons of profitability, or inflation, or simply to regain political power over the working class, workers are laid off. The surplus subsequently expands, held in reserve for the next cycle of growth. Yet these cyclical mechanisms only partly explain our current situation, particularly given that wage pressures have been stagnant for decades, inflation has remained stable, and the labour movement has been devastated. The cyclical account based on economic demand certainly accounts for the depth of the 2008 crisis, but it does not explain longer-term changes in the labour market such as the rise in precarity, the emergence of jobless recoveries, and the growth of non-capitalist labour markets. To understand the current conjuncture fully, other tendencies therefore need to be taken into account. These are the mechanisms that produce a secular trend towards a larger and larger surplus population, independently of cyclical boom-and-bust patterns. It is these that pose the biggest threat to the reproduction of capitalist social relations.

Today, the production of surplus populations through technological change has increasingly hypnotised the media’s imagination. While this attention has been focused on fears of an imminent job apocalypse carried out by vast armies of robots, technological developments can also make older processes more productive without automation (for example, advances in agriculture). In either case, productivity enhancements mean that capitalism needs less labour to produce the same output. Automation appears as the most imminent threat, however, with estimates suggesting that anything from 47 to 80 per cent of current jobs are likely to be automatable in the next two decades. But estimates based solely on advances in technology are insufficient to predict growing unemployment. After all, despite continually rising productivity, employment has remained relatively stable throughout the history of capitalism. With some painful delays, new jobs have been created to replace those that were lost. Yet sanguinity based on past experiences overlooks the political and contingent basis of this historical record: government policies, workers’ movements, the gendered division of the labour force, and simultaneous reductions in the work week have all played a role in sustaining employment in the past. As a result, additional qualifications are necessary to understand under what conditions technological change will lead to increased unemployment. A first qualification argues that because increased productivity lowers production prices, unemployment only increases when demand fails to grow enough in response to these lower prices. If the cheaper prices spark more sales, the company may expand rather than cut workers. A similar argument suggests that technological developments often create new industries, and that this potentially creates replacement jobs. Since the introduction of the personal computer, for instance, over 1,500 new job types have emerged. In either of these cases, consumers buy more goods (because they are cheaper or new) and others are kept employed. The same logic holds for services. The rollout of ATMs, for example, led to fewer bank tellers being employed in each branch – but banks responded to the cheaper costs by opening more branches and expanding their market share. The result was that the number of bank tellers remained steady (though this may be changing today, as banks move their services online). In all of these cases, the logic is that even if technology eliminates some jobs, demand grows sufficiently to create new jobs. In a second situation, technological change reaches such a speed that an increasingly large portion of the population becomes unable to keep up with the skills needed. In this case, even if new demand can be created, there simply are not enough capable workers to take up these jobs – the supply of labour falters. The speed of technological change and diffusion may render entire segments of the population as an obsolete surplus. In a third situation, labour-saving technologies can be of such general use that they diffuse across the entire economy, dampening the overall demand for labour. In this circumstance, even if new industries are created, they will require increasingly less labour because these technologies have a wide range of applicability. If any of the above conditions hold, then technological change can lead to increased unemployment. As we will see, there are good reasons to believe a number of these conditions do hold. But while technological unemployment is the most prominent reason today for swelling surplus populations, it is not the only one.

Another mechanism that actively changes the size of the surplus is one we have already noted: primitive accumulation. This is not just an origin story of capitalism, but also an ongoing process that involves the transformation of pre-capitalist subsistence economies into capitalist economies. Through various means, a poor but self-sufficient peasantry is forced off its land and made to rely on wage labour to survive. As have seen, with globalisation this process has accelerated and led to a doubling of the proletariat. The supply of rural labour that China can draw upon is dwindling, but the integration of Africa and South Asia means the worldwide supply of labour continues to increase at a rapid pace. The outcome of this is a vast new global labour force, dependent upon the creation of equally vast numbers of new jobs. Therefore, independently of any technological changes in capitalist production, surplus population have increased because of this new labour supply. In addition to this, a third mechanism involves the active exclusion of a particular population from capitalist wage labour. Both in the past and present, this has predominantly involved the exclusion of women and racial minorities from the job market. While the problems of slavery, racism and sexism are not reducible to capitalist imperatives – indeed, they have separate logics of domination – these phenomena have also indirectly served capitalist goals. Unfree labour in the form of slavery is well documented as a key element of capitalism’s origins (and continues today), and the unpaid labour of many women and racialised prison populations continues to act as a source of hyper-exploitation. On a more modest level, unemployment continues to be distributed unevenly across distinctions of race, gender and geography (witness the devastation of post-industrial cities, for instance). Certain groups are more likely to be the last hired during a boom, and the first fired during a recession. The vulnerabilities that surplus populations face are therefore differentiated between sexes and races; an economic logic of exploitation and expulsion intersecting with other logics of oppression. But in all of these cases, surplus populations are concentrated within a particular group as a result of political, legal and social structures. It is not, in other words, technological change or primitive accumulation that is responsible for their difficulties in finding waged labour. But these mechanisms often intersect with each other: some people are more likely to be affected by technological change, and the incorporation of new surplus populations usually involves racial coding. In a myriad of ways, these mechanisms – technological change, primitive accumulation and active exclusion – generate an expanding number of proletariat outside the formal workforce.

What, then, is the composition of the surplus population today? Broadly, we can divide it into four different strata: the capitalist segment, the non-capitalist segment, the latent segment and the inactive segment. The first segment we are all familiar with: the unemployed and underemployed, situated within the normal capitalist labour market. This group has access to at least some minimal state welfare, is actively seeking a(nother) job, and therefore exerts pressure on the wages of the employed. Yet, for most of the world, being ‘unemployed’ is a relative luxury. In the absence of any social safety net, most people must constantly work to survive, and are therefore forced into creating new subsistence economies alongside capitalism. This is the non-capitalist segment of the surplus population, filled with people who have been dispossessed of their means of subsistence but have few social safety nets (either community- or state-based) to allow them to go without work for long. These subsistence economies produce goods for the market – small trinkets, for example – but they are organised as non-capitalist forms of production in that they do not seek to accumulate. These types of economies increasingly dominate the labour market of the developing world, ranging from 30 to 80 per cent of the working population in any given country. A third latent group exists primarily in pre-capitalist economic formations that can be readily mobilised into the capitalist labour market. This includes the reservoir of proto-proletarians (including peasants), but this group also includes unwaged domestic labourers, as well as salaried professionals who are under threat of being returned to the proletariat, often through deskilling (for example, medical professionals, lawyers and academics). The importance of this group is that it forms an additional reservoir of labour for capitalism when existing labour markets are tight. Finally, in addition to the other strata, a vast number of people are considered economically inactive (including the discouraged, the disabled and students). Overall, determining the precise size and nature of the global surplus population is difficult with existing data, and subject to fluctuations as individuals move in and out of categories, but a variety of measures converge to suggest it significantly outnumbers the active working class.

This is the crisis of work that capitalism faces in the coming years and decades: a lack of formal or decent jobs for the growing numbers of the proletarian population. In an earlier generation, the identification of surplus populations as a problem was an idea that was often derided. During the ‘golden age’ of capitalism, low unemployment, stable jobs, rising wages and rising living standards meant the idea that capitalism produced a surplus humanity enjoyed little material support. Yet, while most leftist thinkers turned to the economic problems of growth for capitalism, an occluded intellectual tradition has instead emphasised the social reproduction problem of surplus populations. It is no surprise that it was often those outside the functioning capitalist order who saw the potential in this surplus class. Writing from Algiers in the 1970s, Eldridge Cleaver presciently argued that ‘When workers become permanently unemployed, displaced by the streamlining of production, they revert back to their basic [proletarian] condition’ and that ‘the real revolutionary element of our era is the [proletariat]’. From the capitalist core, Paul Mattick called it ‘the most important of all capitalistic contradictions’. And more recently, communisation theorists have made important contributions to analysing the crisis of wage labour, and Fredric Jameson has argued that Capital ‘is not a book about politics, and not even a book about labour: it is a book about unemployment’. Indeed, it is often forgotten that Marx argued that the expulsion of surplus populations was part of ‘the absolute general law of capitalist accumulation’. In the wake of the 2008 crisis and continued sluggishness in the labour market, it is no surprise that the issue of surplus populations should emerge again. With technological change proceeding apace, the already large numbers of surplus humanity look set to swell. The very social basis of capitalism as an economic system – the relationship between the proletariat and employers, with waged work mediating between them – is crumbling.

As we have seen, very little of the global labour force is employed in formal wage labour, and this number has only decreased in the wake of the 2008 crisis. The most obvious symptoms of this rising surplus population are embodied in the long-term changes in unemployment statistics. In the immediate postwar era, unemployment as low as 1 to 2 per cent was once considered a viable goal of developed economies: during the 1950s and 1960s, the UK and the United States saw unemployment hover around 2 per cent, while Germany even saw unemployment dip below 1 per cent. Each decade since has seen a ratcheting up of the acceptable level of unemployment, combined with decreases in employment growth. Today, the Federal Reserve considers 5.5 per cent to be the optimal long-term unemployment rate – more than doubling the postwar levels. In the United States the percentage of men not working has tripled since the late 1960s, and the percentage of women has also increased, despite starting at a much higher level. The proportion of people employed has dropped precipitously, and the overall surplus population has been growing consistently in recent decades. At a global level, the unemployment rate has continued to rise after the 2008 crisis, both in absolute and relative terms. The global rate of job creation has remained significantly lower, has largely generated part-time jobs, and is forecast to continue its sluggish trend. Meanwhile, labour force participation rates have been declining globally for decades, and are set to continue falling for decades more. Yet these statistics are only the tip of the iceberg. The crisis of work and the effects of surplus populations are expressed not only in these direct measures, but also through a series of more subtle and indirect effects.

One of these – increased precarity – has come to exemplify the neoliberal labour market in developed economies. Relative to the stable and well-paying careers of earlier generations, today’s jobs typically involve more casual working hours, low and stagnant wages, decreasing job protections and widespread insecurity. This trend towards precarity has a number of causes, but one of the primary functions of a surplus population is that it enables capitalists to place extra pressure on the lucky few who have found a job. As the surplus grows and the labour market slackens, more workers seek after fewer jobs, and power passes over to the employers. The threat of moving a factory, for instance, is only possible with a global labour glut. The result is that employers gain strength over workers and the quality of jobs decreases (supplementing the quantity measured by unemployment statistics). This is exactly what we have seen in the past few decades. Throughout Europe the intensity of work, in terms of both speed and demands, has increased. The shift to just-in-time supply chains has exacerbated the demands of work, while new surveillance technologies are being forced upon labourers (in some cases, even monitoring them outside of work hours). The decline in the quality of jobs can also be seen in the cutting of work hours, rather than the outright elimination of jobs. We can see this in the small but growing number of part-time, flexible and freelance jobs over the past thirty years. For instance, the relatively low unemployment levels of the UK after the 2008 crisis are largely a result of more self-employed people living off poverty wages. In the United States, more than 6.5 million people are forced to work part-time despite desiring full-time work. This casualisation also involves innovations such as crowd-sourced tasks, temporary staffing agencies and zero-hours contracts, along with the harsh working conditions and lack of benefits that accompany them. In the UK, for example, it is estimated that nearly 5 per cent of the working population is presently on zero-hours contracts. Surplus populations have also put downward pressure on wages. Estimates suggest that every 1 per cent increase in labour market slack is associated with a 1.6 per cent increase in income inequality. The stagnation of real wages and the declining share of income going to labour are both tied to an excess supply of labour, and most economists believe automation and the globalisation of the proletariat are central reasons why wages have been stagnant in recent decades. All of these trends have continued since the 2008 crisis as well, with slow real wage growth across the G20, and outright decline in the UK. The slow growth of wages leads precarity to also be expressed in the anxiety over high levels of consumer debt and low levels of personal savings. In the United States, for example, a full 34 per cent of fulltime workers live paycheque-to-paycheque, while in the UK, 35 per cent of people could not live off their savings for more than a month. And at its most vicious, precarity is indicated by a rise in depression, anxiety and suicides – an ‘excess’ that goes uncounted in traditional economic measures. Indeed, unemployment is associated with a fifth of all global suicides, and this has only worsened in the wake of the financial crisis.

In addition to precarity, surplus populations and technological automation help to make sense of a recent labour market phenomenon: the emergence of ‘jobless recoveries’, in which economic growth returns after a crisis but job growth remains anaemic. Such recoveries have become standard for the US economy, and since the 1990s the trend has been towards longer and longer jobless recoveries. The current crisis is no exception, with more than a million full-time jobs yet to return, and forecasts suggesting that US unemployment will remain above pre-crisis levels until 2024. This is a global phenomenon as well, with the world economy creating jobs so slowly that the number of jobs will remain significantly below pre-crisis levels for at least a decade. While their cause is ultimately still a mystery, jobless recoveries appear to be closely related to automation. In fact, the only occupations that have experienced jobless recoveries are those that have been under threat from automation in recent decades – semi-skilled, routine jobs. Moreover, these job losses have occurred almost entirely during and in the wake of recessions. In other words, crisis periods are when automatable jobs disappear, never to be heard from again. If automation accelerates over the coming decades, these problems are likely to intensify – with capital using periods of crisis to permanently eliminate such jobs. The slow return of jobs also expresses itself as a rise in long-term unemployment, whereby entire groups of people become increasingly segregated from the normal labour market. Since the most recent crisis, the average length of unemployment has doubled and remained stubbornly high. These extended periods of unemployment suggest that a structural problem is responsible – that is to say, a problem that takes longer for unemployed workers to adapt to, such as retraining for an entirely new skill set. Workers laid off from an area like retail will find it difficult to immediately step into a job in growth sectors like programming. Meanwhile, when the long-term unemployed do find a job, they are more likely to enter at the margins of the labour market, with lower pay and more temporary work. Jobless recoveries, in other words, exacerbate the problems of precarity, and increasingly segregate out a portion of the population as permanently underemployed. Ultimately, unemployment and the threat of it are becoming the norms for the labour force.

In some urban areas, joblessness and segregation from the normal labour market have long been features of everyday existence. In the banlieues of Paris, the ghettos of the United States and the rising spaces of suburban poverty, entire communities have been economically separated from broader economic trends, stagnating even during periods of growth. More often than not, these segregated spaces are also divided along racial lines, with deliberate neglect and outright exclusion transforming these communities into increasingly harsh areas of poor social cohesion, inadequate housing and high unemployment. The historical origin of these spaces is well known: racism, slavery and the active exclusion carried out by policy choices, physical violence and white migration. In early-twentieth-century America, for example, the mechanisation of agriculture led the rural black population to migrate and concentrate in urban areas. Yet jobs were hard to come by, as continued racism excluded them from working in textiles or manufacturing. (The racialisation of the surplus population also enabled owners to manipulate the white working class, keeping wages low and preventing unionisation.) As capitalism grew in the postwar era, manufacturing jobs eventually opened up to the black population, and by the mid 1950s rates of black and white youth unemployment were broadly similar. But then the globalisation of the labour supply wreaked havoc on low-skilled black workers. With manufacturing jobs shipped overseas or subject to automation, these workers were disproportionately affected by deindustrialisation. Industrial jobs left the urban centres and were replaced by service work often located in distant suburban areas. The urban ghettos were left to rot, becoming concentrated hubs of long-term joblessness. They became poverty traps, devoid of jobs, with little community support and a proliferation of underground economies. Entire communities were cast aside from the machinery of capitalism and left to fend for themselves with whatever means could be scraped together. People seeking an income were forced into off-the-books work, new businesses turned to loan sharks after being denied by white-owned banks, and increasing desperation led to outright illicit activities.

Mirroring the concentration of joblessness in the urban margins, developing economies have had to deal with the expansion and concentration of surplus populations in slums, favelas and shantytowns. Globally, these have swelled to unprecedented levels as the urban workforce is tossed aside into the informal and marginal economies. As one UN report puts it, ‘the cities have become a dumping ground for a surplus population working in unskilled, unprotected and low-wage informal service industries and trade’. The primary cause behind this expansion of slums has been primitive accumulation. Spurred on, first by colonialism and then by structural adjustment policies, the peasantry in many developing countries has been forced off their lands via global competition, rapid industrialisation and rampaging climate change. Like the earlier European experience of industrialisation, dispossessed rural workers have migrated to urban areas to find jobs. And in Europe, too, this process sometimes led to slum-dwelling and destitution for the new urban proletariat. But this is where the similarities end, as in Europe the transition involved creating sufficient numbers of jobs, the emergence of a strong industrial working class, and the eventual provision of housing for migrants. Under conditions of postcolonial development, this narrative has been broken. Rather than a scarcity of labour, recent industrialisation has occurred in the context of a large and global labour force. The result has been little development of anything resembling a traditional working class, continually weak job prospects and a lack of adequate housing. New urban migrants have been left in a permanent state of transition between peasantry and proletarianisation, and sometimes in seasonal circulation between rural existence and urban poverty. Slums and other improvised housing therefore represent a dual expulsion from the land and from the formal economy. This surplus humanity, having been deprived of its traditional means of subsistence yet left without employment, has been forced to create its own non-capitalist subsistence economies. Much of the labour performed here is informal: low-paid, insecure, irregular and without state support. In these economies, production is typically organised in non-capitalist forms but remains directed towards commodity production – to selling goods on the market, rather than for individual use. Mediation by the market distinguishes these postcolonial subsistence economies from pre-capitalist subsistence economies, even though they both function as a desperate means of survival.

But while primitive accumulation is responsible for the origins of these slums, it is ‘premature deindustrialisation’ that looks set to consolidate their existence. If previous periods of industrialisation at least had the benefit of providing enough factory jobs for the new proletariat, premature deindustrialisation threatens to eliminate this traditional pathway entirely. Technological and economic developments now enable countries to virtually leapfrog the industrialisation phase, which means that developing economies are now deindustrialising at much lower rates of per capita income and with much lower shares of manufacturing employment. China is a good example of this, with manufacturing employment in decline, labour struggles becoming more confident, real wages surging and demographic limits leading to a focus on ‘technological upgrading [and] productivity enhancements’ in order to maintain growth. The automation of factories is at the leading edge of this deindustrialisation trend, with China already the biggest purchaser of industrial robots, and expected to soon have more industrial robots in operation than either Europe or North America. The factory of the world is going robotic. Deindustrialisation can also be seen in ‘reshoring’, where manufacturing returns to developed economies in jobless, automated forms. These deindustrialisation trends are taking hold across the developing economies of Latin America, sub-Saharan Africa and most of Asia. Even in countries where manufacturing employment has increased in absolute terms, there have been significant decreases in the labour-intensity of the process. The result of all of this is not only an incomplete transition to a significant working class, but also the stymying of the expected employment path for the workforce. Premature deindustrialisation is leaving most of the world’s urban proletariat dispossessed of its agricultural livelihood and without the opportunity to be hired for manufacturing jobs. Some hold out the hope that an emerging service sector will absorb the surplus populations, yet this appears increasingly unlikely. Even in India, the centre of service and high-tech outsourcing, only a small portion of the labour force works in the information and communication technology sector. More importantly, the potential of service jobs is constrained by the newest wave of automation, which is likely to eliminate the low-skilled, low-wage service jobs that have traditionally been outsourced – clerical work, call-centre work or data entry, for example. As this non-routine cognitive labour is increasingly automated, what may occur is a premature shift away from a service-based economy – on top of premature deindustrialisation. What this means is that the maintenance of large portions of humanity within slums and informal, non-capitalist economies is likely to be consolidated by emerging technological trends. In the end, while unemployment measures give us some sense of the size of the surplus population problem, it is precarity, jobless recoveries and mass urban marginality that truly express the squeeze on the global labour market.

Larger surpluses of labour are, on the one hand, beneficial to capitalist interests. They serve as a disciplinary tool against the working class (particularly when filtered through racism, nationalism and sexism) and as a reserve to call upon in times of growth. They reduce wages, sow competition among workers and shackle the ambitions of the proletariat. These are among the reasons behind a gradual drive to incorporate the world’s population into a global labour force, fostered by imperialism and globalisation. On the other hand, capital requires a particular type of surplus population: cheap, docile and pliable. Without these characteristics, this excess of humanity becomes a problem for capital. Not content to lie down and accept its disposability, it makes itself heard through riots, mass migration, criminality, and all sorts of actions that disrupt the existing order. Capitalism therefore has simultaneously to produce a disciplined surplus and deploy violence and coercion against those who resist.

One of the principal ways to manage the unruly surplus has been to champion the social democratic ideal of full employment, whereby every physically capable (male) worker has a job. In support of this ideal, economic policies aim to reincorporate the surplus into capitalism as disciplined and waged workers, secured by a hegemonic consensus between the representatives of labour and capital. The apogee of this approach was the postwar period, when working-class struggle and conservative concern with social order positioned full employment as a necessary economic goal. In this brief ‘golden age’ of capitalism, unemployment was kept to a minimum, and capital had to seek out pre-capitalist populations around the world in order to expand and accumulate. For the most part, job growth was achieved through healthy economic growth that increased the demand for labour. Historically, growth of the national economy has often been important in warding off the effects of technological unemployment – either by increasing the output of existing industries or by inventing new industries to employ the displaced workers. For instance, during the latter half of the 1800s, the rise in capital goods output created jobs that offset the surplus population newly released from the agricultural sector. In the prewar and postwar eras, growth in manufacturing jobs was sustained by the rise of mass consumerism and surges in government military spending. Today, we can see similar attempts at creating new markets through accumulation by dispossession – turning public or common goods into privatised (and monetised) commodities. If increases in labour demand are to be successful, however, they require the right supply of labour – which means an increasingly high-skilled workforce. Education has been the primary way to achieve this, with, for example, secondary education having its origins in efforts to produce more skilled workers. The demand to educate workers for jobs held wide support during the high unemployment period of the Great Depression, and early neoliberals went so far as to argue that education was necessary only to adapt human beings to the constant changes in the economy. Today, the growth areas of the labour market tend to be in high-skilled, non-routine and cognitive jobs. This means any attempt at full employment increasingly requires new skills from workers – a demand that helps explain the aggressive efforts to reduce higher education to glorified job training. The overall societal aim becomes the production of competitive subjects undergoing constant self-improvement in an endless effort to be deemed ‘employable’. The demands that workers be constantly retraining and that policies support healthy economic growth are necessary components to the drive for full employment.

But while calls for more jobs remain ideologically pervasive, the practical viability of full employment has largely disappeared. With tight labour markets in the postwar era, the ensuing strength of the working class increasingly became a problem for capitalism. The crisis of stagflation in the 1970s, in particular, presented an opportunity to reverse the priority given to employment. Class pressure and its effects – work stoppages, wage inflation, declining profits – were a major factor in central banks’ decisions to raise interest rates, in the hope of reducing aggregate demand and increasing unemployment. Indeed, Thatcher’s chief economic advisor eventually admitted that the war against inflation was in fact a proxy war against the working class. The tight monetary policy of the early 1980s was therefore precisely an effort to undermine the power of the working class, increase unemployment to a level acceptable for capital, and end the dream of full employment. Yet even if full employment had not been attacked, it requires strong economic growth – a condition that looks increasingly unlikely for the global economy. In recent years, global growth has remained significantly lower than during the pre-crisis period. Across the political spectrum, economists are warning that fundamental changes to the economy mean growth may have settled into a permanently lower state. Moreover, firms that are leading growth sectors – such as Facebook, Twitter and Instagram – simply do not create jobs on the scale of classic firms like Ford and GM. In fact, new industries currently only employ 0.5 per cent of the American workforce – hardly an inspiring record of job creation. And after a steady decline, the average new business creates 40 per cent fewer jobs than it did twenty years ago. The old social democratic plan to encourage employment in new industries falters in the face of low labour-intensity firms and sputtering economic growth. Still, it might be imagined that, with the right political pressure and policies, a return to full employment could be an option. But, given that the height of the social democratic era required the exclusion of women from the waged workforce, we should in fact wonder whether full employment has ever been possible.

If full employment remains operative only as an ideological mystification, its normalisation of work still extends to the unemployed. The transformation of welfare and the rise of workfare – forcing people to work in order to receive benefits – represent an increasingly insidious example of this. Mirroring the changing fortunes of full employment, unemployment has long been governed according to different ideas. Initial approaches saw unemployment as an individual accident – something to be mitigated by insurance-like solutions. But the mass unemployment of the Great Depression overwhelmed this approach, and unemployment subsequently came to be seen as a structural (and male) problem. The labour movement became an employment movement, and governments adopted welfare and full employment policies partly in response. Today, many of the transformations that the welfare state is undergoing can be understood as an attempt to revive the disciplinary function of the unemployed. Their free labour, in the form of workfare, acts to repress wages and threaten the jobs of the employed; the figure of the ‘jobseeker’ imposes a norm of work on everyone; and attacks on disability benefits turn even those outside the labour force into a reserve army of potential workers. The unemployed have to fulfil an increasingly long list of conditions in order to gain even minimal benefits: attending training, constantly applying for jobs, listening to advice, and even working for free. The increase in surveillance and control is designed to produce not only an obedient, skilled and flexible surplus population, but also one that exerts pressure on the employed. It therefore makes little difference whether these schemes actually reduce unemployment or not, since their purpose lies elsewhere. Increasingly, the welfare state is becoming little more than an institution designed to deploy the surplus against the working class.

The management of surplus populations does not just revolve around the production of disciplined workers and pliable jobseekers. Increasingly, domination and punitive measures are becoming the norm in dealing with the excess to capital. For instance, the size and composition of this group is heavily regulated through immigration policies. For the surplus, migrating to countries with better job prospects is a common response to high unemployment and has been the historical norm. In the nineteenth century, as the mechanisation of agriculture transformed the countryside, the dominant outlet was mass emigration to the New World. Yet today the option to migrate is increasingly closed off for the developing world. While there are a variety of reasons voiced to justify tighter immigration controls, reducing the potentially unruly excess labour supply has often been a dominant one. Today, we see the militarisation of America’s border with Mexico and the rise of Fortress Europe in response to mistaken fears about jobs being taken by foreigners. Yet the desperation of immigrants to find a decent job is such that, even when faced with the threat of death, they still make the perilous trip to a new country. The result is that the past fifteen years have seen over 22,000 migrants die trying to get into Europe, more than 6,000 die trying to cross the Mexico–US border, and over 1,500 die trying to get to Australia. These lethal barriers to migration are one of the primary mechanisms used today to segregate and manage global surplus populations. And inextricable from this treatment of migrants is racialised coding: these immigrants are not simply other individuals, but other races. Whether ‘foreign hordes’ threatening the sanctity of the European border, or immigrant textile workers in Thailand being subject to hyper-exploitation and abuse, racial hierarchies are an essential component of the control of surplus populations.

When the co-optation of the surplus into a disciplined excess workforce has failed, the state can always resort to simply locking up, excluding and brutalising large sections of the surplus population. Across the world, mass incarceration has been increasing as the size of prison populations rise in both absolute and relative terms. Moreover, there is a significant racial component to this – most notably in the mass incarceration of the US black population, but also of Muslims in much of Europe, Aboriginals in Canada, and the detention and deportation of foreign migrants around the world. These systems of mass incarceration must be understood to extend beyond prisons, as they encompass an entire network of laws, courts, policies, habits and rules that work to subjugate a group of people. Mass incarceration is a system of social control aimed primarily at surplus populations rather than at crime. For example, increases in manufacturing unemployment are associated globally with increases in police employment. As the reserve army grows, so too does the state’s punitive apparatus. Likewise, the expansion of immigrant detention centres responds to the demise of subsistence economies and the formation of a mobile proletariat. Those who are unwilling to be forced into slums seek better opportunities elsewhere, only to be locked up or left for dead on the Mediterranean. The American system is perhaps the clearest example of how surplus populations and police enforcement intertwine. The well-documented surge in mass incarceration over the past few decades was not a response to rising crime rates, but rather to the proliferation of jobless ghettos and the advances made by the civil rights movement. The racialised nature of this system is well known, but the patterns of incarceration cannot be fully understood without reference to class and surplus populations. For instance, middle-class and upper-class black populations are largely left alone, and the vast majority of the prison population consists of the ‘working or workless poor’. Likewise, the disparities in incarceration between races are outpaced by the disparities in terms of class, and the rise of mass black incarceration coincides with the decline in employment for that same population. In fact, the racial nature of mass incarceration in America stems ‘exclusively’ from the wildly disproportionate locking up of lower-class black populations. Mass incarceration has therefore become a means to manage and control this surplus that has been excluded from the labour market and left in poverty. Spatially concentrated in inner-city ghettos, these groups became an easy target of state control. This intersects with race, of course, as the origins of jobless ghettos lie in the active exclusion of the black population of the United States. And in many ways, the carceral system perpetuates the legacy of slavery, Jim Crow, and the ghettos – replacing many of their functions with a new system of exclusion. But class enables us to see a distinction: whereas those previous systems of social control exploited free labour and attempted to transform black populations into a disciplined workforce, the modern prison system is designed largely to exclude and control the surplus population. Given the effects of having a criminal record, the carceral system brings about a triple exclusion: from cultural and educational capital, from political participation and from public aid. The end result is that incarceration initiates a vicious circle with the urban poor left unemployed and unable to find a job, thereby endlessly reproducing these groups as outside of capital. Rather than trying to reform, educate and reintegrate prisoners into capitalist society, convoluted systems are set up to keep them out and to prevent their re-entry into normal wage labour after prison. At its extreme, these populations become simply disposable, situated outside of normal society and subject to gratuitous violence. The end result is a system that produces and reproduces permanent exclusion from the formal economy. These populations are deemed dispensable, and subjected to all the police brutality and state violence that can be mustered against them. We have, therefore, an entire range of mechanisms that the state and capital use to manage surplus populations, ranging from disciplined integration to violent exclusion.

As we have seen, there is a growing population of people that are situated outside formal, waged work, making do with minimal welfare benefits, informal subsistence work, or by illegal means. In all cases, the lives of these people are characterised by poverty, precarity and insecurity. Increasingly, there are simply not enough jobs to employ everyone. As the hegemonic order predicated upon decent and stable jobs breaks down, social control is likely to revert to increasingly coercive measures: harsher workfare, heightened antagonisms over immigration, stricter controls on the movement of peoples, and mass incarceration for those who resist being cast aside. This is the crisis of work facing neoliberalism and the surplus populations who make up most of the world’s labour force.

With the potential for extensive automation of work – a topic that will be discussed further in the next chapter – it is likely that we will see the following trends in the years to come:

1.The precarity of the developed economies’ working class will intensify due to the surplus global labour supply (resulting from both globalisation and automation).

2.Jobless recoveries will continue to deepen and lengthen, predominantly affecting those whose jobs can be automated at the time.

3.Slum populations will continue to grow due to the automation of low-skilled service work, and will be exacerbated by premature deindustrialisation.

4.Urban marginality in the developed economies will grow in size as low-skilled, low-wage jobs are automated.

5.The transformation of higher education into job training will be hastened in a desperate attempt to increase the supply of high-skilled workers.

6.Growth will remain slow and make the expansion of replacement jobs unlikely.

7.The changes to workfare, immigration controls and mass incarceration will deepen as those without jobs are increasingly subjected to coercive controls and survival economies.

Of course, none of these outcomes is inevitable. But this analysis is based on the current tendencies of capitalism, and on the problems that are likely to arise as surplus populations continue to grow. These trends portend a crisis of work, and a crisis of any society based upon the institution of wage labour. Under capitalism, jobs have been pivotal to our social lives and sense of who we are, as well as being the sole source of income for most people. What the next two decades portend is a future in which the global economy is increasingly unable to produce enough jobs (let alone good jobs), yet where we remain dependent upon jobs for our living. Political parties and trade unions appear ignorant of this crisis, struggling to manage its symptoms even as automation promises to toss more and more workers aside. In the face of these tensions, the political project for the twenty-first-century left must be to build an economy in which people are no longer dependent upon wage labour for survival.

As we will argue in the next few chapters, this struggle can and should span an array of different approaches: it means creating hegemonic ideas about the obsolescence of drudgery, shifting the goals of trade unions from resisting automation to job-sharing and reduced working weeks, government subsidies for automation investment, and raising the cost of labour for capital, along with many other options. It means opposing the expulsion of surplus populations and attacking the mechanisms of control over them. Mass incarceration and the racialised system of domination associated with it must be abolished, and the spatial mechanisms of control – ranging from ghettos to border controls – must be taken apart to ensure the free movement of peoples. And the welfare state must be defended, not as an end in itself, but as a necessary component of a broader post-work society. The future remains open, and which direction the crisis of work takes is precisely the political struggle before us.

Whereas the previous chapter analysed the changing social conditions that are making a post-work world increasingly necessary, this chapter will outline what a post-work world might mean in practice. To that end, we advance some broad demands to start building a platform for a post-work society. In asserting the centrality of demands, we are breaking with a widespread tendency of today’s radical left that believes making no demands is the height of radicalism. These critics often claim that making a demand means giving into the existing order of things by asking, and therefore legitimating, an authority. But these accounts miss the antagonism at the heart of making demands, and the ways in which they are essential for constituting an active agent of change. In this light, the rejection of demands is a symptom of theoretical confusion, not practical progress. A politics without demands is simply a collection of aimless bodies. Any meaningful vision of the future will set out proposals and goals, and this chapter is a contribution to that potential discussion. None of the proposals presented will be radically new, but this is part of their strength: it is not a free-floating project, since frameworks and movements already exist and have traction in the world.

Today, revolutionary demands appear naive, while reformist demands appear futile. Too often that is where the debate ends, with each side denouncing the other and the strategic imperative to change our conditions forgotten. The demands we propose are therefore intended as non-reformist reforms. By this we mean three things. First, they have a utopian edge that strains at the limits of what capitalism can concede. This transforms them from polite requests into insistent demands charged with belligerence and antagonism. Such demands combine the futural orientation of utopias with the immediate intervention of the demand, invoking a ‘utopianism without apology’. Second, these non-reformist proposals are grounded in real tendencies of the world today, giving them a viability that revolutionary dreams lack. Third, and most importantly, such demands shift the current political equilibrium and construct a platform for further development. They project an open-ended escape from the present, rather than a mechanical transition to the next, predetermined stage of history. The proposals in this chapter will not break us out of capitalism, but they do promise to break us out of neoliberalism, and to establish a new equilibrium of political, economic and social forces. From the social democratic consensus to the neoliberal consensus, our argument is that the left should mobilise around a post-work consensus. With a post-work society, we would have even more potential to launch forward to greater goals. But this is a project that must be carried out over the long term: decades rather than years, cultural shifts rather than electoral cycles. Given the reality of the weakened left today, there is only one way forward: to patiently rebuild its power – a topic that will be covered in the chapters to follow. There simply is no other way to bring about a post-work world. We must therefore attend to these longer-term strategic goals, and rebuild the collective agencies that might eventually bring them about. By directing the left towards a post-work future, not only will significant gains be aimed for – such as the reduction of drudgery and poverty – but political power will be built in the process. In the end, we believe a post-work society is not only achievable, given the material conditions, but also viable and desirable. This chapter charts a way forward: building a post-work society on the basis of fully automating the economy, reducing the working week, implementing a universal basic income, and achieving a cultural shift in the understanding of work.

Our first demand is for a fully automated economy. Using the latest technological developments, such an economy would aim to liberate humanity from the drudgery of work while simultaneously producing increasing amounts of wealth. Without full automation, postcapitalist futures must necessarily choose between abundance at the expense of freedom (echoing the work-centricity of Soviet Russia) or freedom at the expense of abundance, represented by primitivist dystopias. With automation, by contrast, machines can increasingly produce all necessary goods and services, while also releasing humanity from the effort of producing them. For this reason, we argue that the tendencies towards automation and the replacement of human labour should be enthusiastically accelerated and targeted as a political project of the left. This is a project that takes an existing capitalist tendency and seeks to push it beyond the acceptable parameters of capitalist social relations.

Capitalism has long been synonymous with rapid changes in technology: driven by the imperative to accumulate, the means of production are continually transformed. In the nineteenth century, agriculture began to be mechanised, and small plots of land became increasingly centralised under larger and larger industrial farms. Craftwork was transformed too, with machinery appearing as an alien intervention into the production process. Work that had traditionally been undertaken by a skilled labourer was now broken down into its deskilled constituent tasks, and often carried out using machinery. Workers became assigned to partial tasks, and tools that had once been governed by workers became machines that rhythmically conducted the labourers. Work became increasingly repetitive, deskilled and ruled by machinery – with greater demand for cheap unskilled labourers (particularly women and children). In the early twentieth century, this tendency began to shift with the introduction of technologies that eliminated the most routine and mundane of manual tasks (such as hauling and conveying goods). Skilled workers became increasingly necessary in overseeing the new machines, carrying out expanding service work, and managing the increasingly large firms that were emerging. The need for skilled labour was further amplified in the early twentieth century by the rise of office technologies – typewriters, photocopiers, and so on – that required relatively well-educated operators. In other words, technology is not uniformly deskilling, and the increased demand for skilled labour over the past century testifies to that. Over this period, manufacturing employment continued to decline, due to its susceptibility to productivity-enhancing technology. The automation of mass-production manufacturing in the early twentieth century was eventually extended, with the automation of small-batch manufacturing. While the industrial sector employed 1,000 robots in 1970, today it uses over 1.6 million robots. In terms of employment, manufacturing has reached a global saturation point. Even in developing countries, the trend is towards deindustrialisation, with employment growth now confined predominantly to the service sector. Concurrent with the decline of manufacturing, the latter half of the twentieth century oversaw another shift. While earlier office technologies had supplemented workers and increased demand for them, the development of the microprocessor and computing technologies began to replace semiskilled service workers in many areas – for example, telephone operators and secretaries. The roboticisation of services is now gathering steam, with over 150,000 professional service robots sold in the past fifteen years. Under particular threat have been ‘routine’ jobs – jobs that can be codified into a series of steps. These are tasks that computers are perfectly suited to accomplish once a programmer has created the appropriate software, leading to a drastic reduction in the numbers of routine manual and cognitive jobs over the past four decades. The result has been a polarisation of the labour market, since many middle-wage, mid-skilled jobs are routine, and therefore subject to automation. Across both North America and Western Europe, the labour market is now characterised by a predominance of workers in low-skilled, low-wage manual and service jobs (for example, fast-food, retail, transport, hospitality and warehouse workers), along with a smaller number of workers in high-skilled, high-wage, non-routine cognitive jobs.

The most recent wave of automation is poised to change this distribution of the labour market drastically, as it comes to encompass every aspect of the economy: data collection (radio-frequency identification, big data); new kinds of production (the flexible production of robots, additive manufacturing, automated fast food); services (AI customer assistance, care for the elderly); decision-making (computational models, software agents); financial allocation (algorithmic trading); and especially distribution (the logistics revolution, self-driving cars, drone container ships and automated warehouses). In every single function of the economy – from production to distribution to management to retail – we see large-scale tendencies towards automation. This latest wave of automation is predicated upon algorithmic enhancements (particularly in machine learning and deep learning), rapid developments in robotics and exponential growth in computing power (the source of big data) that are coalescing into a ‘second machine age’ that is transforming the range of tasks that machines can fulfil. It is creating an era that is historically unique in a number of ways. New pattern-recognition technologies are rendering both routine and non-routine tasks subject to automation: complex communication technologies are making computers better than humans at certain skilled-knowledge tasks, and advances in robotics are rapidly making technology better at a wide variety of manual-labour tasks. For instance, self-driving cars involve the automation of non-routine manual tasks, and non-routine cognitive tasks such as writing news stories or researching legal precedents are now being accomplished by robots. The scope of these developments means that everyone from stock analysts to construction workers to chefs to journalists is vulnerable to being replaced by machines. Workers who move symbols on a screen are as at risk as those moving goods around a warehouse. One report forecasts a ‘depopulation of trading floors’ as robots continue infiltrating the financial world; retail jobs – long a bastion of post-industrial employment – are set to be taken over by machines; and over 140 million cognitive jobs worldwide are forecast to be eliminated. While the last wave of automation led to a polarisation of the labour market, this newest wave looks set to decimate the low-skilled, low-wage end of the labour market. And as robots substitute for human labour, workers are likely to face lower wages and increasing immiseration. At the very least then, the emerging wave of automation will drastically change the composition of the labour market, and potentially lead to a significant reduction in demand for workers.

A number of economists have pointed out, however, that productivity has not increased to the degree that would be expected by a revolution in automation. If a machine is replacing half of the workers in a factory, productivity should double if the factory produces the same number of goods. In fact, however, there has been a broad global slowdown in productivity growth over the past decade, particularly following the crisis. Leaving aside the fact that productivity is a notoriously difficult thing to measure, we believe a few phenomena can help explain this anomaly. First, it is highly likely that low wages are repressing investment in productivity-enhancing technologies. Access to a large reserve of cheap labour means that companies have less incentive to focus on capital investment. Why purchase new machines when cheaper workers will do the same for less? This means that in the effort to bring about full automation, fighting for higher global wages is a crucial complementary task. Second, there is likely a delay factor at work. In the 1990s, the IT revolution took some time to become expressed in productivity figures, as companies had to invest and then adapt to the new capacities of these technologies. Organisations have to be changed, new skills have to be learned, and processes have to be reworked in order to make effective use of these new technologies. In general, it appears that investments in digital technologies face productivity lags of five to fifteen years. Today, many of the technologies under discussion are incredibly new and were unimaginable even a decade ago. This novelty means that we should expect a delay in the response of productivity figures, as the technologies are adopted and then adapted into the way businesses run. Finally, and most importantly, our argument here relies largely on a normative claim rather than a descriptive one. Full automation is something that can and should be achieved, regardless of whether it is yet being carried out. For instance, out of the US companies that could benefit from incorporating industrial robots, less than 10 per cent have done so. This is but one area for full automation to take hold in, and this reiterates the importance of making full automation a political demand, rather than assuming it will come about from economic necessity. A variety of policies can help in this project: more state investment, higher minimum wages and research devoted to technologies that replace rather than augment workers. In the most detailed estimates of the labour market, it is suggested that between 47 and 80 per cent of today’s jobs are capable of being automated. Let us take this estimate not as a deterministic prediction, but instead as the outer limit of a political project against work. We should take these numbers as a standard against which to measure our success.

While full automation of the economy is presented here as an ideal and a demand, in practice it is unlikely to be fully achieved. In certain spheres, human labour is likely to continue for technical, economic and ethical reasons. On a technical level, machines today remain worse than humans at jobs involving creative work, highly flexible work, affective work and most tasks relying on tacit rather than explicit knowledge. The engineering problems involved in automating these tasks appear insurmountable for the next two decades (though similar claims were made about self-driving cars ten years ago), and a programme of full automation would aim to invest research money into overcoming these limits. A second barrier to full automation occurs for economic reasons: certain tasks can already be completed by machines, but the cost of the machines exceeds the cost of the equivalent labour. Despite the efficiency, accuracy and productivity of machine labour, capitalism prefers to make profits, and therefore uses human labour whenever it is cheaper than capital investment. A programme of full automation would aim to overcome this as well, through measures as simple as raising the minimum wage, supporting labour movements and using state subsidies to incentivise the replacement of human labour.

A final limit of full automation is the moral status we give to certain jobs, such as care work. These tasks, including the raising of children, are ones that many would argue must be carried out by human beings. We can outline two broad approaches to these sorts of labours. A first approach would agree that such labour has moral value and should be carried out by humans rather than machines. In a post-work society, however, care labour could be given greater value, turning society away from the privileged status bestowed upon profitable labour. The free time that accrues from full automation could also facilitate experimentation with alternative domestic arrangements. There is a long history of utopian experiments that can be drawn upon to rethink how our societies organise domestic, reproductive and care labour. All of this, it must be stressed, would still require a political movement to achieve; a post-work world may facilitate change, but it cannot guarantee it. A more radical approach, however, argues that automating much of this labour should be a goal for the future. Indeed, the stereotype that women are naturally nurturing and desiring of this affective labour is often a pernicious cover for their continued exploitation. But what if much of this labour could be eliminated? Traditionally, the household has been a space that featured little technological change: its unpaid nature and lack of productivity norms have given capitalism few incentives to invest in the reduction of household labour. Yet increasingly, domestic tasks like cleaning the house and folding clothes, for example, can be delegated to machines. Assistive technologies and affective computing are also making inroads in automating some of the highly personal and embarrassing care work that might be better suited to impersonal robots. More speculatively, some have argued that the pain and suffering involved in pregnancy is something that should be relegated to the past, rather than mystified as natural and beautiful. In this vision, synthetic forms of biological reproduction would enable a newfound equality between the sexes. We will not adjudicate on these paths here, but simply set them out as options opened up by a post-work world. Whatever approach is taken, though, the point is that labour will not be immediately or entirely eliminated, but instead progressively reduced. Full automation is a utopian demand that aims to reduce necessary labour as much as possible.

A second major demand for building a post-work platform involves a return to classic ideas about reducing the length of the working week with no cut in pay. From the beginning of capitalism, workers have struggled against the imposition of fixed working hours, and the demand for shorter hours was a key component of the early labour movement. Initial battles saw high levels of resistance in the form of individual absenteeism, numerous holidays and irregular work habits. This resistance to normal working hours continues today in widespread slacking off, with workers often surfing the internet rather than doing their job. At every step of the way, then, workers have struggled to escape normal working hours, and many of the labour movement’s earliest successes had to do with reducing work time. The two-day weekend, for example, emerged spontaneously from workers’ predilection for drinking and spending an extra day recovering rather than working. The weekend’s eventual consolidation as a recognised and bounded period of time off was the product of sustained political struggles (a process that was not completed in the Western world until the 1970s). Likewise, workers achieved significant success in reducing the working week from sixty hours in 1900 to just below thirty-five hours during the Great Depression. Such was the speed of success that, over a period of five years in the 1930s, the working week declined by eighteen hours. During the earlier years of the Depression, the idea of a shorter working week enjoyed bipartisan support in the United States, and legislation for a thirty-hour working week was thought to be imminent. Simultaneously, intellectuals prophesied even further reductions in work time – imagining worlds where work was reduced to a bare minimum. In a classic statement, Paul Lafargue argued for limiting work to just three hours a day. Keynes famously argued for the same outcome, calculating that by 2030 we would all be working fifteen-hour working weeks – though it is less well known that he was simply verbalising what were the broadly held beliefs of the time. And Marx made the shortening of the working week central to his entire postcapitalist vision, arguing that it represented a ‘basic prerequisite’ to reaching ‘the realm of freedom’.

But such visions of a three-hour work day have disappeared. The near century-long push for shorter working hours ended abruptly during the Great Depression, when business opinion and government policy decided to use make-work programmes in response to unemployment. Soon after World War II, the working week stabilised at forty hours across much of the Western world, and there has since been little serious consideration of changing this. Instead there has been a general expansion of work in the ensuing decades. First, there has been an increase in time spent at jobs throughout society. As women entered the workforce, the working week remained the same, and the overall amount of time devoted to jobs therefore increased. Secondly, there has been a progressive elimination of the work–life distinction, with work coming to permeate every aspect of our waking lives. Many of us are now tied to work all the time, with emails, phone calls, texts and job anxieties impinging upon us constantly. Salaried workers are often compelled to work unrecognised overtime, while many workers feel the social pressure to be seen working long hours. These demands mean that the average full-time US worker in fact logs closer to forty-seven hours a week. On top of this, a vast amount of work is unpaid and therefore uncounted in official data (there is also an ongoing gender divide within this unpaid labour force). While waged work remains difficult for many to find, unpaid work is proliferating – an entire sphere of ‘shadow work’ is emerging with automation at the point of sale, with work being delegated to users (think self-checkouts and ATMs). Moreover, there is the hidden labour required to retain a job: financial management, job searching if unemployed, constant skills training, commuting time, and the all-important (gendered) sphere of the labour involved in caring for children, family members and other dependents.

If work has extended itself into so many areas of our lives, a return to a shorter working week would bring with it a number of benefits. Beyond the most obvious – that it increases free time – it would bring with it a series of more subtle benefits. In the first place, reducing the working week constitutes a key response to rising automation. In fact, the role of this policy in previous periods of automation is often forgotten. Many commentators have rightly pointed to the history of technological change to show that it need not lead to mass unemployment. However, the primary periods of automation coincided with significant reductions in the working week; employment was often sustained by redistributing the work. A second benefit of this policy is its various environmental advantages. For instance, reductions in the working week would lead to significant reductions in energy consumption and our overall carbon footprint. Increased free time would also mean a reduction in all the convenience goods bought to fit into our hectic work schedules. More broadly, using productivity improvements for less work, rather than more output, would mean that energy efficiency improvements would go towards reducing environmental impacts. A reduction in working hours is therefore an essential plank in any response to climate change. Other research suggests that a shorter working week would bring a general reduction in the stress, anxiety and mental health problems fostered by neoliberalism. But one of the most important reasons for reducing work time is that it is a demand that both consolidates and generates class power. In the first place, reducing work time can be deployed as a temporary tactic in political struggle – working to contract, strikes and other ways of removing labour time are means to exert pressure on capitalists. But secondly – and most importantly – the reduction of the working week also makes the labour movement stronger. By withdrawing labour hours from the market, the total supply of labour goes down and worker power increases. As two commentators recently noted, ‘No other bargaining demand simultaneously enhances bargaining position. Furthermore, no other strategic logic initiates a continuous virtuous cycle in which each victory establishes the conditions for strength in the next struggle.’ For these reasons, the goal of reducing the working week should be an immediate and prominent demand of the twenty-first-century left.

Our preference is for the establishment of a three-day weekend, rather than a reduction in the working day, in order to cut down on commuting and to build upon the long holiday weekends already in existence. This demand can be achieved in a number of ways – through trade union struggles, pressure from social movements, and legislative change by political parties. Trade unions building a strategy for the future, rather than accepting the capitalist demand for jobs at all costs, could use collective bargaining to accept automation in return for a shorter working week. Indeed, the historical record suggests that trade unions are often reactive in the face of technological change, and that wage concessions only delay automation, rather than preventing it. An alternative approach that focused on the reduction and diffusion of work could reduce work without leaving workers out on the streets. Efforts can also be made to gain recognition for unofficial, unpaid labour as part of the working week, reducing it simply by bringing attention to it. A focus on a shorter working week also requires that unions build links with part-time and precarious workers. But while unions are necessary in this struggle, they are not sufficient, for the simple reason that each sector has different potentials for automation and productivity increases. A broader struggle is necessary if there is to be a break with the current logic of neoliberalism. Social movements and ideological institutions must contribute to this struggle by shaping the space of possibility. A number of think tanks, including the New Economics Foundation and the Jimmy Reid Foundation, have started to call openly for a reduction of the working week. Groups in the UK such as the Precarious Workers Brigade and Plan C are highlighting unpaid work and mobilising around issues concerning the status of work in society today. But, most significantly, there is already a high level of public desire for the reduction of the working week, with public opinion polls showing a majority of the population support the idea. There are also a variety of policy approaches to shorten the working week. Interventions can alter labour costs from a per-person basis to a per-hour basis, making it less cost-effective for businesses to enforce long hours. Countries like Belgium and the Netherlands have given workers the right to demand reduced hours without being discriminated against by employers. The Netherlands has also begun to shorten the working week at each end of the age spectrum. The young and the old are now transitioned into and out of the workforce, respectively, through gradual changes in their work hours. All of these options can and should be mobilised in pursuit of a project to reduce the working week.

These first two proposals equate to the reduction of labour demand through full automation, and the reduction of labour supply through the shortening of the working week. The combined outcome of these measures would be the liberation of a significant amount of free time without a reduction in economic output or a significant increase in unemployment. Yet this free time will be of little value if people continue struggling to make ends meet. As Paul Mattick puts it, ‘the leisure of the starving, or the needy, is no leisure at all but a relentless activity aimed at staying alive or improving their situation’. The underemployed, for instance, have plenty of free time but lack the means to enjoy it. Underemployed, it turns out, is really just a euphemism for under-waged. This is why an essential demand in a post-work society is for a universal basic income (UBI), giving every citizen a liveable amount of money without any means-testing. It is an idea that has periodically popped up throughout history. In the early 1940s, a version of it was advanced as an alternative to the Beveridge Report that eventually shaped the UK welfare state. In a now largely forgotten period during the 1960s and 1970s, the basic income was central to proposals for US welfare reform. Economists, NGOs and policymakers explored the idea in detail, and a number of small-scale experiments were set up in Canada and the United States. Such was the influence of UBI that over 1,300 economists signed a petition pushing the US Congress to enact a ‘national system of income guarantees’. Three separate administrations gave serious consideration to the proposal, and two presidents – Nixon and Carter – attempted to pass legislation to achieve it. In other words, UBI very nearly became a reality in the 1970s. While Alaska eventually implemented a basic income funded by its oil wealth, the idea largely disappeared from debate in the wake of neoliberal hegemony. But recent years have seen the idea undergo a resurgence in popularity. In both mainstream and critical media, it has gained traction, being taken up by Paul Krugman, Martin Wolf, the New York Times, the Financial Times and the Economist. The Swiss are holding a referendum on UBI in 2016, the proposal has been recommended by parliamentary committees in other countries, various political parties have adopted it in their manifestos, and there have been new experiments with it in Namibia and India. The idea has global scope, having been promoted forcefully by groups in Brazil, South Africa, Italy and Germany, and by an international network involving over twenty countries. The movement for a UBI is thus once again resurgent in the wake of the 2008 crisis and the austerity regimes put in place after it.

The demand for a UBI, however, is subject to competing hegemonic forces. It is just as open to being mobilised for a libertarian dystopia as for a post-work society – an ambiguity that has led many to mistakenly conflate the two poles. In demanding a UBI, therefore, three key factors must be articulated in order to make it meaningful: it must provide a sufficient amount of income to live on; it must be universal, provided to everyone unconditionally; and it must be a supplement to the welfare state rather than a replacement of it. The first point is obvious enough: a UBI must provide a materially adequate income. The exact amount will vary between countries and regions, but it can be relatively easily arrived at with existing data. The risk is that, if set too low, UBI becomes just a government subsidy to businesses. In addition, UBI must be universal and given to everyone unconditionally. As there would be no means-testing or other measures required to receive the UBI, it would break free of the disciplinary nature of welfare capitalism. Moreover, a universal grant avoids the stigmatisation of welfare, since everyone receives it. As we argued in Chapter 4, the invocation of ‘universalism’ also obliges the continual subversion of any restricted application of a basic income (in terms of individuals’ status as citizens, immigrants or prisoners). The demand for universality provides the basis for a continued struggle to expand the scope and scale of the basic income. Lastly, the UBI must be a supplement to the welfare state. The conservative argument for a basic income – which must be avoided at all costs – is that it should simply replace the welfare state by providing a lump sum of money to every individual. In this scenario, the UBI would just become a vector of increased marketisation, transforming social services into private markets. Rather than being some aberration of neoliberalism, it would simply extend its essential gesture by creating new markets. By contrast, the demand made here is for UBI as a supplement to a revived welfare state.

Drawing upon moral arguments and empirical research, there are a vast number of reasons to support a UBI: reduced poverty, better public health and reduced health costs, fewer high school dropouts, reductions in petty crime, more time with family and friends, and less state bureaucracy. Depending on how UBI is presented, it is capable of generating support from across the political spectrum – from libertarians, conservatives, anarchists, Marxists and feminists, among others. The potency of the demand lies partly in this ambiguity, making it capable of mobilising broad popular support. However, for our purposes the significance of UBI as a demand lies in four key interrelated factors.

The first point to emphasise is that the demand for UBI is a demand for a political transformation, not just an economic one. It is often thought that UBI is simply a form of redistribution from the rich to the poor, or that it is just a measure to maintain economic growth by stimulating consumer demand. From this perspective, UBI would have impeccable reformist credentials and be little more than a glorified progressive tax system. Yet the real significance of UBI lies in the way it overturns the asymmetry of power that currently exists between labour and capital. As we saw in the discussion of surplus populations, the proletariat is defined by its separation from the means of production and subsistence. The proletariat is thereby forced to sell itself in the job market in order to gain the income necessary to survive. The most fortunate among us have the leisure to choose which job to take, but few of us have the capacity to choose no job. A basic income changes this condition, by giving the proletariat a means of subsistence without dependency on a job. Workers, in other words, have the option to choose whether to take a job or not (in many ways, taking neoclassical economics at its word, and making work truly voluntary). A UBI therefore unbinds the coercive aspects of wage labour, partially decommodifies labour, and thus transforms the political relationship between labour and capital.

This transformation – making work voluntary rather than coerced – has a number of significant consequences. In the first place, it increases class power by reducing slack in the labour market. Surplus populations show what happens when there are large amounts of slack in the labour market: wages fall, and employers are free to debase workers. By contrast, when the labour market is tight, labour gains the political edge. The economist Michał Kalecki recognised this long ago when he argued that it explained why full employment would be resisted at every step. If every worker were employed, the threat of being fired would lose its disciplinary character – there would be more than enough jobs waiting just outside. Workers would gain the upper hand, and capital would lose its political power. The same dynamic holds for a basic income: by eliminating the reliance on wage labour, workers gain control over how much labour to supply, giving them significant power in the labour market. Class power is also increased in a variety of other ways. Strikes are easier to mobilise, since workers no longer have to worry about pay being docked or dwindling strike funds. The amount of time spent working for a wage can be modified to one’s own desire, with free time spent building communities and engaging with politics. One can slow down and reflect, safely protected from the constant pressures of neoliberalism. The anxieties that surround work and unemployment are reduced with the safety net of a UBI. Moreover, the demand for UBI combines the needs of the employed, the unemployed, the underemployed, migrant labour, temporary workers, students and the disabled. It articulates a common interest between these groups and provides a populist orientation for them to mobilise towards.

The second related feature of UBI is that it transforms precarity and unemployment from a state of insecurity to a state of voluntary flexibility. It is often forgotten that the initial push for flexible labour came from workers, as a way of demolishing the constraining permanency of traditional Fordist labour. The repetitiveness of a nine-to-five job, combined with the tediousness of most work, is hardly an appealing prospect for a life-long career. The demands of care labour often require a flexible approach as well, further undermining the appeal of traditional jobs. Marx himself invokes the liberating aspects of flexible labour in his famous claim that communism ‘makes it possible for me to do one thing today and another tomorrow, to hunt in the morning, fish in the afternoon, rear cattle in the evening, criticise after dinner, just as I have a mind, without ever becoming hunter, fisherman, herdsman or critic’. In the face of these desires for flexibility, capital adapted and co-opted them into a new form of exploitation. Today, flexible labour simply presents itself as precarity and insecurity, rather than freedom. The UBI responds to this generalisation of precarity and transforms it from a state to be feared back into a state of liberation.

Third, a basic income would necessitate a rethinking of the values attributed to different types of work. Given that workers would no longer be forced to take a job, they could instead simply reject jobs that paid too little, required too much work, offered too few benefits, or were demeaning and undignified. Low-waged work is often crass and disempowering, and under a programme of UBI it is unlikely that many would want to undertake it. The result would be that hazardous, boring and unattractive work would have to be better paid, while more rewarding, invigorating and attractive work would be less well paid. In other words, the nature of work would become a measure of its value, not merely its profitability. The outcome of this revaluation would also mean that, as wages for the worst jobs rose, there would be new incentives to automate them. UBI therefore forms a positive-feedback loop with the demand for full automation. On the other hand, a basic income would not only transform the value of the worst jobs, but also go some way towards recognising the unpaid labour of most care work. In the same way that the demand for wages for housework recognised and politicised the domestic labour of women, so too does UBI recognise and politicise the generalised way in which we are all responsible for reproducing society: from informal to formal work, from domestic to public work, from individual to collective work. What is central is not productive labour, defined in either traditional Marxist or neoclassical terms, but rather the more general category of reproductive labour. Given that we all contribute to the production and reproduction of capitalism, our activity deserves to be remunerated as well. In recognising this, the UBI indicates a shift from remuneration based upon ability to remuneration based upon basic need. All the genetic, historical and social variations that make effort a poor measure of a person’s worth are rejected here, and instead people are valued simply for being people.

Finally, a basic income is a fundamentally feminist proposal. Its disregard for the gendered division of labour overcomes some of the biases of the traditional welfare state predicated upon a male breadwinner. Equally, it recognises the contributions of unwaged domestic labourers to the reproduction of society and provides them with an income accordingly. The financial independence that comes with a basic income is also crucial to developing the synthetic freedom of women. It enables experimentation with different forms of family and community structure that are no longer bound to the model of the privatised nuclear family. And financial independence can reconfigure intimate relationships as well: one of the more unexpected findings of experiments with UBI has been that the divorce rate tended to rise. Conservative commentators jumped on this as proof of the demand’s immorality, but higher divorce rates are easily explained as women gaining the financial means to leave dysfunctional relationships. A basic income can therefore enable easier experimentation with the family structure, more possibilities for the provision of childcare and an easier transformation of the gendered division of labour. Moreover, unlike the demand for ‘wages for housework’ in the 1970s, the demand for UBI promises to break out of the wage relation rather than reinforce it.

While a universal basic income may appear economically reformist, its political implications are therefore significant. It transforms precarity, it recognises social labour, it makes class power easier to mobilise, and it extends the space in which to experiment with how we organise communities and families. It is a redistribution mechanism that transforms production relations. It is an economic mechanism that changes the politics of work. And in terms of class struggle, there is little to distinguish full employment from full unemployment: both tighten the labour market, give power to labour, and make it more difficult to exploit workers. Full unemployment has the added advantages of not being reliant upon the gendered division of labour between the household and the formal economy, of not keeping workers chained to the wage relation, and of allowing workers autonomy over their lives. For all of these reasons, the classic social democratic demand for full employment should be replaced with the future-orientated demand for full unemployment.

What are the impediments to implementing a basic income? While the problem of funding UBI appears immense, most research in fact suggests that it would be relatively easy to finance through some combination of reducing duplicate programmes, raising taxes on the rich, inheritance taxes, consumption taxes, carbon taxes, cutting spending on the military, cutting industry and agriculture subsidies, and cracking down on tax evasion. The most difficult hurdles for UBI – and for a post-work society – are not economic, but political and cultural: political, because the forces that will mobilise against it are immense; and cultural, because work is so deeply ingrained into our very identity. We will examine the political obstacles in the next two chapters, but turn to the cultural ones here.

One of the most difficult problems in implementing a UBI and building a post-work society will be overcoming the pervasive pressure to submit to the work ethic. Indeed, the failure of the United States’ earlier attempt to implement a basic income was primarily because it challenged accepted notions about the work ethic of the poor and unemployed. Rather than seeing unemployment as the result of a deficient individual work ethic, the UBI proposal recognised it as a structural problem. Yet the language that framed the proposal maintained strict divisions between those who were working and those who were on welfare, despite the plan effacing such a distinction. The working poor ended up rejecting the plan out of a fear of being stigmatised as a welfare recipient. Racial biases reinforced this resistance, since welfare was seen as a black issue, and whites were loath to be associated with it. And the lack of a class identification between the working poor and unemployed – the surplus population – meant there was no social basis for a meaningful movement in favour of a basic income. Overcoming the work ethic will be equally central to any future attempts at building a post-work world. As we saw in Chapter 3, neoliberalism has established a set of incentives that compel us to act and identify ourselves as competitive subjects. Orbiting around this subject is a constellation of images related to self-reliance and independence that necessarily conflict with the programme of a post-work society. Our lives have become increasingly structured around competitive self-realisation, and work has become the primary avenue for achieving this. Work, no matter how degrading or low-paid or inconvenient, is deemed an ultimate good. This is the mantra of both mainstream political parties and most trade unions, associated with rhetoric about getting people back into work, the importance of working families, and cutting welfare so that ‘it always pays to work’. This is matched by a parallel cultural effort demonising those without jobs. Newspapers blare headlines about the worthlessness of welfare recipients, TV shows sensationalise and mock the poor, and the ever looming figure of the welfare cheat is continually evoked. Work has become central to our very self-conception – so much so that when presented with the idea of doing less work, many people ask, ‘But what would I do?’ The fact that so many people find it impossible to imagine a meaningful life outside of work demonstrates the extent to which the work ethic has infected our minds.

While typically associated with the protestant work ethic, the submission to work is in fact implicit in many religions. These ethics demand dedication to one’s work regardless of the nature of the job, instilling a moral imperative that drudgery should be valued. While originating in religious ideas about ensuring a better afterlife, the goal of the work ethic was eventually replaced with a secular devotion to improvement in this life. More contemporary forms of this imperative have taken on a liberal-humanist character, portraying work as the central means of self-expression. Work has come to be driven into our identity, portrayed as the only means for true self-fulfilment. In a job interview, for instance, everyone knows the worst answer to ‘Why do you want this job?’ is to say ‘Money’, even as it remains the repressed truth. Contemporary service work heightens this phenomenon. In the absence of clear metrics for productivity, workers instead put on performances of productivity – pretending to enjoy their job or smiling while being yelled at by a customer. Working long hours has become a sign of devotion to the job, even as it perpetuates the gender pay gap. With work tied so tightly into our identities, overcoming the work ethic will require us overcoming ourselves.

The central ideological support for the work ethic is that remuneration be tied to suffering. Everywhere one looks, there is a drive to make people suffer before they can receive a reward. The epithets thrown at homeless beggars, the demonization of those on the dole, the labyrinthine system of bureaucracy set up to receive benefits, the unpaid ‘job experience’ imposed upon the unemployed, the sadistic penalisation of those who are seen as getting something for free – all reveal the truth that for our societies, remuneration requires work and suffering. Whether for a religious or secular goal, suffering is thought to constitute a necessary rite of passage. People must endure through work before they can receive wages, they must prove their worthiness before the eyes of capital. This thinking has an obvious theological basis – where suffering is thought to be not only meaningful, but in fact the very condition of meaning. A life without suffering is seen as frivolous and meaningless. This position must be rejected as a holdover from a now-transcended stage of human history. The drive to make suffering meaningful may have had some functional logic in times when poverty, illness and starvation were necessary features of existence. But we should reject this logic today and recognise that we have moved beyond the need to ground meaning in suffering. Work, and the suffering that accompanies it, should not be glorified.

What is needed, therefore, is a counter-hegemonic approach to work: a project that would overturn existing ideas about the necessity and desirability of work, and the imposition of suffering as a basis for remuneration. The media is already changing the conditions of possibility – positioning UBI as not only a possible solution, but increasingly as a necessary solution to problems of technological unemployment. These hegemonic trends should be amplified. The dominance of the work ethic also runs up against the changing material basis of the economy. Capitalism demands that people work in order to make a living, yet it is increasingly unable to generate enough jobs. The tensions between the value accorded to the work ethic and these material changes will only heighten the potential for transformation of the system. Actions to make precarity and joblessness an increasingly visible political problem would go some way to generating the support for a post-work society. (In the same way that Occupy raised awareness of inequality, and UK Uncut highlighted tax evasion.) Perhaps most importantly, there is already a widespread hatred for jobs that can be tapped into. Much as neoliberal hegemony co-opted real desires and garnered active consent, so too must any post-work hegemony find its active force in the real desires of people. The widespread demand that others adopt the work ethic is matched only by the disdain we feel for our own jobs. Today, across the world, only 13 per cent of people say they find their jobs engaging. Physically degraded, mentally drained and socially exhausted, most workers find themselves under immense amounts of stress in their jobs. For the vast majority of people, work offers no meaning, fulfilment or redemption – it is simply something to pay the bills. Those already excluded from jobs should not be fighting for inclusion in a society of work and labour, but rather be building the conditions to reproduce their lives outside of work. Changing the cultural consensus about the work ethic will mean taking actions at an everyday level, translating these medium-term goals into slogans, memes and chants. It will require undertaking the difficult and essential work of workplace organizing and campaigning – of mobilising people’s passions in order to topple the dominance of the work ethic. The success of these efforts will be clear when media discussions about automation shift from fear-mongering over lost jobs to celebrations of the freedom from drudgery.

A twenty-first-century left must seek to combat the centrality of work to contemporary life. In the end, our choice is between glorifying work and the working class or abolishing them both. The former position finds its expression in the folk-political tendency to place value upon work, concrete labour and craftwork. Yet the latter is the only true postcapitalist position. Work must be refused and reduced, building our synthetic freedom in the process. As we have set out in this chapter, achieving this will require the realisation of four minimal demands:

1.Full automation

2.The reduction of the working week

3.The provision of a basic income

4.The diminishment of the work ethic

While each of these proposals can be taken as an individual goal in itself, their real power is expressed when they are advanced as an integrated programme. This is not a simple, marginal reform, but an entirely new hegemonic formation to compete against the neoliberal and social democratic options. The demand for full automation amplifies the possibility of reducing the working week and heightens the need for a universal basic income. A reduction in the working week helps produce a sustainable economy and leverage class power. And a universal basic income amplifies the potential to reduce the working week and expand class power. It would also accelerate the project of full automation: as worker power rose and as the labour market tightened, the marginal cost of labour would increase as companies turned towards machinery in order to expand. These goals resonate with each other, magnifying their combined power. And a new post-work hegemony would be resistant to reversion, having created a mass constituency benefiting from its continuation. The ambition here is to take back the future from capitalism and build ourselves the twenty-first-century world we want. It is to provide the time and money that are central to any meaningful conception of freedom. The traditional battle cry of the left, demanding full employment, should therefore be replaced with a battle cry demanding full unemployment. But let us be clear: there is no technocratic solution, and there is no necessary progression into a post-work world. The struggles for full automation, a shorter working week, the end of the work ethic and a universal basic income are primarily political struggles. The post-work imaginary generates a hyperstitional image of progress – one that aims to make the future an active historical force in the present. The struggles that such a project will face require that the left move past its folk-political horizon, rebuild its power and adopt an expansive strategy for change. It is to these issues that we now turn.

A post-work society holds a potentially broad appeal and would materially improve the lives of most – but this is no guarantee of it coming about. Media discussions of basic income and automation today often seem to assume the benevolence of elites, the political neutrality of technology and the inevitability of a post-work society. Yet an array of powerful forces is invested in the continuation of the status quo, and the left has been devastated over the past few decades. Misery remains more likely than luxury. Under current conditions, automation is likely to cause more unemployment, with the benefits of new technologies going to their wealthy owners. Any free time we get will be eliminated with the production of dreary new jobs or the extension of precarious existence. And if a basic income were achieved tomorrow, it would almost certainly be set below poverty levels and simply act as a handout to companies. To achieve a meaningful post-work society therefore requires changing the present political conditions. In turn, this requires the left to face squarely up to the dismal situation before it: trade unions lying in ruin, political parties rendered into neoliberal puppets, and a waning intellectual and cultural hegemony. State and corporate repression of the left has significantly intensified in recent decades, legal changes have made it more difficult to organise, generalised precarity has made us more insecure, and the militarisation of policing has rapidly gathered speed. And beyond this lies the fact that our inner lives, our social world and our built environment are organised around work and its continuation. The shift to a post-work society, much like the shift to a decarbonised economy, is not just a matter of overcoming a few elite interests. More fundamentally, it is a matter of transforming society from the ground up. An engagement with the totality of power and capital is inevitable, and we should be under no illusions about the difficulties facing such a project. If full transformational change is not immediately possible, our efforts must be directed towards cracking open those spaces of possibility that do exist and fostering better political conditions over time. We must first reach a space within which more radical demands can be meaningfully articulated, and must therefore prepare for the long term if we wish to alter the terrain of politics substantially.

This ought not to be entirely unexpected. Capitalism did not emerge all at once, but instead percolated to a position of dominance over the course of centuries. A large number of components had to be put in place: landless labourers, widespread commodity production, private property, technical sophistication, centralisation of wealth, a bourgeois class, a work ethic, and so on. These historical conditions are the components that enabled the systemic logic of capitalism eventually to gain traction in the world. The lesson here is that, just as capitalism relied upon the accumulation of a particular set of components, so too will postcapitalism. It will neither emerge all at once nor in the wake of some revolutionary moment. The task of the left must be to work out the conditions for postcapitalism and to struggle to build them on a continually expanding scale.

This chapter therefore begins from the premise that the contemporary left is in a dire situation and that any transformative project will take time. We limit our analysis here largely to Western capitalist democracies, with their peculiar apparatuses of political and economic power. We will mostly leave aside the immense (and immensely important) regions of the rest of the world. However, it is worth reiterating that the problems of automation and surplus populations are global in nature, and the grounds for post-work are flourishing around the world – as demonstrated by recent experiments with basic incomes in India and Namibia, the surge in industrial automation across the most populous regions of the world, and the spontaneous emergence of movements against work in numerous countries. Though these dynamics are global, any political project to transform this situation will necessarily need to respond to particular conditions on the ground. While certain core principles will be translatable between contexts, they will need to be realised differently under different circumstances. With these qualifications in mind, how can a better future be built? The classic Leninist strategy of building dual power with a revolutionary party and overthrowing the state is obsolete. Proponents of the Bolshevik Revolution model appear more useful as historical re-enactors than as guides for contemporary politics. Likewise, the recent history of revolutions – from the Iranian Revolution to the Arab Spring – has simply led to some combination of theocratic authoritarianism, military dictatorship and civil war. The electoral reformist approach is equally a failure. The idea of voting in a new world mutated into a convivial elite consensus during the postwar era and became ensconced within neoliberal ideology in recent decades. At its best, such reformism is doomed simply to ameliorate capitalism and act as a type of politically mediated homeostatic system. And as the latest cycle of struggles has shown, the folk-political approach of prioritising various forms of immediacy has failed to transform society. Piecemeal efforts, defensive struggles, withdrawals and prefigurative pockets of activity have been largely incapable of stemming the tide, let alone gaining ground on global capitalism. Equally, it remains insufficient simply to posit that progress will be worked out in practice or that the masses will spontaneously create a better world. While there are undoubtedly elements of luck and unpredictability in any struggle, the difficulty of building a new world demands that strategic thought be carried out in advance. Our efforts must be organised strategically along broad lines, rather than dissipating into a series of partial and disconnected achievements. As modernity asserts, progress towards a better future comes on the back of deliberate reflection and conscious action.

Given the limits of these other approaches, we argue that the best way forward is a counter-hegemonic strategy. This is a strategy that is adaptable from positions of weakness, is scalable from the local to the global, and recognises the hold that capitalism has over every aspect of our lives, from our most intimate desires to the most abstract financial flows. A counter-hegemonic strategy entails a project to overturn the dominant neoliberal common sense and rejuvenate the collective imagination. Fundamentally, it is an attempt to install a new common sense – one organised around the crisis of work and its effects on the proletariat. In this, it involves preparatory work for moments when full-scale struggle erupts, transforming our social imagination and reconfiguring our sense of what is possible. It builds up support and a common language for a new world, seeking to alter the balance of power in preparation for when a crisis upsets the legitimacy of society. Unlike forms of folk politics, such a strategy is expansive, long-term, comfortable with abstraction and complexity, and aimed at overthrowing capitalist universalism. In this chapter, we examine three possible sites of struggle – over the intellectual, cultural and technological mediums of neoliberal hegemony. The next section will examine hegemony at a theoretical level, while the rest of the chapter will explore illustrations of how a counter-hegemonic project might be put into practice – through utopian narratives, pluralist economics and the repurposing of technologies.

The idea of ‘hegemony’ initially emerged as a way of explaining why ordinary people were not revolting against capitalism. According to the traditional Marxist narrative, workers would become increasingly aware of the exploitative nature of capitalism and eventually organise to transcend it. Capitalism, it was believed, ought to be producing an ever more polarised world of capitalists versus the working class, in a process that underpinned a political strategy in which the organised working class would win control over the state through revolutionary means. But by the 1920s it was clear that this was not about to happen in western European democratic societies. How was it, then, that capitalism and the interests of the ruling classes were secured in democratic societies largely devoid of overt force? The Italian Marxist Antonio Gramsci answered that capitalist power was dependent on what he termed hegemony – the engineering of consent according to the dictates of one particular group. A hegemonic project builds a ‘common sense’ that installs the particular worldview of one group as the universal horizon of an entire society. By this means, hegemony enables a group to lead and rule over a society primarily through consent (both active and passive) rather than coercion. This consent can be achieved in a variety of ways: the formation of explicit political alliances with other social groups, the dissemination of cultural values supporting a particular way of organising society (for example, the work ethic instilled by the media and through education), the alignment of interests between classes (for example, workers are better off when a capitalist economy is growing, even if this means mass inequality and environmental devastation) and through building technologies and infrastructures in such a way that they silently constrain social conflict (for example, by widening streets to prevent the erection of barricades during insurrections). In a broad and diffuse sense, hegemony enables relatively small groups of capitalists to ‘lead’ society as a whole, even when their material interests are at odds with those of the majority. Finally, as well as securing active and passive consent, hegemonic projects also deploy coercive means, such as imprisonment, police violence and intimidation, to neutralise those groups that cannot otherwise be led. Taken together, these measures enable small groups to influence the general direction of a society, sometimes through the achievement and deployment of state power, but also outside the confines of the state.

The latter point is particularly important, because hegemony is not just a strategy of governance for those in power, but also a strategy for the marginal to transform society. A counter-hegemonic project enables marginal and oppressed groups to transform the balance of power in a society and bring about a new common sense. To abjure hegemony therefore implies an abandonment of the basic idea of winning and exercising power, and is to effectively give up on the primary terrain of political struggle. While there are some on the left who explicitly endorse such a position, to the degree that horizontalist movements have been successful they have tended to operate as a counter-hegemonic force. Occupy’s major success – transforming the public discourse around inequality – is a prime example of this. A counter-hegemonic project will therefore seek to overturn an existing set of alliances, common sense, and rule by consent in order to install a new hegemony. Such a project will seek to build the social conditions from which a new post-work world can emerge and will require an expansive approach that goes beyond the temporary and local measures of folk politics. It requires mobilisation across different social groups, which means linking together a diversity of individual interests into a common desire for a post-work society. The neoliberal hegemony in the United States, for instance, came about by linking together the interests of economic liberals with those of social conservatives. This is a fractious (sometimes even contradictory) alliance, but it is one that finds common interests in the broad neoliberal framework by emphasising individual freedoms. In addition, counter-hegemonic projects operate across diverse fields – from the state, to civil society, to the material infrastructure. This means an entire battery of actions are needed, such as seeking to spread media influence, attempting to win state power, controlling key sectors of the economy and designing important infrastructures. This project requires empirical and experimental work to identify the parts of these various fields that are operating to reinforce the present general direction of society. The Mont Pelerin Society is a good example of this. Painstakingly aware of the ways in which Keynesianism was the hegemonic common sense of its time, the MPS undertook the long-term task of taking apart the elements that sustained it. This was a project that took decades to come to full fruition, and during that time the MPS had to undertake counter-hegemonic actions in order to install it. Such long-term thinking is an important corrective to the tendency today to focus on immediate resistance and new daily outrages. However, hegemony is not just an immaterial contestation of ideas and values. Neoliberalism’s ideological hegemony, for example, depends upon a series of material instantiations – paradigmatically in the nexus of government power, media framing and the network of neoliberal think tanks. As we observed in our examination of the rise of neoliberalism, the MPS was particularly adept at creating an intellectual infrastructure, consisting of the institutions and material paths necessary to inculcate, embody and spread their worldview.

The combination of social alliances, strategic thinking, ideological work and institutions builds a capacity to alter public discourse. Crucial here is the idea of the ‘Overton window’ – this is the bandwidth of ideas and options that can be ‘realistically’ discussed by politicians, public intellectuals and news media, and thus accepted by the public. The general window of realistic options emerges out of a complex nexus of causes – who controls key nodes in the press and broadcast media, the relative impact of popular culture, the relative balance of power between organised labour and capitalists, who holds executive political power, and so on. Though emerging from the intersection of different elements, the Overton window has a power of its own to shape which future paths are taken by societies and governments. If something is not deemed ‘realistic’, then it will not even be tabled for discussion and its proponents will be silenced as ‘unserious’. We can evaluate the success of neoliberal ideas in terms of this by the degree to which they have framed what is possible over a period of more than thirty years. While it has never been possible to convince the majority of the population of the positive merits of key neoliberal policies, active assent is unnecessary. A sequence of neoliberal administrations throughout the world, in conjunction with a network of think tanks and a largely right-leaning media, have been able to transform the range of possible options to exclude even the most moderate of socialist measures. Through this, the hegemony of neoliberal ideas has enabled the exercise of power without always requiring executive state power. Providing that the window of possible options can be stretched further to the right, it matters little whether right-wing governments hold power – a reality that the US Republican Party has consistently exploited over the last two decades, often to the surprise of those on the liberal left. Ideological hegemony as we present it here is therefore not about maintaining a strict party line on what can be discussed. Simply bringing leftist issues and categories into positions of prominence would already be a major step forward.

While often understood as something that pertains to ideas, values and other immaterial aspects of society, there is in fact also a material sense to hegemony. The physical infrastructures of our world exert a significant hegemonic force upon societies – imposing a way of life without overt coercion. For instance, with regard to urban infrastructure, David Harvey writes that ‘projects concerning what we want our cities to be are … projects concerning human possibilities, who we want, or perhaps even more pertinently, who we do not want to become’. Infrastructure such as suburbs in the United States was built with the explicit intention of isolating and individualising existing solidarity networks, and installing a gendered division between the private and the public in the form of single-family households. Economic infrastructures also serve to modify and sculpt human behaviours. Indeed, technical infrastructures are often developed for political as well as economic purposes. If we think of global just-in-time supply chains, for example, these are economically efficient under capitalism, but also exceptionally effective in breaking the power of unions. In other words, hegemony, or rule by the engineering of consent, is as much a material force as it is a social one. It is something embedded in human minds, social and political organisations, individual technologies and the built environment that constitutes our world. And, whereas the social forces of hegemony must be continually maintained, the materialised aspects of hegemony exert a force of momentum that lasts long past their initial creation. Once in place, infrastructures are difficult to dislodge or alter, despite changing political conditions. We are facing up to this problem now, for example, with the infrastructure built up around fossil fuels. Our economies are organised around the production, distribution and consumption of coal, oil and gas, making it immensely difficult to decarbonise the economy. The flipside of that problem, though, is that once a postcapitalist infrastructure is in place, it would be just as difficult to shift away from it, regardless of any reactionary forces. Technology and technological infrastructures therefore pose both significant hurdles for overcoming the capitalist mode of production, as well as significant potentials for securing the longevity of an alternative. This is why, for example, it is insufficient even to have a massive populist movement against the current forms of capitalism. Without a new approach to things like production and distribution technologies, every social movement will find itself forced back into capitalistic practices.

The left must therefore develop a sociotechnical hegemony: both in the sphere of ideas and ideology, and in the sphere of material infrastructures. The objective of such a strategy, in a very broad sense, is to navigate the present technical, economic, social, political and productive hegemony towards a new point of equilibrium beyond the imposition of wage labour. This will require long-term and experimental praxis on multiple fronts. A hegemonic project therefore implies and responds to society as a complex emergent order, the result of diverse interacting practices. Some combinations of social practices will lead to instability, but others will tend towards more stable (if not literally static) outcomes. In this context, hegemonic politics is the work that goes into retaining or navigating towards a new point of relative stability across a variety of societal subsystems, from the national-level politics of the state, to the economic domain, from the battle of ideas and ideologies to different regimes of technology. The order which emerges as a result of the interactions of these different domains is hegemony, which works to constrain certain kinds of action and enable others. In the rest of this chapter, we examine three possible channels through which to undertake this struggle: pluralising economics, creating utopian narratives and repurposing technology. These certainly do not exhaust the points of possible attack, but they do identify potentially productive areas to focus resources on.

Today, one of the most pervasive and subtle aspects of hegemony is the limitations it imposes upon our collective imagination. The mantra ‘there is no alternative’ continues to ring true, even as more and more people strive against it. This marks a significant change from the long twentieth century, when utopian imaginaries and grandiose plans for the future flourished. Images of space flight, for instance, were constant ciphers for humanity’s desire to control its destiny. In pre-Soviet Russia, there was remarkably widespread fascination with space exploration. Though aviation was still a novelty, the dreams of space flight promised ‘total liberation from the signifiers of the past: social injustice, imperfection, gravity, and ultimately, the Earth’. The utopian inclinations of the time made sense of the rapidly changing world, gave credence to the belief that humanity could channel history in a rational direction and cultivated anticipations for a future society. In the more mystical formulations, cosmists argued with admirable ambition that geoengineering and space exploration were only partial steps towards the real goal: resurrecting the entirety of the dead. Meanwhile, more secular approaches outlined detailed plans for fully automated economies, mass economic democracy, the end of class society and the flourishing of humanity. Such was the level of enthusiasm and belief in imminent space travel that in 1924 a riot nearly erupted when rumours circulated about a possible rocket flight to the moon. Popular culture was saturated with these images and with stories in which technological and social revolution intertwined. But these were not simply matters of extraterrestrial fantasy, as they had concrete effects on people’s ways of living. In the post-revolutionary period, this culture of ambition fostered a series of social experiments with new ways of communal living, domestic arrangements and political formations. These experiments gave credence to the idea that anything was achievable in a time of rapid modernisation, lending support to the Bolsheviks and the people. While utopian ambitions were largely forced underground during the Stalinist era, they re-emerged in the 1950s with the growth of newfound economic confidence and the resources to make good on some of the earlier dreams. The greatest moments of the Soviet experiment – the launch of Sputnik and the economic dominance that it appeared on the verge of attaining in the 1950s – were ultimately inseparable from a popular culture imbued with utopian desires. A similar period of utopian ambition also held sway in the early years of the United States. Fuelled by a widespread belief that the new industrial capitalism was temporary and that a better world would soon emerge, workers militantly struggled for this new world. In a climate far more hostile than our own, labour was able to create an array of strong organisations and exert significant pressure. The successes of this time were inseparable from a broader utopian culture.

By contrast, today’s world remains firmly confined within the parameters of capitalist realism. The future has been cancelled. We are more prone to believing that ecological collapse is imminent, increased militarisation inevitable, and rising inequality unstoppable. Contemporary science fiction is dominated by a dystopian mindset, more intent on charting the decline of the world than the possibilities for a better one. Utopias, when they are proposed, have to be rigorously justified in instrumental terms, rather than allowed to exist in excess of any calculation. Meanwhile, in the halls of academia the utopian impulse has been castigated as naive and futile. Browbeaten by decades of failure, the left has consistently retreated from its traditionally grand ambitions. To give but one example: whereas the 1970s saw radical feminism and queer manifestos calling for a fundamentally new society, by the 1990s these had been reduced to a more moderate identity politics; and by the 2000s discussions were dominated by even milder demands to have same-sex marriage recognised and for women to have equal opportunities to become CEOs. Today, the space of radical hope has come to be occupied by a supposedly sceptical maturity and a widespread cynical reason. And the goals of an ambitious left, which once aimed at the total transformation of society, have been reduced down to minor tinkering at the edges of society.

We believe that an ambitious left is essential to a post-work programme, and that to achieve this, the future must be remembered and rebuilt. Utopias are the embodiment of the hyperstitions of progress. They demand that the future be realised, they form an impossible but necessary object of desire, and they give us a language of hope and aspiration for a better world. The denunciations of utopia’s fantasies overlook the fact that it is precisely the element of imagination that makes utopias essential to any process of political change. If we want to escape from the present, we must first dismiss the settled parameters of the future and wrench open a new horizon of possibility. Without the belief in a different future, radical political thinking will be excluded from the beginning. Indeed, utopian ideas have been central to every major moment of liberation – from early liberalism, to socialisms of all stripes, to feminism and anti-colonial nationalism. Cosmism, afro-futurism, dreams of immortality, and space exploration – all of these signal a universal impulse towards utopian thinking. Even the neoliberal revolution cultivated the desire for an alternative liberal utopia in the face of a dominant Keynesian consensus. But any competing left utopias have gone sorely under-resourced since the collapse of the Soviet Union. We therefore argue that the left must release the utopian impulse from its neoliberal shackles in order to expand the space of the possible, mobilise a critical perspective on the present moment and cultivate new desires.

First, utopian thought rigorously analyses the current conjuncture and projects its tendencies out into the future. Whereas scientific approaches attempt to reduce discussions of the future to fit within a probabilistic framework, utopian thought recognises that the future is radically open. What may appear impossible today might become eminently possible. At their best, utopias include tensions and dynamism within themselves, rather than presenting a static image of a perfected society. While irreducible to instrumental concerns, utopias also foster the imagination of ideas that might be implemented when conditions change. For example, the nineteenth-century Russian cosmists were among the first to think seriously about the social implications and potentials of space flight. Initially considered ineffectual dreamers, they ended up heavily influencing the future science of rocketry. Likewise, early science fiction dealing with space exploration and cosmist utopias went on to influence state policy towards science and technology in the wake of the Russian Revolution. The creation of alternatives also makes it possible to recognise that another world is possible in the first place. As the flawed but significant global alternative posed by the USSR disappears from living memory, such images of a different world become increasingly important, widening the Overton window and experimenting with ideas about what might be achieved under different conditions.

In elaborating an image of the future, utopian thought also generates a viewpoint from which the present becomes open to critique. It suspends the appearance of the present as inevitable and brings to light aspects of the world that would otherwise go unnoticed, raising questions that must be constitutively excluded. Recent US science fiction, for instance, has often been written in response to contemporary issues of race, gender and class, while early Russian utopias imagined worlds that overcame the problems posed by rapid urbanisation and conflicting ethnicities. These worlds not only model solutions, but illuminate problems. As Slavoj Žižek notes in his discussion of Thomas Piketty, the seemingly modest demand to implement a global tax actually implies a radical reorganisation of the entire global political structure. Implicit within this small claim is a utopian impulse, since the conditions for making it possible require such a fundamental reconfiguration of existing circumstances. Likewise, the demand for a universal basic income provides a perspective from which the social nature of work, its invisible domestic aspect and its extension to every area of our lives become more readily apparent. The ways we organise our work lives, families and communities are given a fresh appearance when viewed from the perspective of a post-work world. Why do we devote one-third of our lives in submission to someone else? Why do we insist that domestic work (performed primarily by women) go unpaid? Why are our cities organised around lengthy, dreary commutes from the suburbs? The utopian demand from the future therefore implores us to question the givens of our world. In these ways, utopias can be both a negation of the present and an affirmation of a possible future.

Finally, in affirming the future, utopia functions as an affective modulator: it manipulates and modifies our desires and feelings, at both conscious and pre-conscious levels. In all its variations, utopia ultimately concerns the ‘education of desire’. It provides a frame for us, telling us both how and what to desire, while unleashing these libidinal elements from the bounds of the reasonable. Utopias give us something to aim for – something beyond the stale repetition of the same offered by the eternal present of capitalism. In cracking open the present and providing an image of a better future, the space between the present and the future becomes the space for hope and the desire for more. By generating and channelling these affects, utopian thinking can become a spur to action, a catalyst for change; it disrupts habits and breaks down consent to the existing order. Futural thinking, extended by communications mechanisms, generates collective affects of hope that mobilise people to act on behalf of a better future – affects that are necessary to any political project. While utopian thinking rejects the melancholy and transcendental miserabilism found in some parts of the contemporary left, it also invokes its own negative affect. The obverse of hope is disappointment (an affect that is today embodied in figures like the young ‘graduate with no future’). Whereas anger has traditionally been the dominant affect of the militant left, disappointment invokes a more productive relation – not merely a willed transformation of the status quo, but also a desire for what-might-be. Disappointment indexes a yearning for a lost future.

If the left is to counter the common sense of neoliberalism (‘there’s not enough money’, ‘everyone must work’, ‘government is inefficient’), utopian thinking will be essential. We need to think big. The natural habitat of the left has always been the future, and this terrain must be reclaimed. In our neoliberal era, the drive for a better world has largely been whittled away under the pressures and demands of everyday existence. In this repression, what has been lost is that ambition to produce ‘a world that exceeds – existentially, aesthetically, as well as politically – the miserable confines of bourgeois culture’. But as an apparently universal and irrepressible characteristic of human cultures, utopian thinking can surge forth under even the most repressive conditions. Utopian inclinations play out across the human spectrum of feelings and affects – embodied in popular culture, high culture, fashion, city planning, and even quotidian daydreaming. The popular desire for space exploration, for instance, points to a curiosity and ambition that lies beyond the profit motive. The like-minded trend of afro-futurism offers not only a highly stylised image of a better future, but also ties it to a radical critique of existing structures of oppression and a remembrance of past struggles. The post-work imaginary also contains numerous historical precedents in utopian writing, pointing to a constant striving to move beyond the constraints of wage labour. Cultural movements and aesthetic production have essential roles to play in reigniting the desire for utopia and inspiring visions of a different world.

While utopias seek to transform the cultural hegemony of neoliberalism, education forms a key institution for transforming intellectual hegemony. It is the educational apparatus that indoctrinates new generations in the dominant values of a particular society, reproducing its ideology through the decades. In the education system, children learn the basic ideas of a society, respect for (in fact, submission to) the existing order, and the skills necessary to distribute them along different segments of the labour market. Transforming the educational system of intellectuals is therefore a key task in building a new hegemony. It is not for nothing that the Nobel Prize–winning economist Paul Samuelson wrote that: ‘I don’t care who writes a nation’s laws, or crafts its advanced treatises, if I can write its economics textbooks.’ Projects focused on changing this institutional element of society could focus on three broad goals: pluralising the teaching of economics, reinvigorating the study of leftist economics and expanding popular economic literacy.

It is often forgotten, so deeply are we embedded in neoliberalism, that economics was once a relatively pluralist discipline. The interwar period was a time of healthy competition between a variety of formalist and non-formalist approaches. In academic journals, it was not unusual to see discussions of economic planning, the tendency for the rate of profit to fall, and other standard categories of Marxist economics. In the 1960s, the Cambridge capital controversy brought together heterodox and mainstream thinkers in a seminal debate about the foundations of the discipline – one that everyone admits the heterodox thinkers won. As late as the 1970s, one of the founders of modern economics was discussing exploitation, the labour theory of value and the transformation problem in a leading economics journal. Such an event is difficult to imagine today. While neoclassical economics is a large tent that contains a variety of approaches, it is nevertheless a fundamentally limited perspective on what counts as real economic knowledge. This problem is compounded by the particular methodological demands of the most preeminent journals, with formal modelling taking precedence over more sociological analyses and qualitative understandings.

If the broad cultural and academic ideas of how to run economies are to change, at a minimum it will require more pluralism in the education of students. Here, there are glimmers of hope for a pluralist revival. Work is being done across the world to bring alternative economics to mainstream universities, and groups of students and professionals alike are beginning to mobilise around this issue. Since 2000, numerous universities have seen students vocally demand pluralism in their economics education. More recent years have seen students openly protesting the defenders of mainstream economics, and the emergence of groups like the Post-Crash Economic Society and Rethinking Economics that are making concerted efforts to change the curriculum. Essential to a project of pluralising economics, however, is the development of a research programme and textbooks. Part of the reason for the rise of formalist approaches is precisely their fit with institutional requirements of higher education: they provided theories for researchers to spend time testing, textbooks and PhDs to continue a lineage of thought, and clear and transmissible principles. Today, the field has come to be dominated by neoclassical textbooks, and the result is that, even if professors want to pluralise the discipline, they do not have many accessible resources to hand. Indications that this might be changing include the creation of a heterodox textbook by two proponents of modern monetary theory. But more work needs to be done on this front in order to broaden the parochial horizons of mainstream economics.

To support this process, there should be a movement to rejuvenate leftist economics. The dearth of economic analysis on the left could be seen in the wake of the 2008 crisis, when the most prominent critical response was a makeshift Keynesianism. The left was largely without a meaningful and desirable economic programme, having focused primarily on the critique of capitalism rather than the elaboration of alternatives. This is a crisis of utopian imagination, but also of cognitive limits. A series of emerging contemporary phenomena must be thought through carefully: for instance, the causes and effects of secular stagnation; the transformations invoked by the shift to an informational, post-scarcity economy; the changes wrought by the introduction of full automation and a universal basic income; the possible approaches to collectivising automated manufacturing and services; the progressive potentials of alternative approaches to quantitative easing; the most effective ways to decarbonise the means of production; the implications of dark pools for financial instability – and so on. Equally, research should be revived on what postcapitalism might look like in practice. Beyond a few outdated classics, very little research has been done to think through an alternative economic system – even less so in the wake of emerging technologies like additive manufacturing, self-driving vehicles and soft AI. What role, for instance, could non-state cryptocurrencies have? How does one measure value if not by abstract or concrete labour? How can ecological concerns be fully accounted for in a postcapitalist economic framework? What mechanism can replace the market and overcome the socialist calculation problem? And what are the likely effects of the possible tendency for the rate of profit to fall? Building a postcapitalist world is as much a technical task as a political one, and in order to begin thinking about it, the left needs to overcome its general aversion to formal modelling and mathematics. There is no small amount of irony in the fact that the same people who criticise the abstraction of mathematical modelling often adhere to the most abstract dialectical readings of capitalism. This recognition of the uses of quantitative methods does not mean simply adopting neoclassical models or slavishly following the dictates of numbers, but the rigour and computational elaboration that can come with formal modelling are essential for grappling with the complexity of the economy. However, from modern monetary theory to complexity economics, from ecological to participatory economics, trajectories of innovative thought are being launched – even if they remain marginal for now. Equally, organisations like the New Economics Foundation are leading the way in creating models of the economy that can inform leftist political goals, as well as fostering public literacy in economic matters.

The latter point is particularly important, as increasing economic literacy means not only transforming the practice of academic economists, but also making the economy intelligible to non-specialists. Sophisticated analyses of economic trends need to be connected to the intuitive insights of everyday lives. While, for the near future, the revival of leftist economics is likely to be centred in academia, the aim should be to spread such economics education far beyond the confines of universities. Unions could use their resources to educate their members about the changing nature of the contemporary economy. Through internal education programmes, rank-and-file workers can begin to situate the problems of their workplaces and communities within a larger economic context. Similar approaches can be – and in many cases already are – achieved through the training of activists. Open schools provide another medium for education, giving the public a chance to learn about ideas that are too often made impenetrable by academic jargon, and from which they are excluded by exorbitant tuition and publisher fees. There is a long tradition in the UK of working-class education, which can be drawn upon to learn from. For example, the Workers’ Educational Association already provides low-cost adult education to local communities. Such institutions provide ways in which abstract economic understandings can be linked up with the on-the-ground knowledge of workers, activists and community members, each mutually shaping the other. Working systematically to develop pluralism, economic research and public education will play a significant role in strengthening the utopian narratives outlined in the previous section, and providing the necessary navigational tools to chart a course out of capitalism.

As we argued above, hegemony is embedded not only in the ideas of a society, but also in the built environment and technologies that surround us. These objects carry a politics within them: they facilitate particular uses and actions, while simultaneously constraining others. For instance, our current infrastructure tends to shape our societies into individualistic, carbon-based, competitive forms, regardless of what individuals or collectives may want. The significance of these politicised infrastructures is only increasing as technology expands into the smallest nano-scales and out to the largest post-planetary formations. No aspect of our lives remains untouched by technology, and indeed, many would argue that humanity is intrinsically technological. In response to this materialised hegemony – one thoroughly constructed by and implicated in capitalism – a few different options present themselves. A first position argues we must destroy this built environment in order to ever liberate ourselves. While this argument reaches its zenith in primitivism and its demand to be done with civilisation, similar inclinations permeate the left today. Given the devastation such a project would bring about, and the theoretical ineptitude behind these claims, we consider this position little more than an academic curiosity. A second position instead argues that technology is the basis for a postcapitalist order, but that any meaningful focus on changing our technology should wait until after the political project of post-capitalism is achieved. This would undoubtedly make our task simpler, but, given the pervasive entanglement of technology with politics, and given the latent potentials in current technology, we believe the far more prudent option is to look at how developments can be redirected today, and existing technology repurposed immediately. A third approach therefore focuses on invention and emphasises that the choice of which technologies to develop and how they are designed is primarily a political matter. The direction of technological development is determined not only by technical and economic considerations, but also by political intentions. More than just seizing the means of production, this approach declares the need to invent new means of production. A final approach focuses on how existing technology contains occluded potentials that strain at our current horizon and how they might be repurposed. Under capitalism, technology’s potential is drastically constrained – reduced to a mere vehicle for generating profit and controlling workers. Yet potentials continue to exist in excess of these current uses. The task before us is to uncover the hidden potentials and link them up to scalable processes of change. This is ultimately a utopian intervention, insofar as repurposing aims to ignite collective imagination about what can be done with the resources to hand.

We have, therefore, two effective strategies in approaching the question of technological hegemony. In the first approach, the focus is on the invention and adoption of new technologies, emphasising that we can create tools of change. In this vein, some have called for greater democratic control over the design and implementation of infrastructures and technologies. In the workplace, this means struggling over which technologies are brought in and how they are used. Given that technologies are rarely, if ever, introduced all at once, there is a lengthy period of time in which to leverage power to gain control over how technologies are being developed and implemented. The rejection of surveillance measures is one of the most obvious goals, but workplace struggle also means resisting technologies which simply intensify, speed up and worsen working conditions. At the level of the state, there is an equally strong case to be made for democratic control over technology development, given that most significant innovations come from public-sector financing rather than the private sector. It is the state that leads significant technological revolutions – from the internet to green technology, nanotechnology, the algorithm at the heart of Google’s search engine, and all of the major components of Apple’s iPhone and iPad. The microprocessor, the touchscreen, the GPS, the batteries, the hard drive and SIRI are just a few of the components that emerged from government investment. The fact of the matter is that capitalist markets tend towards short-term views and low-risk investments. It is governments that provide the long-term resources that enable major innovative changes to develop and flourish, whereas contemporary venture capital increasingly tends towards the generation of short-term profit. It is governments that make investments in high-risk developments that are likely to fail – but for that reason are also likely to lead to major changes. Given government’s role in technological development and consumer product innovation, public funding should be under democratic control. This would mean that governments have a role to play not only in the rate of technological development, but more importantly in its direction. Particularly significant here are what have been called ‘mission-oriented’ projects. These do not aim at product differentiation and marginal improvements to existing goods, but are instead concerned with large-scale inventive projects such as space travel and the internet. This is revolutionary development, aimed at creating entirely new paths of technology and open to the possibility of unexpected innovations emerging in the process. Under democratic control, it could respond to the biggest social problems of the day and foster large-scale thinking by, for instance, using state investment banks to shape the social value of projects through funding decisions. A forward-thinking government could support mission-oriented projects such as decarbonising the economy, fully automating work, expanding cheap renewable energy, exploring synthetic biology, developing cheap medicine, supporting space exploration and building artificial intelligence. The challenge is to develop institutional mechanisms that will enable popular control over the direction of technological creation.

Public control over how government funds are spent for development was also at the heart of a series of worker-based struggles in the 1970s. In now largely forgotten experiments, workers in the UK and Japan (and later across Brazil, India and Argentina) sought to channel technological development towards the production of ‘socially useful goods’. These were goods that responded to social needs and were produced in such a way as to minimise waste, be ecologically sustainable, and respect workers and their skills. The most influential of these projects occurred at Lucas Aerospace in the UK – a company that focused on producing high-tech components, predominantly for the military, and received significant government funding. Faced with rising structural unemployment and impending redundancies, workers at Lucas Aerospace came together to develop an alternative proposal for how to run the company and maintain jobs. Their basic argument was that, given the public funds being channelled into the corporation, society should have a say in, and benefit from, how these resources were being used. This was an argument that entailed channelling resources away from military armaments and into useful products. In order to develop the proposal for socially useful goods, the workers compiled a list of the skills and equipment available to them, took on the perspective of planners, sought product suggestions from workers and their communities, and collectively decided how these technologies and skills could be repurposed to different ends. Rather than high-tech military equipment, the existing capacities were to be repurposed to design and produce medical technologies, renewable energy, safety improvements, and heating technology for social housing. The final plan ran to over 1,200 pages and included detailed proposals for 150 products. In order for it to achieve its political goals against an intransigent management, the strategy undertaken was in many ways a counter-hegemonic project, with workers explicitly aiming to ‘inflame the imaginations of others’ and revise what people thought production was for.

Notably, the Lucas Plan refused to remain a temporary space of prefigurative politics, and instead aimed to mobilise the resources of unions and governments in an effort to create a new hegemonic order. In this endeavour, the plan resonated with peace activists, environmentalists, feminists and other labour movements, leading to the building of international connections and a wave of worker-led action. Ultimately, however, the stagnation of the Labour Party and national trade unions, combined with the rising turn to neoliberalism, meant that the Lucas Plan fell short of its goals. But the successes it had – slowing job losses – were largely the result of moving beyond defensive approaches and towards creating an alternative. Despite these failures, the Lucas Plan demonstrates a clear example of how repurposing the productive forces of society might be used to transform the technological direction of society. This was not an attempt simply to build a worker-controlled factory in the middle of a profit-orientated economy; more radically, it was an attempt to reorganise technological development away from marginal weapon improvements and towards socially useful goods. It is an ideal model of how technical knowledge, political awareness and collective power can be combined to achieve a radical repurposing of the material world.

An even more ambitious project of repurposing occurred in Chile in the early 1970s. The newly elected government of Salvador Allende sought to transform Chile into a socialist nation through gradualist change, implemented through the existing economic and political institutions. A crucial part of this process was the development of Cybersyn, an innovative attempt at decentralised economic planning that sought to connect firms throughout the country to government and bureaucratic functions. The project involved transforming cybernetics from what has often been excoriated as a system of control into an infrastructure of democratic socialism. The Cybersyn system was designed not for an omnipotent and external central government, but as a partial and internal modulator of ongoing economic flows. It was intended to give workers a say in the planning process and enable factories to self-manage, all while giving a rational orientation to the national economy. To achieve these goals, Cybersyn was to include a proto-internet connecting factories, an economic simulator to test out policies, a statistical forecaster to predict problems, and an operations room taken straight from science fiction. But US hostility to the country made it virtually impossible to purchase new computers, and attempted deals with France only came to fruition after Allende had been overthrown. The result was that Chile’s effort to build a cybernetic socialism largely had to repurpose existing technologies in order to stand any chance at being successful. It was a sort of bricolage approach, using what was available and cobbling together something new. At the time, Chile possessed only four mainframe computers (only one of which was available to Cybersyn) and fifty computers around the nation – so the proto-internet was pared down, and based instead on more widely available telex machines. The ambition for a system of democratic, worker-managed enterprises was ultimately cut short by the US-backed coup that ended Allende’s regime in 1973. But while the project was never fully realised, parts of Cybersyn nevertheless demonstrated their potential in one notable experience. Faced with rising opposition from the economic elite, in 1972 the government had to deal with a strike by over 40,000 truck owners. The petite bourgeoisie sought to undermine the government by preventing shipping of essential materials for factory production. But workers took over factories and continued to drive trucks wherever possible, while the national government deployed the telex network of Cybersyn in order to coordinate around the blockades and the strike. Effectively, as the preeminent historian of Cybersyn writes, ‘the network offered a communications infrastructure to link the revolution from above, led by Allende, to the revolution from below, led by Chilean workers and members of grassroots organisations’. In other words, the strike showed the potential of Cybersyn for repurposing the infrastructure of society towards democratic and socialist ends. It enabled a historically unique and promising vision of what an alternative future might have looked like. In the end, therefore, the experiment provides an imaginative and utopian example of the repurposing of cybernetic principles, existing Chilean technology and cutting-edge software.

While the previous examples suggest how repurposing could be the focus of immediate political projects, more speculative propositions can also be imagined for a postcapitalist future. As a central source of productivity and the expansion of our capacities to act, technological innovations form an essential part of any mode of production beyond capitalism. A new world will have to be built, not on the ruins of the old, but on the most advanced elements of the present. Today we see the occluded potentials of this approach everywhere, in the fact that the technologies for achieving classic leftist goals (reduced work, increased abundance, greater democratic control) are more available than ever before. The problem is that they remain encased within social relations that obscure these potentials and render them impotent. In this context, the demand to reflect upon and repurpose technologies operates to reignite a utopian imagination in the heart of a stale capitalism. An entire array of possibilities already exists. The last chapter examined automation technologies as a key hinge between capitalism and postcapitalism, but repurposing extends much further than just the automation of the productive forces. Similar arguments have been mobilised around logistics networks, around repurposing cities for ecological reasons and around deploying the latest computing technology for postcapitalist ends. Pinpointing these sorts of technologies can help to focus energy on political struggles over their development and use. Logistics provides a particularly significant example, insofar as it simultaneously exploits wage differentials, enables global production and is at the leading edge of automation. Without denying the significance of logistics to the project of exploiting cheap labour across the world, it is possible to see that logistics would be useful to postcapitalism in a variety of ways. Its uses, in other words, go far beyond just capitalist ones. First, any postcapitalist economy will require flexibility in both production (for example, additive manufacturing) and distribution (for example, just-in-time logistics). This enables an economy to be responsive to changes in individual consumption, unlike the grand and inflexible planning efforts of the Soviet era. Without these technologies, postcapitalism would risk repeating all the economic problems already seen in the first communist experiment. Second, global logistics makes possible the use of a wide array of comparative advantages – not simply wage differentials. To cite one example: research has found that it is more environmentally friendly for certain agricultural goods to be produced in New Zealand and shipped to the UK, as opposed to being produced and consumed in the UK. Even after being shipped across the world, they still have a smaller carbon footprint. The simple reason for this is that reproducing the appropriate climate in the UK would involve intense energy consumption. Such environmental comparative advantages only exist where there is an efficient and global logistics network. Finally, logistics is at the forefront of the automation of work, and therefore represents a prime example of what a postcapitalist world might look like: machines humming along and handling the difficult labour that humans would otherwise be forced to do. It is worth recalling that before the logistics revolution, transporting goods was a physically demolishing task for the bodies of workers. The automation of this labour is something to be applauded, not held back for parochial reasons. For all these reasons, logistics therefore presents an important transition technology between capitalism and postcapitalism.

But there are important limits to repurposing. The Soviets, for example, believed that capitalist technologies and techniques could simply be taken over and turned towards communist ends, but these technologies were biased towards maximal efficiency and rigorous control by management. Given their wholesale adoption of capitalist machinery and management techniques, it was no surprise that the system tended towards capitalist modes of operation. Workers became – once again – mere cogs in the machine, deprived of autonomy and coerced into working harder. The ambitious plan to conquer the capitalist means of production ran aground on the reality that power relationships are embedded within technologies, which cannot therefore be infinitely bent towards purposes that oppose their very functioning. Numerical control technologies, for example, have been used to set the pace of production, forcing workers to keep up with a machine – rendering the power of management more indirect and invisible. In this way, machines can conceal power relations by making them appear as simple mechanical processes. Yet repurposing remains possible in spite of these limits because there is often a significant untapped reservoir of potentials lying dormant within a technology. The difficult point to understand is that, in the words of one historian, ‘Technology is neither good nor bad; nor is it neutral.’ Any given technology is political but flexible, as it always exists in excess of the purposes for which it may have been designed. Rather, the design, meaning and impact of a technology are constantly shifting, altering as users transform it and as its environment changes. Paraphrasing Spinoza, we can say that we know not what a sociotechnical body can do. Who among us fully recognises what untapped potentials await discovery in the technologies that have already been developed? What sorts of postcapitalist communities could be built upon the material we already have? Our wager is that the true transformative potentials of much of our technological and scientific research remain unexplored.

How, then, can we distinguish between technologies that are bound by their limits and technologies whose properties offer potential affordances for a postcapitalist future? There is no a priori way to determine the potentials of a technology, but we can still establish broad parameters to adjudicate on the potentials of a technology, and to apply these in thinking through the specific aspects of individual technologies. In terms of criteria, one approach is to determine what functions constitute necessary and/or exhaustive aspects of a technology. For example, if a technology’s only role is that of exploiting workers, or if such a role is absolutely necessary to its deployment, then it can have no place in a postcapitalist future. Taylorism, based necessarily on the control and heightened exploitation of workers, would be rejected according to these criteria. Nuclear weapons, requiring the capacity to inflict mass destruction, would likewise have no place in a postcapitalist world. For the most part, however, technologies will be more ambiguous than that. If technology designed to reduce skilled labour permits domination by a managerial class, it also opens up spaces for job-sharing and the reduction of work. If technology that reduces production costs reduces the percentage of people employed, it also reduces the need for people to work. If a technology that centralises decision-making over infrastructures facilitates private control, it also provides a nodal point for collective decision-making. These technologies embody both potentials at the same time, and the task of repurposing is simply one of how to alter the balance between them. One goal of any future-orientated left could be to outline these broad parameters of adjudication, and to pursue further research and analysis in determining how specific technologies can be repurposed and mobilised towards a postcapitalist project. This is particularly crucial for workers involved in the technology sector who are, through their design choices, building the terrain of future politics. Let us be clear, though: without a simultaneous shift in the hegemonic ideas of society, new technologies will continue to be developed along capitalist lines, and old technologies will remain beholden to capitalist values.

This hegemonic strategy is therefore necessary to any project to transform society and the economy. And in many senses, hegemonic politics is the antithesis to folk politics. It seeks to persuade and influence, rather than presuming spontaneous politicisation; it works on multiple scales, rather than just the tangible and local; it sets out to achieve forms of social power that are long-lasting, rather than temporary; and it operates in domains that are often not superficially ‘political’ at all, rather than focusing on the most spectacular political mediums, such as street protests. A counter-hegemonic strategy would include efforts to transform the common sense of society, revive a utopian social imagination, rethink the possibilities of economics, and eventually repurpose technological and economic infrastructures. None of these steps are sufficient, but they are examples in which concrete action can be taken to build the social and material conditions for a post-work world. They prepare the ground for a moment when transformative change can occur, backed by a mass movement. However, the strategy of counter-hegemony as it has been outlined so far remains abstract. What is needed is some sense of exactly how a counter-hegemonic strategy might gain traction in the real world. Hegemony needs to be constructed, and power needs to be built. We turn next to how such power can be constructed, and who will be building it.

A strategy may indicate the broad direction to take, but it still leaves open the question of what forces exist to carry it out. Any strategy requires an active social force, mobilised into a collective formation, acting upon the world. But while putting a counter-hegemonic strategy into practice will require the use of power, the left has been both overwhelmed by and systematically rendered averse to the use of power. The traditional agents of leftist power (the working class and its associated institutional forms) have wilted under attacks from the right and from their own stagnation. Meanwhile, chastened by the failures of previous attempts at social transformation, many have mobilised behind marginal and defensive folk-political actions. Yet building a post-work world will involve large-scale social transformation and require building capacity for the use of power. This chapter argues that, in order to install a new hegemonic order, at least three things will be required: a mass populist movement, a healthy ecosystem of organisations and an analysis of points of leverage. The questions of class unity and organisational form are subjects of perennial debate among the left. Class unity is thought to generate networks of solidarity, strength in numbers, confidence and an awareness of common interests. Likewise, organisational strength provides leadership, coordination, stability over time and the concentration of resources. Leverage points are less often discussed, but no less important. These are points of political or economic power that can be used to compel others to adapt to the interests of a particular group. The classic tactic of the strike, for instance, aims to disrupt production in order to force the owners to accede to workers’ demands. Without such leverage points, change can only come about when it is in the interests of the powerful. This chapter examines these three elements for building power and outlines some ways forward. What follows is not intended as an exhaustive or sufficient prescription for what should be done, but offers reflections on the limits of historical precedents, and an argument for the significance of the factors listed above for rebuilding the power of the left. Reconstructing this power is probably the most difficult task facing the left today, yet it is an essential task if a post-work world is to emerge from the devastation wrought by neoliberalism.

Perhaps the most important question for building power is the question of who will be the active agent of a post-work project. What social positions will find a post-work society in their interest? The most obvious answer is one we have already seen: the expanding surplus population. Indeed, as workers in developed countries fall back into precarity, and as more and more of the global population is incorporated as ‘free’ labourers under capitalism, the basic proletarian condition is coming to characterise a wider swathe of people. We are all, as Marx argued, virtual paupers. At first glance, these trends therefore seem to support a traditional Marxist narrative, whereby the working class was supposed to achieve a dominant position by incorporating ever greater numbers of people and simplifying its economic position. Condensed into increasingly large industrial factories, the working class was forecast to unite in physical terms (sharing space), in terms of its interests (reduced labour, higher wages), and eventually in terms of consciousness (becoming aware of its position as a proletariat). The deskilling of labour would eliminate hierarchies between skilled and unskilled labour, while high demand for labour would mean capital cared little about identity-based divisions (over race, gender, nationality). This did occur in some places and at some times. For instance, while the early twentieth century saw the US black working class violently excluded from white unions, after World War II these racial divisions began to break down in many areas. Distinctions based on age, sex, skill, nation and income were likewise supposed to fall aside as capitalism progressed. Perhaps most importantly, this emerging working class had strategic importance because of its access to a set of leverage points centred on production. Strikes, factory takeovers, slow-downs and similar tactics were all designed to disrupt the production process and force management and capitalists to acquiesce to working-class demands. This class – para-digmatically comprised of white, male factory workers – was therefore predicted to become large, homogeneous and powerful, making it the vanguard of a post-capitalist revolution. But this did not happen. The working class fragmented, its organisational structures fell apart, and today ‘there is no longer a class fraction that can hegemonise the class’.

Under the combined pressures of deindustrialisation, the globalisation of production, the rise of service economies, the expansion of precarity, the demise of classic Fordist footholds and the proliferation of diverse identities, the industrial working class has become severely fractured. Across the world, the traditional working class is predominantly marginal in terms of its strength (with a few exceptions in countries such as South Africa and Brazil). The Chinese labour movement has some strength, but even here the outsourcing of production to peripheral countries is already working to undermine its power. The power of the global working class is today severely compromised, and a return to past strength seems unlikely. As it stands today, the classical revolutionary subject therefore no longer exists; there is only a diverse array of partly overlapping interests and divergent experiences. However, we might question the idea that the industrial working class was ever in a position to transform the world – today’s situation is not so different from the early years of the labour movement. First, the image of worker unity has always been more of an aspirational vision than an achieved reality. From its origins, the proletariat was riven by divisions – between the waged male worker and the unwaged female labourer, between the ‘free’ worker and the unfree slave, between skilled craftsmen and unskilled labourers, between the core and periphery, and between nation-states. The tendency to unify was always a limited phenomenon, and these differences persist today, exacerbated under conditions of a globalised division of labour. Perhaps more fundamentally, if deindustrialisation (the automation of manufacturing) is a necessary stage along the path towards a postcapitalist society, then the industrial working class could never have been the agent of change. Its existence was predicated upon economic conditions that would have to be eliminated in the transition to postcapitalism. If deindustrialisation is required for the transition to postcapitalism, then the industrial working class was inevitably going to lose its power in the process – fragmenting and falling apart, just as we have seen in recent decades.

Who, then, can be the transformative subject today? Despite the growing size of the surplus population and common immiseration of the proletariat, we must accept that no answer readily presents itself. The breakdown of lines between employed and unemployed, formal and informal, coincides with the decline in a coherent transformative agent. The fragmentation of traditional groups of resistance and revolt and the generalised decomposition of the working class means that the task today must be to knit together a new collective ‘we’. There is no pre-existing group that would embody universal interests or constitute the necessary vanguard of this transformative project – not the industrial worker, not the intellectual labourer and not the lumpenproletariat. How, then, to compose a people in light of the fragmentation of the proletariat? In practice, there are a variety of ways to organise such a convergence. As we saw, the classic Marxist approach presupposed that the tendencies of capitalism would heighten the division between classes and lead to the unity of the proletariat. Others have argued for a unity on the basis of generic common interests – biological need, for instance – but minimal commonalities tend to lead to minimal demands. By contrast, in the Occupy movements, unity often emerged out of physical proximity – bodies working and living together in camps. Yet such unity often papered over real differences, making it nothing more than a fragile façade. When the physical proximity was destroyed in the dismantling of occupied spaces, unity rapidly collapsed. With the Arab Spring, meanwhile, unity was forged through opposition to shared tyrannical opponents, bringing together a disparate series of groups. However, these recent experiences demonstrate that a unity built solely upon opposition tends to break down when the opponent falls.

The problem for a post-work project is that, despite the underlying commonality of proletarian existence, this provides only a minimal cohesion, which can support a vast range of divergent experiences and interests. The challenge facing a transformative politics is to articulate this series of differences into a common project – without simply asserting that class struggle is the only real struggle. Under these conditions, it is no surprise to see that many of the most promising political struggles in recent years have identified themselves as populist movements rather than class movements. By ‘populism’, we do not mean a sort of mindless mass movement, or a lowest-common-denominator revolt, or a movement with any particular political content. Populism is instead a type of political logic by which a collection of different identities are knitted together against a common opponent and in search of a new world. From the anti-globalisation movements, to Syriza in Greece, Podemos in Spain, numerous Latin American movements, and Occupy across the Western world, these movements have mobilised large cross-sections of society rather than just particular class identities.

These populist movements have originated out of the frustration of unmet demands. Under normal democratic circumstances, demands are dealt with separately and within existing institutions – for instance, minimum wage increases, unemployment benefits and healthcare provision. Small changes are granted, but institutional arrangements, including society as a whole, are never questioned. In this fashion, existing hegemonies can be reinforced and threats generally modulated effectively. By contrast, a populist movement begins to emerge when these demands – for fair pay, social housing, childcare, and so on – are increasingly blocked. As the leading thinker on political populism, Ernesto Laclau, explains:

Once we move beyond a certain point, what were requests within institutions became claims addressed to institutions, and at some stage they became claims against the institutional order. When this process has overflown the institutional apparatuses beyond a certain limit, we start having the people of populism.

Particular interests become increasingly general in this process, and populism emerges, set resolutely against the existing order. The ‘people’, unlike traditional class groupings, are held together by a nominal unity even in the absence of any conceptual unity. The people is a complex, contested and constructed actor. They name themselves as a coherent group, rather than having any necessary unity of material interests. This helps to explain why, for instance, it was so difficult to pin down the politics of the Occupy movement. The 99 per cent was held together more by a name than by any common politics. This nominal unity is complemented by populism naming the fracture in society and the opposition against which they set themselves. In naming an enemy, it becomes possible for a wide range of people to see their interests and demands expressed by the movement. Occupy, for example, named the 1 per cent, Podemos named ‘the caste’, and Syriza named the Troika. As with the naming of the people, the naming of the antagonism has some attachment to empirical facts, but need not be bound by them. The division that Occupy posited between the 1 per cent and the 99 per cent, for instance, is an antagonism that mobilised people despite its lack of empirical accuracy. The naming of the people and their opposition is a political act, not a scientific statement. Both the people and the antagonism in society are therefore constituted through an act of nomination. This represents a response to the impossibility of simply reading off the antagonism of society from brute historical necessity, in an era where class identities have fragmented and differences proliferated.

In order for the ‘people’ of populism to emerge, however, additional elements are necessary. First, one particular demand or struggle must come to stand in for the rest. The Occupy movement, for example, mobilised a range of local, regional and national grievances that became knotted together under the struggle against inequality. In such cases, it is not a particular group which seeks recognition from society, but rather a particular group which comes to speak universally for society. In order to do so, however, it must be seen to embody multiple interests. It must stand not only for its own self-interest but come to actually reflect a broad array of interests. For a traditional working-class movement, common interests would be sufficient to secure the allegiance of all. But in a populist movement, the absence of an immediate unity based on material interests means its coherence is perpetually plagued by a tension between the struggle that has come to stand in for the rest and those other struggles. Populism thus involves a continual negotiation of differences and particularisms, seeking to establish a common language and programme in spite of any centrifugal forces. The difference between a populist movement and folk-political approaches lies in this stance towards differences: whereas the former seeks to build a common language and project, the latter prefers differences to express themselves as differences and to avoid any universalising function. The mobilisation of a populist movement around anti-work politics would require articulating a populism in such a way that a variety of struggles for social justice and human emancipation could see their interests being expressed in the movement. Importantly, anti-work politics provides such resources: for example, it is perhaps the best option for a red-green coalition, insofar as it overcomes the tensions between an economic programme of jobs and growth and an environmental programme of decreased carbon emissions. The post-work project is also an inherently feminist one, recognising the invisible labour carried out predominantly by women, as well as the feminisation of the labour market, and the necessity of providing financial independence for women’s full liberation. Equally, it links up with anti-racist struggles, insofar as black and other minority populations are disproportionately affected by high unemployment and the mass incarceration and police brutality associated with jobless communities. Finally, the post-work project builds upon postcolonial and indigenous struggles with the aim of providing a means of subsistence for the massive informal labour force, as well as mobilising against barriers to immigration.

Articulating the character of a movement that can bring together such differences helps to emphasise the importance of demands to any proper populism. Demands form a key medium for building unity, and must therefore connect in multiple ways with different people. Such demands do not presume to know in advance who will be called into action by them, but they allow people to see their own particular interests within them while nevertheless maintaining their differences from each other. For example, the demands of an anti-work politics have different meanings for a university student, a single mother, an industrial worker, and those outside the labour force; but in spite of these differences, each of them can find their own interests represented in the call for a post-work society. Mobilising these people together and under the name of a demand then becomes the work of on-the-ground politics. A movement predicated on a populist logic can therefore give consistency to a series of diffuse grievances and requests, without necessarily negating differences. Particular demands are inscribed into a coherent narrative articulating how various demands share a common antagonist. This is why a vision of the future is essential to a proper populism, and it is what many recent populist movements have lacked. Occupy, for instance, never translated the negative moment of insubordination into a positive political project around which the people could be organised. It never combined diverse interests into a project for a better future, remaining at the negative level of rejection and never providing an ‘autonomous focus of subjectivation’.

In the end, while the post-work project demands that centrality be given to class, it is not sufficient to mobilise only on the basis of class interests. A broad spectrum of society needs to be brought together as an active and transformative force. It is to this need that populism responds. Yet the negotiation of commonality at the level of slogans, demands, signs, symbols and identities cannot remain the primary level on which such politics is conducted. A populist movement also needs to act in and through a series of organisations, as well as aiming to achieve the overturning of neoliberal common sense and create a new one in its place. It must seek to build hegemonic forms of power, in all their diverse forms, both inside and outside the state.

Organisation is a key mediator between discontent and effective action – it transforms a certain quantity of people into a qualitatively different form of power. As the Occupy movement, the anti-war movement and the anti-globalisation movement have made clear, the problem with the left is not necessarily one of raw numbers. On a purely quantitative level, the left is not noticeably ‘weaker’ than the right – in terms of its ability to achieve popular mobilisation, the reverse seems to be true. Particularly in times of crisis, the left seems eminently capable of mobilising a populist movement. The problem lies in the next step: how that force is organised and deployed. For folk politics, organisation has meant a fetishistic attachment to localist and horizontalist approaches that often undermine the construction of an expansive counter-hegemonic project. Yet this organisational fetishism is one of the most detrimental aspects of recent leftist thought: the belief that if only the proper form of organisation is developed, political success will follow. Folk politics is guilty of this, but the same holds for many orthodox positions as well – the range of miracle cures advanced for the decline of the left’s power have included trade unions, vanguards, affinity groups and political parties. In most cases, these organisational forms are advocated without regard for the different strategic terrains they face. Folk politics, for example, takes a particular organisational form built under specific conditions and attempts to transpose it across the entire social and political field. Rather than a decontextualized approach to the problem of organisation, we need to think in terms of a healthy and diverse ecosystem of organisations.

The simple point to make against organisational fetishism is that a political project requires a division of labour. There are a variety of essential tasks to be carried out in a successful political movement: awareness raising, legal support, media hegemony, power analysis, policy proposals, the consolidation of class memory, and leadership, to name just a few. No single type of organisation is sufficient for performing all of these roles and bringing about large-scale political change. We therefore do not seek to promote any single organisational form as the ideal means of embodying transformational vectors. Every successful movement has been the result, not of a single organisational type, but of a broad ecology of organisations. These have operated, in a more or less coordinated way, to carry out the division of labour necessary for political change. In the process of transformation leaders will arise, but there is no vanguard party – only mobile vanguard functions. An ecology of organisations means a pluralism of forces, able to positively feedback on their comparative strengths. It requires mobilisation under a common vision of an alternative world, rather than loose and pragmatic alliances. And it entails developing an array of broadly compatible organisations:

The point is to create something more than mere alliance building (where the parts, understood as constituted groupings of people, are supposed to stay the same, only co-operating punctually) and less than a one-size-fits-all solution (e.g. the idea of the party). This is about strategic interventions that can attract both constituted groups and the ‘long tail’ that does not belong to any groups, pitched not as exclusive but as complementary, whose effects can reinforce each other.

This means that the overarching architecture of such an ecology is a relatively decentralised and networked form – but, unlike in the standard horizontalist vision, this ecology should also include hierarchical and closed groups as elements of the broader network. There is ultimately no privileged organisational form. Not all organisations need to aim for participation, openness and horizontality as their regulative ideals. The divisions between spontaneous uprisings and organisational longevity, short-term desires and long-term strategy, have split what should be a broadly consistent project for building a post-work world. Organisational diversity should be combined with broad populist unity.

A quick overview of how such an ecology might operate will offer some sense of how these proposals might work together. This can only be highly schematic, given the particularities of any given struggle and the complexity of the issues at hand. Inevitably, an ecosystem of organisations is forged in specific circumstances, with different decisions being made in the face of different political contexts. That said, a broad social movement would be essential to any anti-work politics, affording a wide range of different organisational and tactical compositions. At one end of the spectrum, there are transient bursts of political energy, in the form of riots and spontaneous protests. Urban unrest in America, for instance, was a key motivating factor behind elite support for a basic income in the 1960s. Such eruptions may not make intricate demands, but they demand a response. In slightly more organised modes, social movements take on the folk-political approaches seen in recent decades. Operating under principles of direct democracy can be conducive to certain objectives, such as giving people a voice, creating a powerful sense of collective agency and enabling different perspectives to be articulated. It can foster the creation of a populist identity and empower people to start to see themselves as a collective. But what these folk-political organisations lacked was the strategic perspective to transform spectacular scenes of protest and broad populist movements into effective long-term action. It is often the ability of other, more long-term institutionalised organisations to hegemonise around the demands, tactics and strategies of relatively ephemeral movements that determines the ultimate effect of their protests. The most successful occupation movements in recent years have been those that have fostered ties to labour movements (in Egypt, for example) and/or to political parties. In Iceland, for instance, the greatest protest successes were achieved when a red-green coalition was voted in after forcing the conservative administration out; as we write, Spain is showing the potential that arises when social movements engage in a dual strategy both within and outside the party system. If a major social transformation such as the post-work project is to occur, it will come on the back of a mass movement rather than simply decreed from on high. Populist movements on the street will be one of its essential elements.

It has already been hinted at in earlier chapters, but media organisations are an essential part of any emergent political ecology aimed at building a new hegemony. The tasks involved in such a strategy demand a healthy media presence – creating a new common language, giving voice to the people, naming the antagonism, raising expectations, generating narratives that resonate with people and articulating in clear language the grievances we feel. It is these elements that provide the anchors for media narratives to be changed over time. Foundations and journalists are particularly well placed to make efforts at changing media narratives. It was no accident that the Mont Pelerin Society included numerous journalists among its members. This communication also has to be achieved in a way that resonates with everyday conversation. The jargon of academics is rightly deemed useless by most people. Leftist media organisations should not shy away from being approachable and entertaining, gleaning insights from the success of popular websites. At the same time, the left has typically focused on creating media spaces outside the mainstream, rather than trying to co-opt existing institutions and leaking more radical ideas into the mainstream. Too often, these news organisations end up simply preaching to the choir, pushing narratives that never escape their own insular echo-chamber. The internet has enabled everyone to have a voice, but it has not enabled everyone to have an audience. Mainstream media sources remain indispensable for this and will continue to do so in the future. Their ability to influence and alter public opinion through framing what is and is not ‘realistic’ remains surprisingly strong. If a counter-hegemonic project is to be successful, it will require an injection of radical ideas into the mainstream, and not just the building of increasingly fragmented audiences outside it. Indeed, one of the key lessons from the US experience with a basic income policy is that the framing of such issues in the media is central to its prospects of success. It is for these reasons that existing media organisations constitute a key battleground in the project set out here.

Alongside the media, intellectual organisations are indispensable components of any political ecology. These extend from bodies like think tanks, to captive university departments and other educational institutions, through to more loosely organised training and consciousness-raising bodies. But building hegemony does not necessarily mean sending down decrees from vanguard intellectual organisations. It is no accident that it is Gramsci, the key thinker of hegemony, who also struck upon the idea of the ‘organic intellectual’ – the intellectual closely linked to and emerging from key material and economic forces within society. Organic intellectuals are participants in practical life, organisers and constructors. A properly functioning leftist intellectual infrastructure would operate to support those institutions identified as broadly in line with their own worldviews by participating in them, spreading their work and, where possible, providing resources. In a world of complexity, no one has a privileged view of the totality, and thus a healthy intellectual sphere will involve intellectuals with multiple perspectives. This will combine with on-the-ground inquiries carried out by workers – examining, for instance, the way in which retail logistics function and the potentials for their disruption, or the detailed analysis of local power networks as a means to bring about change. In addition to that of organic intellectuals, certain kinds of valuable work can only be carried out in specialist bodies that are able to retain a certain distance from the hurly-burly of everyday politics. As the Mont Pelerin Society understood, some intellectual efforts need to be devoted less to immediate and pressing concerns, and more to the development of long-term proposals. These would include such vital endeavours as the development of new ways of organising and understanding the economy, which requires highly technical knowledge and long-term research. But such work always needs to be fed back into the networks of political actors and social narratives to gain its full effect.

Labour organisations have traditionally been significant forces of social transformation, but today they find themselves on the back foot. At the same time, deeply entrenched habits and inflexible – if not outright corrupt – union leaderships have made the revitalisation of these organisations an uphill battle. Yet they remain indispensable to the transformation of capitalism, and any effort to imagine a new union structure must learn lessons from both the failures of older models and the changing economic conditions facing them today. These include basic things such as enriching the connection between leadership and members, building support across traditional sectoral boundaries (academics supporting cleaners in a university, for example), learning from innovative and often worker-led unions (those around immigrant labourers, for example), radicalising existing unions and building new unions in areas devoid of this organisational lever. In broad terms, the adequacy of a union depends on the alignment of its political form with economic and infrastructural conditions. As we saw in earlier chapters, these conditions are currently defined by the emerging crisis of work. The rise of surplus populations, the return of precarity, the stagnation of wages and the painfully slow recovery of employment all present key challenges for the traditional model of trade unionism. As the work–life distinction breaks down, job security dwindles and rising personal debt lurks in the background, issues around work have effects far beyond the workplace. These shifting social conditions alter the relationship between the union, its members and the wider community. This requires, first of all, a recognition of the social nature of struggle, and the bridging of the gap between the workplace and the community. Problems at work spill over into the home and the community, and vice versa. At the same time, crucial support for union action comes from the community, and unions would be best served by recognising their indebtedness to the invisible labour of those outside the workplace. These include not only domestic labourers, who reproduce the living conditions of waged workers, but also immigrant workers, precarious workers and the broad array of those in surplus populations who share in the miseries of capitalism. The focus of unions therefore needs to expand beyond supporting only dues-paying members. To be sure, there is a history of worker organisations establishing such connections with the broader community, but today this needs to be made an increasingly explicit goal of union organising. This process can work both ways. For instance, France has seen ‘proxy strikes’ in which workers declare themselves not to be on strike (and therefore continue to get paid), yet allow people to blockade or occupy their workplace. In addition, workers’ movements have always relied upon the local community for moral and logistical support, and if solidarity is built up, communities will come out to defend workers against state repression. Unions can involve themselves in community issues like housing, demonstrating the value of organised labour in the process. Rather than being built solely around workplaces, unions would therefore be more adequate to today’s conditions if they organised around regional spaces and communities.

In expanding the spatial focus of union organising, local workplace demands open up into a broader range of social demands. As we argued in Chapter 7, this involves questioning the Fordist infatuation with permanent jobs and social democracy, and the traditional union focus on wages and job preservation. An assessment must be made of the viability of these classic demands in the face of automation, rising precarity and expanding unemployment. We believe many unions will be better served by refocusing towards a post-work society and the liberating aspects of a reduced working week, job sharing and a basic income. The West Coast longshoremen in the United States represent one successful example of allowing automation in exchange for guaranteeing higher wages and less job cuts (though they also occupy a key point of leverage in the capitalist infrastructure). The Chicago Teachers’ Union offers another example of a union going far beyond collective bargaining, and instead mobilising a broad social movement around the state of education in general. Moreover, shifting in a post-work direction overcomes some of the key impasses between ecological movements and organised labour. The deployment of productivity increases for more free time, rather than increased jobs and output, can bring these groups together. Changing the aims of unions and organising community-wide will help to turn unions away from classic – and now failing – social democratic goals, and will be essential to any successful renewal of the labour movement.

Lastly, the state remains a site of struggle, and political parties will have a role in any ecology of organisations – particularly if the traditional social democratic parties continue to collapse and enable a new generation of parties to emerge. Ensuring a post-work society for all will require more than just individual workplaces; it demands success at the level of the state as well. While parties are frequently denounced for their cynical consent to electoralism and the limits posed by international capital, this changes within an ecology of organisations. Rather than making them the impossible vehicle of revolutionary desires – associated with the hopeless prospect of ‘voting in’ postcapitalism – they can instead take on the more realistic task of forming the ‘tip of the iceberg’ in terms of political pressure, as well as developing the ability to bring together a widely varied constituency. The state can complement politics on the street and in the workplace, just as the latter two can broaden the options for parties. The avoidance of the state – common to so many folk-political approaches – is a mistake. Mass movements and parties should be seen as tools of the same populist movement, each capable of achieving different things. At their most general level, parties can integrate various tendencies within a social movement – from reformist to revolutionary – into a common project. While international capital and the inter-state system make radical change virtually impossible from within the state, there are still basic and important policy choices to be made about austerity, housing support, climate change, childcare, demilitarisation of the police and abortion rights. Simply to reject parliamentary politics is to ignore the real advances these policies can make. It takes quite a privileged position to not care about minimum wage regulations, immigration laws, changes to legal support or rulings on abortion. At their best, electoral entities can act as a disruptive force (stalling, publicising controversies, articulating popular outrage), and even act as a progressive force in some situations. This does not imply that social movements should simply be turned into the vote-mobilising wings of political parties. The relationship between parties and social movements should extend far beyond this, into a process of two-way communication. On the one hand, financial support can be given from the party to community initiatives, and various policies – such as laws on public protest – can be amended to facilitate the activities of social movements. In Venezuela, for instance, the state supported the creation of neighbourhood communes as a way to embed socialism in everyday practices. On the other hand, resources for new parties can be mobilised collectively – Podemos, for example, got started through crowd-funding €150,000 – and the vitality of the party can be maintained through constant institutionalised negotiations between local movements, party members and central party structures.

Podemos, for instance, has aimed to build mechanisms for popular governance while also seeking a way into established institutions. It is a multi-pronged approach to social change and offers greater potential for real transformation than either option on its own. Meanwhile, Brazil’s Partido dos Trabalhadores has maintained openness to multiple groups (liberation theology groups, peasant movements) while still organising around an essentially union-based core. In the words of one researcher, ‘this combination of grassroots and vanguard constituted a Leninism that was not very Leninist’. What all these experiences show, however, is the mass mobilisation of the people is necessary in order to transform the state into a meaningful tool of their interests, and to overcome the blunt division between the power of movements and the power of the state. The aim must be to avoid both ‘the tendency to fetishise the state, official power, and its institutions and the opposing tendency to fetishise antipower’. In a context of widespread discontent with the political system, this remains possible – though, again, the importance of having a discursive framework in place to channel this discontent is obvious. In the end, parties still hold significant political power, and the struggle over their future should certainly not be abandoned to reactionary forces.

It should be clear how far away we now are from the folk-political fetishism of localism, horizontalism and direct democracy. An ecology of organisations does not deny that such organisational forms may have a role, but it rejects the idea that they are sufficient. This is doubly true for a counter-hegemonic project that requires the toppling of neoliberal common sense. What we are calling for, therefore, is a functional complementarity between organisations, rather than the fetishising of specific organisations or organisational forms.

If a populist movement successfully built a counter-hegemonic ecosystem of organisations, in order to become effective it would still require the capacity to disrupt. Even with a healthy organisational ecology and a mass unified movement, change is impossible without opportunities to leverage the movement’s power. Historically speaking, many of the most significant advances made by the labour movement were achieved by workers in key strategic locations. Regardless of whether they had widespread solidarity, high levels of class consciousness or an optimal organisational form, they achieved success by being able to insert themselves into and against the flow of capitalist accumulation. In fact, the best predictor of worker militancy and successful class struggle may be the workers’ structural position in the economy.

For example, within the early logistics infrastructure, dockworkers found themselves occupying a key point in the circulation of capital. Intermodal transport – the transferring of goods between ships, trains and trucks – was labour-intensive and costly. Lodged in a key passage through which goods had to circulate, the longshoremen who carried out the work controlled a major point of leverage. The result was that dockworkers were incredibly militant and lost more work days to labour disputes than almost any other industry. The famed strength of unions like the United Automobile Workers also arose from their structural position in the production process and the importance of the car industry to the national economy. Their power emerged, moreover, in a time of high unemployment and low levels of organisation – it turned out that neither a supportive labour market nor organisational strength was necessary for success. A similar point of leverage was held by coalminers. Working in mines lent itself to greater autonomy from management in an environment where work stoppages were particularly potent. The consequence was that ‘their position and concentration gave them opportunities, at certain moments, to forge a new kind of political power’. The same holds for mining today, which is resistant to the threat of capital flight, since the resource supply is itself immobile. The mining areas of South Africa present a contemporary example, revealing both the potency of the unions and the violence of capital. When miners went on a wildcat strike in 2012, the state was called in and over thirty workers were killed in the Marikana massacre. Less violent, but no less significant, is the monopoly position of certain suppliers. Strikes at these points, such as in the Pou Chen Group in China, pose a real threat to capitalist interests by blocking off an entire supply chain. At the other end of that chain, retail distribution is also primed for significant militant action, providing rich opportunities for the disruption of contemporary capitalism’s reliance on just-in-time logistics. The significance of such points of leverage can hardly be overestimated.

But the past century has seen the conscious and unconscious winnowing away of these points of leverage. The development of shipping containers enabled the automation of intermodal transport; the globalisation of logistics facilitated capital’s ability to move factories in response to strikes; and the shift to oil as the primary energy source drastically reduced the number of choke-points available for political action. Today, the classic points of leverage have largely disappeared, necessitating a new round of experimentation and strategic reflection. Experimentation is necessary precisely because politics is a set of dynamic systems, driven by conflict, and by adaptations and counter-adaptations, leading to tactical arms races. This means that any one type of political action is highly likely to become ineffective over time, as its opponents learn and adapt. Thus, no given mode of political action is historically inviolable. Indeed, over time, there has been an increasing need to discard familiar tactics as the forces they are marshalled against learn to defend against and counter-attack them more effectively. Secrecy is met by undercover infiltrators; the use of masks is met by new legislation against it; kettling is met by apps that track police movements; the recording of police violence is met by its criminalisation; mass protest is met by heavy regulation that renders it boring and sterile; non-violent civil disobedience is met by violent police brutality. Political tactics are a dynamic field of forces, and experimentation is essential in working around new state and corporate impediments to change.

The history of the labour movement provides an exemplary picture of such an approach. One of its primary tactics has been to limit the supply of labour, thereby making it more powerful and valuable. Early efforts towards this end often operated by withholding the training for particular jobs by discriminating on the basis of skills, gender and race. Early typesetters, for example, organised to protect a male-centred skilled workforce against the threatened introduction of relatively unskilled female labourers. However, deskilling by capital and the industrialisation of production made it possible to undermine many of the skilled labour unions and opened up the labour supply to a much wider extent. The result was the breakdown of many traditional craft unions that were based around particular skill sets, with the emergence instead of industrial unions organising both skilled and unskilled workers along industry lines. Another possible tactic for reducing the labour supply is one that we examined earlier: moving towards the reduction of working hours. This produces a reduction of the labour supply, as was achieved by the exclusionary unions above, but with an important difference. Rather than relying on excluding particular groups from skilled trades, the tactic of reducing working hours relies on withdrawing a portion of everyone’s labour time. For various reasons, though – not least because of the postwar consensus between capital and labour – this tactic fell out of favour, and the labour movement’s attention instead turned towards collective bargaining over pay. As we argued earlier, however, this tactic has the potential to be revived in the effort to transform our socioeconomic system. Another key tactic has been strikes, whose logic is to inflict costs on capital and force its hand in negotiations. But this approach was limited by the fact that unskilled labour could be easily replaced with new (and more docile) scab workers. Strikes also allow employers to use the downtime to bring in new machinery – precisely the changes which workers may be struggling against. As a response, a new tactic of sit-down strikes and factory occupations emerged in the early twentieth century – making it impossible for replacement workers to operate and threatening to demonstrate that management was superfluous. What we see here is a dynamic arms race occurring between opponents as each seeks to leverage new tactics and technologies for its own purposes.

Today, the terrain of these struggles is again changing, indicated by at least two broad and emerging problems with classic workplace disruption. In the first place, there is the tendency towards automation. Just as the automation of logistics took away some of the leverage points occupied by dockworkers, so too does the automation of factories, transportation, and eventually service work portend a significant decline in the potential for workplace struggles. The emergence of self-driving vehicles, for instance, will rapidly diminish the points of leverage contained within transportation systems. The National Union of Rail, Maritime and Transport Workers in the UK will have to face this problem directly in the near future, with self-driving trains already in operation and further expansion planned. The mayor of London, Boris Johnson, has explicitly stated that automation should be used to destroy one of the few remaining militant British unions. Crucially, however, leverage points remain, and new ones will emerge in the wake of restructuring and automation. For instance, as one author pointed out – in 1957! – ‘a strike by a very small number of workers is liable to hold up an entire automated factory’. A decline in the number of workers overseeing a process also means a concentration of potential power within a smaller group of individuals. Likewise, while an automated transport system may not be subject to driver strikes, it may be open to strikes by programmers and IT technicians, as well as being more susceptible to blockades, because of the technical limitations of self-driving cars. These vehicles function by reducing environmental variation, making them ‘more akin to a train running on invisible tracks’. The intentional manipulation of the environment is therefore likely to be particularly disruptive. Equally, the use of pattern recognition algorithms in various tasks (e.g., diagnostics, emotion- and face-detection, surveillance) is highly susceptible to disruption. A technical understanding of machines like these is essential to understanding how to interrupt them, and any future left must be as technically fluent as it is politically fluent. In the end, what is required is an analysis of the automation trends that are restructuring production and circulation, and a strategic understanding of where new points of leverage might develop.

The second related limitation of classic disruptive tactics is that they might falter in the face of mass unemployment and struggles organised around surplus populations rather than the working class. If there is no workplace to disrupt, what can be done? Again, the repertoires of contention were transformed in response to changing social, political, technological and economic conditions. As precarity, zero-hour contracts, temporary work and internships spread throughout society, movements of the unemployed and movements based around social reproduction offer important and instructive examples of resistance. These struggles have never had a workplace to disrupt, so they have always had to invent new means of leveraging power. It is one of the myopias of many on the left to only see workers’ power coming from disrupting production, when in fact contesting the existing order has taken numerous forms outside the workplace. In Argentina, for instance, unemployed workers’ movements blockaded major streets in order to make themselves heard and were central to the overthrow of the government. Expelled from the wage, shorn of a workplace, blockading urban arteries becomes a primary means of exerting political power. The surge in freeway blockades in the wake of the August 2014 police killing of Michael Brown in Ferguson, Missouri, demonstrates the increasing prevalence of this type of struggle. Similar tactics take on other aspects of capitalist reproduction with the same basic objective, including rent strikes and debt strikes. Port blockades also have potential as a tactic, and computer modelling can offer insights into how to avoid scattershot and ineffective political action. These new tactics must, of course, be situated within a larger strategic plan, or risk becoming so many temporary movements that erupt only to disappear without a trace.

The classic basis of power for the labour movement, then, has been diffused and weakened. Yet this need not herald the death-knell of class struggle. Automation and precarity may spell the decline of interruptions at points of production, but they do not mean the end of disruption in total. Just as traditional points of leverage have been effaced in the context of a flexible, global infrastructure, this shift has also increased the vulnerability of that infrastructure in other ways. Well-positioned local struggles can immediately become global. The task before us must be to have a sober reckoning with changed material realities and to strategise over new spaces for action. There are precedents and lessons to be learned in existing practices like the ‘power structure analysis’ undertaken by unions and community organisers, which maps local social networks and key actors, determining their weaknesses, strengths, allies and enemies. The argument we are making here is for the construction of a complement to this process, emphasising the material conditions of struggle rather than just its social networks. In either approach, though, on-the-ground knowledge must be linked up with more abstract knowledge of changing economic conditions.

A post-work world will not emerge out of the benevolence of capitalists, the inevitable tendencies of the economy or the necessity of crisis. As this and the previous chapter have argued, the power of the left – broadly construed – needs to be rebuilt before a post-work society can become a meaningful strategic option. This will involve a broad counter-hegemonic project that seeks to overturn neoliberal common sense and to rearticulate new understandings of ‘modernisation’, ‘work’ and ‘freedom’. This will necessarily be a populist project that mobilises a broad swathe of society and that, while being anchored in class interests, nevertheless remains irreducible to them. It will involve a full-spectrum approach to organisations that seeks to use different organisational advantages in combination – not according to a pragmatism of loose alliances, but under the aegis of a vision for a better world. And these organisations and masses will have to identify and secure new points of leverage in the circuits of capitalism, with its increasingly barren workplaces. In the face of a globalised capitalism that is always on the move, opposition to it must pre-empt the transformations of tomorrow in a supple politics of anticipation.

Where, then, do we stand? The latest cycle of struggles has been exhausted, undone by their tendencies towards folk politics, and everywhere today mass outrage combines with mass impotence. We have argued that the most promising way forward lies in reclaiming modernity and attacking the neoliberal common sense that conditions everything from the most esoteric policy discussions to the most vivid emotional states. This counter-hegemonic project can only be achieved by imagining better worlds – and in moving beyond defensive struggles. We have outlined one possible project, in the form of a post-work politics that frees us to create our own lives and communities. Triumph in the political battles to achieve it will require organising a broadly populist left, building the organisational ecosystem necessary for a full-spectrum politics on multiple fronts, and leveraging key points of power wherever possible.

Yet the end of work would not be the end of history. Building a platform for a post-work society would be an immense accomplishment, but it would still only be a beginning. This is why conceiving of left politics as a politics of modernity is so crucial: because it requires that we not confuse a post-work society – or indeed any society – with the end of history. Universalism always undoes itself, possessing its own resources for an immanent critique that insists and expands upon its ideals. No particular social formation is sufficient to satisfy its conceptual and political demands. Equally, synthetic freedom compels us to reject contentment with the existing horizon of possibilities. To be satisfied with post-work would risk leaving intact the racial, gendered, colonial and ecological divisions that continue to structure our world. While such asymmetries of power would hopefully be unsettled by a post-work world, the efforts to eliminate them would undoubtedly need to continue. Further, we would still be seeking a systemic replacement for markets and facing the task of building new political institutions. We would still not know what a sociotechnical body can do, and we would still have to unfetter technological development and unleash new freedoms. Transcending our reliance on waged labour is important, but we would still be faced with the immense tasks of undoing other political, economic, social, physical and biological constraints. A project towards a post-work world is necessary but insufficient.

Yet a post-work platform does provide us with a new equilibrium to aim at, completing the shift from social democracy to neoliberalism to a new post-work hegemony. We believe it focuses the tasks of the present and provides a stable point from which to seek out further emancipatory gains. As with any platform, those who create it cannot fully predict how it will be used. While certain constraints and opportunities are built into a platform, they do not exhaustively determine the ways of life it will enable. A platform leaves the future open, rather than presuming to close it. When it is designed correctly, it succeeds precisely by allowing people to build further developments on top of it. With a post-work platform, people may begin to participate more in political processes, or perhaps they will retreat into individualised worlds formed by media spectacles. But there are reasons for hope, given the shift in work ethic required for a post-work society. Such a project demands a subjective transformation in the process – it potentiates the conditions for a broader transformation from the selfish individuals formed by capitalism to communal and creative forms of social expression liberated by the end of work. Humanity has for too long been shaped by capitalist impulses, and a post-work world portends a future in which these constraints have been significantly loosened. This does not mean that a post-work society would simply be a realm of play. Rather, in such a society, the labour that remains will no longer be imposed upon us by an external force – by an employer or by the imperatives of survival. Work will become driven by our own desires, instead of by demands from outside. Against the austerity of conservative forces, and the austere life promised by anti-modernists, the demand for a post-work world revels in the liberation of desire, abundance and freedom.

Such a future is undoubtedly risky, but so is any project to build a better world. There are no guarantees that things will work out as expected: a post-work world may generate immanent dynamics towards the rapid dissolution of capitalism, or the forces of reaction may co-opt the liberated desires under a new system of control. Concerns about the risks of political action have led parts of the contemporary left into a situation where they desire novelty, but a novelty without risk. Generic demands to experiment, create and prefigure are commonplace, but concrete proposals are all too often met with a wave of criticism outlining every possible point at which things might go wrong. In light of this dual tendency – for novelty, but against the risks inherent in social transformation – the allure of political ideas celebrating spontaneous ‘events’ becomes clearer. The event (as revolutionary rupture) becomes an expression of the desire for novelty without responsibility. The messianic event promises to shatter our stagnant world and bring us to a new stage of history, conveniently voided of the difficult work that is politics. The hard task ahead is to build new worlds while acknowledging that they will create novel problems. The best utopias are always riven by discord.

This imperative runs in opposition to the kind of precautionary principle that seeks to eliminate the contingency and risk involved in making decisions. On strong readings, the precautionary principle aims to convert epistemic uncertainty into a guardianship of the status quo, gently turning away those who would seek to build a better future with the imperative to ‘do more research’. We might also consider here that the precautionary principle contains an almost inherent lacuna: it ignores the risks of its own application. In seeking to err always on the side of caution, and hence of eliminating risk, it contains a blindness to the dangers of inaction and omission. While risks need to be reasonably hedged, a fuller appreciation of the travails of contingency implies that we are usually not better off taking the precautionary path. The precautionary principle is designed to close off the future and eliminate contingency, when in fact the contingency of high-risk adventures is precisely what leads to a more open future – in the words of conceptual artist Jenny Holzer, ‘You live the surprise results of old plans.’ Building the future means accepting the risk of unintended consequences and imperfect solutions. We may always be trapped, but at least we can escape into better traps.

The post-work project and, more broadly, the project of postcapitalism are progressive determinations of the commitment to universal emancipation. In practice, these projects involve ‘a controlled dissolution of market forces … and a delinking of work from income’. But the ultimate trajectory of universal emancipation is towards overcoming physical, biological, political and economic constraints. This ambition to undo constraints is one that, taken to its limits, leads inexorably towards grand and speculative frontiers. For the early Russian cosmists, even death and gravity were obstacles to be overcome through future ingenuity. In these post-planetary speculations, we see the project of human emancipation transformed into an unceasing one that winds its way along two highly intertwined paths of development: technological and human.

Technological development follows a recombinant path, bringing together existing ideas, technologies and technological components into new combinations. Simple objects are united into increasingly complex technological systems, and each newly developed piece of technology forms the basis for a further technology. With this expansion, the combinatorial possibilities rapidly proliferate. It would appear that capitalist competition has been a significant driver of this technological advancement. Under a popular narrative, intercapitalist competition is seen as driving technological changes in the production process, while consumer capitalism demands an increasingly differentiated set of products. But at the same time, capitalism has placed substantial obstacles in the way of technological development. While the carefully curated image of capitalism is one of dynamic risk-taking and technological innovation, this image in fact obscures the real sources of dynamism in the economy. Developments like railways, the internet, computing, supersonic flight, space travel, satellites, pharmaceuticals, voice-recognition software, nanotechnology, touch-screens and clean energy have all been nurtured and guided by states, not corporations. During the golden postwar era of research and development, two-thirds of research and development was publicly funded. Yet recent decades have seen corporate investment in high-risk technologies drastically decline. And with neoliberalism’s cutback in state expenditure, it is therefore unsurprising that technological change has diminished since the 1970s. In other words, it has been collective investment, not private investment, that has been the primary driver of technological development. High-risk inventions and new technologies are too risky for private capitalists to invest in; figures such as Steve Jobs and Elon Musk slyly obscure their parasitical reliance on state-led developments. Likewise, multi-billion-dollar megascale projects are ultimately driven by non-economic goals that exceed any cost–benefit analysis. Projects of this scale and ambition are in fact hindered by market-based constraints, since a sober analysis of their viability in capitalist terms reveals them to be profoundly underwhelming. In addition, some social benefits (those offered by an Ebola vaccine, for example) are left unexplored because they have little profit potential, while in some areas (such as solar power and electric cars) capitalists can be seen actively impeding progress, lobbying governments to end green-energy subsidies and implementing laws that obstruct further development. The entire pharmaceuticals industry provides a particularly devastating illustration of the effects of intellectual property monopolisation, while the technology industry is increasingly plagued by patent trolling. Capitalism therefore misattributes the sources of technological development, places creativity in a straitjacket of capitalist accumulation, constrains the social imagination within the parameters of cost–benefit analyses and attacks profit-destroying innovations. To unleash technological advancement, we must move beyond capitalism and liberate creativity from its current strictures. This would begin to liberate technologies away from their current purview of control and exploitation, and towards the quantitative and qualitative expansion of synthetic freedom. It would enable the utopian ambitions of megaprojects to be unleashed, invoking the classic dreams of invention and discovery. The dreams of space flight, the decarbonisation of the economy, the automation of mundane labour, the extension of human life, and so on, are all major technological projects that find themselves hampered in various ways by capitalism. The boot-strapping expansionary process of technology, once liberated from capitalist fetters, can potentiate both positive and negative freedoms. It can form the basis for a fully postcapitalist economy, enabling a shift away from scarcity, work and exploitation, and towards the full development of humanity.

Intertwined with this picture of liberated technological transformation is therefore the future of human beings. The pathway towards a postcapitalist society requires a shift away from the proletarianisation of humanity and towards a transformed and newly mutable subject. This subject cannot be determined in advance; it can only be elaborated in the unfolding of practical and conceptual ramifications. There is no ‘true’ essence to humanity that could be discovered beyond our enmeshments in technological, natural and social webs. The idea that a post-work society would simply inculcate further mindless consumption neglects humanity’s capacity for novelty and creativity, and invokes a pessimism based upon current capitalist subjectivity. Likewise, the development of new needs must be distinguished from their commodification. Whereas the latter locks new desires into a profit-seeking framework that constrains human flourishing, the former denotes a real form of progress. The ‘extension and differentiation of needs as a whole’ is to be lauded over any folk-political dream of returning to a ‘primitive natural state of these needs’. The complexification of needs is disfigured under capitalist consumer society, to be sure, but, unbound from this mutation, ‘their aim is necessarily the development of a “rich individuality” for the whole of mankind’.

The postcapitalist subject would therefore not reveal an authentic self that had been obscured by capitalist social relations, but would instead unveil the space to create new modes of being. As Marx noted, ‘all history is nothing but a continuous transformation of human nature’, and the future of humanity cannot be determined abstractly in advance: it is first of all a practical matter, to be carried out in time. Nevertheless, some general notions might be entertained. For Marx, the primary principle of postcapitalism was the ‘development of human powers which is an end in itself’. Indeed, the fundamental aim of his project was universal emancipation. The various ideas that Marxists have advanced to get there – the socialisation of production, ending the value-form, eliminating wage labour – are simply means towards achieving this end. The immediate question is: What does this aim entail? The synthetic construction of freedom is the means by which human powers are to be developed. This freedom finds many different modes of expression, including economic and political ones, experiments with sexuality and reproductive structures, and the creation of new desires, expanded aesthetic capabilities, new forms of thought and reasoning, and ultimately entirely new modes of being human. The expansion of desires, of needs, of lifestyles, of communities, of ways of being, of capacities – all are invoked by the project of universal emancipation. This is a project of opening up the future, of undertaking a labour that elaborates what it might mean to be human, of producing a utopian project for new desires, and of aligning a political project with the trajectory of an endless universalising vector. Capitalism, for all its appearances of liberation and universality, has ultimately restrained these forces in an endless cycle of accumulation, ossifying the real potentials of humanity and constricting technological development to a series of banal marginal innovations. We move faster – capitalism demands it; yet we go nowhere. Instead, we must build a world in which we can accelerate out of our stasis.

The argument of this book has been that the left can neither remain in the present nor return to the past. To construct a new and better future, we must begin taking the necessary steps to build a new kind of hegemony. This runs counter to much of our political common sense today. The tendencies towards folk politics – emphasising the local and the authentic, the temporary and the spontaneous, the autonomous and the particular – are explicable as reactions against a recent history of defeats, of partial, ambivalent victories, and of surging global complexity. But they remain radically insufficient for achieving broader victories against a planetary capitalism. Rather than seeking temporary and local relief in the various bunkers of folk politics, we must today move beyond these limits. Against ideas of resistance, withdrawal, exit or purity, the task of the left today is to engage the politics of scale and expansion, along with all the risks such a project entails. Doing so requires us to salvage the legacy of modernity and reappraise which parts of the post-Enlightenment matrix can be saved and which must be discarded; for it is only a new form of universal action that will be capable of supplanting neoliberal capitalism.

Without tabulae rasase or miraculous events, it is within the tendencies and affordances of our world today that we must locate the resources from which to build a new hegemony. While this book has focused on full automation and the end of work, there is a broad palette of political options for a contemporary left to choose from. This would mean, most immediately, rethinking classic leftist demands in light of the most advanced technologies. It would mean building upon the post-nation-state territory of ‘the stack’ – that global infrastructure that enables our digital world today. A new type of production is already visible at the leading edges of contemporary technology. Additive manufacturing and the automation of work portend the possibility of production based on flexibility, decentralisation and post-scarcity for some goods. The rapid automation of logistics presents the utopian possibility of a globally interconnected system in which parts and goods can be shipped rapidly and efficiently without human labour. Cryptocurrencies and their block-chain technology could bring forth a new money of the commons, divorced from capitalist forms.

The democratic guidance of the economy is also accelerated by emerging technologies. Famously, Oscar Wilde once said that the problem with socialism was that it took up too many evenings. Increasing economic democracy could require us to devote an overwhelming amount of time to discussions and decisions over the minutiae of everyday life. The use of computing technology is essential in avoiding this problem, both by simplifying the decisions to be made and by automating decisions collectively deemed to be irrelevant. For example, rather than deliberating over every aspect of the economy, decisions could instead be made about certain key parameters (energy input, carbon output, level of inequality, level of research investment, and so on). Social media – divorced from its drive to monetisation and tendency towards narcissism – could also foster economic democracy by bringing about a new public. New modes of deliberation and participation might emerge from a postcapitalist social media platform. And the perennial problem facing postcapitalist economies – that of how to distribute goods efficiently in the absence of market prices – can also be overcome through computers. Between the early Soviet attempts at economic planning and today, computing power has grown exponentially, to become 100 billion times more powerful. The calculation of how to distribute our main productive resources is increasingly viable. Equally, data collection on resources and preferences through ubiquitous computing means that the raw data for running an economy are more readily available than ever before. And all of this could be mobilised towards the implementation of the Lucas Plan on national and global scales – redirecting our economies towards the self-conscious production of socially useful goods like renewable energy, cheap medicine and the expansion of our synthetic freedoms.

This is what a twenty-first-century left looks like. Any movement that wishes to remain relevant and politically potent must grapple with such potentials and developments in our technological world. We must expand our collective imagination beyond what capitalism allows. Rather than settling for marginal improvements in battery life and computer power, the left should mobilise dreams of decarbonising the economy, space travel, robot economies – all the traditional touchstones of science fiction – in order to prepare for a day beyond capitalism. Neoliberalism, as secure as it may seem today, contains no guarantee of future survival. Like every social system we have ever known, it will not last forever. Our task now is to invent what happens next.

Speed is a problem. Our lives are too fast, we are subject to the accelerating demand that we innovate more, work more, enjoy more, produce more, and consume more. Hartmut Rosa declares that today we face a ‘totalitarian’ form of social acceleration.1 That’s one familiar story. I want to tell another, stranger, story here: of those who think we haven’t gone fast enough. Instead of rejecting the increasing tempo of capitalist production they argue that we should embrace and accelerate it. We haven’t seen anything yet as regards what speed can do. Such a counsel seems to be one of cynicism, suggesting we come to terms with capitalism as a dynamic of increasing value by actively becoming hyper-capitalist subjects. What interests me is a further turn of the screw of this narrative: the only way out of capitalism is to take it further, to follow its lines of flight or deterritorialization to the absolute end, to speed-up beyond the limits of production and so to rupture the limit of capital itself.

To be clear from the start, I don’t agree with this story. The core idea of this book originated in the early ’90s, when I first encountered the work of Nick Land and the Cybernetic Cultures Research Unit (CCRU) while working on a thesis on Georges Bataille. This work, as I will discuss in Chapter 4, is the one of the most explicit statements of the desire to accelerate beyond capital. Formulated in the language of science-fiction and contemporary theory (particularly the work of Gilles Deleuze and Félix Guattari), Land and the CCRU rigorously abandoned any humanist residues. Land and his colleagues at the University of Warwick strove for a new post-human state beyond any form of the subject, excepting the delirious processes of capital itself. They claimed that the replication and reinforcement of capital’s processes of deterritorialization – of flux and flow – would lead to a cybernetic offensive capital could no longer control. Reading this full-blown accelerationism alongside discussions of the New Right and their aim to ‘dissolve’ the state led me, at the time, to coin the term ‘Deleuzian Thatcherism’.

It was the resurgence of these ideas in the ’00s, including the republication of Land’s essays,2 that made me return to these questions and offer a more precise critical description by using the term ‘accelerationism’.3 It turns out that term occurs in Roger Zelazny’s sci-fi novel Lord of Light (1967), which I’d read. The unconscious, as usual, works in mysterious ways. After my initial critical analysis a new wave of contemporary accelerationism emerged and it was this fact, especially as this took place at a time of capitalist crisis, that led me to write this book.

My aim is not to offer an exhaustive account of accelerationism, but rather to choose certain moments at which it emerges as a political and cultural strategy. In the Introduction I begin with the theorization of accelerationism by a small group of French theorists in the early to mid-1970s. This brief moment of theoretical excess is, I will argue, a paradoxical attempt to articulate a path beyond a capitalism that seems to have absorbed and recuperated all opposition. It will provide the key which will unlock the different historical moments of acceleration that I then track. Starting with Italian Futurism, I proceed through Communist accelerationism following the Russian Revolution, to fantasies of integration with the machine, the Cyberpunk Phuturism of the ’90s and ’00s, the apocalyptic accelerationism of the post-2008 moment of crisis, and the negative form of terminal accelerationism. In the final chapter I return to the 1920s and 1930s to restage the debate around accelerationism through the encounter between Walter Benjamin and Bertolt Brecht. This scene condenses the problem of acceleration and the production of the new. In my conclusion I want to suggest a way out of the impasse, which doesn’t simply counter acceleration with a desire to slow down.

As this is a work written out of the sense of the difficulty of defeating accelerationism, I don’t hope to write its epitaph here. I can’t deny the appeal of accelerationism, particularly as an aesthetic. What I want to do is suggest some reasons for the attraction that accelerationism exerts, particularly as it appears as such a counter-intuitive and defeatist strategy. I’ll argue that this attraction relies on the ways in which accelerationism takes-up labor under capitalism as site of extreme and perverse enjoyment. The use by accelerationists of the concept of jouissance – that French word used to refer to an enjoyment so intense it is indistinguishable from pain, a kind of masochism – is the sign of this. While accelerationism wants to accelerate beyond labor, in doing so it pays attention to the misery and joys of labor as an experience. If we are forced to labor, or consigned to the other hell of unemployment, then accelerationism tries to welcome and immerse us in this inhuman experience. While this fails as a political strategy it tells us much about the impossible experience of labor under capitalism. We are often told labor, or at least ‘traditional labor’, is over; the very excesses of accelerationism indicate that labor is still a problem that we have not solved. That I think the accelerationist solution of speeding through labor is false will become evident. This does not, however, remove the problem itself.

I want to begin with the moment when the strategy of accelerating through and beyond capitalism was first explicitly theorized. This took place in France in the early to mid-1970s with three books, each appropriately trying to outdo and out-accelerate the other in the attempt to give this strategy its most provocative form. It is these works that frame the debate concerning acceleration and which probe the tense relation between strategies of acceleration and the solvent forces of capitalism.

The first is Gilles Deleuze and Félix Guattari’s Anti-Oedipus: Capitalism and Schizophrenia (1972), which, as its title suggests, was devoted to a scathing critique of psychoanalysis for confining the force of desire within the Oedipal grid. The ambitions of the book, as its subtitle indicates, went far beyond this. Deleuze and Guattari reevaluated schizophrenia as the signature disorder of contemporary capitalism, arguing that the breakdowns of the schizophrenic were failed attempts to break through the limits of capitalism. Capitalism was unique for unleashing the forces of deterritorialization and decoding that other social forms tried to constrain and code. This release was, however, always provisional on a reterritorialization that dragged desire back into the family and the Oedipal matrix, recoding what it had decoded.

Deleuze and Guattari’s strategy for revolution was posed in a series of rhetorical questions:

But which is the revolutionary path? Is there one? – To withdraw from the world market, as Samir Amin advises Third World Countries to do, in a curious revival of the fascist ‘economic solution’? Or might it be to go in the opposite direction? To go further still, that is, in the movement of the market, of decoding and deterritorialization? For perhaps the flows are not yet deterritorialized enough, not decoded enough, from the viewpoint of a theory and practice of a highly schizophrenic character. Not to withdraw from the process, but to go further, to ‘accelerate the process,’ as Nietzsche put it: in this matter, the truth is that we haven’t seen anything yet.

It is obvious that if we follow Samir Amin’s suggestion that countries delink from capitalism we are at the risk being chided with incipient fascism. Instead, we have to follow Deleuze and Guattari’s Nietzschean preference to ‘accelerate the process’. To break the limit of capital requires further deterritorialization and decoding, beyond the constraints of the Oedipal family and of capitalist economy. This leads to the new figure of the ‘schizo’, who is no longer the ‘limp rag’ of the schizophrenic locked in the asylum but a kind of relay for all the uncontainable liquid and accelerating flows of deterritorialization; in Nietzsche’s ‘schizo’ delirium he announced ‘I am all the names of history’.

No doubt this is only one extreme moment of a provocative work, which also offers other pathways to analyse the opaque and inertial forms of capital. That said, the recommendation that we reach absolute deterritorialization by accelerating the tendencies of capitalism is explicit enough. Of course the aim of such acceleration is not to reinforce capitalism but rather to generate its meltdown. Marx and Engels, in The Communist Manifesto (1848), used the metaphor of capital as the ‘sorcerer’s apprentice’, unleashing forces it cannot control. Deleuze and Guattari stand in this lineage, pushing Marx along the line of hard-edged excess that ruins all values, including the ‘value’ that is the core function of capitalism itself. This is a metaphysics of production as desiring-production, which can trace and exceed capitalist forces of production.

In reply, Jean-François Lyotard argued that Deleuze and Guattari hadn’t gone far enough. Their celebration of desire still supposed that it formed some kind of exterior force that capitalism was parasitical to, and which we could turn to as an alternative. Instead, Lyotard’s Libidinal Economy (1974) insisted there was only one libidinal economy: the libidinal economy of capitalism itself. We cannot find an ‘innocent’ schizo desire, but instead have only the desire of capitalism to work with. In what is perhaps the most notorious accelerationist statement of all Lyotard did not shy away from the implications of his position:

the English unemployed did not have to become workers to survive, they – hang on tight and spit on me – enjoyed the hysterical, masochistic, whatever exhaustion it was of hanging on in the mines, in the foundries, in the factories, in hell, they enjoyed it, enjoyed the mad destruction of their organic body which was indeed imposed upon them, they enjoyed the decomposition of their personal identity, the identity that the peasant tradition had constructed for them, enjoyed the dissolutions of their families and villages, and enjoyed the new monstrous anonymity of the suburbs and the pubs in morning and evening.

Lyotard denies the kind of left politics that would insist that the worker suffers alienation in their separation from their community, their body, and the organic. Instead Lyotard suggests that the worker experiences jouissance, a masochistic pleasure, in the imposed ‘mad destruction’ of their body. Unsurprisingly, Lyotard’s remark lost him most of his friends on the left, and even he would later refer to Libidinal Economy as his ‘evil book’.

In contrast to Deleuze and Guattari’s reworking of Marx’s ‘hidden abode of production’ as forces of desire, Lyotard remains on the surface. His is a metaphysics of credit and speculation, in which value is generated from the shifting relations of trade and exchange that accelerate beyond the constraints of actual production. This accounts for Lyotard’s weird promotion of the doctrine of mercantilism – as articulated in France in the seventeenth and eighteenth centuries, this is an economic doctrine that aims to control foreign trade in order to secure a positive balance of trade. In Lyotard’s hands this doctrine is retooled as a zerosum game of looting that reveals capitalist libido as the obsession with currency as intensity.

Jean Baudrillard’s Symbolic Exchange and Death (1976) would criticize both Lyotard and Deleuze and Guattari for their nostalgic attachment to desire and the libidinal as oppositional forces. Only ‘death, and death alone’ incarnated a reversible function that could overturn the omnivorous coding capitalism imposed. What Baudrillard found in death was a ‘symbolic’ challenge that exterminated value by returning to a pre-capitalist economy of the challenge of the gift, which was now linked to exceeding the forces of capital by ‘magical’ reversal.

Baudrillard, however, takes a distance from accelerationism by disputing the metaphysics of production that underlay Marxism and these dissident currents. In The Mirror of Production (1973) he had already critiqued ‘an unbridled romanticism of productivity’. For Baudrillard what accelerated was not some force of libidinal flux or flow, but a catastrophic and entropic negativity that floods back into the system causing it to implode – the result is a terminal accelerationism.

This is an accelerationist metaphysics of inflation – not simply capitalist inflation, which hollows out the function of money but also a superior symbolic exchange that insinuates itself within capitalist exchange and accelerates this process. While Baudrillard does not celebrate production or the circulation of libido, he tracks the inflationary bubbles of money as signs of capitalism evacuating itself of meaning and value.

It is an irony that Lyotard, responding to earlier versions of Baudrillard’s argument, had already suggested that: ‘[t]here is as much libidinal intensity in capitalist exchange as in the alleged “symbolic” exchange’. Mocking Baudrillard’s anthropological turn to the ‘primitive’ Lyotard stated there was no ‘good hippy’ to practice symbolic exchange, only ‘the desire of capital’. What Lyotard suggested was that even death was no way out of capitalism, which was the only game in town. The result was that Baudrillard’s faith in another principle of exchange was misguided, as capitalism could absorb and parasite on any symbolic exchange.

In this dizzying theoretical spiral we can see a common accusation: each accuses the other of not really accepting that they are fully immersed in capital and trying to hold on to a point of escape: desire, libido, death. Each also embodies a particular moment of capital: production, credit, and inflation. The result is that each intensifies a politics of radical immanence, of immersion in capital to the point where any way to distinguish a radical strategy from the strategy of capital seems to disappear completely.

In Joseph Conrad’s novel Lord Jim (1900), the character Stein gives some (for Conrad) characteristically enigmatic advice:

A man that is born falls into a dream like a man who falls into the sea. If he tries to climb out into the air as inexperienced people endeavour to do, he drowns – nicht wahr? … No! I tell you! The way is to the destructive element submit yourself, and with the exertions of your hands and feet in the water make the deep, deep sea keep you up. So if you ask me – how to be?

His answer: ‘In the destructive element immerse.’ These theoretical accelerationists take Stein’s advice to heart. We fall into capitalism and, rather than try to climb out, we have to submit and swim with the capitalist current.

This reaction could be seen as a result of the defeat of the hopes inspired by the revolutionary events in France, which are condensed in the signifier ‘May ’68’. At the time Deleuze and Guattari, Lyotard, and Baudrillard were writing this defeat was not evident, and many others were working throughout the 1970s to sustain and radicalize the struggles unleashed in ’68. Those energies would fade into the reactionary 1980s, and then the accelerationist positions of Deleuze and Guattari, Lyotard, and Baudrillard would become prescient. Their positions registered the durability of capitalism and its ability to spread its domination, often by recuperating forms of struggle. The totalizing effects of capital would appear capable of rolling-up revolutionary advance, making the search for a revolutionary subject outside of capital superfluous. While Deleuze and Guattari would maintain faith in new revolutionary subjectivities – the ‘schizo’, and what they would later call ‘minor’ becomings – Lyotard and Baudrillard would more firmly embrace disenchantment.

Far from simply being signs of the times these accelerationist formulations gained resonance as predications of the bad days to come. They would find more purchase in the ‘polar night’ of the 1980s. At that point rising fears of nuclear destruction, a glaciated Cold War, and the beginnings of the neoliberal counteroffensive, offered a felt experience of closed, if not terminal, horizons. Being a teenager at that time was to live in an atmosphere of ambient dread, summed-up for me in viewing the traumatic BBC post nuclear-attack film Threads (1984) and the paranoia of Troy Kennedy Martin’s Edge of Darkness (1985). It has recently been revealed that Whitehall planners had formulated a nuclear war-game scenario with the suitably chilling codename Winter-Cimex 83. My later reading of Baudrillard’s In the Shadow of the Silent Majorities, published in the Semiotext(e) Foreign Agents series of little black-books, produced an immediate sense of recognition of this mood. Baudrillard’s implosive theorization would be truer to the inertial nature of capitalism, disputing accelerationist images of ever-expansive capitalism.

The reason theoretical accelerationism caught this mood was precisely because it was formulated in the mid-1970s, at the beginning of the long capitalist downturn. These hymns to the excessive powers of capitalism were articulated in the face of crisis – the ‘oil crisis’, the abandonment of the gold standard, and the crisis of productivity, as well as the political crisis of legitimation (Watergate, etc.). In 1972 the Club of Rome published The Limits to Growth, which used computer modelling to argue that capitalism was undermining the material bases of its own ‘success’. So, in a strange way this theoretical moment of accelerationism seemed to be running against the current of capitalism entering a period of stagnation, deceleration, and decline. On the other hand, however, it appeared predictive of the sudden ‘acceleration’ of cybernetic and financial forces that would form the basis for neoliberalism, signalled by the election of Margaret Thatcher in the UK in 1979 and the election of Ronald Reagan in the US in 1980. The fact that, in particular, Deleuze and Guattari’s term ‘deterritorialization’ would find a fecund future in being used to describe neoliberal capital is one sign of this.

These models formulate, in advance, the common sense of the ’90s that ‘there is no alternative’ (TINA). If we follow the career of accelerationism across these moments we see it engaging and reengaging with the closing of the horizon of capitalism. It offers a way of understanding the continuing penetration of capitalism – horizontally, across the world and vertically, down into the very pores of life – and also, of celebrating this as the imminent sign of transcendence and victory. Our immersion in immanence is required to speed the process to the moment of transcendence as threshold. In this way immanence is paired with a (deferred) transcendence and defeat is turned into victory. At the same time defeat is registered by these forms of theoretical accelerationism in the form of ecstatic suffering, of jouissance, experienced in our deepening immersion.

This theoretical moment involved a strange fusion of Marx and Nietzsche. It took from Nietzsche the apocalyptic desire to ‘break the world in two’, and the need to push through to complete the nihilism, the collapse of values, that afflicts our culture. Nietzsche did not decry the collapse of values, but saw these ruins as the possibility to move beyond the limits of Western culture.

This would be fused with Marx’s contention that history advanced by the bad side, which welcomed the solvent effects of capitalism in dissolving the old world. The result was a Nietzschean Marx, a Marx of force and destruction. In 1859 we find Marx hymning the productive powers of force:

No social order is ever destroyed before all the productive forces for which it is sufficient have been developed, and new superior relations of production never replace older ones before the material conditions for their existence have matured within the framework of the old society.

In this modelling we have a teleology – the linear passage through different modes of production in which communism solves the riddle of history and promises a superior mode of productivity, one not subject to the antagonism of capitalism.

Perhaps the most controversial moment of the ‘Nietzschean Marx’ is the series of articles he wrote on India. In his 1853 article ‘The Future Results of the British Rule in India’ Marx stressed how British colonialism would disrupt the ‘stagnation’ of India and appears to welcome the violence of colonialism, the arrival of industry, and the railways, as a necessary shattering of the old ways. Even this is, however, equivocal. Marx notes that bourgeois ‘progress’ always involves ‘dragging individuals and peoples through blood and dirt’, and that British colonialism has hardly brought anything beyond destruction. For Marx it would only be through social revolution that these ‘developments’ could be appropriated to forge a just society.

While there is a teleological Marx of development and production, Marx also insisted that capitalism does not automatically lead to communism. In The Communist Manifesto Marx and Engels argued that capitalist crisis posed the choice between the ‘common ruin of the contending classes’ and ‘the revolutionary reconstitution of society at large’. Marx welcomed worker struggles to reduce the working day and to struggle against the despotism of the factory; he did not argue that it would be better if factory conditions got worse so workers would be forced into revolt. The fact that history advances by the bad side does not mean we should celebrate the ‘bad side’, but rather recognize this is the ground on which we struggle, which must be negated to constitute a new and just social order.

The theoretical accelerationists try to break this dialectic of redemption by emphasizing only the violent moment of creative destruction. In place of the just society generated through struggle, it is acceleration that becomes the vehicle of disenchanted redemption. This makes them heretics of Marx. While the classic theoretical accelerationists often adopt Nietzschean themes of contingency and chance, in terms of acceleration they tend to reinstate the most teleological forms of Marxism. To resolve this problem accelerationism projects contingency on to capitalism, which becomes an anti-teleological, or ‘acephalic’ (headless) social form. In making this projection the accelerationists take as fact capitalism’s fundamental fantasy of self-engendering production. They are an archetypal instance of the fetishists of capital.

Certainly such a fantasy of self-engendering production is present in Marx, as we have seen. I think that the critique of this fantasy is a fundamental necessity. While we can certainly only begin to construct a just society on the ground of what exists this does not entail accepting all that exists or accepting what exists as it is given. This is a crucial political question: how can we create change out of the ‘bad new’ without replicating it? Of course, the accelerationist answer is by replicating more because replication will lead to the ‘implosion’ of capital. Replication, however, reinforces the dominance of capitalism, leaving us within capital as the unsurpassable horizon of our time.

It might be easy to dismiss theoretical accelerationism as a malady of those who take theory too far, spinning-off into abstract speculation. In fact, the very point of accelerationism is going too far, and the revelling and enjoyment engendered by this immersion and excess. They push into the domain of abstraction and speculation which, with the financial crisis, is evidently the space of our existence. I am sceptical that such a ‘road of excess’ will, in William Blake’s words, lead ‘to the palace of wisdom’. It does, however, lead us to think what this excess and abstraction might register. If accelerationism is not the revolutionary path it may be the path that records, in exaggerated and hyperbolic form, some of the seismic shifts of capitalist accumulation from the 1970s to the present.

What accelerationism registers in particular are two contradictory trendlines: the first is that of the real deceleration of capitalism, in terms of a declining rate of return on capital investment, which has led to a massive switching into debt. The second is the acceleration of financialization, driven by the new computing and cybernetic technologies, which themselves create an image of dynamism. Of course, this ‘contradiction’ of deceleration and acceleration speaks to a dual dynamic as capitalism tries to restart processes of accumulation by acceleration. The financial crisis that began in 2008 brought this contradiction to the point of collapse.

It is in this double dynamic that accelerationism finds its theorization, answering deceleration with the promise of a new acceleration, driven by faith in new productive forces that come online and disrupt the ideological humanism that tends to be capitalism’s default ideology. In capitalism we are treated as free agents, although always free to choose within the terms set by the market. Accelerationists reject this ‘humanism’ by embracing dehumanization. They take utterly seriously the Marxist argument concerning the dehumanizing aspects of capitalism and they also take seriously those ideologues of the market who try to dehumanize us into ‘mere’ market-machines. This accounts for the instability of accelerationism, which is poised on this faultline.

It also speaks to the position of labor within capitalism: at once necessary, as Marx noted, to the production of value, while also constantly squeezed out by machines and unemployment. For Marx capitalism is ‘the moving contradiction’, which ‘presses to reduce labor time to a minimum, while it posits labor time, on the other side, as sole measure and source of wealth.’ This contradiction has only become more and more striking over the last forty or so years. The place of labor has shifted, at least in countries like the UK and US, from manufacturing to the so-called service economy (although this shift should not be overstated). It has also been displaced geographically and displaced in form – dispersed beyond the concentrated forms that it once held, or seemed to hold. At the same time, many of us work longer and harder. The relief that technology was supposed to bring from labor merely leaves less labor doing more work. No longer, as in Marx’s day, are we all chained to factory machines, but now some of us carry our chains around with us, in the form of laptops and phones.

My suggestion is that accelerationism tries to reengage with the problem of labor as this impossible and masochistic experience by reintegrating labor into the machine. In what follows, we will see this fantasy of integration, the ‘man-machine’ (note the gendering), that might at once save and transcend the laboring body. This will take various forms, at once radically dystopian and radically utopian. Rather than taking this as a solution, I will argue it is a symptom. If we take accelerationism critically then we can use it to gauge the mutations of labor and its resistance to integration within capitalism and the machine – including sabotage, strikes, and more enigmatic forms of passive resistance. The stress of theoretical accelerationism on our immersion in capitalism will prove central to unlocking the various cultural and historical moments I will trace in this book. It is the extremity of accelerationism makes it the most useful diagnostic tool. It will also allow us to try and break the appeal of acceleration.

To visit Gabriele D’Annunzio’s villa and garden at Gardone Riviera on Lake Garda is to experience the commemoration of speed as the essential sign of modernity. This is speed vectored through that other sign of modernity: mechanized warfare. Beyond his poetry, the villa and garden are D’Annunzio’s truly prefigurative artworks of the twentieth century. The Vittoriale degli italiani (The Shrine of Italian Victories), as the estate is named, is a remarkable and disturbing testament to the ‘man-machine’ of D’Annunzio’s protofuturist and protofascist vision. It contains all the ‘speed machines’ that embody this aesthetics of acceleration and war. There is the Motoscafo Armato Silurante MAS-96 anti-submarine motorboat D’Annunzio captained, and the name of which he détourned into the Latin motto Memento audere semper – ‘remember always to dare’). The SVA-5 aeroplane in which he flew to drop propaganda leaflets and bombs in the ‘il Volo su Vienna’ (‘Flight over Vienna’) as squadron leader of the ‘La Serenissima’ 87 fighter-squadron on 9 August 1918. The most striking machine is the warship Puglia, donated by the Italian government and now embedded into the hillside.

The phallic ship thrusting from the hillside seems to embody exactly the masculine and protofascist mastery over nature by technology and acceleration. D’Annunzio wrote that the prow of a warship was ‘a monstrous phallic elongation’. It embodies what Paul Virilio, writing of the Italian Futurist F.T. Marinetti, called the ‘inhuman type’: ‘an animal body that disappears in the superpower of a metallic body able to annihilate time and space through its dynamic performances.’ D’Annunzio’s personal motto ‘per non dormire’ (‘In order not to sleep’) captures perfectly, in advance, this vectoring of human will into a mechanized acceleration that displaces any organic need. It might also stand as the motto for contemporary capitalism, which, as Jonathan Crary has noted, declares war on sleep as one of the few residual and non-productive human activities.

The ship, however, is somehow integrated into nature, in a strange fusion that accelerates the forces of nature as the vessel thrusts itself from the hillside into the lake. To stand on the deck is to experience a vertiginous toppling of the frozen moment of launching. The fact that the other various machines and devices of speed and destruction are placed in a house and garden offers an incongruous experience that estranges both the natural and the technological. This techno-pastoral figures the desire to infuse the forces of technology into nature and to give life to technology through the integration of nature. What is crucial is the link between technological speed and the dynamic and vital will of the ‘animal’ or natural body.

In this chapter I want to consider the Italian Futurist celebration of speed and their attempt to harness the forces of velocity and acceleration as the Ur-form of accelerationism. The Futurist’s cult of war, their misogyny, and their alliance with fascism, make them the symbolically toxic avant-garde. My aim is not to redeem the irredeemable, or to use them to convict accelerationism in advance. Instead, I want to explore how the Futurists try to grasp and integrate forces of production that appear as forces of destruction. This involves strange integrations and displacements, as the Futurists try to fuse and infuse mechanical bodies with vital forces and accelerate these new fused forces towards a threshold of destruction and rebirth.

The Italian Futurists fully inhabited the cult of speed predicted by D’Annunzio. Point Four of ‘The Founding and Manifesto of Futurism’ (1909), written by Marinetti, announces:

We affirm that the beauty of the world has been enriched by a new form of beauty: the beauty of speed. A racing car with a hood that glistens with large pipes resembling a serpent with explosive breath … a roaring automobile that seems to ride on grapeshot – that is more beautiful than the Victory of Samothrace.

In Point Eight the Futurists go on to declare that ‘we have already created velocity which is eternal and omnipresent’, and in Point Nine to make clear the importance of military speed (and misogyny): ‘We intend to glorify war – the only hygiene of the world – militarism, patriotism, the destructive gesture of anarchists, beautiful ideas worth dying for, and contempt for woman.’

The contempt for woman indicates the usual armoured trope of erecting the hard, phallic and mechanized male body over and against the feminized: soft, liquid, and organic. In response the Futurist ‘feminist’ Valentine De Saint-Point wrote the ‘Manifesto of Futurist Woman’ (1912), which suggested women were equal to men – equal in terms of meriting the same disdain. After this amusingly anti-humanist opening the argument falls back into arguing that both men and women needed more virility, and that both should take the ‘brute’ as their model. The solution to misogyny is to join an equality of brutality, confirming the phallic hardness of the machine as destination for both genders.

In a similar fashion Marinetti’s misogyny also opens on to a general anti-humanism – the cult of speed is one that bursts apart the limits of the human. Marinetti declared: ‘Those who are weak and sick [will be], crushed, crumbled, pulverized by the relentless wheels of intense civilization. The green beards of moss-grown streets in the provinces will be shaved clean by the cruel razors of velocity.’ The only survival is elective surgery by ‘the cruel razors of velocity’ that will provide the ‘clean’ speed to transform the human body into a new individual war-machine.

The Futurists try to perform what Fredric Jameson calls ‘a virtual cooptation of the machine, a homeopathic expropriation of its alienated dynamism.’ This virtual co-optation of dynamism by means of war runs through to the very end of Futurism. In 1941 Marinetti composed the manifesto of ‘Qualitative Imaginative Futurist Mathematics’, with the Futurist poet Pino Masanta and the renegade mathematician Marcello Puma. Puma was a student of quantum mechanics and the diffusion patterns of infectious diseases. This new ‘antistatic antilogical antiphilosophical mathematics’ offered modes of acceleration that are non-linear. The Futurist embrace of chance and randomness meant that they could imagine a ‘poetic geometry’ in which the river Nile could be redirected to turn back on itself, which suggests that Futurist accelerationism is not simply a teleological movement forward.

Yet, this is still a deeply dubious political mathematics, which plays off the disruptive force of the Futurists against their political enemies. The manifesto celebrates the battle of 15 April 1919, when Futurists and war veterans assaulted a communist rally on the Via dei Mercanti in Milan, before going on to burn down the headquarters of the Socialist Party’s newspaper Avanti!:

Calculate the clear sum of revolutionary Victory obtained in Milan the 15th of April 1919 (the Battle of Via dei Mercanti) by means of 50 Futurist poets 100 Arditi 50 early Fascist squadristi and 300 students from the Polytechnical Institute + the political genius of Mussolini + bold aeropoetic imagination of Marinetti + Ferruccio Vecchi in order to defeat 100,000 socialists-communists routed because imbued with pacifism and hence frightened by pistols multiplied a hundredfold by patriotic courage.

Marinetti and Puma’s calculus appears objective, but it rests success in combat on the qualitative value of ‘great men’. The contingent allows the infusion of the leader into the ‘objective’ array of mechanical forces.

This Futurist mathematics, according to Jeffrey T. Schnapp, engages with the new statistics generated by capitalist society by trying to overload the circuits of accumulative linear mathematics with a ‘statistical sublime’. In the case of their machinic integration we can see how the attempt at virtual co-optation of dynamism also tries to inhabit and overload the technological forces Futurism lauds. This suggests that Futurism isn’t simply the celebration of technology and war, but a reworking or struggle to push acceleration into new forms. Obviously the dominant forms of Italian Futurism compromised or celebrated the Fascist ‘solution’, while also remaining in a complicated and marginal position to Fascist modernization. What the Futurists highlight is that accelerationism is always an intervention or a selection of forces, particularly structured by the need to integrate labor within a new ‘mechanical’ configuration.

In the Epilogue to his famous essay ‘The Work of Art in the Age of Mechanical Reproduction’ (1936) Walter Benjamin condemned the Futurists for aestheticizing war, in which ‘we experience [our] own destruction as an aesthetic pleasure of the first order.’ While this has become the accepted diagnosis of the Futurists, Benjamin goes on to add a caveat: we can accept the Futurist diagnosis if we understand their aestheticization of war as the result of the impeding of the ‘natural’ use of the productive forces. The Futurists aestheticize the destructive turn of the productive forces because they cannot truly grasp the possibility of redeploying these forces.

Benjamin’s brief suggestion returns to his short work ‘To the Planetarium’, contained in his book One-Way Street (1928). There he argued that the First World War was ‘an attempt at new and unprecedented commingling with the cosmic powers.’ While science seems to have disenchanted the stars we cannot simply evade these cosmic powers, which are retranslated into technological forces. The war presents the equivocal site of released and intoxicating forces of destruction:

Human multitudes, gases, electrical forces were hurled into the open country, high-frequency currents coursed through the landscape, new constellations rose in the sky, aerial space and ocean depths thundered with propellers, and everywhere sacrificial shafts were dug in Mother Earth. (103–4)

In Benjamin’s quasi-mystical reading this is an ‘immense wooing of the cosmos’ carried out via ‘the spirit of technology’ (104). The resulting ‘bloodbath’ was due to these cosmic forces being subject to profit, i.e. to capitalism.

This does not imply these forces should be abandoned. Benjamin argues that we reconfigure the relation between mastery and technology. No longer should humans master nature, but humans need to master the relation between us and nature. The intoxication of these cosmic powers has gone astray, and this turns on the question of speed:

One need recall only the experience of velocities by virtue of which mankind is now preparing to embark on incalculable journeys into the interior of time, to encounter there rhythms from which the sick shall draw strength as they did earlier on high mountains or on the shores of southern seas. The ‘Lunaparks’ are a prefiguration of sanatoria. (104)

‘Lunaparks’ was an early name for what we now call amusement parks, and the first park to use this name was in Coney Island, New York in 1907. Benjamin’s suggestion is that these parks – with their rollercoasters and other rides – form a kind of homeopathic or therapeutic intoxication or acceleration, which will allow us to cure the tubercular sickness of technology. Intoxication is played against intoxication.

The result is an embrace to wrest technology, as second nature, into a new configuration:

In the nights of annihilation of the last war the frame of mankind was shaken by a feeling that resembled the bliss of the epileptic. And the revolts that followed it were the first attempt of mankind to bring the new body under its control. The power of the proletariat is the measure of its convalescence. If it is not gripped to the very marrow by the discipline of this power, no pacifist polemics will save it. Living substance conquers the frenzy of destruction only in the ecstasy of procreation [Rausche der Zeugung]. (104)

In Benjamin’s strange cosmic phantasmagoria, which he will later problematize or rescind (as we will see in Chapter 7), the forces of annihilation produce a new intoxication, a new collective and personal body that we have to master – a ‘rush’ [Rausche].

Despite their extreme political differences we can see a convergence between the Futurists and Benjamin on this equivocal ground of the mastery of technologies of acceleration. While Benjamin banks on communist revolt and the Futurists favour the new ‘discipline’ of Fascism, they both suggest a utopian possibility of the collective mastery of acceleration. What they attend to is the integration and acceleration of intoxicating and ecstatic forces. There is no turning back, they imply. What needs more probing is the form and nature of these forces.

The Futurists operated an aesthetic of acceleration that was not only predicated on war, but also on the industrial revolution. The energies they aimed to tap were, in fact, positioned at the confluence between industry and warfare. Yet, there was something odd and even anachronistic about this attempt. In his autobiography the English Vorticist Wyndham Lewis reports his encounter with the Futurist Marinetti. When Marinetti tried to enlist Lewis as a Futurist, Lewis replied in a typically racist and acerbic fashion:

‘Not too bad,’ said I. ‘It has its points. But you Wops insist too much on the Machine. You’re always on about these driving-belts, you are always exploding about internal combustion. We’ve had machines here in England for a donkey’s years. They’re no novelty to us.’

Putting aside the racial sneer, Lewis’s point invokes another experience of the machine – one that isn’t about the shock of modernity but rather the integration of the machine in everyday life.

Marinetti’s reply to Lewis is, precisely, predicated on acceleration: ‘You have never understood your machines! You have never known the ivresse of travelling at a kilometre a minute. Have you ever travelled a kilometre a minute?’ Lewis’s reply is: “Never.’ I shook my head energetically. ‘Never. I loathe anything that goes too quickly. If it goes too quickly, it is not there.” Lewis invokes, as he often would, the need for sharp division, which is opposed to the blurring caused by speed. His invocation of the experience of the machine in Britain, however, suggests a complex relationship between speed, machines, and labor, which is not limited to the mechanization of warfare.

It is Lyotard who closely links the experience of the avantgarde with the experience of the worker. Reflecting on his own notorious invocation of the worker’s experience of jouissance in factory labor Lyotard later commented that: ‘[T]he point was to convey that there is in the hardest working-class condition an impressive contribution that easily matches, and perhaps exceeds, the adventures of poets, painters, musicians, mathematicians, physicists, and the boldest tinkerers and tamperers.’ The imposed demand on the worker to construct a new body, a new sensorium, and new sensibility matched or exceeded the experiments of the avant-garde in the creation of ‘man-machines’.

Lyotard traces the energies of the integration of labor and the machine over a longer time-span, in which the avant-garde, ironically, features as a late arrival. The workers of the nineteenth century had already gone beyond the sensory limit of the body and, in Lyotard’s controversial addition, enjoyed that experience. Lyotard’s stress is two-fold. First, that we shouldn’t dismiss the experience of peasants become workers as that of simple victims who suffered passively. There was an active engagement with these new possibilities of the augmented and expanded body. His second point is that this engagement creates a new mode of experience and, even, of ethics. The workers practiced, long before the avant-gardes, a ‘mechanical asceticism’, by holding on in a place in which it had seemed impossible to do so.

The result was the birth of ‘a new sensibility made up of little strange montages.’ (15) In pugnacious style Lyotard has little time for those who don’t accept the experience of workers as an ecstatic one: ‘“Jouissance.” The French think it means the euphoria that follows a meal washed down with Beaujolais.’ (18) Rejecting this sanitization of masochistic pleasure Lyotard, like Lewis, points to the longer form of the worker’s engagement with the machine. This is implicit in the forms of Futurism, which flirted with anarchism and syndicalism, as well as Fascism. The difficulty of accelerationism, which will thread its way through this book, is its attempt to solve this suffering of labor by integrating labor into the machine. If war, for all its destructive power, can be flipped into heroism, labor remains more resistant.

Lyotard’s mechanical sublime, which he will later translate into a tragic register by taking the Holocaust as his model, indicates, at this point, an excess that is utopian. The rupture is one that places the worker at the center, on the condition they disappear into an aesthetic of forces. Such a model speaks to the Futurist’s ‘statistical sublime’, which was their attempt to map an accelerated access that exceeded the forces of structure and control. For Lyotard this sublime moment would mark his departure from the left, and the Futurists were even more politically dubious. It seems that the desire to transgress leftist ‘pieties’ leads to the embrace of the sublime, and an embrace which restores that trope to its conservative roots. Excess is not necessarily good.

Paul Virilio draws out a whole genealogy of the celebrants of speed: ‘whether it’s the drop-outs, the beat generation, automobile drivers, migrant workers, tourists, Olympic champions or travel agents, the military-industrial democracies have made every social category, without distinction, into unknown soldiers of the order of speeds’. The Futurists are the pioneers of this new order. The brevity of their own moment, disappearing into a war which killed several of their leading members before a brief interwar revival, is one sign of their own desire to accelerate into the future. Their own lived experience of avant-garde time was predicated on speed and obsolescence. In the Founding Manifesto Marinetti announced that ‘others who are younger and stronger will throw us in the wastebasket, like useless manuscripts. — We want it to happen!’

This logic of obsolescence speaks not only to the frantic emergence and extinction of the avant-garde, with each trying to accelerate beyond the other, but also to the experience of labor. The worn-out bodies of factory workers, or other laborers, are retired or dumped to be replaced by new ‘younger and stronger’ bodies. In a way Futurism zeros in on this logic of replacement – first, in its attempt to replace the soft and decadent bourgeois body with a new hardened Futurist body, then with the discarding of that body as it wears out. This model of finitude implies that acceleration and technology do not smoothly unfold in a linear teleology that delivers us beyond the limits of labor. Instead we seem to remain at this limit as a point of struggle and contradiction.

The aim of my discussion of Futurism as the crucible of accelerationism has been to explore this limit. On one hand, Futurism appears mimetic and apologetic of the acceleration of capitalist technology, if not wanting to re-order this in Fascist forms. On the other hand, the non-linear and destructive moments of Futurism threaten to collapse this ideological programme and put accelerationism into question. That I don’t think this questioning goes far enough should be obvious. The reappearance of acceleration today, however, suggests the equivocal attraction of an avant-garde that promised an intervention which could grasp, or attempt to grasp, technological forces. Our current moment, as we will go on to see, lacks this hope and tries to recover it from the past. The irony is that accelerationism, which is relentlessly directed toward the future, turns out to be nostalgic. This irony will recur. The nostalgia of accelerationism suggests, I think, the difficulty in engaging with the problem of labor and with disengaging from the existent lines of flight that determine acceleration. The revenge of replication is one which haunts the accelerationist pursuit of the sublime, whether in warfare or in industrial production. The Futurists did not predict the retooled future of technology integrated with man they intended, but rather the brutal history of displacements and reworkings that fall back within the forms of value. In trying to escape to some statistical sublime, they fall back into the value sublime.

Robin Blackburn reports a story told to him when he worked for the Cuban Ministry of Soviet Trade in the 1960s. At an economic conference convened by the then-President Osvaldo Dorticós there was a discussion of a particular plan for a sector of the economy. One adviser argued that the aim must be to produce the maximum output for the minimum effort and expense. Dorticós emphatically disagreed: ‘This is not the revolutionary way,’ he insisted, ‘instead we aim to achieve the maximum of output with the maximum forces (fuerzas).’ I want to explore this attitude as key to what I will call ‘communist accelerationism’. We have seen that accelerationism is usually a strategy that tries to ride the infinitely self-expanding value of capital. Communist accelerationism, of the kind practiced by what Chris Arthur calls ‘no-longer-existing socialism’, did something rather different. It tried to find a find a new and superior mode of production – one that could take the ‘best’ of capitalism, but reorganize it to go beyond the limits of a system driven by profit. In doing so it appealed, as we will see, to this ‘cavalry-charge method’, precisely to breakthrough to the future and, in doing so, to put human labor in charge.

My focus will be on the Russian Revolution, and the utopian dreams released as a result of that event. It’s a commonplace that the revolution unleashed a new imagination of time and the place of the worker. Susan Buck-Morss remarks that: ‘Machine culture, Soviet style, had its origins as the expression of a lack, so that even its brutality could be seen to possess a utopian quality.’ In particular, as the later story from the later Cuban revolution illustrates, the factor of human labor was seen as key to accelerating beyond capital by bringing production under rational control.

Of course, this is a story of failure, violence, and brutality. The extreme suffering caused by these attempts to develop and control production is evident, especially for the peasantry. While in no way wishing to minimize or condone this, we should note that ‘capital comes dripping from head to foot, from every pore, with blood and dirt’. The fact that capital’s processes of control and reproduction are often more ‘indirect’ obscures this historical violence from view, as does the fact that the victors write history. It was the desire to interrupt and develop a different form of production that drove the communist experiments.

Marx had explored how labor-power was the only commodity that generated surplus-value, the only commodity that could exceed its own limit due to its labor-power or potential. Capital, as ‘the moving contradiction’, depends on labor-power to generate surplus value but, on the other hand, it constantly tends to replace labor with machinery. The productive forces are the ‘dead labor’ that had become congealed and encrypted into machines and other devices. Lacking these advanced technologies, devastated by civil war, the new communist regime in Russia was forced to rely on labor. It was this use of living labor that seemed to be able to restore control and human will over the despotism of capital. Placing living labor first could be the first step into a new regime of production.

‘War communism’ was the retrospective name given to the period 1918-1921 in Russia. In the face of civil war, international intervention, and the collapse of production, this was the ‘degree zero’ for the new Soviet society. Trotsky wrote: ‘Russia – looted, weakened, exhausted, falling apart’, and that matters were ‘In the highest degree tragic’. Confronting the weakening of the proletariat through civil war, in whose name the revolution had been made, the new Communist state faced a life-or-death crisis. In response, infamously, Trotsky called for the militarization of labor in his Terrorism and Communism (1920). This call for ‘an exceptional wave of labor enthusiasm’, is often regarded as a kind of hallucination induced by Bolshevik desperation. The usual argument is that the disastrous conditions of war communism were mistaken by the Bolsheviks for the capacity to give birth to communism immediately. In this case acceleration emerged from zero, from radical destruction.

This view is disputed by Lars T. Lih, who argues that Trotsky’s calls for ‘labor duty’ and ‘shock work’ were not driven by fantasies of production, but rather a response to emergency conditions – what Trotsky described as ‘the regime of a blockaded fortress with a disorganized economy and exhausted resources’. That said, some Bolsheviks did see war communism, or would look back on it, as a site on which to radically rearrange capitalism starting from zero. A huge number of experiments and proposals emerged from this period, and continued into the partial restoration of capitalism in the period of the New Economic Policy (NEP) (1921-1928). War Communism, during which money ceased to function and production ground to a halt, seemed to demand new utopias to save the revolution. The period of NEP, although restoring ‘state capitalism’, as Lenin put it, was also a time of relative intellectual freedom and experimentation. So, while not wanting to reinforce the usual image of the Bolshevik leadership as driven by a crazy ‘euphoria’, I do want to trace some of the debates and proposals that tried to restart devastated production in this period and aimed to fulfil the communist dream of offering a superior mode of production to capital.

One of the central points of this debate was the work on ‘scientific management’ of the American Frederick Winslow Taylor (1856-1915), who introduced techniques of breaking down tasks into discrete units to improve efficiency and extract more labor. Writing in 1913 Lenin spoke of Taylorism as ‘man’s enslavement by the machine’. In 1918, however, Lenin suggested that adopting Taylorism, under socialist organization, might offer a progressive measure. This dream of ‘proletarian Taylorism’ was aimed at minimising work by increasing its productivity so Soviet workers could have time to participate in the life of the new regime. The difficulty was that the management required to ensure this ‘scientific work’ would itself become dominant in the Soviet State. The dream of ‘proletarian Taylorism’ remained a dream, but an influential dream.

The lag between the reality of devastation and the desire to embrace new capitalist technologies as the means to create a new communist society produced a contradiction. This contradiction would only become more acute as the European revolutions, especially in Germany and Hungary, were crushed, or failed to materialize. Susan Buck-Morss has argued that the Soviet avantgarde sacrificed the time of the avant-garde experiment, which is a ‘lived temporality of interruption, estrangement, arrest’, for the vanguard time of progress to resolve this contradiction. While this difference between art and politics remained, especially in the dreams of new forms of production, the subordination of experimentation would eventually be completed under Stalinism. I want to suggest something a little different, and rather more disturbing. The time of certain elements of the avant-garde was a time of acceleration, which found itself in congruence with the vanguard desire for the future. While a gap between dream and reality remained, the avant-garde wanted not only to stop or interrupt time, but to force time into the future. So, this was active cooperation, rather than a chosen subordination. In the words of Vsevelod Meyerhold, theatre director and prophet of biomechanics, it was the time to create a ‘new high-velocity man’.

We can trace this desire to close the gap between present and future through the career of the proletarian poet Aleksei Gastev (1882-1939). His work takes the tension of harnessing communism to acceleration to an extreme. It seems to embrace the worst of regulated capitalist work and the alternative utopian re-imagination of work as strange site of freedom at the same time. Son of a school teacher, Gastev had a career as a latheoperator, skilled metal worker, and tram repairman, as well as being a poet. His 1913 ‘Factory Whistles’ is characteristic:

The crowd steps in a new march, their feet have caught the iron tempo.

Hands are burning, they cannot stand idleness ….

To the machines!

We are their lever, we are their breathing, their impulse.

We already have a sense of new speed – the ‘iron tempo’ – and of the integration of the animal body with the machine – ‘we are their breathing’.

This vision of the transformative power of technology explored in his work ‘Express – a Siberian Fantasy’, written while in exile before the revolution. It presents a utopia of Siberia as a machine paradise viewed through the voyage of the express train ‘Panorama’. This is a vision of Siberia laced with factories and roads, of the train ‘drown[ing] man in metal’, which violently reworks nature to human will. It is a world in which Russia will join-up with America to form a technological utopia and the Arctic ice-cap will be melted. A reworking we would now contemplate with horror, thanks to global warming, carried then a dream of peace and plenty, of synthesis between later antagonists.

Gastev was shocked by the backwardness of Russian labor during the Civil War. Yet, he saw the destruction he witnessed as the possibility of a new beginning. In his theoretical text How to Work (1923) he wrote:

Too much is destroyed, much destroyed to the point of madness, to the point that chronology is wiped out, but even more is begun, begun with open naiveté and faith. We have to accept all that, accept it without conditions, accept it as the emotional-political manifesto of the times and give ourselves up to the whirlpool of the new epoch, where the general platform must be bold rationalism.

The end of chronology must be welcomed as the condition to plunge into the ‘whirlpool’ of a new epoch – a new time in which we can rationally grasp and control production. Already, on August 12 1920, Gastev had founded the Central Institute of Labor (1920-1938), and given up his role as poet and as Commissar of the Arts in Kharkhov.

Gastev’s poetic utopian fantasies of ‘machinism’ and the engineering of souls would now be put into practice. The twin prophets for Gastev were Frederick Taylor, with his techniques of scientific management, and Henry Ford, for his creation of mass production lines. These capitalist heroes would become models for a new communist way of working. Gastev’s vision was profoundly anti-humanist:

Soulless and devoid of personality, emotion, and lyricism – no longer expressing himself through screams of pain or joyful laughter, but rather through a manometer or taximeter. Mass engineering will make man a social automation.

It was Gastev’s vision of a mechanized society that would draw the ironic ire of Yvgeny Zamyatin, in his novel We (1921). Zamyatin’s hero D-503 would worship Taylor, like Gastev, as well as incarnating Gastev’s dream of numeric designation for people (Gastev had remarked that mechanization ‘permits the qualification of separate proletarian units as A, B, C, or as 325, 075, or as 0’). Zamyatin would cast as dystopia what for Gastev was utopian promise.

Gastev was not alone. He cited a speech from 1923 by the Bolshevik Nikolai Bukharin to the Komsomol (the ‘All-Union Leninist Young Communist League’), which declared: ‘We must direct our efforts at creating in the shortest possible time the greatest number of specialized living machines that will be ready to enter into circulation.’ The ‘living machine’ is the dream of the rupture of existing production relations and acceleration beyond the limits of capital. The test of communism, in this view, is its ability to transcend and out-produce capitalism. Of course, this seemed to lead to the worst of both worlds: the adoption of the most dehumanizing capitalist techniques of management and the implementation of them in dictatorial and authoritarian form.

Gastev was not simply a prophet of the later Stalinist subordination of humans to production. His work, rather, is poised uncomfortably in the space of the transformation of both machines and labor, as Rosa Ferré suggests:

Gastev’s technical utopia is both an aesthetic concept with connotations of fantasy and sensuality in its praise of the machine, clean glass and steel, and a practical way of thinking aimed at improving workers’ conditions: now to best avoid accidents, economise on labor and improve performance.

His utopia is not predicated on the mobilization and brutalization of labor, such as that found in the use of slave labor under Stalinism. Instead, far from being a machine, animal, or robot, Gastev’s worker is ‘an active, sentient, and creative part of the productive process’. In the spirit of Lenin’s hopes for proletarian Taylorism the total subordination of the worker to work aims to free the worker to dream on the job and to escape the rigours of work as quickly as possible for an active life. The incompatibility of Gastev’s vision with Stalinism would soon become brutally apparent.

Stalin engineered his rise to power after Lenin’s death. In 1928 he launched the first five-year plan, which ended NEP and recaptured the utopian energies of War Communism in the cause of a violently rapid process of industrialization and a catastrophic war on the peasantry. The ‘accelerationism’ of this first five-year plan is evident in that it was completed in four years. The result was a far more radical and destructive reworking of society than had been undertaken between 1917 and 1928, but also ‘the abandonment of all the varied, autonomous revolutionary utopian strivings in favour of the single utopia of Stalinism.’ The historical irony was that Stalin, the ‘conservative’, used utopian tropes against the utopians, insisting on discipline, obedience and conformity to achieve the necessary historical ‘acceleration’ (uskorenie), and ‘slowing the tempo’ (gromozhenie) would become a counterrevolutionary act. This ‘Stalinist jouissance’ offers the masochistic sacrificial ‘pleasure’ of acceleration through submission to labor.

It was now Stalin who would control time, criticising those who tried to go too fast as being ‘dizzy with success’, while also insisting that any slowdown was unacceptable. A Stalinist slogan of time declared that ‘In the epoch of reconstruction tempos decide everything’. Andrei Platonov’s surreal novel of Stalinist collectivization, The Foundation Pit (written in 1930, but only published in 1987), constantly recurs to the term ‘tempo’. The novel concerns the digging of the foundation pit for a future house of the proletarians and the elimination of the kulaks, the ‘rich’ peasants, who are sent downriver on a raft.

It also includes perhaps the strangest attempt to characterize the new Stalinist tempo of shock work. The village blacksmith has as his assistant the ‘unknown last proletarian’ and last instance of ‘residual exploited labor’ on the collective farm: a bear who hammers at the forge. In fact the forge is a ‘shock’ workshop and the bear is not only the last proletarian but also the first shock worker (udarniki). After having been taken around the collective farm to denounce kulaks – in actuality, those who have mistreated him – the bear sees a banner ‘For the Party, for Party loyalty, for the Shock Labor Forcing Open for the Proletariat the Doors into the Future!’ Taking this injunction absolutely the bear begins to hammer out iron at a frantic rate, distressing the villagers as his labor threatens to ruin the iron.

The bear prefigures the destructive excess of ‘shock work’ as the storming of production, by trying to force the door for proletarian future by ‘expending all this furious, speechless joy into the zeal of labor’. Anna Epelboin sees the bear as figuring not only acceleration into the future but also as ‘the agent of ultimate destruction’ who ‘threatens to return the world to primordial chaos’. In Platonov’s vision the Stalinist tempo reverses itself as the revolution turns into its opposite – destruction replaces production, and order is revealed as chaos.

The fate of Aleksei Gastev under Stalinism reflects the impossibility of adapting his utopian acceleration to this new form of Stalinist shock work. Gastev had written a collection entitled Poeziia rabochego udara [Poetry of the Worker’s Blow] in 1918, which some have anachronistically translated as Shockwork Poetry. Gastev’s attempt to rationally control work was, however, contrary to the ‘storming’ of shock work and the destructive chaos that resulted. Certainly Gastev did try to conform to the new regime, but the Stalinists recognized the incompatibility. In 1938 the Central Institute of Labor was closed and Gastev arrested on 8 September of that year, charged with ‘counter-revolutionary terrorist activity’. He was found guilty and sentenced to death on 14 April 1939, and shot the next day. N. V. Ustryalov remarked, ‘The revolution is merciless not only toward those who lag behind it but also toward those who run ahead of it.’

Gastev’s end in Stalin’s prison system also reveals something about this new Stalinist politics of productivity. Kate Brown has demonstrated that much of the ‘work’ of the Gulag, the prison and camp system that camp to dominate the USSR, can be understood as the disciplining and organization of labor. In the absence of a regime of private property, which restricts people’s settlement through the need to earn wages and afford housing, the Soviet regime used various forms of zoning and internal passport controls. The bulk of those incarcerated in the Gulag fell foul of these laws, so as well as providing slave labor the Gulag also served to restrict and control freedom of labor as well. Stalinist ‘politics of productivity’ rescinded the dreamworld of the integration of living labor into the machine, only to replace it with the brutal organization of slave and unfree labor through social regulation and spatialization.

Communist accelerationism, I have suggested, can be understood as the attempt to answer the capitalist dynamic in which living labor (i.e. people) is squeezed out by ‘dead labor’ (i.e. machines). Communist accelerationism tries to answer this dynamic in two ways. First, it tries to reverse the dependence of living labor on dead labor. For Marx dead labor in capitalist society ‘subordinates labor instead of being subordinate to it, it is the iron man confronting the man of flesh and blood.’ Accelerationism, here and elsewhere, answers this problem by fusing the man of flesh and blood with the iron man – integrating man and machine, or person and machine, to fuse and infuse living labor into dead labor. This will mutate into the cyborg fantasy of the ‘man-machine’. Rather than being reduced to the ‘mere appendage’ of the machine, the worker will control and direct the machine, reworking capitalist technology to communist ends.

Second, the machine will be used as a substitute for living labor, but not in the capitalist form which leads to unemployment or the misery of working for the machine. The bonding of living labor and dead labor means dead labor does not replace living labor, but rather they can coordinate and work together. The machine can be used to free-up people to engage in one of Marx’s few positive views of a communist society:

while in communist society, … , society regulates the general production and thus makes it possible for me to do one thing today and another tomorrow, to hunt in the morning, fish in the afternoon, rear cattle in the evening, criticize after dinner, just as I have a mind, without ever becoming hunter, fisherman, herdsman or critic.

This bucolic vision will, ironically, come about as a result of a thorough industrialization and resort to the machine to regulate and minimize labor.

This is the utopian dream of communist accelerationism, in which the seeming horror of the full mechanization of the human is, in fact, regarded as the freeing of labor. We might say, to adapt Lenin, that the formula is Taylor + Fourier = Communism. The techniques of Fredrik Taylor for work-place efficiency will lead to a Fourierist vision of engaged labor and free time. The result of such thinking, however, was ‘in the highest degree tragic’, as the fate of Gastev indicates. In fact the system could not achieve the dream which animated it. In an acerbic description Chris Arthur had noted that ‘The Soviet system was not a labor-saving system but a labor-hoarding one.’ Labor was hoarded precisely to permit the moments of ‘storming’ to meet plan deadlines and this was a result of guaranteed employment. The ‘problem’ was that the labor discipline of capital, of which Taylorism was one influential ideological form, could not operate effectively. Yet, for the utopians of Soviet accelerationism this was the point. In this guarantee new possibilities offered themselves. Of course Stalinism, through the Gulag archipelago, would generate new forms of labor discipline.

The repetitions of this scenario, which we mentioned briefly in regards to the Cuban revolution but which also speaks to the Maoist ‘Great Leap Forward’, would also repeat the tragedy. The new socialist economy would prove much more recalcitrant to serving labor than had originally seemed possible. It is this experience of failure, I would argue, that drives accelerationism to its acceptance and even celebration of the coordinates of capitalism. Rather than attempting to change the relationship of labor and capital, accelerationism celebrates the disappearance of labor into capital. In an uncanny fashion it fuses, as we shall see, elements of the communist dream of accelerationism with capitalism’s own fantasies of self-engendering production.

Thomas Brinkmann’s 1998 minimal-techno track ‘Maschine’, recorded under the name Ester Brinkmann, includes a repeated voice sample that kicks in at 3.18. In German, the voice says: ‘Ich will eine Maschine sein. Arme zu greifen Beine zu gehn kein Schmerz kein Gedanke.’ ‘I want to be a machine. Arms to grab [,] legs to walk [,] no pain [,] no thought.’ The sample is the voice of Blixa Bargeld, lead vocalist of Einstürzende Neubauten, from their album Die Hamletmaschine, which is a score for Heiner Müller’s play of that name. In Brinkmann’s hands the sample repeats the techno trope of machinic acceleration and integration, from Kraftwerk through Detroit to Sheffield, in a semi-parodic fashion. What Nick Land had celebrated as ‘manically dehumanized machine-music’ is here slowed and repeated in a lulling techno rhythm. The sample holds up for critical inspection the exit from feeling and consciousness (‘no pain, no thought’) promised by machinic integration that is, I will argue, the fantasmatic underpinning of accelerationism.

In this chapter I want to explore these fantasmatic and libidinal elements of the promised integration of the human with the machine, which is so prevalent within accelerationism. To do so I will treat two exemplary and widely-spaced moments: the first is Victor Tausk’s psychoanalytic research on the ‘influencing machine’, published in 1919, shortly before his suicide by shooting and hanging in the same year. Freud remarked in a letter, with honesty verging on callousness, that ‘I confess I do not really miss him; I had long taken him to be useless, indeed a threat to the future.’ Tausk’s ‘machine’ would get an accelerationist retooling by Deleuze and Guattari in Anti-Oedipus, shifted from the status of fantasy to the Real of desiring-production. The second moment is Thomas Pynchon’s novel Gravity’s Rainbow (1973), which explores the psychopathology of machinic integration in the context of the Second World War. Pynchon’s novel would be taken-up as one of the texts subject to cybergothic remix by the Cybernetic Cultures Research Unit (CCRU) (which I will discuss in Chapter 4), and read as a manifesto of technological acceleration. My concern, in both cases, is to return to these moments as keys to the libidinal elements of the ideological fantasies of acceleration.

In his seminal essay On the Origin of the Influencing Machine in Schizophrenia (1919), Victor Tausk sketched out the pathological experience of identification with the machine that is suffered by certain schizophrenics. He traced out how in this situation we feel controlled by a machine, which might make us see pictures, produce or remove thoughts and feelings, control our bodies, create strange sensations, or produce physical ailments:

The schizophrenic influencing machine is a machine of mystical nature. The patients are able to give only vague hints of its construction. It consists of boxes, cranks, levers, wheels, buttons, wires, batteries, and the like. Patients endeavour to discover the construction of the apparatus by means of their technical knowledge, and it appears that with the progressive popularization of the sciences, all the forces known to technology are utilized to explain the functioning of the apparatus. All the discoveries of mankind, however, are regarded as inadequate to explain the marvellous power of this machine, by which the patients feel themselves persecuted.

If the apparatus is obscure, so is its operation: ‘the patient rarely having a clear idea of its operation. Buttons are pushed, levers set in motion, cranks turned.’ The black-boxing of technology – in which the functions of a device are made opaque behind an interface, such as in the case of the computer – makes the experience of all machines something like these fantasmatic ‘influencing machines’. This perhaps accounts for our experience of machines as persecutory, as when we bargain with devices in the hope they will work, or violently attack them. It is not only certain schizophrenics who fall under the influencing machine.

Tausk sees this pathological projection of the machine as developing from our alienation or estrangement from our own bodies. The pathology behind this process is due to the formation of the ego – the sense of self that distinguishes us from the world and which is lacking or eroded in the schizophrenic. Tausk argues that the origin of the influencing machine lies in a disorder of the libido at the early stage of narcissism, in which we identify with our own bodies and have no clear conception of the outside world. In particular, following Freud, Tausk sees the problem as being a result of a struggle with homosexual libido – libido directed towards our own bodies. The socially-unacceptable nature of such a desire drives us to project out this libido onto the world.

The child does not initially recognize their body as their own and as separate from the world. Instead they have to gradually recognize all its parts, what Tausk calls the ‘disjecta membra’ (scattered fragments), as parts of a whole and invest libido into the ego as the image of the whole body. Once this has taken place it becomes possible to project this image onto the world. The pathological projection of the influencing machine is a regression to the stage in which we are trying to find our own body through projection. We return to a sense of our body as mere fragments and therefore of a continuity between us and the world. To cope with the experience of anxiety that results as we fail to distinguish ourselves from the world, libido is projected out and then returns to us as persecution: ‘The estranged organ – in our case, the entire body – appears as an outer enemy, as a machine used to afflict the patient.’ The influencing machine is, therefore, ‘a summation of some or all of the pathologically altered organs (the whole body) projected outward.’

When we start to feel our bodies becoming strange we explain this fact by projecting this feeling on to an ‘influencing machine’ which then becomes the ‘cause’ of our bodily alienation. In Tausk’s words we move from ‘the feeling of self-estrangement’ to ‘the delusion of reference’. The machine, however, remains inexplicable. For Tausk this ungraspable machine is a symbol and, more than that, a symbol of our own genitalia. In order to repress this fact we complicate the machine to disguise its symbolism, resulting in the complexity of the influencing machine.

It is this treatment of the machine as a projection that Deleuze and Guattari object to in Anti-Oedipus. For them, machines can only ever be real, in the sense of the Real of productive desire. The Real is capitalized to indicate this is not the ‘real’ qua reality, but rather the excessive force of production that is only ever cooled-off to form the apparently ‘real’. This is a metaphysics of the production of the Real as the Real of production. It is one form of the metaphysics of accelerationism, which can be more widely grasped as a metaphysics of forces – forces of production, of destruction, and human, mechanical and cybernetic forces, that must be welded or melded together into a plane of immanence. For Deleuze and Guattari this notion of the Real as immanent production is neutralized or led astray if, as Tausk does, it is conceived as a pathological symbol.

I want to stay longer with Tausk, however, to put pressure on the accelerationist desire to translate everything into Real production. Both terms – ‘Real’ and ‘production’ – are contestable as libidinal fantasy productions, which is my line of attack. The collapse of fantasy into the Real by accelerationists is, I’ll argue, a sign of fantasy that tries to produce the Real as such. In doing so it evades the problem of the simulacral and fantasmatic notion of production. This is a fantasy of the end of fantasy. It also evades the pathological and painful elements of this identification with the machine, the friction between the body and its integration, that this extreme experience attests to. With this in mind, let’s return to Tausk.

Tausk’s case study was based around ‘Miss Natalija A.’, a thirty-one year-old former philosophy student who believed she was being controlled by a machine operated by her ex-fiancée. The machine took the form of her body symbolized by a trunk having the shape of a lid of a coffin and lined inside with silk or velvet. At first the limbs of the machine were natural, and then merely drawn on the lid of the coffin. The head appeared to be absent. The inner parts of the machine consisted of electric batteries. For Tausk the machine is both a projection of the genitalia and the patient’s body. As the projection gets stronger becomes more like a machine and less like a body to protect her from recognising herself in the machine.

The machine is operated by love objects, as a result of the transfer of libido. In fact in this situation some of our close love objects are also persecuted, which is because we do not distinguish them from ourselves because of our fluid ego-boundaries. So, those who operate the machine are love objects at more of a distance – doctors, lovers, suitors or, as with Natalija A., an exfiancée. The ‘body’ that is projected onto the machine becomes identified with the genitalia, which saturates the body into a libidinal zone. The increasingly unreal machine becomes an image of derealized libido, a receding figure of jouissance.

Deleuze and Guattari valorize this experience as the fragmented multiplicity of the schizo-machine that exceeds the normalized body and normalized ego enforced by psychoanalysts like Freud and Tausk. Against the wholeness and integration preached by psychoanalysis, which they see as the true paranoid fantasy, they try to free up these frozen projections into zones of exchange and interaction. The task of schizoanalysis is not to force the patient to recognize a false projection and return it to the self, but to embrace the possibilities of fragmentation and dispersion that paranoia freezes.

While this offers a useful corrective to some of the normative projections of psychoanalysis, which admits fragmentation and multiplicity only to always insist on return to the ego and structure, it risks missing the anxiety and paranoia that marks the relation of humans to machines, and of humans to the machine that is our body. Instead of exploding paranoia through the accelerationist embrace of the schizo trip I want to follow more closely the problem that the ‘influencing machine’ reveals of our own machinic nature that coincides with the repetitions of labor and production.

Tausk emphasizes the libidinal dimension of this alienation, but we can also see the fear of our own becoming-machine – the machinic nature of our own libido and the increasing penetration of the machine into our bodies. Marx noted that the trend of capitalist production is to reduce us to a ‘mere appendage’ of the machine. In the case of the influencing machine this is literalized as we become libidinally manipulated by the projected machine. The choice to valorize the influencing machine by Deleuze and Guattari speaks to how they welcome this integration – the explosion of the body on the deterritorializing lines or flows of capital. We find the machinic body as saturated libidinal zone. The fantasy of the influencing machine, in contrast, interrupts this smooth circuit of integration, suggesting the fraught zone of transfer between body and machine that never achieves smooth integration.

In his mordant postwar reflections collected in Minima Moralia (1951) Theodor Adorno remarks on the effects of the new technologies of death on our conception of history:

Had Hegel’s philosophy of history encompassed this epoch, then Hitler’s robot-bombs would have taken their place, next to the death-scene of Alexander and similar images, among the empirically selected facts in which the symbolic state of the world-spirit is immediately expressed. Like Fascism itself, the robots are self-steering and yet utterly subjectless. Just like the former, they combine the utmost technical perfection with complete blindness. Just like the former, they sow the deadliest panic and are completely futile. – “I have seen the world-spirit,” not on horseback but on wings and headless, and this at once refutes Hegel’s philosophy of history.

The ‘subjectless’ weapons – the V-1 flying bombs, and V-2 rockets – incarnate a refutation of history as potentially rational process. Today the world-spirit is not a person, for Hegel Napoleon, but a self-steering device. In contemporary terms, we might say the world-spirit is the drone.

In some enigmatic passages of Speed and Politics (1978) Paul Virilio turns to the metaphysics of metempsychosis – the transmigration of souls – to suggest the tension of the loading of the soul on to various metabolic vehicles. Virilio argues that the soul is ‘plural, multiform, fluidiform, coagulated here and there in social, animal or territorial bodies.’ The philosophy or theology of the military class is Gnostic, in that it assumes the ‘powerful’ soul is deterritorialized, fluid and transferable, while the ‘weak soul’ is imprisoned within the body and the world. Virilio likens this powerful soul to the ‘gyrovagues’, wandering and itinerant monks often condemned by the church of the early Middle Ages for their parasitic mobility, selling of fake relics, and gluttony. In this military Gnosticism acceleration is not only the acceleration of the vehicle but the ‘pure’ acceleration of the soul moving smoothly from embodiment to embodiment, and so able to exceed any territorial capture.

For Virilio, of course, this deterritorialization is not to be lauded. It incarnates the nihilistic politics of ‘pure war’ in which global space becomes a playground for these detached souls. Military Gnosticism, which incarnates a fantasy of pure mobility, finds a resonant literary figuration in Thomas Pynchon’s 1973 novel Gravity’s Rainbow. Set during the Second World War, the novel is partly a picaresque exploration of the wanderings of Tyrone Slothrop through the ‘zone’ – the remains of postwar Germany. Slothrop was subject to Pavlovian conditioning as infant, sensitising him sexually to the mysterious plastic Impolex G. This plastic is used in the German V-2 rockets, and thanks to his conditioning results in pre-strike erections and sexual encounters for Slothrop. The conditioning makes Slothrop a machine controlled by the influence of his conditioning: ‘erection hums … like an instrument installed, wired by Them into his body as a colonial outpost’.

Adrift in the zone Slothrop is ‘thrown back on dreams, psychic flashes, omens, cryptographies, drug-epistemologies, all dancing on a ground of terror, contradiction, absurdity.’ (582) This sketches in advance what might have been the adopted research programme of the accelerationists of the CCRU, who operated in the ’90s and which we will encounter in Chapter 4. The absurd accelerative forces of the war fragment and explode Slothrop’s identity, to the point where ‘[s]ome believe that fragments of Slothrop have grown into consistent personae of their own. If so there’s no telling which of the Zone’s present population are offshoots of his original scattering’ (742). One of Slothrop’s (in)consistent personae is the comic-book superhero ‘Rocketman’, which implies already the fantasy fusion of man and machine.

Slothrop is, however, subject to much more profound conspiratorial forces, from industrial cartels to the very way in which ‘[t]he War has been reconfiguring time and space into its own image.’ (257) Pynchon, with tongue as usual somewhat in cheek, suggests that ‘secretly, [the War] was being dictated instead by the needs of technology … by a conspiracy between human beings and techniques, by something that needed the energy-burst of war.’ (521) ‘War’ and ‘Technology’ become forces demanding acceleration and the integration of the human into the suicidal ‘war-machine’. They also code capitalist deterritorialization, as the ‘Manual’, on file in the War Department, states: ‘The true war is a celebration of markets.’ (105) In Pynchon’s pessimistic and conspiratorial view the emergence of great systems of control operate precisely through energy and acceleration.

This reconfiguration takes its terminal form in the human passenger that is integrated into a remaining Nazi V-2 rocket, in an experiment staged by the rocket crew following the Nazi defeat. Of course, in agreement with Tausk, we could hardly have a more phallic fantasy of integration than the V-2. The V-2 is also a cryptic text or symbol, one ‘to be picked to pieces, annotated, explicated, and masturbated till it’s all squeezed limp of its last drop’ (520). The V-2 is phallus as Spermatikos Logos, as endlessly interpretable symbol. Pynchon traces the theologies and heresies that surround the rocket, but never touch its core:

Gnostics who have been taken in a rush of wind and fire to chambers of the Rocket-throne … Kabbalists who study the Rocket as Torah, letter by letter – rivets, burner cup and brass rose, its text is theirs to permute and combine into new revelations, always unfolding … Manicheans who see two Rockets, good and evil, who speak together in the sacred idiolalia of the Primal Twins (some say their names are Enzian and Blicero) of a good Rocket to take us to the stars, an evil Rocket for the World’s suicide, the two perpetually in struggle. (727)

The V-2 generates constant forms of heretical metaphysics, which try and fail to close the symbol around any ‘Kute Korrespondences’ (590).

In fact, the integration of the passenger with the V-2 is not so much phallic as masochistic. The passenger is Gottfried, the lover of Captain Blicero, who Blicero has subjected to masochistic and incestuous rituals. This culminates in Gottfried’s insertion into a special compartment in the V-2 while clothed in a shroud of Impolex-G. The fantasy here, although terminal, carries echoes of Jung’s idea of incest as the possibility of re-birth and individuation, an idea which was also influential on Gilles Deleuze. It also modifies Adorno’s assertion that Hitler’s robot weapons ‘utterly subjectless’. The dream – masochistic in this case – is of the integration of the subject into the futile trajectory of the machine. Unusually, such a conclusion may be more pessimistic than Adorno’s, as there is a subject integrated but they have no role in steering. This is in line with Adorno’s pessimistic conclusions about the nullification of the subject in modernity, but this is a nullification that is welcomed and embraced. In Pynchon’s text the accelerative fantasy of integration reaches a literally terminal point of self-cancellation.

And yet such a conclusion may be just another ‘Kute Korrespondence’, another theology of the V-2. It’s certainly possible, as the CCRU did, to read Gravity’s Rainbow as accelerationist. Rather than a fascist hardening or securing of identity through fusion, here we have dissolution and fragmentation through the fusion with the accelerative technologies of warfare. To use a much abused word, this is a postmodern accelerationism, that explodes or disperses the concentrated force of modernist or avant-garde acceleration. What Pynchon called ‘soul-transvestism’ in V (1963), or the ‘fluidiform soul’ as Virilio puts it, can be loaded or distributed across vehicles, to the point we welcome our own disintegration.

We see a collapsing of fantasy, and also a collapsing of the fictional space, into the Real of production and acceleration. If someone like me should accuse this of a psychotic collapsing of our capacities for language and symbolization then the response can simply be you haven’t really gone all the way… No matter how impossible it might be to imagine or think a pure immanence the appeal to such an experience carries relentless attraction as utopian promise. To put fantasy into action, to realize ourselves as productive machines, to realize our scattering of personality as gateway, is the promise of accelerationism. And yet…

Virilio’s insight into the boarding of metabolic vehicles, reinforced by Pynchon’s provocation, suggests the metaphysical desire for integration and dispersion of human and machine at work in the dynamic of technology, military power, and capitalism. It is this dynamic of dispersion that is often lauded in contemporary accounts of protests and struggles, which are seen as instances of resonance between bodies, including technical bodies, that can resist power. The difficulty is that these metabolic vehicles, which is to say living bodies, risk being occluded by an assimilation of their struggles to the same dynamic by which capitalism insists that we are endlessly transferable and mobile labor. What is lost is a real sense of the friction or resistance of the body against integration into fluxes and flows, as the Real acceleration of struggles is seen as a line of flight from the limits of the State and capital.

The experience of most work is of profound boredom and pointlessness – hardly one of acceleration. Work is the eternal ‘hell of the same’, as Baudrillard put it – repetitive and often ridiculous tasks to no good or even useful end. Accompanying this experience is the erotic reverie, an experience of endless variation and exploration of erotic possibility both at and beyond work in a libidinal acceleration. Those familiar with the most boring forms of work – factory work, office work – will also be familiar with the endless exchanges and discourses about sex. Pornography is passed around, the sexual possibilities of colleagues discussed, and the mind is occupied with the libidinal.

The libidinal fantasies of machinic integration, ‘pathological’ as they are, suggest the utopian merging of libidinal acceleration with an acceleration of labor that is repetitive and machinic. For accelerationists this infusion or melding produces a multiplicity that explodes the limits of the ego in new vital possibilities. The real of production, as desire infuses the machine, ruptures the iterative routines. Work would (finally) be sexy. Although this is a state without feeling or thought, which could also suggest that sex might be worklike…

If, as psychoanalysis suggests, our experience of sexuality is fundamentally repetitive and boring then this fusion does not have to go far. The seeming endlessness of erotic possibilities becomes frozen in the tableaux of our own singular drives. It is the work of the Marquis de Sade that demonstrates this mode of possibility as repetition and, even, as labor. The relentless iterations of the 120 Days of Sodom (1785) produce the deadening sense of timetabled labor, increasing in intensity and activity. Adorno remarks that Sade’s ‘orgies are arranged like mechanical ballets.’ I’m suggesting that we don’t simply confront the integration of fluid and mobile life into deadening and alienated labor, but also the desire to integrate the repetitive and deadening circuit of the sexual drive into the deadening circuit of labor. While accelerationism might promise an integration of desire and labor in a machinic ‘synthesis’ to accelerate the boredom of work it disguises the boredom of desire. Accelerationism wants to enchant sex as something accelerative and machinic, away from the iterative reverie of fantasy.

The fantasy of integration is the fantasy of abolishing fantasy. What accelerationism promises is the integration of the person into machine, of sex into work, and the generation of the Real of production. In this way fantasy as the access to the Real is collapsed into an immersive and immediate experience of the Real without mediation. Although couched in terms of the libidinal, what is extinguished is the libidinal, as accelerationism reproduces the deadening experience of labor as the site of masochistic enjoyment. At the same time contempt is often expressed to actual workers for their failure to fully ‘enjoy’ this situation. The result is an evasion of the deadlock of desire through the claim to immediately access desire and fantasmatically dissolve the deadlock. This is the libidinal fantasy of accelerationism.

There seems to be little place for the modernist linear-dynamics of progression and acceleration that I have traced in the dispersed and slackened forms of postmodernity. Whether futurists, capitalists, or communists, the avant-garde ‘passion for the real’, that tried to accelerate us to new human types, now seems quaint, kitsch, and politically dubious. And yet the dream and reality of speed machines is not merely the province of dubious nostalgia to be found in the remnants of petrolhead macho excess or in the fetishization of contemporary military technologies.

Acceleration, today, passes from the car, the quintessential technology of mass speed and modernity, to the computer. If the car, as Enda Duffy argues, was the lived experience of modernist time for many – a new mass aesthetic, when modernism tended to the hermetic – then the computer plays that role today. It is the computer, especially for those who work with them, that embodies the ‘speed-up’ of labor, as each new model becomes faster and faster (or that is the promise). The Internet provides the ‘one-click’ solution, computers speed-up and slim down, seemingly providing one of the last utopian remnants worthy of any commodity fetishism; the very frustration of a computer slowing down or freezing-up indexes our own internalized demand for speed. The computer also now vectors the alliance of speed and war, as the acceleration of computer processing permits the rapidity of ‘fire-and-forget’ warfare, the drone attack, the militarization of civilian space, and, in US-military jargon, the ‘compression of the kill chain’.

So, the integration of the accelerating man-machine does not simply disappear, but mutates. Fredric Jameson comments:

there are no great utopian texts after the widespread introduction of computers (the last being Ernest Callenbach’s Ecotopia of 1975, where computers are not yet in service). Instead, we have the freemarket deliria of cyberpunk, which assumes that capitalism is itself a kind of utopia of difference and variety.

Cyberpunk is the utopia not only of difference and variation, but also of deliria and acceleration. It is that ‘utopia’ I want to explore, which is rather more durable and robust than Jameson’s dismissal might suggest.

This new aesthetic can be thought of as the attempt to recapture the energy of the classical avant-garde in the slackened time of postmodernity. It is not simply the repetition of the avantgarde, but a mutated and modulated futurism, which, in typical postmodern fashion, straddles between genres, forms, and cultural domains. This is what I will call ‘cyberpunk phuturism’. Certainly ‘cyberpunk phuturism’ has an anachronistic and kitsch ring. The term ‘cyberpunk’ did not really recover from Billy Idol’s album of that title, released in 1993. ‘Phuturism’ is my adaptation via the Chicago Acid House practitioners Phuture, whose ‘Acid Tracks’ (1989) has a claim to be the first Acid House record. That said, perhaps the kitsch element, as we’ll see, reflects something of this aesthetic.

I will focus on three moments: cyberpunk fiction, Detroit techno, and their synthesis in Cybertheory. In line with my general argument I am not interested in simply expressing disenchantment with this avant-garde and celebrating chastened conformity to the ‘democratic’ protocols of the present. Instead, I want to probe these re-tooled forms of accelerationism as a response to the mutations and continuities of contemporary capitalism. Accelerationism is not merely an historical curiosity, but an aesthetic and political attitude that continues to exert a gravitational pull on the present.

The Ur-text of cyberpunk phuturism is William Gibson’s Neuromancer (1984), which is perhaps its most effective manifesto and predicts all its later mutant forms. The novel of cyberpunk science-fiction, and to my mind the only successful work of this form (along with its sequels), it tracks the new shifting forms of cybernetic embodiment. The very technology of ‘jacking-in’ to cyberspace is rooted, within the novel, in the frame of military technologies: ‘“The matrix has its roots in primitive arcade games,” said the voice-over, “in early graphics programs and military experimentation with cranial jacks.”’ Also, the wellknown description of ‘Night City’ as ‘a deranged experiment in social Darwinism, designed by a bored researcher who kept one thumb permanently on the fast-forward button’, prefigures the neoliberal future, and the compulsive attachment to the speed that promises to break the shackles of social confinement. The simile suggests, in the figure of the ‘bored researcher’, that this deregulatory fantasy has more than an element of (anti-) planning and direction, contrary to fantasies of the acephalic market. While speed is the promise of the opening to a new deterritorialized fluidity of social and virtual space – beyond the Fordist social-compact and the ‘static’ segmentations of social democracy – this is no blind process. The historical significance of Gibson’s novel (leaving aside aesthetic judgements) lies in the fact that it is poised between anxiety and endorsement, critical distance and immersive jouissance, in its vision of cyberspace, augmentation and the accelerative disembedding of social relations.

Joshua Clover points out that Neuromancer incarnates the ‘thrill and threat of dematerialization’ that lies at the heart of neoliberalism; the thrill of new fluid forms of accumulation and super-wealth (for a very few), and the threat of obsolescence and abandonment (for many). In Gibson’s novel the thrill lies in the discarding of the ego, ‘de-sleeving’ consciousness, to borrow a term from Richard Morgan’s sci-fi novel Altered Carbon (2002), from its material support. The threat lies in being condemned to the ‘meat’ (the body), and excluded from the delights of cyberspace. This is the fate of the hacker Case at the beginning of the novel, who has had his capacity to jack-in surgically removed as punishment for an earlier entrepreneurial failure. Yet we could rewrite Clover to say that say that the novel’s cyberpunk phuturism also captures the ‘thrill and threat of materialization’. The thrill here is augmentation and integration, from Tally Isham (‘the girl with the Zeiss-Nikon eyes’) to Molly Numbers (with her implanted retractable razor blade implants). The threat is from bad tech, bad surgery, and falling behind the accelerative race to the future. Acceleration into the utopian horizon of capitalism – as a social form of pure drive and accumulation, freed from its dependence on the meat of labor – is always haunted by our obsolescence. Gibson’s novel tracks a capitalist utopia in dystopian formulations, figuring the self literally as the ‘entrepreneurial machine’ that Foucault had already anatomized as the subjectivity of neo-liberalism.

Cutting to another scene, it is, I would argue, Detroit techno that forms one of the most fascinating and most aesthetically successful instances of cyberpunk phuturism. Deliberately couched as a post-industrial Afro-futurism, it aimed to ‘erase the traces’ (in Brecht’s phrase) of the Fordist sound of Motown and to mimic the new robot production-lines that had displaced the remains of ‘variable capital’ (i.e. humans) for ‘constant capital’ (i.e. machines) at Ford. This so-called ‘automation’ was called ‘niggermation’ by radical black workers in the 1970s – the systematic forcing-up of production under unsafe conditions through super-exploitation. They disputed the story of new hitech production, noting that what was happening was often just old-fashioned speed-up on the line. Once again, we might be cautious about the images of acceleration we encounter.

Detroit techno traced the mutating social space of Detroit – from the ‘white flight’ following the 1967 insurrection, the deindustrialization that followed, and its own position in the suburban site of Belleville High, where the pioneers Derrick May, Juan Atkins, and Kevin Saunderson met. Mixing European influences (Kraftwerk, New Order, Depeche Mode, etc.) with the Detroit funk of Parliament / Funkadelic, the result was a singular form that defied the studied reflexes of postmodern collage for an integrated acceleration.

The axes of Detroit techno were an increase in speed (in bpm) from previous forms of disco and House and a stripping-out of the humanist residues that often dominated those forms – not least the voice. The singularity of its aesthetic invention lay in this welcoming of the ‘mechanization’, or better ‘computerization’, of the aesthetic (which had obviously been prefigured by Kraftwerk’s Man-Machine (1978) and Computer World (1981)). The apotheosis of the form, at least as I regard it, is the work ‘It is what it is’ (1988), by Rhythim is Rhythim (aka Derrick May). This was, as one semi-ironic description of the time put it, ‘dance music with bleeps’. Retaining funk, the insistence of Detroit techno had the utopian, if not kitsch, elements of sci-fi futurism coupled to the dystopian fragmentation of the city-space (‘Night Drive Thru Babylon’, as the track by Model 500 had it). Again, the equivocations lay in a sense of abandonment: an escape to the future, escape from labor, or the loss of labor and the collapse of the future into permanent unemployment?

The Detroit electro/techno-duo Drexciya, who emerged in the ’90s, made explicit a longer history of disposable laboring bodies. Their name, as revealed on their 1997 album The Quest, referred to an underwater country populated by the unborn children of pregnant African women thrown from slave ships who had adapted to their underwater environment. This Afrofuturist sci-fi vision placed cutting-edge contemporary techno in contact with the abandoned bodies who ‘escaped’ the fate of slavery and their descendants who labored in Detroit’s factories, before being abandoned by capitalism to destitution, drugs, and prison. Here the future is haunted by the traces of impossible labor, which ruptures with the possibility of an accelerationist continuum. Detroit techno could be re-read, along these lines, as a critique of the ‘smoothness’ of acceleration, by a repetition that disrupts the future rather than the endorsement of accelerationism.

The splicing of these two moments, and the real instance of full-blown cyberpunk phuturism in explicit accelerationist form, can be found in the 1990s work of Nick Land and his allies in the Cybernetic Culture Research Unit (CCRU). This ‘nomad’ (anti-) academic grouping, formed at Warwick University in 1995, couched its ‘disjunctive synthesis’ of the drives of sci-fi and techno through the work of Gilles Deleuze and Félix Guattari, especially their Anti-Oedipus (1972). The aim was to format an avant-garde practice that would explode the limits of 1990s inertia.

The ‘rush’ of this cyberpunk phuturism operated through a new radicalization of acceleration. Vectored through cyberpunk fiction and the post-rave speed-up of Jungle and drum-and-bass, Nick Land and the CCRU’s discourse aimed at maximum intensification into immanence until ‘impending human extinction becomes accessible as a dance floor’. The mass drug experimentation of rave culture was also spliced into this mutagenic remix. It aimed at immersion in immanence that had been, according to Nick Land, already realized in the then-future of 2012 (!). In case of present scepticism we should note Land’s prediction is hyperstitional – a kind of performative fiction, which creates the future it predicts – and that his theorization (according to Land) disrupts linear, chronological time. In the present moment we only have traces of that future – drugs, sci-fi, Jungle, theory, biotech – that prefigures the meltdown to come: ‘as if a tendril of tomorrow were burrowing back.’

The project of this race to the realized future is best captured in Nick Land’s restatement and remixing of Deleuze and Guattari’s original accelerationist formulation. Land gives this accelerationism a deliberately provocative and late-punk antisocialist and anti-social democratic form:

Machinic revolution must therefore go in the opposite direction to socialistic regulation; pressing towards ever more uninhibited marketization of the processes that are tearing down the social field, ‘still further’ with ‘the movement of the market, of decoding and deterritorialization’ and ‘one can never go far enough in the direction of deterritorialization: you haven’t seen anything yet’.

Machinic revolution, in Land’s metaphysics, reaches out to the horizon of absolute deterritorialization – the realized capitalism that has decapitated itself into full-blown immanent marketization.

This posing of the market against capitalism was derived from the historian Fernand Braudel. Obviously markets have preexisted capitalism, and Braudel suggested that capitalism formed itself as a monopolistic anti-market, tying down exchange. For Braudel, however, the virtue of markets was that they were face-to-face, localized and controllable. The problem of capitalism as anti-market, especially financialized capitalism, was that it was speculative, opaque and exceptional. Land mutates this argument to identify markets with monstrously powerful cybernetic forces, which are ‘speculative, opaque and exceptional’. It is these forces of exchange that can resist the stagnations of capitalism. A purified capitalism, shedding the dictates of the State, would traverse to a pure market accelerated out of capitalism altogether.

This theory fed-off the localized economic ‘boom’ of the ’90s in which, at least in the UK and US, regimes claiming some tenuous and residual connection to social democracy instantiated a further deepening of the neoliberal project. It would be this coupling of attenuated social-democracy and neo-liberalism that bred a series of ideological tropes that dominate the perception of that moment, the ’00s, and the present time of crisis. In this discourse it was the ‘left’ (or pseudo-left), and the ‘left’ in State power, that authorized, ratified and exacerbated the excesses of financialization and consumer credit. It was the spending of the State and the public sector, not the excesses of capitalism, which came to be treated as the ‘dead weight’ that is now holding us back from another leap into the future. Politicians of the present can play the austerity card in the elimination of this State and public debt, while accelerationist positions can argue that the only problem was the State itself, which did not unleash these processes far enough. It was the ‘humanist’ residues of State spending that failed to measure up to the anti-humanism of capitalism.

The position of the CCRU, despite its radicalized antihumanism and inhuman immersive promise of capitalism exploding its own limits, resonates with these contemporary ideological claims that capitalism wasn’t really allowed to follow through. In this narrative, the acceleration of capitalism was held back by State spending and State regulation (focused, in the UK, often on ‘health-and-safety’, as in the trope of ‘health-and-safety gone mad’). It was a ‘left’ failure of nerve to go all the way to capitalism (and not all the way to the left…), that leaves us in the situation we find ourselves in.

This story of constrained capitalism was coupled, in the work of Nick Land, to a switch to China as the only State formation really willing to go all the way, or that had already gone all the way, as ‘neo-China arrives from the future’. What China could offer, in its post-Maoist embrace of capitalism, was the final synthesis between Stalinist acceleration (‘shock work’, rapid and violent industrialization), the Maoist ‘great leap forward’, and capitalist acceleration (although, of course, the ultra-left had long argued Stalinism was really a form of State-capitalism and ‘primitive accumulation’). The State-directed excesses of China, in its uncompromising developmental drive, become a utopian element. Hence Land’s decamping from academia to work as a journalist in China was the personal embrace of this trajectory. His more recent toying with the neo-reactionary theories of Mencius Moldbug (aka computer scientist and entrepreneur Curtis Yarvin) renders critique of this latest work superfluous.

The anti-Statism of cyberpunk phuturism is more opposition to particular kinds of State, and makes the demand for a State that is willing to acephalically decapitate itself – in ‘special zones’ – to engage in self-termination (allowing that this is certainly not what the Chinese State is doing). It leaves exposed the toxic core of capitalism, hence its anti-ideological drift, but this exposure aims to reconnect and exacerbate this core to meltdown.

The political vagaries of these aesthetic forms of accelerationism do not fall on the tired tropes of fascism and ‘totalitarianism’, but rather on this difficult and tense imbrication with the dynamics of capitalism. Implicit in cyberpunk phuturism is not only the logic of increased computing speed and power, but also the claim that capitalism is maintaining its dynamic of acceleration first given its most memorable form by Marx and Engels in ‘The Communist Manifesto’ (1848). While we are all familiar with the line that ‘all that is solid melts into air’, the more resonant line for cyberpunk phuturism, especially as articulated by Nick Land, is: ‘[the bourgeoisie] has drowned the most heavenly ecstasies of religious fervour, of chivalrous enthusiasm, of philistine sentimentalism, in the icy water of egotistical calculation.’ Land’s work dissolves the ego in the flows of this ‘icy water’, although the cult of personality that developed around him indicates the paradox of calls to dissolve the ego: some kind of ego has to be there to experience this dissolution into immanent flux and to theorize or report on its own extinction.

This drowning of the ego is closely linked to the question of labor. It is as laboring subjects we are subjected to the ego and it is in the cyberneticization of labor that we are redeemed from the ego. In his text ‘Meltdown’ (1996) Nick Land proclaims: ‘Industrial machines are deployed to dismantle the actuality of the proletariat, displacing it in the direction of cyborg hybridization, and realizing the plasticity of labor power.’ It is this integrated plasticity that reshapes the proletariat from subject of history into disappearing vector of acceleration. The displacement of labor will not be achieved by communism, or communist accelerationism, but through capitalism’s dynamic. Another of Land’s formulations, from ‘No Future’ (1995), paints a more horrifying fate: ‘The full labor-market cycle blurs into meatgrinder.’ Now the fate of labor is not simply to disappear into an accelerated future, but to be processed as if in a meat plant. Land’s statements code the paradox of extinction in-and-through machinic acceleration. The cybernetic machine is at once liberation from the meat and destruction of the meat, resolved in the jouissance of immersion into immanence.

Land’s final theoretical texts, from the late ’90s and then mid’00s, explore non-standard numeric and alphabetic anti-systems. These deeply strange experimental texts, which engage with the QWERTY keyboard and with esoteric Kabbalist number systems, explode into a hyper-rational deliberate non-sense. They continue Land’s project to break with the despotism of Western reason through a parodic hyper-reason, through an acceleration into the iterative. In a strange convergence with the qualitative mathematics of late Futurism, Land became interested in the numerical as a medium of counter-practice, a new technics. I think this could also be considered a response to the digital field of the computer, trying again to inscribe disruptive moments of fatal acceleration within and beyond the accumulative field – releasing the ‘energy’ of numbers.

The bursting of the dot.com bubble on Friday 10 March 2000, which indicated the emptiness of the cybernetic regeneration or reinforcement of the productive forces, didn’t simply wreck Land’s programme. Instead it became more frantic, more intensive, and more weird, as it tried to extract any remaining vestige of dynamism from the series of financial shocks that wash round the global capitalist economy.

The contemporary moment is nicely summarized in Fredric Jameson’s remark from 1998: ‘Stasis today, all over the world … certainly seems to have outstripped any place for human agency, and to have rendered the latter obsolete.’ The failure of agency leads to the accelerationist dream of the reinsertion of agency by the merging of humans and computers in a new technological synthesis. Gopal Balakrishnan, in his recent survey of the deceleration of global capitalism, notes that Fredric Jameson’s account of postmodernism and the excess of global capitalism was initially predicated on ‘unleashed nuclear and cybernetic productive forces’, before ‘the locus of the problem silently shifted to mapping an opaque, pseudo-dynamic world of financial markets.’ At the centre of both is the speed-machine of the computer. We might say that the shift in Jameson’s work is the one not fully taken by cyberpunk phuturism, which remains at the first moment. In fact, cyberpunk phuturism often implicitly posed the first dynamic of ‘cybernetic productive forces’ against the emergent sense of the ‘opaque, pseudodynamic world of financial markets’. This is explicitly the case in contemporary accelerationism’s ambiguous discussion of ‘accelerative’ elements of financial capitalism, such as High-Frequency Trading (HFT).

For all their postmodern panache, cyber-accelerationism was far more concerned with the exploding of opacity, rather than the revelling in the usual clichés of the play of signs or simulacra. In that sense, they do not simply play ‘real production’ against ‘fictional finance’, but rather try to produce the Real as the Real of production and circulation (combining Deleuze and Guattari with Lyotard). That is why I have argued that cyberpunk phuturism is a postmodern ‘passion for the real’, passing through the forms of simulation and semblants to accelerate out and beyond the antinomy of circuit and flesh.

Of course, the difficulty is that it involved a certain attachment to an accelerative dynamic of ‘productive forces’ that proved illusory, although this was something of a material ‘transcendental illusion’ generated by capitalist forms of value. Capitalism’s drive to accumulation, its squeezing of labor, and its penetration of existence through abstraction, shape the conditions of our experience giving rise to a felt experience of dynamism. Accelerationism enhances and celebrates this, but the future it could not grasp was the future of crash and crisis – the terminus of acceleration in the grinding to a halt of the speed machine of capitalism.

This slowing-down did not signal the end of cyberpunk phuturism. Accelerationism is, as we will see, remarkably resilient. In response to the drawn-out moment of crisis, which resists being cast as the punctual interruption to capitalist service soon to be resumed, the attraction of the return to speed is an unsurprising development. This desire can gain purchase precisely through the resistance to the slowing-down of the moment of crisis, and the self-serving and nostalgic language of austerity being deployed as its remedy (‘Keep Calm and Carry On’). Also, the process of creative destruction that is ensuing, to supposedly ‘free up’ capitalism from its own contradictions, can become recoded as a new piercing of existing barriers, including that of subjectivity itself. The accelerationist desire can revel in the apocalyptic destruction caused by the crisis, or used to resolve the crisis, and take this as the sign of a new take-off. If, as Marx said, ‘[t]he real barrier of capitalist production is capital itself’, then cyberpunk phuturism can pose itself as the transgressive desire to surpass that barrier ‘beyond capital’.

The difficulty is that this ‘barrier’ is, in fact, what serves the ‘dynamic’ of capitalism as contradictory social formation. The perpetual desire to purify and pierce the barrier of ‘capital itself’ is encoded within the genetic structure of the capitalist social relation. This leaves cyberpunk phuturism in the uncomfortable position of joining with those attempts by the managers of capital to induce movement and acceleration by removing the dead weight of variable capital. This confluence can be seen as a result of the attempt by cyberpunk phuturism to resolve ‘the moving contradiction’ of capital. It does so by integrating labor or variable capital into constant capital. The potential obsolescence of labor is resolved by a violent sublation into the machine, or more precisely the computer or cybernetic device. Then the constant acceleration of the computer, via increases in processing power, memory, or software upgrades, promises the upgrading of the integrated meat that can finally keep pace with capitalism: Labor 2.0, or 2.1, and so on. We have the ‘immortality’ of labor not as ‘mere appendage’ of the machine, but as integrated within it.

Virilio remarks that: ‘The Japanese Kamikaze will realize in space the military elite’s synergistic dream by voluntarily disintegrating with this vehicle weapon in a pyrotechnical apotheosis; for the ultimate metaphor of the speed-body is its final disappearance in the flames of explosion.’ This is the apocalyptic realization of speed-body indexed to military acceleration (as we saw in Chapters 1 and 3); another realization takes place in the dream of cyberpunk phuturism indexed to capitalist acceleration – the disappearance in integration. The perpetual-motion machine of capital generates the perpetual temptation to cybernetic accelerationism. One more effort, if we are to really speed-up capitalism, one more effort to dispose or displace the drag of labor and the meat. The difficulty, at its heart, is that cyberpunk phuturism gives over to capital a monopoly on our imagination of the future as the continuing intensification of accumulation and the reinforcement of the capitalist continuum.

In a time of crisis, apocalyptic desires and fantasies become pressing and real. Norman Cohn’s In Pursuit of the Millennium (1957) offered a secret history of the periodic emergence of a ‘revolutionary eschatology’ in the Middle Ages in response to a collapsing social order, immiseration, disease, and war. Responding to crisis these dreamers dared to imagine an apocalypse that would turn the world upside down, and create a new heaven on earth in which Princes would bow to peasants. The apocalypse that became real was the apocalypse of repression. During the Peasants’ War in Germany (1524-26) over one hundred thousand peasants were killed and Thomas Müntzer, one of the leaders who, under torture, proclaimed ‘Omnia sunt communia’ (‘All things are to be held in common’), executed. Cohn, an anti-communist liberal, regarded these millenarians as dangerous forerunners of the ‘totalitarian’ movements of the twentieth century and, in the 1970 edition, extended this to condemn ’60s counter culture by linking these medieval protoanarchists to Charles Manson’s death cult. Guy Debord and the Situationists would deliberately re-purpose Cohn, reclaiming these rebels not as symptoms of irrationalism but as forerunners of modern revolution. Apocalyptic desires are ambiguous: at once consolatory fantasies, deferred hopes, and, potentially, spurs to radical re-orderings.

We are living in a time of crisis and potential apocalypse, with the overlapping of the financial crisis, ecological crisis, and the crisis of movements of resistance. This rupture of the capitalist continuum results in an apocalyptic imagination that produces dreams or nightmares of a world ‘cleansed’ of humanity, from 2012 to the History Channel’s Life After People. These fundamentally reactionary fantasies can only imagine redemption of our fallen world on the condition that humanity ceases to exist, or is reduced to the ‘right’ number of the ‘saved’. There is, however, another apocalyptic tone that also runs through radical and revolutionary thought in the present moment: apocalyptic accelerationism.

If the current conjuncture of overlapping crises – financial, ecological, and political – figures the bad side of history at its worst, then apocalyptic accelerationism tries to radicalize the worst. To choose some examples, we have Franco ‘Bifo’ Berardi’s contention that the current crisis is actually the sign of the demise of capitalism under the pressure ‘of the potency of productive forces (cognitive labor in the global network)’; the claim by Angela Mitropolous and Melinda Cooper that the crisis is generated by ‘usury from below … that extended beyond the limits which were tolerable to capital’; and Antonio Negri’s argument that ‘no New Deal is possible’, and so we must go on to more radical demands.

All these thinkers are trying to call for a new inventiveness in the face of crisis and resisting, rightly I think, the usual calls for sacrifice and austerity – calls which usually fall on the victims of the crisis rather than those who caused it. That said, they also imply that by a kind of radical or quasi-Marxist ‘cunning of reason’ the very worst will produce the ‘good’ and remain within the ambit of Marx at his most accelerationist. The desire is, again, to immerse in the destructive element to extract a power that can shatter capitalism. Apocalyptic accelerationism tries to speed the rupture of the capitalist continuum by fusing with it, trying to integrate with forces that exceed control. It is this immanent apocalypse that I will dispute.

We can track the problem of immanence and acceleration through exploring the multiple uses of Marx’s concept of the tendency. This concept makes a key appearance in volume three of Capital, with what Gopal Balakrishnan calls Marx’s ‘notoriously unclear’ reflections on ‘the tendency of the rate of profit to fall’. Marx’s assertion is that this tendency will result, subject to counter-tendencies, in the long-term crisis of capitalism. It has led to a lengthy and vituperative debate, which continues today. I will not address this debate, but instead focus on how Marx’s remarks on the tendency became re-worked into a method of analysis. It is the tendency that is seen as the key to unlock the possibilities of crisis and rupture.

Crucial here is Lukács’s History and Class Consciousness (1923) and his argument, in the central essay on ‘Reification and the Consciousness of the Proletariat’, that the tendency is the key tool in allowing us to grasp the historical process by dissolving the reified appearance of capital. Lukács notes, pertinently to acceleration, that: ‘This image of a frozen reality that nevertheless is caught up in an unremitting, ghostly movement at once becomes meaningful when this reality is dissolved into the process of which man is the driving force.’ The image of ‘reality’, which is at once frozen and in movement, has to be dissolved to reveal the actions of people that generate the world of capitalism.

The tendency has a particularly tricky form – a dialectical form in fact – in which ‘the objective forms of the objects are themselves transformed into a process, a flux.’ (181) This ‘flux’ is no Bergsonian ‘duration’ (durée réelle), which is merely ‘vacuous’ according to Lukács, but a tracing of the ‘unbroken production and reproduction of … [social] relations’. (181) Of course, the tension is that such a dissolution of the (reified) ‘facts’ can easily be regarded as mere speculation detached from reality, which is often the way in which the dialectic has been taken by bourgeois thought, and even by certain forms of Marxism. Lukács recognises that this is a ‘theory of reality which allots a higher place to the prevailing trends of the total development than to the facts of the empirical world’. (183). It is the very immediacy of ‘facts’ which is the sign of their reification, and instead the tendency returns reality to its mediation, to the complex totality that can only be truly registered, and so given ‘empirical’ confirmation, from the standpoint of the proletariat. The method of the tendency is therefore constitutively ambiguous because, necessarily departing from the ‘facts’, it can only be successful if confirmed in and by revolutionary practice.

Of course my brief overview of the contemporary apocalyptic tone would suggest that Lukács is not at all the key reference point. If the current financial crisis has its roots in the breakdown of the Fordist compact in the 1970s and the switch to financialization to deal with dropping corporate profits, then it may not be surprising to find that the contemporary apocalyptic tone is also rooted in that moment. These examples of contemporary post-autonomist thought all take off from the fusion of the work of Negri with that of Deleuze and Guattari. In particular they draw on Negri and Deleuze and Guattari’s re-imagining of the concept of the tendency in the early 1970s. I am not suggesting a simple isomorphism between capitalist base and theoretical superstructure; after all this retooling of the tendency was precisely an attempt to articulate a theoretical means to grasp the precise effects of the economic ‘base’. I am, however, suggesting that we do not simply regard theory as a hermetically-sealed realm that has no relation to economic, political, and social forms. In fact, as will become clear, this is a moment of theoretical reaction and response to the crisis of Fordism.

In the case of Negri, his canonical statement of the method of the tendency is given in his 1971 work ‘Crisis of the Planner-State’. At this point Negri remains within remarkably classical and dialectical terms, arguing that: ‘[t]he tendency gives us a determinate forecast, specified by the material dialectic that develops the factors comprising it.’ In a similar fashion to Lukács Negri correlated the tendency with the viewpoint of the workers and also stressed that:

the procedure of the tendency is far from being rigid or deterministic. Instead, it represents an adventure of reason as it comes to encounter the complexities of reality, an adventure of reason that is prepared to accept risks: in fact, the truth of the tendency lies in its verification.

As in Lukács the tendency is here deliberately pitched between the necessity of departing from the ‘facts’; it is ‘an adventure of reason’, but also returning to a newly re-ordered world through the mechanism of revolutionary verification.

Negri’s practising of this method in the 1970s was predicated on accepting and radicalising the crisis of the Fordist social compact to license a thinking of the imminent and immanent apocalypse of capitalist relations. If capitalism started to rupture the structure of the factory and guaranteed employment then one should not regret this and go backwards to some lost world of social democracy, but push the tendency further into exodus, sabotage, and destruction of the ‘fetters’ of the remnants of Fordism. This is a form of the accelerationism of struggles.

The implication of his work, reflecting on the crisis of Fordism and its ‘planner-state’, was that communism had already arrived and would need to simply be realized. Negri was obviously ‘prepared to accept risks’, and the uncharitable could say that his own reading of the tendency fell victim to the failure of verification, with the defeat of the movement of autonomy and Negri’s imprisonment. This failure did not, however, lead to a further nuancing of the method of the trajectory in his work. In Empire (2000), co-written with Michael Hardt, Negri would exchange the ‘encounter with the complexities of reality’ for an ‘adventure of reason’ in which the tendency was flattened further into the pure immanence and positivity of communism.

In a case of unlikely bedfellows, Alain Badiou, in his 1982 work Theory of the Subject, also makes recourse to the method of the tendency:

To the logic of the trajectory, which the structural dialectic comes up against and which announces the new only in the retroactive operation of its mise-en-scène, we oppose the logic of tendencies, of currents, of vanguards, wherein that which is barely at its birth, though placed and subjected, links up with the most terrible force of the future.

Badiou’s presentation of a contrast between the ‘logic of tendencies’ and a quasi-structuralist ‘logic of the trajectory’ is cast in surprisingly Lukácsian terms – considering that they are not usually seen as compatible figures. Badiou’s comment that in the logic of the trajectory ‘[t]ime is extinguished by space’ (108), could easily be mistaken for a quotation from Lukács.

Badiou identifies a deviation intrinsic to the logic of tendencies, which is that practised by ‘the dynamicists’ who ‘posit … the multiplicity of variable intensities’ and ‘who believe in the insoluble tendency.’ (209) These thinkers, and Badiou obviously has in mind Deleuze and Guattari, emphasize the priority of the flowing tendency over any objective moment. In Badiou’s brilliant piece of diagnostics: ‘[t]he asymptotic perspective of flight makes of the empiricist a wandering materialist, a vagabond philosopher of natural substances. Ignorance of the mirror turns the empiricist into the mirror of the world.’ (209) Badiou’s contention is that in their haste to depart from the ‘static’ or reified forms of capital’s logic of economic and political places the dynamicists, ironically, end up reflecting the accumulatory and accelerative logic of capital.

In this way Badiou produces a critique of accelerationism, as a ‘vagabond’ method that tries to accelerate and rupture with the capitalist world, while falling back into it. The accelerationist believes in a possible fusion with ‘the insoluble tendency’ to produce a new immanent rupture. Badiou’s answer to this problem is that we have to zigzag between the logic of trajectories and the logic of tendencies so they each correct the other. Those who emphasize a static logic of the trajectory and the necessity of patient analysis of the world as it is prevent us from rushing into revisions of our method that would leave it detached from reality. At the same time the dynamicists provide a necessary sense that we must take risks with the method and cannot simply follow the contours of reality. Although not consistently developed in his later work, Badiou’s suggestion provides a useful means for ‘balancing’ between those sorts of pessimistic analyses which suggest an all-encompassing capitalism that always allocates people to their ideological place (as we find in certain moments in Althusser, Adorno, and contemporary value-form theorists like Moishe Postone), and those optimistic analyses that always stress ‘resistance comes first’ and the imminent arrival of a new era of flux and freedom (precisely Negri, Deleuze and Guattari, and even certain moments in Jacques Rancière).

Badiou’s criticism of Deleuze and Guattari and his suggestion that we practice a method of the tendency that does not embrace the perspective of ‘flight’ makes it no surprise that he should later vehemently reject Negri’s own variant of accelerationism:

As is well known, for Negri, the Spinozist, there is only one historic substance, so that the capitalist empire is also the scene of an unprecedented communist deployment. This surely has the advantage of authorizing the belief that the worse it gets, the better it gets; or of getting you to (mis)take those demonstrations – fruitlessly convened to meet wherever the powerful re-unite – for the ‘creation’ and the ‘multiform invention’ of new petit-bourgeois proletarians.

Badiou notes what we earlier gestured towards: the tendency is taken by Negri as the immediate fusion of reason and reality in one Spinozist ‘historic substance’. What is lost is any nuancing of the tendency, any real sense of the tendency as riven by contradictions, tensions, and reversals. The implication of such a reading of the tendency is that crisis is not to be reined in by the rationality of socialist or communist planning, but exacerbated by new forms of flight and flow – truly we haven’t seen anything yet.

Perhaps the best indication of the fatality of Negri’s ‘mirroring’ of capital is his constant stress that the revolutionary movements of the 1960s and 1970s were successful. Negri argued that the recuperation of the revolutionary impulses of the 1970s was not a sign of defeat, but of actual communist success lurking beneath the rotted carapace of capital. One more effort and the fetters of capital would be shaken free releasing the communist content within. This perpetual chant can crescendo at the onset of any crisis. Paolo Virno, in contrast, and rightly in my view, argued that the defeat of the revolutions of the 1960s and 1970s led to a ‘communism of capital’; rather than a hyper-capitalism leading to communism, instead capitalism recuperated and redeployed communist elements (abolition of wage labor, extinction of the state and valorization of the individual’s uniqueness) for its own purposes. Negri, in contrast, magically parlays defeat into victory.

Of course the criticism that Negri’s theorization of the multitude is a ‘mirror of capital’ is not particularly original. My concern is not simply to point out the possible confusion of a supposedly communist apocalypse with an actually capitalist apocalypse. Instead, another, more important, irony is at work in this apocalyptic accelerationism. Gopal Balakrishnan has recently raised the more classical form of the tendency by returning to Marx’s speculations about the tendential limits of capitalism. Deleuze and Guattari had argued that Marx’s contention that ‘[t]he real barrier of capitalist production is capital itself’ did not so much indicate that capitalism was doomed by its own limits of accumulation, but rather that this barrier should be smashed by the radicalization of capitalism’s deterritorializing tendencies. Balakrishnan, instead, returns to the implied meaning of Marx’s barrier metaphor that capitalism actually ‘undermin[es] the original sources of all wealth’. He notes that the ‘acceleration’ of capitalism since the 1970s, especially its technological developments of new cybernetic production forces, did not indicate some ‘exhilarating new cultural condition’ but rather ‘[c]apitalism’s culture became an organized semblance of worldhistoric dynamism concealing and counteracting a secular deceleration in “the real economy”.’

Contemporary accelerationism is predicated on economic deceleration – there is a disjuncture, or even inversion, between the superstructure and the base. The ‘mirror’ of accelerationism is, as in Marx’s (1845) famous metaphor of ideology as camera obscura, in fact an ‘upside-down’ image of ‘historical life-processes.’ Although claiming to track the tendencies the analyses of the accelerationists took appearance for reality, or to put it in more precise Marxist terms could only grasp the ‘real abstractions’ of the capitalist form of value. While these ‘real abstractions’ truly are real, they shape and determine the forms of value, they lack the dynamism that accelerationists detected, and which such forms had, of necessity, to project. This is what makes Deleuze and Guattari’s analysis of capital as an axiomatic machine or virus of deterritorialization at once so resonant and so problematic.

Balakrishnan is amusingly scathing about the supposed technological and economic achievements which might be thought to give material substance to these speculative flights:

the innovations of this period of capitalism have powered transformations in the Lebenswelt of diversion and sociability, an expansion of discount and luxury shopping, but above all a heroic age of what was until recently called ‘financial technology’. Internet and mobile phones, Walmart and Prada, Black-Scholes and subprime – such are the technological landmarks of the period.

Certainly Balakrishnan indicates the danger of a tendential accelerationism taking a particular projected tendency of capital, or even the fantasmatic self-image of capital, for its reality. Of course, part of the ‘drive’ of contemporary accelerationism is to overcome this inertia in the name of Real forces of acceleration.

It is this fact that accounts for the persistence of accelerationism and its hyperbolic verve. Against ‘Walmart and Prada, Black-Scholes and subprime’ it restates the promise of the ‘insoluble tendency’ of the development of forces, both technological and human. These are melded in the concept of the ‘cognitariat’, the ‘new’ cognitive and affective workers who fuse together the capacities of the human and technological in an immanent matrix. Instead of this fusion I am arguing for a necessary detachment from this image of dynamism in which history is on our side. The method of the tendency needs correction in terms of charting more closely the forms and forces of contemporary labor and modes of struggle, rather than an apocalyptic assertion of some final unveiling of forces (the Greek meaning of the word ‘apocalypse’ is the ‘lifting of the veil’). Apocalyptic accelerationism reverses T.S. Eliot’s assertion that the world will not end in a bang, but a whimper. The promised bang, however, has not materialized in quite the right form.

When I talk about shit, it is hardly a metaphor: Capitalism reduces everything to shit, that it to say to the state of undifferentiated and decoded streams out of which everyone has to take its part in a private mode and with a sense of culpability. Félix Guattari

Things are shit. Terminal accelerationism, however, sees this shit as what Alain Badiou calls ‘nourishing decomposition’; as the chance to break through the sterility of a failed capitalism and leap into a new future. I want to analyse, or anal/yse, this ‘excremental vision’ as one of the signature forms of contemporary accelerationism. Rather than the relentless positivity of thinkers like Deleuze and Guattari, or Negri, here the path of acceleration lies in the negativity and nihilism of capitalism. We’ve already seen that Jean Baudrillard is one of the key figures of this form, but I want to return to two earlier moments to track the convergence of the negative and the apocalyptic. These are the 1930s work of Georges Bataille and Jean-Luc Godard’s 1967 film Weekend. If the car was the model of modernist speed then Godard’s Weekend, with its famous single tracking shot of a traffic jam lasting over eight minutes, suggests the terminus of that model. The film also bears the intertitle ‘A FILM FOUND ON A SCRAP-HEAP’, which we could rephrase as ‘A FILM FOUND ON A SHIT-HEAP’, considering its staging of a veritable scatological apocalypse.

Godard’s film makes an obvious reference to Georges Bataille. The image ‘anal/yse’ appears before Corinne’s monologue – a fantasy, or nightmare, or reality – which describes sex scenes that deliberately mimic the anal eroticism of Bataille’s 1928 novel Story of the Eye (and which makes it to wikipedia’s cultural references for the film). We could also add the more esoteric reference that ‘Emily Brönte’ appears as a character in the film and one of the ‘case studies’ in Bataille’s Literature and Evil (1957) is dedicated to her work. At a more general level we could say that Godard develops Bataille’s ‘heterological’ vision, which Bataille articulated in the 1920s and 1930s, of ‘an irruption of excremental forces’ that void value. In Bataille’s excremental Marxism the revolution erupts from the ‘materialist bowels of proletarians’ (35), while class struggle, for Bataille and Godard, is an excremental apocalypse in which everything turns to shit.

This shit forms a site of equivocation and reversal: from an anal capitalism of crisis and waste to a revolution that will accelerate beyond the ‘limited’ waste capitalism produces, which is always subordinate to value. In this way accelerationism can weave together the apocalyptic possibilities of the productive forces and the apocalyptic possibilities of destruction. If capitalist crisis operates, as the Austrian economist Joseph Schumpeter argued, by periodic bouts of ‘creative destruction’, then this form of terminal accelerationism aims to exceed capitalism on its own ground.

In an article of 1929 titled ‘The Language of Flowers’ Bataille writes, apocryphally as it unfortunately turns out, of

[t]he disconcerting gesture of the Marquis de Sade, locked up with madmen, who had the most beautiful roses brought to him only to pluck off their petals and toss them into a ditch filled with liquid manure – in these circumstances, doesn’t it have an overwhelming impact? (14)

The impact of Sade’s gesture for Bataille is that it confirms his invocation of ‘base materialism’ as that which returns to excrement to void beauty and value. This is why Bataille would chide Nietzsche for being ‘altogether incapable of wallowing in the mud’ (39). Unlike Nietzsche’s attempt to constitute the possibility of the overman (übermensch), Bataille’s vision was of the ‘underman’: of dragging ‘man’ down into the excrement.

In the 1920s and 1930s Bataille developed what he would later call a ‘general economy’, which ‘founded’ itself in the excremental, the perverse, and all the elements that could not be coordinated with utility, and which ruptured the restricted economy of capitalism. I don’t think it is a coincidence that he should develop this theory at the same time capitalism entered into worldwide depression after the Wall Street Crash of 1929. This ‘heterology’ functioned as a ‘cloacal’ critique that targeted the stabilizations of value accumulation and labor. Bataille’s materialism not only ruptured the image of a stable economy, but also the image of stable matter. For Bataille materialists were too-often guilty of turning matter into a ‘dead God’ by simply reversing the place of matter from below to above. In contrast Bataille argued that the disruption of ‘senile idealism’ required we see matter as unstable, active, and excessive (15). We have to drag all ideals and values down into the mud.

Of course, as Jean-Joseph Goux points out, Bataille’s economy of excess might have had traction on the asceticism of the Protestant ethic of a capitalism committed to accumulation but it seems to have a strange congruence with a ‘postmodern’ capitalism of excess. Even Bataille’s proximity to the Wall Street Crash signals this ambiguity, as capitalism enters into its own voiding and destruction of value only then to restart in a destructive war economy. If we read the life story of Don Simpson – the producer of so-called ‘high concept’ films during the 1980s and early ’90s, such as Beverly Hills Cop (1984) and Top Gun (1986) – we can see how a transgressive world view conforms to capitalism’s fantasmatic self-image as liberatory and excessive. Simpson’s punishing regime of excess – from drugs and prostitutes, to exercise and plastic surgery – involved him working on the very materiality of his body to make himself the ‘perfect’ capitalist subject. We could also turn to the more quotidian fact that those abandoned by capitalism, as ‘surplus humanity’, often live, literally, in shit. Instead of the excremental and perverse setting out some alternative space to capitalist modernity it becomes coded within it, as its inherent and licensed transgression, and hence reconnected to value production but at the level of ‘pure’ speculation and excess. The so-called ‘sound investment’ can turn into excrement, but also excrement or waste can suddenly become a speculative resource.

The impasse of Bataille’s critique is not only that it has been outpaced by a ‘cloacal’ capitalism, a capitalism that thrives on excess and waste. The more damaging problem is that it conceives this excess or waste as the site of a new production, which hardly seems to break with capitalism. This is an inverted or negative productivism, which accelerates destruction to a ‘higher’ level of solar excess – a terminal acceleration. This productivism makes it hard to see how Bataille can be used, as Baudrillard wished, to shatter the ‘mirror of production’. Bataille is equivocal. While it’s true he can be read as hymning a new form of production, his work also insinuates a crisis within production. It is not so much that Bataille is offering an alternative principle of waste, but that his undermining production from within, eroding or sapping its capacity. His use of the figure of the ‘rotten sun’ suggests this equivocal undermining of solar excess by dragging down excess into a rotten base matter (57–58). Bataille attempts the impossible task of thinking elevation together with the sudden downward fall.

Bataille’s line of flight along the excremental demonstrates the difficulty of the attempt to find an absolute resistance to accelerationist and productive dynamics. If we erect a principle of waste then we can find that principle reversed into a ‘nourishing decomposition’. Bataille’s ‘solution’, which doesn’t exactly solve the problem in the traditional sense, is to suggest a reversible moment that lies within any ‘productive’ discourse or practice. In this moment the negative and positive can suddenly, and catastrophically, shift places. The difficulty remains, however, of extracting this possibility from the shifting ‘dynamics’ of contemporary capitalism.

Godard’s Weekend concerns a bourgeois couple, Roland and Corinne, who are driving to Corinne’s father to collect her inheritance. Both have secret lovers, both are plotting to murder each other, and both are happy to murder Corinne’s father if necessary to claim the inheritance. Their journey through France rapidly descends into anarchy as the bourgeois social-order falls apart around them. Here the excremental is revolutionary – the apocalyptic crisis of the bourgeoisie. Godard casts this crisis in the satirical form of cannibal revolutionaries – the ‘Seine-et-Oise Liberation Front’ (FLSO) – who dominate the closing sequences of the film. Quasi-hippy revolutionaries, dressed in parodic Native American costume, the FLSO provide a literalization of the metaphor of ingestion, not so much digging the grave of the bourgeois world as consuming and voiding it.

In fact, as Godard’s film registers, this ‘excremental vision’ is split: we have the revolutionary anality of Bataille, in which the heterological forces open a reenchantment and resacralization of reality, but also the anality of capitalist production, with its cycles of digestion and voiding in ‘creative destruction’. Godard reproduces explicitly the tension we noted in Bataille, in which revolution and creative destruction intertwine and merge in new forms of destructive consumption. In fact the cannibal is at once the irrecuperable figure of extremity and the figure of an auto-consumptive capital.

Norman O. Brown’s Life against Death (1959) analyses this split vision in his, now contested, reading of Jonathan Swift. For Brown, Swift’s ‘excremental vision’ reveals the anality of culture and the psyche. In Brown’s words, ‘for Swift [scatological imagery] … becomes the decisive weapon in his assault on the pretensions, the pride, even the self-respect of mankind.’ And yet the revelation by Swift of the excremental core that wrecks human dignity is also the historical revelation of the anal economy of capitalism itself. Eli Zaretsky notes: ‘Capitalism at root, Brown argued, was socially organized anality: beneath the pseudo-individuated genitality of early modern society, its driving force was literally the love of shit’. The chapter on Weekend in the discussion between Kaja Silverman and Harun Farocki on Godard is titled ‘Anal Capitalism’.

If the excremental is under the sign of the sacred then it displays the typical equivocation of the sacred: revolutionary or bourgeois, terminal regression or rebirth? If the ‘driving force’ of capitalism is ‘the love of shit’ then this ‘driving force’ is appropriately figured in the equivocal status of the car, which in Weekend is both ‘treasured commodity’ and ‘worthless junk’. The ‘weekend’ break from production leads to the heterological space of stasis, in which production is reversed into voiding; the traffic jam is the blockage of this driving force, the indigestible moment of failed flow and the accumulation of the excremental. The famous long tracking-shot of the traffic jam, as Brian Henderson points out, finds its future echo in the tracking-shot of the car production-line in British Sounds (1970). Again Godard plays on the reversal of production and destruction, production and anti-production, value and waste. He injects, as Bataille did with his thinking of instability, an oscillation into this vision of excremental vitalism.

The equivocation of the ‘driving force’ of capitalism – the question whether this anal economy of incorporation, digestion, and excretion that Bataille traces can be derailed into an ecstatic and apocalyptic voiding – is redoubled in the moment of the scatological apocalypse. We equivocate on the waste of a decomposing culture. Does Godard offer us ‘a nourishing decomposition’, are we merely mired in the scrap-heap? In Swift’s words, will we find ‘Such gaudy Tulips rais’d from Dung’? Weekend implies is that we no longer have socialism or barbarism, but barbarism per se; but it is this barbarism that seems to be the only way to socialism? Harun Farocki argues that: ‘there is the suggestion that under the thin veneer of this “civilization” beats the heart of a more affectively vital “barbarism.”’ For Godard’s ‘revolutionaries’, ‘We can only overcome the horror of the bourgeoisie by even more horror.’ This could well be the motto, avant la lettre, of terminal accelerationism.

The lesson of Weekend, which is why it resonates in the present moment, is that an excremental vitalism emerges in terminal crisis. In Bataille’s formulation, the revelation of ‘a disagreeable and terminal stagnation’ destroys ‘the prestige of industrial reality’. This is the promise that, as Robin Wood puts it, ‘Weekend is not about the end of the world – it is simply about the end of our world.’ In a rather touching remark, Wood continues: ‘The film postulates, rather convincingly, the irrelevance, uselessness, and ultimate disintegration of everything I have always believed in, worked for, and found worth living for, and I don’t think I can be unique or even unusual in this.’ The apocalypse is limited to the end of the bourgeois world, and out of the shit the rebirth of a new vital order.

The horror of vital barbarism predicts a new impassioned future. This chimes with the remark of the nineteenth-century socialist William Morris, after reading Richard Jefferies apocalyptic novel After London (1885), that:

I have no more faith than a grain of mustard seed in the future history of “civilization”, which I know now is doomed to destruction, and probably before very long: what a joy it is to think of! and how often it consoles me to think of barbarism once more flooding the world, and real feelings and passions, however rudimentary, taking the place of our wretched hypocrisies.

Barbarism is regeneration. The difficulty is that Godard represents the ‘new world’ as one of stasis and drift and not a world of ‘real feelings and passions’. The cannibal revolutionaries feast on the remains of the old order, literally, and live lives that are hardly passionate.

While the promise is that one world will end in horror to give birth to a vital and passionate new world, presumably without horror, it seems unlikely, in Godard’s film, that horror will peaceably disappear. Although Weekend appeared just before the events of May ’68, which would reinvigorate ‘the passion for the real’, in Godard’s film this revolutionary passion takes the terminal form of cannibal extinction. His cannibal revolutionaries are studied hippie primitivists, who play drums, rape their captives, and are served their meals by the cook in blood-stained apron. The dialectic in the revolutionary ‘passion for the real’ between voluntarist vitalism and historicist confirmation is ruptured in Godard’s film through a regression. In this regression ‘vitality’ detaches itself from history and pulverizes history into a mythic space of social degree-zero and auto-consumption.

If capitalism is all shit, if we have an ‘anal capitalism’ that levels all into general equivalence, then the end of everything is required in a final voiding. The apocalyptic tone is required prior to some ‘future’, a full decomposition to consume that rotting culture. Godard, as Silverman notes ‘launches an extended assault upon all forms of abstraction.’ With abstraction, itself the organization of levelling and equivalence through value, voided, we have what appears to be another abstraction of absolute barbarism. This voiding and levelling of abstraction takes its own revenge, as a kind of capitalist nihilism or exhaustion that turns the film once again into shit. The signs equivocate again, and the ‘liberation’ of the anal, of the ‘excremental forces’, is, to again quote Silverman, ‘not the utopian sexual liberation hailed by Hocquenghem thirty years ago, but the catastrophic end of all singularity. What we might call “anal capitalism” decrees the commensurability of “male” and “female,” but only by consigning both, along with Weekend itself, to the cosmic scrap heap.’ The apocalypse reveals then not another revolutionary order, the film as gate to May ’68 which redeems its hippy-cannibal revolutionaries into the ‘good hippies’ of libidinal revolt, but watched again at the point of the voiding of the capitalist order in crisis, seems also to reveal a terminal levelling of capital itself.

Does the equivocation of satire have to be met with a full politicization to escape the relentless dialectic of reversal between satire and object? For Godard Weekend was his last film before the collective experiment of political filmmaking the Dziga-Vertov Group. Writing in 1973, Thomas M. Kavanagh argues Godard’s turn to explicitly political and didactic cinema as the only possible response to the fact that the bourgeoisie adored Weekend. The commercial and critical success of Weekend would lead Godard to depart for the austerity and collective practice of his explicitly political filmmaking of the early 1970s.

Recuperation and re-digestion; an anal biopolitical economy à la Pasolini’s film Salo (1975) beckons. The irrecuperable ‘foreign body’ becomes an object of jouissance, of self-disgust that returns to bourgeois narcissism. Revolution itself is circular: ‘There is even the familiar suggestion, rendered concretely in the film in terms of similarities and parallels in their rituals – eggs and fish between girls’ thighs – that the revolutionary society will be another formulation of the murderously bourgeois one we knew already.’ Godard’s escape out of this circle of consumption was an indigestible political austerity that could not, he felt, be capitalized on.

And yet the collapse of Godard’s political certainties and those of his critics re-locate the satire or parody of Weekend in our moment: the Weekend of crisis, the bursting of the bubble, abandonment of house and car as debt-loaded ‘hostile objects’. Excremental or cannibal hostility now shapes the decomposing culture of capitalism. The impasse of Godard’s film was to be saved through political praxis, but the decomposition of capitalism and of that praxis makes the ‘levelling’ of Weekend if not ‘radically funny’, at least necessary again. In this way it is the terminal document of negative accelerationism. It is at once its most extreme satiric form, but tips over into the abstract voiding that figures our moment.

Fredric Jameson, reflecting on the contemporary moment, comments that:

we may pause to observe the way in which so much of left politics today – unlike Marx’s own passionate commitment to a streamlined technological future – seems to have adopted as its slogan Benjamin’s odd idea that revolution means pulling the emergency brake on the runaway train of History, as though an admittedly runaway capitalism itself had the monopoly on change and futurity.

In light of the persistence and resurgence of accelerationism Jameson’s characterization of the contemporary left is dubious. Acceleration hasn’t gone away, and Jameson’s own retooled productivism is part of a ‘passionate commitment to a streamlined technological future’ that persists and even increases at our moment of crisis.

I want to pause on Jameson’s reference to Walter Benjamin’s ‘odd idea’ that revolution might be an act of deceleration, interruption, or stopping the ‘runaway train of History’. This obviously suggests a counter to accelerationism. The reference is to the notes for Benjamin’s 1940 essay ‘On the Concept of History’, where he writes: ‘Marx says that revolutions are the locomotive of world history. But perhaps it is quite otherwise. Perhaps revolutions are an attempt by the passengers on this train – namely, the human race – to activate the emergency brake.’ For Jameson, obviously, this conception is an ‘odd idea’ because it is a failure to measure up to Marx’s own embrace of capitalism, and capitalist production, as the condition of revolutionary change.

Benjamin’s ‘odd idea’ had an explicit context. This was the critique of German Social Democracy, especially in Thesis XI of ‘On the Concept of History’, where Benjamin chided it for ‘moving with the current’. The conformity of Social Democracy to the ideology of progress and acceleration, and not least technological progress, meant that it was unable to grasp the dynamic of fascism and unable to critique capitalism effectively. Beyond this historical argument I want to suggest that there is something more to Benjamin’s ‘odd idea’, both then and now.

If we return to Benjamin’s work we can see that it is closely engaged with questions of acceleration and production, especially in his dialogue with Bertolt Brecht. After they met in the late 1920s Brecht and Benjamin engaged in an intense debate over how to subject capitalist production to ‘refunctioning’ (Umfunktionierung). While this took place in a very different historical context – the failure of the revolutionary wave after 1917, inflation in Germany and global capitalist crisis, and the rise of fascism – the Brecht/Benjamin debate resonates in our moment. Invocations of Weimar, the 1929 Crash, and anxieties of incipient fascism or war, have become familiar tropes in commentary on our crisis. This is a rather speculative connection, but Brecht and Benjamin offer resources to interrupt a capitalism locked-into crisis and destruction.

Gershom Scholem suggests that Brecht entered Benjamin’s life, in 1928, as an ‘elemental force’. We can read this ‘force’ as Brecht’s insistence on the reworking of production. When Benjamin came to know Brecht in the early 1930s, Brecht was articulating his critical practice of cultural and political production to come to terms with the crisis-ridden and destructive effects of capital, in the wake of 1929 and the experience of German inflation.

A key statement is Brecht’s poem ‘The Proletariat Wasn’t Born in a White Vest’ [Das Proletariat ist nicht in einer weissen Weste geboren] (1934). The poem presents a litany of capitalist decline, before concluding: ‘oh, on that day the proletariat will be able to take charge of a /culture reduced to the same state in which it found production: in ruins.’ The proletarian is not the ‘clean’ modernist new man, but is willing to get his or her hands dirty. This is the only class able to grasp and resolve the ‘dirty’ ruins of capitalism. Alain Badiou argues that Brecht’s poem is founded on the ‘essential thematic [that] the new can only come about as the seizure of a ruin. Novelty will only take place on the basis of a fully accomplished destruction’. The proletariat dirties itself with completing the work of destruction on capitalism, but in the service of a new communist production. The ruin of capital is what Badiou calls a ‘nourishing decomposition’.

Brecht is suggesting the re-use of the ruins of capitalism, and this can take provocative forms. Like the Soviet avant-garde Brecht is not afraid to engage with the worst elements of capitalism:

Behaviourism is a psychology which begins with the needs of commodity production in order to develop methods with which to influence buyers, i.e., it is an active psychology, progressive and revolutionizing kathode (Kathoxen). In keeping with its capitalist function, it has its limits (the reflexes are biological; only in a few Chaplin films are they already social). Here, too, the path leads only over the dead body of capitalism, but here, too, this is a good path.

Brecht’s ‘refunctioning’ turns on the most extreme forms of capitalist technology as the means to find a ‘good path’ over the ‘dead body of capitalism’. We have to traverse what Benjamin calls ‘the dirty diapers of the present.’ Again, what is crucial here is not just the ‘dirt’ or waste produced by capital but, as we saw with terminal accelerationism, the need to dig into this dirt to produce the new.

In his ‘Conversations with Brecht’ Benjamin mentions ‘the destructive aspect of Brecht’s character, which puts everything in danger almost before it has been achieved.’ That Brecht is one of the models for Benjamin’s essay ‘The Destructive Character’ (1931) is, by now, a commonplace. Brecht’s ‘destructive character’ provoked Benjamin to think about destruction and production. While the Benjamin essay can be taken as a manifesto for destruction, it is also a manifesto for the retooling or refunctioning of production. ‘The Destructive Character’ destroys to clear the way for something new. This moment of production, however, is predicated on interruption. In this chapter I want to trace this thinking of interruption in Brecht and Benjamin as a complication of any resort to accelerationism.

Irving Wohlfarth has noted that Benjamin’s destructive character is ‘the efficient executor of an eviction order.’ What kind of eviction order? I want to suggest this is an eviction order executed by a slob. In Fredric Jameson’s 1998 book on Brecht he poses the Brechtian energies of production and praxis against the stasis of our opaque and financialized postmodernism. Reflecting on Brecht’s pre-Marxist work Baal (1918) Jameson identifies the character Baal with the figure of the slob:

These are the slobs of literature rather than its zombies or living dead: creatures of physical and vestimentary neglect, satyrs, dirty old men, and the like, they are the archetypes of appetite, surging up from popular culture (rather than, as with supreme villains and manifestations of evil, from the lettered).

This figure is destructive, in the sense, as Jameson says, that they ‘erupt and break the furniture’. Jameson notes that: ‘The Brechtian aversion to respectability in general is richly documented in the early works – with Baal as its virtual allegory: the Marxian turn is thereby able to tap those “antisocial” energies for a new and more productive engagement with the negative.’ So, the seemingly ‘purely’ destructive slob does not simply disappear in Brecht’s embrace of Marxism and production. In fact the slob persists within the moment of production as a moment of interruption.

Brecht’s short story ‘North Sea Shrimps’, probably written around 1926, and subtitled ‘or the modern Bauhaus apartment’, is an allegory of the slob’s interruption. It tells of the visit of Müller and the narrator to the apartment of their wartime friend Kampert. Kampert is committed to a life of luxury after his experiences in the trenches of the First World War and, having married into money, fulfils his dream. The apartment is now perfect Bauhaus, whereas before: ‘It was two plain bourgeois rooms. You know the kind of thing, cramped to start with and then stowed to the gunwales with furniture.’ (79)

The all-lilac room, the delicate blinds, and the lack of pictures, drive the narrator, and particularly Müller, to distraction:

What irritated Müller was the flat. He was completely wrong about this. It was a very pleasant flat, not at all ostentatious. But I think Müller just could not stand the carefully contrived harmony and the dogmatic functionalism of it any longer. (82)

Although Müller has brought a present of North Sea shrimps he sends out Kampert on a false errand to buy some, and then proceeds to redecorate. He violently rearranges the furniture, tears down the blind, and sticks up magazine pictures on the wall with sugar water. The narrator concludes, ‘Man is like a terrible tornado, creating the grandiose multiplicity and admirable disharmony of all creation out of an almighty pile-up of patent American chaise-longues, common washbasins and old, venerable, magazines.’ (84)

This short story disrupts Benjamin’s later invocation of the glass architecture of Scheerbart and Bauhaus in ‘Experience and Poverty’ (1933) as the gesture of ‘erasing the traces’ called for by Brecht. The creation of ‘rooms in which it is hard to leave traces’, is exactly what Brecht’s ‘destructive slob’ is reacting against, with Müller having ‘this longing for all that was most illmatched, most illogical and most natural.’ (85) While Benjamin’s version of the destructive character wipes away the traces of those who want comfort, Brecht’s destructive slob makes his space comfortable by putting his trace on things. The destructive ‘baseness’ of Müller, his lumpen status, interrupts the clean modernist space. He actively turns the new into ruins, interrupts the new, to create something that is not exactly productive, but rather illogical.

My second scene of interruption is from one of Walter Benjamin’s radio talks for children, given in 1932, on ‘The Railway Disaster at the Firth of Tay’ (‘Die Eisenbahnkatastrophe vom Firth of Tay’). As the title suggests the central subject of the talk is the railway disaster of 28 December 1879, when a passenger train of six carriages and two hundred people was lost after plunging into the Tay, when the iron bridge it was passing over collapsed during a fierce storm. Benjamin does not begin with the disaster, but rather with the early technologies of iron working and train construction and with what he calls, in his essay on Eduard Fuchs, the ‘defective reception of technology’. This ‘defective reception’ turns, in part, on acceleration, as Benjamin reports the view of the medical faculty at Erlangen suggesting that the speed of rail travel would lead to cerebral lesions, while an English expert suggested that moving by train is not travel but simply being dispatched to a destination like a package. Perhaps neither could foresee the current British train system…

In describing the disaster Benjamin quotes from a poem by Theodor Fontane, not the renowned poem by William Topaz McGonagall – renowned for being terrible. This is the first stanza of the McGonagall:

Beautiful Railway Bridge of the Silv’ry Tay!

Alas! I am very sorry to say

That ninety lives have been taken away

On the last Sabbath day of 1879,

Which will be remember’d for a very long time.

Benjamin reports that when the accident occurred the storm was raging so severely it was not evident what had happened. The only sign were flames seen by fishermen, who did not realize this was the result of the locomotive plunging into the water. They did alert the stationmaster at Tay, who sent another locomotive along the line. The train was inched onto the bridge and had to be stopped a kilometre out, before reaching the first central pier, with a violent application of the brakes that nearly led to the train jumping from the tracks: ‘The moonlight had enabled him to see a gaping hole in the line. The central section of the bridge was gone.’

The brake is a figure of interruption, and this foreshadows its later use in ‘On the Concept of History’. While one catastrophe has already occurred, in which two hundred people have lost their lives, the act of braking prevents, although only barely, a second catastrophe. We can place this consideration of the locomotive, speed, and the malignancy of technology, alongside Benjamin’s remark in the essay on ‘Eduard Fuchs’ that:

The disciples of Saint-Simon started the ball rolling with their industrial poetry; then came the realism of a Du Camp, who saw the locomotive as the saint of the future; and a Ludwig Pfau brought up the rear: ‘It is quite unnecessary to become an angel’, he wrote, ‘since the locomotive is worth more than the finest pair of wings.’

This angelic locomotive, which rushes into the future and into destruction, can be paired with Benjamin’s famous invocation of the Angelus Novus or Angel of History in ‘On the Concept of History’ (1940), which is turned to the past and contemplates the wreckage of history.

The ‘Angelic Locomotive’ is, therefore, the sign of acceleration to the point that indicates that the ‘energies that technology develops beyond their threshold are destructive.’ The point here is that we can’t simply accept technology as it is, but the ‘refunctioning’ of technology depends on the interruption of capitalist acceleration. Benjamin reiterates this point in his essay ‘Surrealism: The Last Snapshot of the European Intelligentsia’ (1929), where he criticizes the surrealists for their ‘overheated embrace of the uncomprehended miracle of machines’. Such a characterization speaks, obviously, to the currents of accelerationism. Benjamin is poised in a tense debate not only with Brecht, but also with his own earlier desire to wrest the forces of production for revolution (which we discussed in Chapter 1).

Both Brecht and Benjamin adopt positions that can, at times, loosely be described as accelerationist. I’ve tried to probe the fact that they also disrupt and interrupt the accelerationist fantasy of tapping into the capitalist forces of production. What I’ve suggested is that the image Jameson offers of ‘a streamlined technological future’ as the key to revolutionary change is precisely what they put into question. The result is not simply some nostalgic or pastoral vision, but rather an interruptive politics that refuses to treat capitalist production on its own terms. Instead, Brecht and Benjamin are attentive to the destructiveness of the productive forces, and particularly those that have gone off the rails.

Benjamin’s registering of destruction, and its equivocation, suggests exactly that heterogeneity of time that will find its formulation in ‘On the Concept of History’ (1940). Homogenous empty time is the time of the train on the tracks, which can speed up and slow down. The emergency brake of Benjamin’s metaphor for revolution is not simply the stopping of a train on the smooth tracks of progress. Rather, as with the metaphor of the angel of history, it suggests that the train tracks into the future are being laid immediately in front of the train. In fact, the anecdote of the Tay Bridge disaster suggests that the emergency brake is applied precisely due to the derailing of the train, and threatens another catastrophic derailing. The ‘rails’ of history accelerate us to disaster if we are not aware of the destructive side of the dialectic of production.

The irony, as Benjamin’s notes make clear, is that the desire for acceleration on the tracks of history breeds passivity before the productive forces:

Once the classless society had been defined as an infinite task, the empty and homogeneous time was transformed into an anteroom, so to speak, in which one could wait for the emergence of the revolutionary situation with more or less equanimity.

The idea of the tracks stretching into the future leaves revolution as a receding moment – the station we never quite arrive in. The result, contra to the revolutionary intervention, it is the constant stoking of the train, i.e. the capitalist productive forces. This is another instance of accelerationism, which either tries to actively increase the speed of capital, or simply becomes the passenger on the train, allowing the constant destruction of living labor at the hands of dead labor to do the work.

The conclusion is that the emergency brake is not merely calling to a halt for the sake of it, some static stopping at a particular point in capitalist history (say Swedish Social Democracy – which the American Republican Right now takes as the true horror of ‘socialism’). Neither is it a return back to some utopian pre-capitalist moment, which would fall foul of Marx and Engels’s anathemas against ‘feudal socialism’. Rather, Benjamin argues that: ‘Classless society is not the final goal of historical progress but its frequently miscarried, ultimately [endlich] achieved interruption.’ We interrupt to prevent catastrophe, we destroy the tracks to prevent the greater destruction of acceleration.

The emergency brake is the operator of Benjamin’s non-teleological politics of temporality, which aims to wrest the classless society from the continuing dialectic of production/destruction that is our constant ‘state of emergency’. Instead of accelerating into destruction, we have to think destruction as an intimate and on-going possibility. In the case of Brecht’s slob we have a kind of anti-handyman destruction posed against the clean new. Here we rearrange and take apart the new in ‘illogical’ ways. Benjamin’s interruption suggests a more definitive break (or brake) with the aim of production. The stopping of the angelic locomotive tries to jump the tracks of history, or jump out of the vision of history as infinite waiting for the revolutionary situation.

Inevitably this jumping of the tracks will produce something new – there is no simple way outside of production, as we have repeatedly seen. To interrupt acceleration(ism) is not to give up on the new. We can, instead, consider production as an interruption, as a series of experiments that have ‘frequently miscarried’. This does not prevent the ‘ultimately [endlich] achieved interruption’ which would be the real condition of the new. Brecht and Benjamin’s thinking of interruption is a thinking of intervention that not only stops acceleration, but also rethinks production and the very notion of ‘productive forces’. The difficulty of applying the emergency brake does not mean that interruption should be abandoned.

Lenin once described ‘left communism’ – the radical rejection of parliamentary elections and unions as sites of struggle – as an ‘infantile disorder’. I would describe contemporary accelerationism as a ‘postgraduate disorder’. This is not just a reference to the subjective position of contemporary accelerationists, and neither is it mere name calling or ad hominem argument. I’m referring to the specific position of the postgraduate on the edge or cusp of the job market. The postgraduate possesses, usually, significant cultural capital, but they confront full immersion in the labor market fairly late in life. Of course, in the UK and US, student financing already forces them into a future life of debt servitude. Also, many are working, trying to get ahead or, more often, stay afloat. That said, this merely adds to the fact that the world of labor is confronted as one of future horror – endless and trivial. Accelerationism provides an answer by turning the horror of work into the jouissance of machinic immersion. We may face a life of labor, but we can try and face it ‘kein Schmerz, kein Gedanke’ – without feeling, without thought.

This is the immersive fantasy of work as site of repetitive libidinal acceleration, where the bourgeois ego is drowned in the icy waters of inhuman labor. While remarkably easy to criticize, such a vision recognizes a truth of the decomposition of contemporary capital. In particular, it is the collapse of the future as sustainable mode of life under capitalism, which accelerationism answers with an ersatz future in its place: retooled retro-70s futurism coupled to the frayed remains of capitalist ‘dynamism’.

What could be an alternative? To pose this problem I want to first consider the current attempts to put the brakes on accelerationism and contemporary restatements of accelerationism. Tracking between these two extremes I want to suggest that the traversal of accelerationism requires more than a simple rejection or the discovery of some (un)happy median. We have to tap and resist the incitement of desire that capitalism produces and which accelerationism mimics – the fantasy of immersion into Real forces of acceleration.

The few scattered anti-accelerationist critiques of our present moment often seem to leave untouched the libidinal core of accelerationism. These alternatives seem tepid, or even reactionary – take Franco ‘Bifo’ Berardi’s invocation of a politics of exhaustion that would ‘become the beginning of a slow movement toward a “wu wei” civilization, based on withdrawal, and frugal expectations for life and consumption’. This postmodern Taoism hardly enchants, and its expectation of sacrifice and escape seems to mock those paying for the current financial crisis. ‘Frugal expectations’ are what many of us already have, and such promises can hardly compete with offers of acceleration and excess. For this reason it is not surprising that accelerationism gains adherents uncomfortable with such re-treads of the usual political moralisms.

A more convincing version of the politics of deceleration has been given by Timothy Brennan, partly based on the slow slide of Cuba from its state as one of the last remaining ‘actually-existing’ forms of socialism to what, almost certainly, will be a capitalist future. In this strange hiatus or transition Brennan glimpses another possibility, in which the pleasure of socialism would be ‘the pleasures of a slower pace’. In particular, Brennan is willing to contemplate the problem of pleasure and to confront the incitements to desire of actually-existing capitalism with an alternative order:

The relative lack of commodities – at first glance anti-pleasure – would actually allow for a less extreme division of labor, freeing one from illusory ‘choices’ and the mental overload of advertising, as well as a greater (if not absolute) freedom from the tyranny of things.

Pleasure is reconfigured, rather than abandoned to the frugalities of inhabited exhaustion. It is reconfigured in an alternative mode of choice, rather the compulsive exercise of ‘choice’ offered and demanded by contemporary capitalism. This reconfiguration of pleasure is a crucial element of any counter-accelerationist programme.

The recent restatements of accelerationism come explicitly against the background of ongoing financial crisis, the evident stasis of the world-system of capitalism, and the structural (mal)adjustments of Neoliberalism 2.0. The work of Alex Williams and Nick Srnicek has most explicitly tried to reinvigorate and retool accelerationism for our moment. They do so by reworking Nick Land’s ’90s vision, suggesting that we need to split speed from acceleration. Williams and Srnicek argue, on the one hand, that the endorsement of speed is the failing of ‘traditional’ accelerationism. This endorsement remains within the parameters of capitalism – it is a ‘dromological acceleration’ that proffers a ‘fundamentally brainless increase in speed’, or even ‘a simple brain-dead onrush’. In contrast they suggest an ‘acceleration which is also navigational, an experimental process of discovery within a universal space of possibility.’ We could speak of an accelerationist critique of accelerationism…

While this is a useful corrective to Landian excesses, it faces some conceptual and political problems of its own. Srnicek and Williams discuss High-Frequency Trading (HFT), in which new algorithmic computer instruments push trading below the limits of human perception and to the very limits of physics, but they cannot endorse it. Instead they find themselves in a rather uncomfortable position in which HFT is taken as a new extreme:

Where humans remain too slow – too fleshy – to push beyond certain temporal, perceptual, and quantitative barriers, HFT systems surge past, generating the fine nanoscale structure of modern financial markets, too intricate for the naked mind to observe.

Yet, they insist, these systems are fundamentally stupid, unable to open out into a new conceptual space of possibility. HFT systems explicitly do not incarnate a new acceleration, but remain operators of dumb speed.

This leaves their accelerationism, unlike in Land’s unequivocal endorsement of capitalist processes, ungrounded. Alternative possibilities of acceleration only open in a post-revolutionary space, which we get to in a much more traditional fashion: ‘the tension fuelled dynamic between labor and capital incalculates a system-wide rupture.’ So, we have revolution as a result of the moving contradiction of capital and labor, then acceleration after. But even then it doesn’t seem obvious why the opening of a space of possibilities necessarily entails acceleration, which implies forward momentum and advance of existing possibilities? Adorno remarked that ‘Perhaps the true society will grow tired of development and, out of freedom, leave possibilities unused, instead of storming under a confused compulsion to the conquest of strange stars.’ While we can agree the end of capitalism would involve the loosening of new possibilities it is not selfevident that this accelerationism 2.0 can fully reconfigure the limitations or parameters of capitalism. In its nostalgia for space programmes and others forms of technological rush, it treads the same path of the accelerationism of speed. While Williams declares a push towards a ‘future that is more modern – an alternative future that neoliberalism is inherently unable to generate’, it seems this remains within the parameters of the modern as much as Land’s vision did.

What we can trace between anti-accelerationists and accelerationists is a strange convergence on nostalgia – nostalgia for a vanishing possibility of socialist slow-down, itself a terminal slide away from socialism, versus a capitalist ostalgie that can only fill in our absent future with past dreams of acceleration. This is a painful irony for accelerationism, in particular, which stakes so much on its futurism. The nostalgia is a nostalgia for forces – a desire for something, anything, to generate enough energy and momentum to break the horizon of the present. It is important that this is a metaphysics of forces, and not force in the singular, to account for the dispersion and linking of different possible sites into a plane of immanence. Accelerationism is constructive, but the construct replicates the past in the guise of a possible future.

If accelerationism points to the problem of labor as the ‘moving contradiction’ of capital – both source of value, and squeezed out by the machine – then it tries to solve this contradiction by alchemising labor with the machine. I want to suggest that this is not a solution. We can’t speed through to some future labor delegated to the machine, nor can we return to the ‘good old days’ of labor as ‘honest day’s work’. In fact, accelerationism indicates the impossibility of labor within the form of capitalism. This obviously doesn’t mean labor does not take place, but it means labor can’t and doesn’t perform the function of political, social, and economic validation capitalism implies. The readiness of capitalism to abandon any particular form of labor at the drop of a hat, or at the drop of the markets, suggests that labor cannot carry the ideological weight it is supposed to.

In his study of workers in post-Apartheid South Africa Franco Barchiesi has detailed how, on the one hand, work is the condition of neoliberal citizenship, and how, on the other hand, it can’t allow for true self-reproduction. The privatization of healthcare, insurance, transportation costs, home ownership, etc., leaves those ‘lucky’ enough to be in work unable to survive. While labor is essential for citizenship – if we think of the demonization of ‘welfare scroungers’, ‘benefit cheats’, and so on (and on) – it also never performs that function. Barchiesi notes that work under capital is always precarious, and this status isn’t simply reserved for the ‘precariat’ – those in more obviously precarious work conditions that have emerged most strikingly in post-Fordist conditions. What is also crucial about Barchiesi’s argument is that he notes that the revelation of this precariousness or impossibility of labor does not simply lead to left-wing political activation but, in the current ideological context, is as likely to lead to anti-immigrant and anti-welfare sentiments. Those struggling to survive as precarious workers are as likely to turn on others as they are to start new forms of support and struggle that recognize the impossibility of work.

This is, I think, one of the crucial conundrums of the present moment. Accelerationism tries to resolve it in machinic integration and extinction, which bypasses the problem of consciousness, awareness, and struggle in a logic of immersion. We are torn by the moving contradiction of capital into two broken halves that can’t be put back together – neither able to go forward into the ‘streamlined’ future, nor return to the ‘stability’ of the Fordist past. There is no simple solution to this contradiction. What I want to suggest is that replication along the lines of nostalgia for images of capitalist ‘productivity’ is no way into the future. In fact the struggles over the state and condition of labor, even as impossible labor, have to be fought now.

My perhaps minimal suggestion is recognition of this contradiction is the first necessary step. This returns us to ‘traditional’ problems of how we might intervene and negate the forms and forces of labor that mutilate and control our existence. Yet the discourses of the refusal of work or techno-libidinal fantasies of liberation from work do not operate. What are particularly absent are institutions and collective forms in which to engage the negation of work while considering the necessity and possibilities of sustainable existence. We encounter a capitalism that is, sometimes, quite happy to refuse us work while, at other times, to place extreme demands on us for work.

A working solution, to be deliberately ironic, is to struggle for decommodification of our lives. Campaigns against privatization and for the return of privatized services to public control try to reduce our dependence on work by attacking the way work is supposed to account for all of our self-reproduction. These struggles are in parallel for struggles to defend public services, protect benefits, and sustain social and collective forms of support. While they may be unglamorous, especially compared to space travel, these struggles can negate the conditions of the impossibility of work by trying to detach ‘work’ from its ideological and material role as the validation of citizenship and existence. In relation to the Nietzschean rebels of absolute communism or absolute acceleration these struggles can be dismissed as reactive, but they react precisely to the contradiction in which we are currently bound.

This is also true of the defence of workplace and employment conditions against new waves of privatization and outsourcing. The struggles at the University of Sussex over the outsourcing of support work, under much worse contracts and conditions, has forged an alliance of workers and students on the grounds of the precarity and impossibility of labor. It has also involved new experiments with forms and organizations against unresponsive unions and neoliberal management strategies. This impossibility of labor, I’m suggesting, does not simply mean abandoning work as an impossible site in the name of a dream of exit. Instead the negation of capitalist work can also be the struggle to free that true choice Timothy Brennan indicates by breaking our relation with constant ‘accelerative’ demand that we attend to the commodification of our lives.

When Jean-François Lyotard invoked ‘mechanical ascetism’ he wrote of it as a ‘new sensibility made up of little strange montages.’ This sensibility was explicitly one of full jouissance with Lyotard, as we saw, mocking the French who thought jouissance meant ‘the euphoria that follows a meal washed down with Beaujolais.’ The political sensibility underlying accelerationism is one of jouissance, taken to the extreme, and merged with the promise or fantasy of full immersion in the Real forces of acceleration. The attraction of this sensibility lies, as I’ve tracked, on this fantasy of immersion into Real forces, with a new acceleration always promised and always just out of reach. To adapt Sade, it’s always ‘one more effort, to truly be accelerationists’.

While explicit accelerationists remain fairly rare, the emphasis on a sensibility of acceleration and speed is much more widespread. From discussions of the ‘resonance’ of contemporary struggles to the spreading wildfire of communization, a range of disparate and often conflicting theoretical and activist positions converge on the need for speed. While these models don’t adhere strictly in the accelerationist form of speeding-up capital or offer various forms of speeding-up of struggles (which often rely on the technological media of capital, such as Facebook), ‘little strange montages’ that integrate acceleration are everywhere.

This sensibility is one of flux and flow – in accelerationism the liquid is everywhere. At the same time a residual hardness, most evident in the early twentieth-century avant-gardes, still remains. The hardness is now the capacity to form strange montages without reserve, to fully immerse and so disperse into fluxes and flows. This is an aesthetics or practice of liquefaction that can temporarily solidify to activate force, before dispersing again into new liquid immanent forces.

From the classical accelerationist position any rejection of acceleration leads to a sensibility of what Nick Land calls ‘transcendental miserablism.’ To give up on the dream of accelerating is to lapse into a Gnostic belief that the world is fallen into evil. Supposedly lacking any positive alternative the antiaccelerationist can only regard everything as negative and is left with only the feeling of resentment. Land’s answer is ‘Go (hard) for capitalism’. If we want to counter accelerationism, as I do, then we have to address how an alternative political sensibility might define itself not simply as a mode of misery.

The first point I’d make is that the immersive accelerationist makes a lot of their misery, but simply changed into jouissance. It is the accelerationist who risks constructing an absolute image of capitalism as monstrous machine or, in the case of Land, as the summoning of one of H.P. Lovecraft’s monstrous Shoggoths.

The Shoggoth, which appears in Lovecraft’s novella of Antarctic horror At the Mountains of Madness (1931), is an apt symbol for accelerationism. It is a creature that was genetically engineered as a ‘beast of burden’ to do the work for the Old Ones – ancient alien beings who inhabited the earth before humanity, and which were masters of occult knowledge. The Shoggoths developed a rudimentary intelligence and eventually rebelled, but were defeated by the Old Ones. A few remain and it is one of these creatures that is encountered at the climax of Lovecraft’s narrative by his unlucky human explorers. This is how it appears to Lovecraft’s unfortunate heroes:

the nightmare, plastic column of fetid black iridescence oozed tightly onward through its fifteen-foot sinus, gathering unholy speed and driving before it a spiral, rethickening cloud of the pallid abyss vapor. It was a terrible, indescribable thing vaster than any subway train – a shapeless congeries of protoplasmic bubbles, faintly self-luminous, and with myriads of temporary eyes forming and un-forming as pustules of greenish light all over the tunnel-filling front that bore down upon us.

Capitalism, for the accelerationist, bears down on us as accelerative liquid monstrosity, capable of absorbing us and, for Land, we must welcome this. The history of slave labor and literally monstrous class struggle is occluded in the accelerationist invocation of the Shoggoth as liquid and accelerative dynamism. The horror involves a forgetting of class struggle (even in dubious fictional form) and the abolition of friction in the name of immersion.

The second point is that this desire for immersion and forgetting is, I’d suggest, generated out of the psychopathologies which capitalism induces. By now we are familiar enough with a litany of psychological maladies that have been claimed as the signature disorder of capitalism: psychopathy, narcissistic personality disorder, schizophrenia, depression, hysteria, anxiety, etc. In response to these psychic effects accelerationism responds by intensification to transcend the limit: schiz to the point of excess, the potency of depression, and the enjoyment of subjection. The pathological effects of contemporary capitalism barely need pointing out and are the lived experience of most of us. We all know what’s wrong. Therefore, I don’t think the task is to add or refine the relentless framing of capitalism as generator of negative experience or the mutilation of ourselves. To be called to merge with the capitalist Shoggoth is hardly useful… Instead, and what is much more difficult, is what we do with this basis of affects, experiences, and moods.

I want to suggest that the starting point of any political sensibility, by which I mean a sensibility from the left, is to break with fantasies of Real forces of acceleration. This fantasy consists of the premise of the existence of forces that promise accelerative vitality, even in the most extreme moments of despair. These are dispersed and plural forces, which allow for multiple possibilities of accelerationism that can change form or content. It is integration with these real forces that offers an immersive immediacy without any mediation or any fantasy, and abandons the order of human language for the disorder of an inhuman existence.

What I’m arguing for is a restoration of the sense of friction that interrupts and disrupts the fundamental accelerationist fantasy of smooth integration. This smoothness is neatly summarized by a statement from one of the characters in another Lovecraft story ‘The Whisperer in Darkness’ (1931): ‘All transitions are painless, and there is much to enjoy in a wholly mechanized state of sensation.’ The fact this line is spoken by a human whose brain has been removed and placed in a metal cylinder to allow for space travel indicates the ‘transcosmic horror’ disavowed by accelerationism. It’s something to the credit of accelerationism that it doesn’t tend to figure transitions as ‘painless’, but as sites of jouissance. The solution, however, to making the transition is ‘going hard’ to go soft, in a peculiar mixture of machismo and the valorization of feminised immersion.

I’m not suggesting a return to the human, or a simple decelerative equilibrium, withdrawal, or new asceticism, as an answer. Our task today is to collectively sustain forms of struggle and negation that do not offer false consolation, either of inbuilt hope or of cynicism and absolute despair. In terms of political sensibility this would mean neither relentlessly tracking pathologies nor celebrating their coming magical transformation into new powers. Starting from misery might instead involve developing forms of politicization that could not only recognize misery but delink from what causes us misery.

This strange montage would involve the recognition of the friction of integration, which isn’t simply posed as an alternative of hard or soft, transcendent or immersive. Instead we are already up to our necks in potential and actual integrations, immersions, and extractions. The tension of these moments requires a collective sense of past struggles and of struggles to come, a recognition that the impossibility of work as it is has been shaped not only by capitalism but also by resistance. It also involves attention to the aesthetics of these moments of friction, which encode the tension accelerationism wishes to dissolve. There is not much consolation or celebration to be found here, this is not as fun as the montage promised by accelerationism, but it is a place to start.

Jim Reid retired to his hotel room at around midnight on 22nd August 1994. Half an hour later there was a knock at the door. It was Bill Drummond and Jimmy Cauty, and they had the suitcase with them.

"Come on, we're going to do it now", said Drummond.

Reid asked why. "There's just a time when you instinctively know it is right," Cauty replied. The plan had been to get up early on the morning of the 23rd and climb, with the suitcase and its contents, to the top of one of the mountains that dominate the island of Jura. Well, it was now technically the morning of the 23rd. The mountain was unimportant.

"Do you remember Christmas when you were a kid, and you just couldn't wait for morning?" Drummond asked.

Reid was a journalist who had been taken to Jura by Drummond and Cauty in order to act as a witness. He grabbed his Dictaphone and followed. They left the warmth of the hotel and went outside into the night. Here they met the fourth member of their party, Alan Goodrick, a Falklands War veteran and rock tour manager more commonly known as Gimpo. It was raining.

Drummond did not look like one of the most successful and credible pop stars on the planet. He was forty years old with an everyman haircut and the sort of thoughtful, respectable demeanour you might associate with a secondary school teacher. Nevertheless, he had produced a string of global number one singles and had just come first in Select magazine’s ‘100 Coolest People’ list. Jimmy Cauty, the other half of the duo known as The KLF (amongst other things), was a few years younger with wild dark curly hair and a more anarchic sparkle in his eyes.

The suitcase went into the hire car’s boot. Reid had still not seen the contents of the case at this point, but he was pretty sure he knew what was inside. Gimpo had also guessed. During the flight to the Hebridean island the thought of killing Drummond and Cauty in order to steal the suitcase had entered his head. He didn't do that, of course. He just thought about it.

Gimpo drove them away from the hotel, down a rough track and across the Scottish island. The night was pitch black. "This just feels better", Drummond said, "going out in the night when it's pissing down with rain."

A few minutes later they pulled up by a deserted stone boathouse. Cauty had discovered it earlier in the evening when he and Drummond had been searching for the remains of a giant wicker man they had burned three years earlier, in front of dozens of robed and hooded members of the music press. They stepped out into the cold. Gimpo left the car lights on and they illuminated the rain, the bracken and the boathouse. They took the suitcase out of the boot.

They went inside. The flame from a cigarette lighter revealed rough stone walls and an earth floor. Ropes hung from old wooden rafters. And at the far end: a fireplace.

The suitcase was opened and its contents were dumped onto the ground. The four men stared down at the heap of paper at their feet.

Very few people get to see a million pounds sterling first hand. Even fewer get to dump it on to a dirt floor in a remote abandoned building in the middle of the night. Those fifty pound bundles were power and potential in its purest form. It was countless acts of compassion and charity, or a lifetime without work. The amount was highly symbolic. It was the amount that is associated with success; the quantity of money needed to not only escape the rat-race, but to win it. That money was freedom, both physically and symbolically.

Cauty opened the first bundle and took out two fifty pound notes. He handed one to Drummond and set fire to both with his lighter. Despite the cold and damp, the flame readily ate through the paper. More notes were placed in the fireplace and, over the course of the next two hours, the fuckers burned the lot.

On their return from the Isle of Jura, Drummond and Cauty found themselves at the start of the long, hard process of coming to terms with what they had just done. As Cauty told the BBC six months after the burning, "Every day you wake up and think, 'Oh God – I've just burned a million quid.' Nobody thinks it was good. Everyone thinks that it's a complete waste of time." The heart of the problem was that they did not know why they had done it. "I don't know what it is, what we did. Some days I do. Bits of it," Drummond said, "But I've never thought that it was wrong."

Drummond and Cauty's inability to justify or explain their actions is one of the most intriguing aspects of what happened on Jura. It echoes the fates of the founders of Dadaism, the small group of artists and radicals who opened the Cabaret Voltaire in Zurich in the midst of the First World War. The Cabaret only lasted for six months, and no recordings were made of what happened there, yet those present spent the rest of their lives trying to come to terms with what they had done. They never really did. As the writer Greil Marcus points out, "This is the best evidence - the only real evidence - that something actually happened in Zurich in the spring of 1916."

The money burning, however, was recorded. Gimpo had filmed the event with a small camcorder. In the months after the burning, as Drummond and Cauty searched for some context or insight to allow them to understand their actions, the idea that they should show people the film arose. Perhaps if they showed the film and asked for help, someone might be able to explain to them what they had done? This was, needless to say, a terrible idea. They were hardly in their right minds at the time, however, so they set about organising a film tour of arts venues and unusual locations around the British Isles. The first screening, on August 23rd 1995, would be in the village hall back on Jura.

People were, by and large, rather angry. This is not surprising. If you ask a crowd to tell you why you burned a million pounds, when that crowd would very much like to have a million pounds themselves and know that they never will, then there is not going to be a huge amount of sympathy in the room.

It was the pointlessness of the whole thing that got to people. When it was revealed in a court case in 2000 that Elton John had somehow spent £40 million in 20 months, including £293,000 on flowers, people reacted differently. There was much head shaking, tutting and many jokes, but generally speaking people didn’t take it personally. It was Elton John's money after all, and his extravagance seemed in keeping with the personality that earned him that money in the first place. His wasted money, at the very least, made a number of florists very happy.

When Cauty and Drummond wasted their money it felt different. Seeing video footage of the burning was a genuine shock. Their money looked like kidney dialysis machines, beds in homeless shelters or funding for young artists in a way that Elton John's wasted money didn't. This wasn't money being wasted; it was money being negated. The argument that it was their money, and they could do what they liked with it, didn't ring true. What they had done felt wrong.

The adverts for the film screenings read, “Jimmy Cauty and Bill Drummond urgently need to know why did the K Foundation [Drummond and Cauty’s post-KLF name] burn a million quid? Was it a crime? Was it a burnt offering? Was it madness? Was it an investment? Was it Rock n' Roll? Was it an obscenity? Was it art? Was it a political statement? Was it bollocks? There will be screenings of the film 'Watch The K Foundation Burn A Million Quid' at relevant locations over the next twelve months. Each will be followed by a debate attended by Messrs Cauty and Drummond where the answers to the above questions and others will be sought.”

Debate did follow, but very little of it seemed helpful to Drummond and Cauty. There was some talk of art, 'pranks', 'scams' or promotional activity, but nothing that really held up to scrutiny. Many wondered if the whole thing was a hoax, and that they never burned the money at all (this idea was discredited by a later BBC documentary, which produced a trail of evidence that the money was genuine).

Very quickly, however, a consensus view formed. It was a view that explained to most people's satisfaction exactly what had happened. This consensus arose spontaneously from many different audiences and it allowed most people to put what had happened behind them and move on. The consensus was this: Drummond and Cauty are a pair of attention seeking arseholes.

It did seem like a power trip. As the pair sat behind a desk at the screenings it was easy to imagine that they were thinking, "We had a million pounds, something that you will never be able to obtain no matter how hard you work. And we didn't want it. But we wouldn't give it to you. We'd rather burn it than give it to you. So we did. Because we could."

The fact that they did not know why they burned the money did not really figure in this reaction. Very few really believed that anyway. Were not the pair, according to almost every article written about them, some form of "master media manipulators?" The KLF, it was understood, were people who definitely knew what they were doing, for how else could you explain their success? From this perspective, their claim to be unable to justify their actions appeared to be an excuse to hold screenings and rub people's noses in what they had done.

There were some supporters, of course, who praised the burning sincerely and genuinely. They often had some pet critical theory, a personal tower of cards, which allowed them to view the burning as artistically important. They were very much a minority, however, and nothing they could do or say could compete with the pair of attention seeking arseholes interpretation.

And really, who could say that that interpretation wasn't true? Perhaps that was the crux of the matter. Perhaps there was nothing else to add.

The futility of it all came to a head whilst sitting in a Little Chef diner near Aviemore, in the Scottish Highlands, the morning after a screening of the film in Glasgow. Drummond and Cauty had had enough. The screenings, they finally understood, were not going to achieve anything. They began to draw up a contract that would force them to walk away from the whole thing. The contract read:

For the sake of our souls we the trustees of the K Foundation agree unconditionally, totally, and without hesitation to a binding contract with the rest of the world, the contract is as follows.

Bill Drummond + Jimmy Cauty agree to never speak, write or use any other form of media to mention the burning of one million pounds of their own money which occurred on the Island of Jura on 23 August 1994 for a period of 23 years after the date of signature.

Bill Drummond + Jimmy Cauty are free to end the K Foundation in all respects for a period of 23 years after the date of signature.

Bill Drummond + Jimmy Cauty agree to store all assets of the K Foundation, including the ash of the one million pounds burnt on Jura, for a period of 23 years from the date of signature. This is to be completed within 14 days of signature.

Bill Drummond + J Cauty agree to allow Alan Goodrick use, for whatever purpose, the film "Watch The K Foundation Burn A Million Quid" and all film rushes.

Bill Drummond + Jimmy Cauty agree to publish this contract as a one page advert in a broadsheet of their choice within 14 days of signature and to cover costs.

It is agreed that in signing this contract, the postponing of the K Foundation for the said period of 23 years, provides opportunity of sufficient length for an accurate and appropriately executed response to their burning of a million quid.

All that remained was to sign the contract and confirm the agreement. Cauty and Drummond had an idea about how to do this. They would write the contract on Gimpo's van and then push that van over the cliffs at Cape Wrath on the northern tip of Scotland. That, it was felt, would be a suitable end to the matter.

Gimpo reacted to this idea by immediately returning to his van and driving back to London, leaving Drummond and Cauty stranded. This is one of the few sensible acts in this story.

Nevertheless, a G-reg Nissan bluebird was soon hired, Cauty and Drummond signed the contract in gold pen on the windscreen, and the poor car was duly pushed over the cliff to fall hundreds of feet into the crashing North Atlantic surf. Cauty had first removed the radiator cape because it would 'smoke better' as it fell.

And that should have been that.

Except...

Except that the pair of attention seeking arseholes consensus doesn't really explain a great deal. It's an incomplete picture. There are many attention seeking arseholes about but, by and large, they don't go around burning their last million pounds.

Then there's the matter of their inability to come to terms with what they did. The writer Andrew Smith described in The Observer how a long-time friend and associate of the KLF told him that they knew the burning was real "because afterwards, Jimmy and Bill looked so harrowed and haunted. And to be honest, they've never really been the same since." Like the founders of the Cabaret Voltaire, the fact of their bewilderment is evidence that they were swept along by something larger, and something not of their design.

The fact that their actions are so incomprehensible suggests that we must be missing something. Somehow our view of our world or our culture is incomplete. Even if we accept that Cauty and Drummond were attention seeking arseholes, there still must have been some strange influences pushing them in that particular direction. We can be fairly certain, given the end result, that these influences will be disturbing and irrational. But if we pursue those influences, what will we find? Will they be interesting? More importantly, will they be useful?

How do you tell a story such as this?

In December 1995 I was fortunate enough to spend an evening with the American author Robert Anton Wilson. At the time I was researching a book about Timothy Leary, and Leary was a good friend and a major influence on Wilson.

It occurred to me to ask him his thoughts on the KLF. Robert Anton Wilson, it was generally understood, was a major figure in the KLF story. He co-wrote The Illuminatus! Trilogy, an underground but influential series of novels that had acted as inspiration and a guiding philosophy for Drummond and Cauty’s musical adventures. The first name they used together, The Justified Ancients of Mu Mu, was taken directly from his work.

The reason I asked Wilson about The KLF had nothing to do with Timothy Leary. It was because I was intrigued by a rumour that I had heard via a friend of Cauty. The rumour was this: Although it was frequently claimed that the initials 'KLF' didn't mean anything, or that they meant different things as different times (Kings of Low Frequencies, Kopyright Liberation Front, and so on), the initials did actually have a specific meaning. According to this rumour, KLF stood for 'King Lucifer Forever'.

I was unsure what to make of this, but it didn't feel right. The idea that there was the hidden secret at the heart of the band contradicted everything else I knew about them. It implied that they had a purpose, and that they knew what they were doing. This, to my way of thinking, seemed deeply out of character. Still, it was an odd thing for a friend of Cauty's to claim, and an odd thing for someone to invent. I wondered if there was an air of 'Chinese whispers' about the phrase. Perhaps someone had made this suggestion as a joke after the band had ended, and the nature of word of mouth morphed it into the more interesting and definitive version which I heard?

Regardless, it planted in my head the idea that the story of the KLF would need to be told on very different levels to normal rock biographies. So I asked Wilson what his thoughts about the KLF were.

"I've never heard of them," he told me.

"They were a British band who first called themselves the Justified Ancients of Mu Mu? They went on to burn a million pounds?" I prompted.

He shrugged. He explained that there were an awful lot of bands who played around with that imagery, and that he couldn't keep track of them all. He also said that punk bands seemed particularly keen on it, which surprised him a little, as he wasn't really into the punk thing.

I hadn't expected that. Almost every account of the origins of The KLF mentioned Robert Anton Wilson. He was, I was sure, an integral part of their story and it seemed reasonable for him to be aware of this. The fact that he didn't, however, provided the first hint into how this story could be told. 

It is not necessary for a character in a story to be aware of that story. This is not something that we understand instinctively or intuitively. The films we watch are focused on a hero's journey, and we automatically interpret the other characters as being part of that hero’s story. If we see merchandise from the Harry Potter movies (for example) which shows minor characters from the films, then this does not strike us as odd. That character is part of those films, after all, and therefore part of Harry Potter's story.

Often, however, those characters should have no knowledge of the story that they are in. They may feature in an early scene and never be seen again, remaining blissfully ignorant of the events that follow. They would have no more reason for thinking that they were part of 'Harry Potter's story' than the story of anyone else that they met. Indeed, the idea that this was 'Harry's story' would seem ludicrous because, as far as they are concerned, they are in the middle of their own story. Their story could conceivable be more dramatic and exciting than Harry's. To them, Harry would be a bit player in their own story, not vice versa. This is certainly the situation in narratives which deal with real, as opposed to fictitious, people. We are all forming our own narratives and we can't be expected to keep track of everybody else’s narratives, no matter how much they would like us to.

In the light of Wilson's comments, I started to wonder if there was such a thing as a story that no-one knows they are in - least of all the main characters. Could a complete narrative develop by itself with no-one guiding it or steering it? You would instinctively think not, yet whenever I thought about the KLF story and Cauty and Drummond’s confusion about their actions, I couldn’t shake the idea that there was nobody involved who could hear the story that was being told.

On one level the story of The KLF is easy to tell, because almost everything that they did between 1987 and 1994 was well recorded. Almost every song they produced, interview they gave, video they made or press release they issued is archived on the internet somewhere (or at least was and will be again - KLF websites and .ftp archives have a habit of appearing and disappearing). For this we must thank Drummond and Cauty's championing of Situationist ideas, particularly with regard to their views on copyright. The Situationists were a small but influential group of avant-garde thinkers from the 1950s who thought that culture was forced upon us, and that we needed to take control of it. These ideas sufficiently influenced KLF fans so that, when the internet grew in the years after the band split, they digitised their collections and shared them with the world.

Thanks to these copyright-ignoring KLF fans, it is possible to download the entire story of The KLF, as it played out in the media, in an afternoon. Then, with every press article, photograph and interview laid out before you, you can then begin to pull a narrative out of all that data. The Situationists would have made a distinction between this mass of cultural data, what they would have called the spectacle of The KLF, and the actual events that caused this spectacle. What we have is not what happened, but it is all we can know about what happened. As the Situationists saw it, it is all that you can ever have to go on.

This made sense to me because of my experience researching the Timothy Leary biography. For that book, I behaved as you would expect a conscientious biographer to behave, and for a very good reason. I had never written a book before, or indeed any text of length. I didn't know what I was doing, essentially, and wanted to hide that fact from people. As a result I worked diligently and tracked down people who had first-hand knowledge of events, formed a good relationship with his estate and gained access to a number of archives, including Leary's own. I travelled thousands of miles and I got to know as many people as my budget and time frame would allow, because basically that is what you are supposed to do.

As I progressed with this research, however, I noticed a surprising pattern in the data. Time and again, older books, letters and interviews proved to be far more illuminating than first hand interviews. It soon came apparent that accounts of events changed over time, and that the 'truth' of what happened depended very much on the date of your source. This was clear to me because I had access to Leary's own archive of papers. I could read letters and diary entries written at the time, find later magazine interviews about the same period, and also speak to surviving witnesses thirty or forty years after the event. These differing sources revealed a drift away from the raw chaos of what actually happened into a neater, simpler narrative which didn't always match with the original sources. Even though later sources could offer greater perspective and illuminate things that were not apparent at the time, I adopted a rule of favouring the older sources whenever possible. They captured the flavour of the times, somehow, in a way that the more considered later versions didn't.

Researchers have studied this drift of memory into error in great detail, and found it to be an undeniable fact of our lives – even if most people refuse to accept it about their own memories. This drift has been found to be so precise and predictable that it can be plotted on a graph, known as the Ebbinghaus curve of forgetting. What happens is that witnesses slowly absorb events into their own narrative, losing the loose ends and unexplained incidents and making sense of what they can with respect to their own lives and prejudices. We all do this. Indeed, if modern neuroscience is correct, it is something that we do far more than we think. The role of the ego, it appears, is less like a President or a Prime Minister deciding on a course of action, and more like their spin doctor, explaining the action afterwards in the best possible light. We rationalise the actions of our unconscious minds and present them as an entirely correct, politically consistent course of action regardless of what it was or how uninvolved we are in the decision.

All this needs to be considered in any attempt to say why the KLF burnt a million pounds. If the central protagonists were as baffled as everyone else about their behaviour, and if other characters are not even aware that they are in this story, that leaves us with something of a problem. In this instance, asking the protagonists what happened all these years later would not only fail to illuminate those events, it would almost certainly take us decidedly off course. Many journalists have already tried this approach, interviewing Cauty and Drummond at length about the burning, and it hasn’t really got them anywhere.

What is the alternative? We are left with the spectacle, and it is from within this spectacle that any answer to why they burnt a million pounds must be sought. This approach seems particularly well suited to this story, because taking an encyclopaedic, academic approach to The KLF is not going to reveal the things that we’re searching for. Drummond and Cauty stumbled map-less through their own stories, taking and using whatever they felt useful, so that is the approach we will take as well. We are attempting to find the spirit of those events, and we can only do that by invoking them ourselves.

Here, then, is a story that the cast were not told they were in.

Bill Drummond and Julian Cope drove across Liverpool in an old, battered Transit van. In the back was a stolen mattress which they were taking to Devonshire Road in Toxteth. This was a row of grand Georgian mansion houses that had been built from slave trade wealth, but which had long since decayed into squats and cheap, run down flats. The mattress was for Cope, who was moving into the top floor of the house with his new wife. It was 1976, and Drummond was 24. In the eyes of teenage punks like Cope, he was already old.

Drummond may have been old, but he had plans. He had previously achieved a touch of local fame with a band called Big in Japan. The band had included Holly Johnson, Pete Burns and Ian Broudie, all of whom would go on, like Drummond, to have more than their fair share of number one records. They had played regularly at Eric's, an influential club on Matthew Street, and they had released one song as part of a split 7-inch single. Ultimately, however, they were always a shambolic affair and they had recently split up, leaving behind a semi-legendary reputation and a string of debts. It struck Drummond that he could raise money to pay these debts by setting up a record label and releasing a Big in Japan EP. It seemed an obvious next step for a man of his age. He still loved music but, being 24, he was clearly too old to make music himself.

More than anything, Drummond loved 7" vinyl. Singles possessed a magic that indulgent, career-minded albums sorely lacked. They were immediate, cheap and democratic. They could be terrible, of course, but the best ones had power over their owners which no other art form could compete with. There's nothing vague about the love you feel for a perfect pop song. It does not need explanation or context. And what other art form, in the late twentieth century, could make similar claims?

If Drummond was going to start a record label then he would do so with the same attitude that musicians should make music with, keeping one eye on personal honesty and the other on the far horizon. His label would only release singles, for a start. And it would only sign bands that possessed an otherworldly something, bands that sent shivers down his spine. It was not necessarily the music that these bands created that he was interested in, for that was out of his hands. It was the idea of the bands that was important. This was why he needed Julian Cope.

Punk had arrived in Liverpool. It was the sudden return of all the feelings and emotions that hippy culture had tried to repress, a reawakening of all the disrespect and raw frustration that the peace and love generation believed they were above. The punks may have kept the hippies' DIY attitude and their contempt for the older generation, but they were quick to rip down their indulgent fantasies with an ugly blast of blunt realism and angry mockery. They had no intention of putting up with the bullshit any longer. They wanted to do stuff.

History has adopted a very limited definition of 'punk', one which boils down to a spitting kid with a Mohawk haircut and a safety pin through his nose. Modern punk bands recreate the raw guitar music and confrontational fashion that were created before the original punk spirit faded, but this is to recreate the result of punk rather than punk itself - the symptoms rather than the disease. The attitude and look of The Sex Pistols came to be adopted as the definitive archetype, but away from the Kings Road and outside of London the punk ethic found many different ways to display its contempt for conformist society. In Belfast, for example, the Troubles were at their peak in the late Seventies and early Eighties and slight nuances in speech or dress were enough to indicate sectarian allegiance and, potentially, bring violence or even death. Against this background a woman walked around the city dressed in a bin bag and flippers, carrying a kettle for a handbag. That was pretty damn punk.

Liverpool, too, had its own local flavour of punk, and it was one with strict, self-policing ideas about what was acceptable. Fierce competition between local egos created an atmosphere where anything gimmicky or fragile was immediately leapt upon and torn to shreds for sport. There was a general contempt for anything from outside the city, with the notable exception of Manchester, with whom Liverpudlians shared an uneasy respect disguised as a bitter rivalry. The Liverpool scene worked on the principal that great things were just around the corner. They were still out of reach, admittedly, but they were definitely getting closer. The big question was not what the future held, but who would be the first to claim it. The Liverpool punks were driven by a fear that their enemies would achieve great things first – or worse, their friends.

It was into this world that Julian Cope arrived in the summer of '76, a well-spoken student teacher from middle-class Tamworth with an upper-class name and a fondness for wearing a toilet seat around his neck.

Despite these drawbacks, Drummond recognised two important things about Cope. The first was his obvious talent, raw and untamed as it was. The second, and most important, was that he had put a band together called The Teardrop Explodes and, in Drummond's estimation, this was by far the best band name in Liverpool. True, the Teardrops had not yet recorded, played live, or indeed learnt how to play their instruments, but this was pretty normal for the Liverpool scene. Most bands that Drummond's friends talked about didn't actually exist beyond the idea and a self-printed T-shirt. Cope was ahead of most, as he had already written the best part of three songs and was showing no signs of getting bored and giving up.

So as the pair drove towards Toxteth, Drummond explained to Cope his aspirations for his label, and why he wanted to put out records by a band called The Teardrop Explodes. Cope was initially wary, conscious of his band's inability to play and of his own current inability to sing. He had however once been in a band with Ian McCulloch, a young scouser who definitely could sing, so Cope suggested Drummond release a record by McCulloch's new band. Drummond was initially wary. McCulloch was known to be a fan of David Bowie, which at the time was unforgivable. Still, he asked what the band was called and Cope told him. They were Echo & the Bunnymen.

Echo & the Bunnymen. The name was not quite as good as The Teardrop Explodes, but it was good. It was mysterious yet, at the same time, strangely confident. Something about the name struck a nerve in Drummond, and after he founded Zoo Records he released singles by both The Teardrop Explodes and Echo & the Bunnymen. The singles were "shit", at least in Drummond's opinion, but he loved the bands that made them. Or more accurately, he loved the idea of those bands.

In the mid-1960s a photocopier was state of the art technology, and having access to one was something of a privilege. The act of using an office photocopier after hours for personal projects, without the boss knowing, was therefore a far riskier and more rebellious act than it is today. This was certainly the case for Lane Caplinger, a secretary for New Orleans District Attorney Jim Garrison.

In 1991 Garrison would be portrayed by Kevin Costner in Oliver Stone's movie JFK, a film based on Garrison's book On The Trail Of The Assassins. But this was 1965, a year before he became involved in Kennedy conspiracies and two years before the Summer of Love thrust hippies, psychedelic drugs and alternative lifestyles in front of an unprepared public. Things had not yet begun to get weird, in other words, and for a respected public figure like Garrison there was little to indicate what surprises the future had in store. He would have been quite unprepared, then, for the book that Caplinger and her friend Greg Hill were producing in his office.

This book was the original version of what would become known as the Principia Discordia, or How I Found The Goddess and What I Did To Her When I Found Her, by an writer named Malaclypse the Younger. They made a first edition of five copies. At the time it was little more than a joke for some of their friends, but its influence is now scrawled in a haphazard and frequently illegible manner across the history of the late Twentieth Century.

There was some debate in the 1970s, when the book's influence began to spread, as to just who this 'Malaclypse the Younger' was. Some believed that the book was the work of Timothy Leary. Others claimed it was written by Alan Watts, or by Richard Nixon during "a few moments of lucidity". It is now generally accepted that the book was largely the work of Caplinger's friend Greg Hill, and that some parts were written by Hill's old school friend Kerry Thornley.

The ideas behind the book can be traced back to the late 1950s, when Hill and Thornley attended California High School in East Whittier, a rural Southern Californian town that was then nestled amongst vast orange groves. In school they were viewed as nerds. Hill was short, squat and introverted, while Thornley was tall, very thin, and bursting with a nervous energy. They both shared an enthusiasm for pranks and strange ideas. They were also both keen on bowling alleys, largely because they served alcohol and remained open until two in the morning.

It was in one such bowling alley in 1957 that Thornley showed Hill some poetry he was writing. It included a reference to order eventually arising out of chaos. Hill laughed at this. He told Thornley that the idea of 'order' was an illusion. Order is just something that the human mind projects onto reality. What really exists behind this fake veneer is an infinite, churning chaos. For Hill, an atheist, the failure to understand this was the major folly of the organised religions of the world, all of which claim that there is an organising principle at work in the Universe.

Hill also told Thornley that the Ancient Greeks were an exception to this rule, for they had a Goddess of Chaos. Her name was Eris, which meant 'strife' and which is translated as 'Discordia' in Latin. Clearly, if anyone wanted to worship a deity who was genuinely active in this world, then Eris was the only credible option. All that was needed was for someone to create a religion around Her which, naturally, they decided to do. They called it Discordianism.

Discordianism is, at its heart, wilfully contradictory.  It claims that chaos, confusion and uncertainty are the true nature of reality. This claim does tend to raise the question as to how Discordianism itself, and all the assumptions that it is based on, can be accepted with any authority. Or to put it another way, if someone tells you that there can be no certainty, then believing in what they've told you becomes a paradox. Hill and Thornley were not put off by such problems. If anything, they enjoyed them. As they developed their ideas over the following years, they found that there were ways around such things, if they only kept their sense of humour about them.

One such innovation was Hill and Thornley's invention of the concept of 'catmas.' Catmas are similar to dogmas, but they are considerably less rigid. Normal religions consider dogmas to be absolute, unquestionable truths. Discordians consider catmas to be absolute, unquestionable truths, for now at least. This is an approach that echoes the philosophy of the American writer Charles Fort, who in 1932 wrote that, “I conceive of nothing, in religion, science or philosophy, that is more than the proper thing to wear, for a while.” Discordians understand that every catma may one day be discarded on the grounds that it is nonsense. Until that day comes, however, it should be accepted and respected. Some Discordians may even genuinely believe catmas on occasions, should the mood take them, but this is certainly not compulsory.

For one example, consider the Discordian catma regarding food.  Most religions include strict dietary rules. Jews are forbidden to eat pork. Catholics should fast from meat on Fridays.  Certain sects of Buddhists and Sikhs are vegetarian and Hindus cannot eat any part of a cow. In the same spirit, Discordians are forbidden from eating hot dog buns.

There is a 'reason' for this catma. It originates in a story in which Zeus held a party for the Gods but did not invite Eris on the grounds that she tended to cause trouble. Thus Eris experienced what Discordians refer to as the 'original snub' and was reduced to eating a frankfurter sausage by herself sitting alone outside the party. Nobody believes a word of this, of course, yet Discordians have respected the catma of the forbidden hot dog buns for over forty years. They don't respect it particularly thoroughly, admittedly, and indeed you'd be hard pressed to find a Discordian who has never eaten a hot dog bun. Nevertheless, at Discordian events and special occasions, people still make a show of eating frankfurters with no buns. The reason for this is that the catma, despite being nonsense, is useful. It is a terrific satire against the forbidden food dogmas of established religions. For those who've found it funny, it becomes that much harder to take seriously any claims about food being unclean, kosher or halal. It helps make any religious leader who expresses belief in similar dietary rules appear ludicrous, and this makes any other dogma that they may preach appears equally suspect. Should Discordians ever find a better catma to ridicule religious dietary dogma, then the hot dog rule will no doubt be dropped without ceremony. But until that day, Discordians keep the 'no hot dog buns' catma – not because it is true, but because it is powerful.

Slowly Hill and Thornley recruited a few like-minded friends into their new religion. Their aim was to undermine existing belief systems by spreading confusion and disinformation with as much humour as possible. To this end they each adopted a host of new names under which their Discordian endeavours were credited. Hill became known varyingly as Malaclypse the Younger, Rev. Dr. Occupant, Mad Malik, Ignotum P. Ignotious or Professor Iggy. Thornley became Omar Khayyam Ravenhurst, Rev. Jesse Sump, Ho Chi Zen or the Bull Goose of Limbo. Many different Discordian chapters were founded. The majority of these contained only one member, and some contained none. Discordians then wrote essays and letters under these aliases, only to then follow them with completely contradictory essays and letters under a different alias. Gradually this process spread and, by the time it reached its height in the late Sixties and early Seventies, it had become known as Operation Mindfuck. The aim of Operation Mindfuck was to lead people into such a heightened state of bewilderment and confusion that their rigid beliefs would shatter and be replaced by some form of enlightenment.

That was the aim, anyway. In practice it rarely worked out so well, with those heavily absorbed in Discordianism proving more likely to succumb to paranoid schizophrenia than to any form of enlightened bliss. Still, they meant well.

Discordianism was a joke, of course, at least to start with. Discordianism is often described as being either an elaborate satire disguised as a religion or an elaborate religion disguised as a satire, a description which wrongly assumes that it cannot be both at the same time. The whole concept was a satire or, at most, a way to deal with nihilism by wrapping it up with a goddess and a sense of humour. As events unfurled, however, those at the heart of Discordianism stopped making this distinction. As Discordianism started to take on a life of its own, it became harder and harder to claim that what was going on was 'just' a joke.

Eris, or rather the concept of Chaos, had a busy second half of the twentieth century. Clearly, she was making up for lost time. The concept of chaos had not been recognised academically since the time of the Ancient Greeks. The closest concept you could find in engineering or physics literature was turbulence, and this was only described as something to be avoided.

During the 1970s, however, the concept became embraced in places as diverse as university maths departments and occult sub-cultures (or perhaps those places aren't so diverse after all, for university maths departments and occult sub-cultures in the 1970s were both places where young men took lots of LSD). Regardless, whole new fields such as chaos maths and chaos magic sprang up. The relationship between chaos and order was being modelled mathematically, and the results were surprising. In what was thought to be order, people found chaos, yet when they then looked into chaos they found order. Phrases like 'the Butterfly effect,' became universally known, if perhaps not universally understood. Hill and Thornley were only joking when they talked of helping chaos manifest in the modern world, but that is precisely what happened.

The unthinkable started to happen: music journalists from London actually travelled to Liverpool to write about Liverpool bands. They had to, for something was definitely happening - just as those in the Liverpool scene always knew it would. Every one of the early singles from Echo & the Bunnymen and The Teardrop Explodes which Drummond released were hailed as the 'single of the week' by the influential British music weekly the NME.

Those journalists wanted to know what the name 'Echo & the Bunnymen' meant. It didn't actually mean anything. Cope had gone against the tide of the usual, 'blunt' punk band names when he came up with The Teardrop Explodes and now other Liverpudlian bands were creating similarly elaborate and psychedelic-sounding names in an effort to compete. Echo & the Bunnymen was one of the better attempts, while names such as Frankie Goes To Hollywood or Orchestral Manoeuvres in the Dark were perhaps less impressive. Echo & the Bunnymen was just one of handful of names suggested by a friend of the band known as Smelly Elly, and was adopted on the grounds that it was the best suggestion that they had. The band wanted a better story than this for journalists, however, so they claimed that Echo was their drum machine, and that they were Bunnymen in a similar way that Playboy models were Bunnygirls.

The spreading of this story did not please Bill Drummond.  He had his own personal meaning for the name, and he far preferred his version. It was triggered by the sleeve of their first single, Pictures On My Wall, which featured a scratchy silhouetted drawing of a strange powerful beast. The two shapes emerging from the top of its head would perhaps normally be interpreted as horns, but in the context of the band could be considered to be rabbit ears. But what a rabbit! This strange beast was sinister and powerful, and Drummond intuitively knew that this creature, whatever it was, was Echo. The Bunnymen, therefore, were his followers.

At the time Drummond liked to spend hours in the Central Library in the centre of Liverpool, searching through the shelves marked Religion, Myth and Tribal. As he wrote in 1998, "I was on the hunt for real or even imagined information on who this weird Echo character was." He quickly discounted a Greek mountain Nymph and lover of Pan who was called Echo. That story did not connect with him in any way. But there were stories that did make an impression, stories of a mythical trickster being who could take the shape of a rabbit. These stories came from native people from the far north, from Siberia, North Canada and Scandinavia. Drummond began merging these separate tales in his head, creating a clearer image of this elemental spirit from dark, cold landscapes.

He didn't tell anyone this, of course. That would be crazy.

So when the band gave the press their version of the story, Drummond held his tongue. "I had to stop myself from butting in and saying, 'No no, you've got it wrong. It's nothing to do with Bunny Girls. Bunnymen are the scattered tribes that populate the northern rim of the world and are followers of a mythical being, divine spirit, prime mover who takes who takes the earthly form of a rabbit.' But I didn't."

In 1980 Echo & the Bunnymen released their first album, Crocodiles. Drummond had licensed the album to Warners, thus keeping Zoo pure and free from such self-indulgent projects as albums. But it still felt like a compromise. McCulloch and the band clearly had very different dreams to Drummond. They wanted to make albums, tour the world and become hugely rich and successful. As their manager, Drummond had to accept this, but he was still of the impression that a real band should just make a few perfect singles and then split up.

The album sleeve was lying on the floor of his office when Drummond glanced at it, its image foreshortened by the angle.  The cover photo showed the band in a forest at night, lit by strong red and yellow light. In the centre of the frame bassist Les Pattinson sat leaning against an ash tree which, strangely, had two primary trunks which gracefully curved around each other.

Then suddenly – the picture changed.

Red and evil, a huge rabbit's head stared at Drummond, solid and unblinking. Instantly he knew who he was looking at.  It was Echo.

And then, in a blink, the band photo returned. Picking up the sleeve, Drummond realised that it contained an optical illusion.  The tree trunks looked like the head and ears of a rabbit, one that appeared evil thanks to the downward angle of its eye, the sharp elongated point to its face and the red light on the tree. Once he had seen it, it seemed incredible that no-one had never noticed it before.

This was weird. Echo was supposed to be an idle fantasy of Drummond's, a strange personal thought which he kept to himself. It was not supposed to appear out in the world, eyeing him coldly from an album sleeve. He spoke to the photographer to determine whether it had been done deliberately, and learnt that it had not. The final cover photograph had been one that no-one had wanted, but which had eventually been accepted as a compromise. No-one had seen the rabbit head in the image before Drummond pointed it out.

He was discreet when he spoke to the photographer, of course. He knew that the idea of Echo was a personal fantasy from his inner life, an idea that could survive in his mind but not withstand the scrutiny of others. But the appearance of the rabbit in the world outside him had strengthened the idea, giving it the potential to grow and evolve and become more elaborate and intricate. Such constructions grow secretly in many minds, acknowledged and understood only by their creators.  Their imaginary nature, however, does not mean that they are unable to affect the world at large.

The psychologist Carl Jung credited a particular dream as being a turning point in his life, one which convinced him to embark on the study of synchronicity and the subconscious. He wrote about this dream in his book Memories Dreams & Reflections. In due course the Liverpudlian poet Peter O'Hallighan read about the dream in that book, and came to view it with equal significance.

In his dream, Jung found himself "in a dark, sooty city. It was night, and winter, and dark, and raining. I was in Liverpool. With a number of Swiss - say half a dozen - I walked through the dark streets."

Like many Scousers, O'Hallighan's home city was a significant part of his personal identity, so Jung's mention of Liverpool immediately grabbed him. In later years, he researched Jung's life in an effort to discover if there was a link that explained the setting of Liverpool in this dream. But he did not find any. Jung had never been to Liverpool and didn't have any obvious connection to the place.

The dream continued. "It reminded me of Basel, where the market is down below and you go up through the Tottengässchen (Alley of the Dead), which leads to a plateau above and so to the Petersplatz and the Peterskirche." The 'Peter' in these street names gave Peter O'Hallighan a personal connection to the dream. "When we reached the plateau, we found a broad square, dimly illuminated by street lights, into which many streets converged. The various quarters of the city were arranged radially around the square." O'Hallighan later searched Liverpool for the best candidate for such a place, and came to believe that Jung referred to the square at the end of Matthew Street. This was an area that then consisted of old warehouses between the centre of the city and the waterfront. This was also the exact same place where O'Hallighan had recently leased a building. Some years after Jung's dream one of these warehouses would become a club called The Cavern, from where the Beatles would emerge to change the world.

Jung continued. "In the centre was a round pool, and in the middle of it, a small island. While everything around was obscured by rain, fog, smoke and dimly lit darkness, the little island blazed with sunlight. On it stood a single tree, a magnolia, in a sea of reddish blossoms. It was as though the tree stood in the sunlight and was, at the same time, the source of light. My companions commented on the abominable weather, and obviously did not see the tree. They spoke of another Swiss who was living in Liverpool, and expressed surprise that he should have settled here. I was carried away by the beauty of the tree and the sunlit island, and thought, ‘I know very well why he has settled here.’ Then I awoke."

Jung felt that his subconscious had showed him something of profound importance. "Everything was extremely unpleasant, black and opaque - just as I felt then", he wrote. "But I had had a vision of unearthly beauty, and that was why I was able to live at all." Jung had found, bubbling up from his subconscious, an image of illumination that inspired him. It was no more than a dream image, but it was more powerful and had a greater impact on him than things which physically exist.

Jung's dream also had a profound effect on O'Hallighan, because he too had had a dream. He had dreamt that he saw a spring bubbling forth from a cast-iron drain cover in the middle of the road where Matthew Street, Button Street and others converge. He came down to Matthew Street the next day and sure enough, there was a manhole cover where he had dreamt one. He also saw that one remaining warehouse had a 'To Let' sign outside. He had then gone to the bank, got a loan and leased the building. He turned the downstairs into a market, and opened a café above it. The market became known as Aunt Twackies, a pun on the Scouse mispronunciation of 'antiques' as 'an teek wees'. He would later discover that there was an ancient spring underneath the building, which fed into an old brick-built reservoir.

When he later read of Jung's dream, he was struck by the way that Jung seemed to have dreamt of the exact same location, and that he too had linked it to some elemental source of life.  This seemed deeply significant to O'Hallighan. He arranged for a bust of Jung to be placed in an alcove in the outside wall.

The market began to attract members of the local music scene due to its proximity to Probe Records and Eric's nightclub, and because they could spend a day talking and planning in the café for the price of a cup of tea. Bill Drummond, then 23, was one of many who would spend hours in the place. Drummond was working as a set builder at the Everyman theatre. He had returned to Liverpool, where he had attended college, after a short period working on trawler boats in his native Scotland. One day he wandered in and found O'Hallighan hammering a nail into a piece of wood. O'Hallighan told him that he was planning to open what he called the 'Liverpool School of Language, Music, Dream and Pun'. He also told him about Jung's dream. "I didn't really understand what O'Hallighan was on about," Drummond recalled later, "but it resonated and I remembered it almost word for word. Also, he didn't look like a hippy, more a scouse Beat, so he was okay with my prejudices at the time."

The Liverpool School of Language, Music, Dream and Pun was planning on staging plays. O'Hallighan had persuaded the actor and director Ken Campbell to base his next project there. This was quite a coup, as Campbell's previous touring show, The Ken Campbell Roadshow, had been something of a success. It had featured Campbell, together with a troop of actors including Bob Hoskins and Sylvester McCoy, dramatising weird and wonderful 'friend of a friend' stories. The reason why O'Hallighan wanted to stage plays was, naturally enough, another one of his dreams. This dream had featured a building with a raging fire upstairs and a play being performed in a theatre in the basement. There had been a copy of Playboy magazine on a seat in the theatre. This didn't immediately make a great deal of sense, but in the world of the dream it was in some way significant.

The editors of the Playboy 'forum' letters pages during the mid-to-late Sixties were Robert Anton Wilson and Bob Shea. In many ways their jobs were not that different to most office jobs, except that the secretaries tended to be prettier and every week or so they'd be invited up to Hugh Hefner's mansion to “watch movies and stuff”.

A lot of the readers' letters they received, though, were decidedly odd.

In part this was because some of these were from the small, initial group of Discordians. The two Bobs found themselves in frequent letter communication with Kerry Thornley. They soon became committed Discordians themselves, with Wilson adopting the Discordian name Mordecai the Foul and Shea calling himself Josh the Dill. It was not long before the Playboy forum took on, under these two editors, a decidedly weird turn. Letters were printed that proclaimed deeply complicated and contradictory conspiracy theories, not because the writers believed what they were claiming, but because they wanted to mess with the heads of the people who read Playboy.

Context is important here. Those letters appeared considerably more surreal simply because they were part of the Playboy letters page. To use the April 1969 edition as an example, there was the usual letters which begin “After an hour or so of heavy petting, I often find myself in substantial pain in the area of my testicle and lower abdomen” and “The girl who lives across the street from me has been my friend since childhood. Now that we’ve both reached maturity, I see our relationship in a new light.” These letters are then followed by one that starts, “I recently heard an old man of right-wing views – a friend of my grandparents’ – assert that the current wave of assassinations in America is the work of a secret society called the Illuminati. He said that the Illuminati have existed throughout history, own the international banking cartels, have all been 32-degree masons and were known to Ian Fleming, who portrayed them as SPECTRE in his James Bond books – for which the Illuminati did away with Mr. Fleming.” This was then followed by a lengthy reply, detailing the history of the 11th Century Islamic Hashshasin sect and pointing out that Ian Fleming died of natural causes.

The strange thing was, though, that Thornley and friends weren't writing all these letters themselves. Whilst many could be attributed to their small core of Discordian colleagues, there were many others which appeared to be from complete strangers. Or were they? This was a problem with Operation Mindfuck, for you couldn't trust your friends to be honest about their activities. But still, judging by factors such as the postmarks on letters and unknown handwriting, there appeared to be many conspiratorial letters arriving from people that they didn't know. The Discordian ideas, which Thornley had been spreading in printed handbills and, eventually, in the Principia Discordia, were starting to spread. They were spreading to people who liked to write letters to Playboy.

Wilson and Shea did their best to make sense of what was going on. The concept we now call 'conspiracy theory' was emerging, fully formed, just a few brief years after the flaws in the Warren Commission report into the JFK assassination had become evident. People were now openly accusing sections of the US Government of being involved in Kennedy's death, an idea that would have been unthinkable to the average American when the murder occurred in 1963. To Wilson and Shea, as they waded through all the different accusations, it started to look like everyone had killed Kennedy. Some blamed the CIA, others the Mafia. Some claimed that it was Castro, while others pointed to anti-Castro forces. As they joked to each other, what if every conspiracy was true? From all this came the idea for the trilogy of novels that they wrote together between 1969 and 1971, the award winning Illuminatus! trilogy, which they dedicated to Hill and Thornley.

The wilfully complicated plot of the book boils down to a struggle between order and chaos. It features a organisation of enlightened beings called the Illuminati, who secretly rule the world for their own evil ends. The Illuminati was a real organisation which had been founded in Bavaria in 1776 with the aim of exploring and spreading Enlightenment ideals. Shea and Wilson claimed that the organisation has existed in secrecy ever since, and indeed for centuries beforehand, although most historians insist that it only lasted for about ten years.

 In the book, the Illuminati are opposed only by small groups of Discordians, who have to prevent the Illuminati from bringing about the end of the world. The Discordians, in true Discordian fashion, go under many names, such as the ELF (the Erisian Liberation Front), the LDD (The League of Dynamic Discord, also known as Little Deluded Dopes) and The Justified Ancients of Mummu, otherwise known as the JAMs. The JAMs had helped organise the assassination of JFK. They were "at least as old as the Illuminati and represent the primeval power of Chaos." They had once been part of the Illuminati, but they had rebelled in a similar way that Satan rebelled in Heaven and had either left, or been kicked out. As a side line, they had set up a record company to create some decent music. The rest of the music industry was controlled by the Illuminati, the book explained, which was how they were able to incorporate the anti-JAMs slogan "Kick out the Jams, motherfuckers!" into MC5 records.

Or at least, that's a typical interpretation of the plot. In true Discordian style, these things are fluid and open to interpretation. The book likes to play tricks with its narrative, happy to contradict itself in order to generate confusion and paranoia in the reader. Nevertheless, the idea that the Justified Ancients of Mummu represent chaos, and are at war with order or control, is a core idea that most take away from the book.

Needless to say, publishers were baffled by the whole thing. Eventually, after four years of effort, the first volume was published in 1975. It has remained in print ever since, won awards and inspired conspiracy fiction from Foucault's Pendulum to The Da Vinci Code, as well as countless video games and comic books. It planted the idea of the Illuminati as an organisation who are currently active, and who secretly run the world, into modern culture. This idea was intended as no more than a joke or a 'mindfuck.' Nevertheless, there are now countless conspiracy theorists around the world who believe that it is true. Imaginary ideas have a way of being just as influential, it seems, as more grounded ones.

Ken Campbell was paying for a stack of books in Compendium, an independent esoteric bookshop in Camden, London, when he noticed a copy of Illuminatus! on display by the till. He was searching for some science fiction that might be suitable to adapt into his next project because, following a pleasant evening drinking with the sci-fi author Brian Aldiss, he had decided that he quite liked the company of science fiction people. So it was that in 1976 Campbell and the writer and actor Chris Langham formed the Science Fiction Theatre of Liverpool, with the intention of creating a play to stage at Aunt Twackies. All he had to do now was find some science fiction.

His eye was drawn to this one book because it had a yellow submarine on the cover, which has obvious connections to Liverpool. The book itself was not science fiction, but booksellers had not known what to make of it and had placed it on the science fiction shelves for want of anywhere better. This, it seemed, was good enough for the Science Fiction Theatre of Liverpool.

Of all the books that he had bought, it was Illuminatus! that grabbed Campbell. It grabbed him in a way that none of the other ones did. Reading it was an eye-opener. It made him see the world differently. What had previously appeared to be hierarchical, ordered and neatly categorised now appeared as random connections of chance and ignorance. This effect was not just limited to the world in the book. The real world itself was changed, or at least how he perceived it. Illuminatus! made him simultaneously wiser and more baffled. It was good stuff.

Campbell decided to turn the entire trilogy into a cycle of five plays, lasting a total of eight and a half hours. There would be 23 actors playing over three hundred distinct parts. This epic tale of global domination would be told on a small stage at the back of a warehouse café. Most people would not consider this to be a plausible goal, but Campbell went ahead and did it anyway. As he saw it, things were only really worth doing if they were impossible. To quote the actor Chris Langham, who co-wrote the play with Campbell, "if it's possible it will end up as some mediocre, grant-subsidised bit of well-intentioned bourgeois bollocks. But if it's impossible, then it will assume an energy of its own, despite everything we do or don't do."

The cast and crew were recruited, often in ways as strange and disorientating as Wilson and Shea's writing. Bill Nighy, for example, was flat-sitting in London when he came across a copy of Illuminatus! After spending a day reading it, he turned on the TV and was confronted by a different image of something from the book every time he changed the channel, such as the bank robber John Dillinger or an American dollar bill (the symbolism of which the book discusses at length). Disturbed, he decided to turn to the TV off and go to the pub. He took the book along with him, only to be approached by a strangely dressed bloke with bushy eyebrows. It was Ken Campbell. When Nighy told Campbell that he was an actor, he was hired on the spot.

Other cast members included David Rappaport, Jim Broadbent and Prunella Gee, who played the Goddess Eris and later had a daughter with Campbell named Daisy Eris. Bill Drummond also came into Campbell's orbit. The pair spent a day down by the Mersey and by the end of it Drummond had been recruited to produce the sets for the show.

 It was never going to be easy. Campbell's key piece of direction to the cast and crew was, when thinking about the tone of what they were doing, to keep asking the question 'Is it heroic?' Drummond went back to the table in the back room that doubled as his workshop and painted the phrase 'Is it heroic?' on the wall in white paint. He then got to work.

 "...And fuck me, did he deliver!", to quote Bill Nighy. Drummond's solution was to build the sets in strange scales, utilising tricks such as foreshortening and strange angles, all of which perfectly suited the disorienting style of the play. Tables or beds were stood upwards and stuck to the rear wall, giving the audience the impression that they were looking down on the action from the ceiling. Given the seemingly contradictory scales of the story and the café stage, Drummond took Campbell's advice, assumed that the impossible would be possible, and just knuckled down and did it. And why not? Everyone was achieving things previously unimaginable. Jim Broadbent recalled the production of Illuminatus! working on a "genius level... It's wasn't that Ken was being a genius... it was the whole creation of doing the greatest show yet done on Planet World... his creative imagination was just stunning."

The success of the play led to a move south, and a sold-out run at the National Theatre in London began in March 1977. It now featured a pre-recorded prologue performed by John Gielgud, who played a computer called the First Universal Cybernetic Kinetic Ultramicro Programmer, or FUCKUP ("The best anarchist joke ever perpetrated at the heart of the National," in the view of Campbell's biographer Michael Coveney.) It also featured Robert Anton Wilson himself, who was given a role that involved lying naked on the stage shouting Aleister Crowley's maxim, "Do what thou will shall be the whole of the law!"

Wilson also brought a large amount of acid with him, which he offered to the cast. Bill Nighy recalls that "everyone went very quiet and then... 'Yeah, why not, thanks,' and we all dived in. So we were all tripping. It's a terrible idea if you want to act, but there you are..." Nighy's position was made more difficult because he had a scene with Neil Cunningham where they had to 'act' tripping. "How do we act tripping as we already are anyway?" Nighy asked. Cunningham suggested that they just stood there and held hands. So the pair of them stood on the stage, and held hands.

For many in the audience of the National Theatre run, this was their first exposure to Discordian ideas. Among them was a young artist called Jimmy Cauty. Cauty, originally from Liverpool and then aged 22, had already had some success painting best-selling Lord of the Rings and The Hobbit posters for Athena (they were bought, he said, "mainly by student nurses".) He did not, however, meet Bill Drummond at this performance. Drummond had disappeared from the project back in Liverpool. After the sets were completed and as the premiere of the play grew nearer, Drummond announced that he was just popping out to get some glue and never returned. It was the late Seventies and punk was starting to rumble. As radical as the book and play was, the spirit of the age was not emerging in the form of eight and a half hour plays. Together with Ian Broudie, then a young guitarist whom Campbell had recruited to perform music for the play, Drummond formed the band Big In Japan.

Campbell had shown Drummond that the impossible was only impossible if you did not stand up and do it. It did not matter how big the practical problems were, or how crazy the enterprise may seem. This was an important lesson in Drummond's education. He took that attitude, got a bass guitar, and went off to make music.

In October 1966, Jim Garrison sat down to read the Warren Commission Report and tried to make sense of the assassination of the President. The Commission had published 26 volumes of hearings and evidence. This was a lot of data, but Garrison was an experienced District Attorney and he was used to working with large and complicated sets of information. Methodically, he read through every witness statement and examined every photograph. With all the evidence mentally spread in front of him, he began to analyse. He saw connections and contradictions emerging from this web of data, and by linking these key facts he began to weave a narrative. This narrative, if he did his job properly, would provide clarity about what really happened. He was attempting to tease out the one story that was true.

It did not take him long to dismiss the Commission's findings. Their narrative claimed that President Kennedy had been shot for unknown reasons by an ex-marine named Lee Harvey Oswald, and that Oswald had acted alone, without the assistance of any other individuals or groups, either foreign or domestic.  Garrison could see how they had pulled this story from the mass of data, but he also saw too many errors in their analysis. Too much contradictory information had been ignored, and too many omissions had not been followed through. The Commission's conclusions did not, to his mind, tell the story of what really happened. If anything, it told the story of what people wanted to have happened. It had chosen the most palatable narrative, rather than the true one.

And it was important to know what had happened. Murder is serious and human life is valuable, but JFK's murder had another dimension above and beyond the loss of one man's life.  His murder hit people on a symbolic level. Kennedy was not then as universally popular as he is now remembered, but he was young, virile, and the figurehead of the nation. The beheading of a King is an ancient archetype, and when the second bullet removed much of Kennedy's head, that archetype played out in the psyche of the country. The American people, collectively, went into a kind of shock. Like the events of 9/11 and the death of Princess Diana, it was a tragedy whose impact on the subconscious was greater than anything a rational assessment of the death toll would suggest. The killer shot at one man, but millions were hit. And whoever was responsible, or so it appeared to Garrison, was getting away with it.

Oswald had spent time in New Orleans, so that gave Garrison an excuse to investigate further. If the true narrative couldn't be identified in the mass of data in front of the Warren Commission, then he would have to get more data. With more and more information, more and more connections would become visible, causing the number of potential narratives to increase exponentially. With enough data, it seemed sensible to assume, the true narrative would eventually emerge. So he began to ask questions.

One individual who soon took his interest was Kerry Thornley. Garrison did not know about Thornley's ideas of Discordianism, or indeed that his key writing had been reproduced on Garrison's own office photocopier. What he did know was that Thornley had enlisted in the Marine Corps in 1959, after graduating from High School with Greg Hill, and had met and became close with Lee Harvey Oswald. "You might say that I was [Oswald's] best buddy," he had told the Warren Commission, "but I don't think he had any close friends. I was a close acquaintance." Thornley was close with Oswald for just a few months before Thornley was posted to Japan and separated from him. It was while in Japan that Thornley heard that Oswald had entered the American Embassy in Moscow, handed over his passport, denounced his American citizenship, and defected to the Russians.

After leaving the military, Thornley had supported himself by washing dishes in New Orleans while he worked on a novel, The Idle Warriors, which featured a main character whom he based on Oswald. During this time Oswald returned from Russia, moved to New Orleans, and began hanging out in the same places and with the same people as Thornley. Garrison also knew that Thornley, who at the time was interested in extreme Libertarian politics, had been seen celebrating after JFK's death and was connected to a number of other people he considered suspicious. Garrison had witnesses who claimed to have seen Thornley with Oswald in New Orleans, so it was no surprise that Garrison would be interested in Thornley.

The problem was that Thornley had not known that Oswald was in New Orleans. He had not seen him since his marine days, and was at a loss to explain was why Garrison's witnesses claimed otherwise. Unless Thornley was genuinely involved in the JFK assassination, which hardly anyone believes, then some strange coincidences were at play. Clearly it must have been a case of mistaken identity, but the accounts which showed that Oswald frequented many of Thornley's hangouts and knew similar people seemed too suspicious to ignore - even to Thornley. As Garrison’s investigator Andrew Sciambra told him before Thornley's grand jury testimony, "If it checks out on the lie detector that you are telling the truth about having no prior knowledge of the Kennedy assassination, you can write another book: because if you aren't lying – and I personally don't think you are – you're a victim of the most fantastic chain of coincidences ever. This is just fantastic!"

He was right, it was fantastic. It was so fantastic that Thornley became fixated on trying to understand just what the truth about those days was. He had to somehow marry his memory of events with the testimonies of others, but try as he might he couldn't find any version of events that could be held up as credible and believable. In time he started to question his own memory, and began seriously entertaining the idea that he was a victim of false memories or mind control. These ideas would eventually lead to the confused and frightening world of paranoid schizophrenia, a fate that would prove to be not unusual for those who immersed themselves in Discordianism. He may have been the first Discordian to start hearing voices in his head, but he would not be the last.

For Garrison, however, there was the slow realisation that much of the information he was working with was contradictory. Someone somewhere was lying, in other words, and he didn't know who to trust. It was almost as if disinformation was being deliberately manufactured. Clearly some of the facts that he was analysing were wrong, but which ones were they?

In Garrison's narrative Oswald had been a 'patsy', a person set up to appear guilty to allow the real villains to go undetected, just as Oswald had himself claimed in custody before he was killed. Conflicting eyewitness reports claimed that Oswald had been in different places at the same time, so Garrison began to theorise that there had been Oswald impersonators planting fake evidence of communist or anti-American activities. Thornley himself was at one point considered to be a possible "second Oswald". Once Garrison's theory started entertaining ideas like this, there was little hope that it would produce a narrative of certainty and objective clarity.

Garrison uncovered a lot more information than the Warren Commission had, but this created less clarity, not more. This increased amount of data now suggested many different and contradictory narratives. The list of possible conspirators grew, coming over time to include the Mafia, anti-Castro rebels, Fidel Castro, the FBI, CIA, the Russians, the American Government and Lyndon B. Johnson - and this was before crazy people started adding fictional groups such as The Justified Ancients of Mummu to the list. The number of possible truths increased exponentially, each adding to the atmosphere of confusion and paranoia. Garrison did tease his own preferred narrative out of the chaos, and he eventually tried a local businessman named Clay Shaw for conspiracy to murder the President. Shaw was found not guilty, and the narrative Garrison chose has not convinced many others. Over time the amount of information surrounding the crime has continued to increase, and the real account of what happened in Dallas has long since disappeared under an ever-churning sea of fact and fiction. Confusion has grown as research has accumulated, and there are few who believe that the one true narrative, the only honest account of the assassination, will ever be found.

Sciambra's claim that Thornley was "a victim of the most fantastic chain of coincidences ever" raises some interesting questions. To choose just one example, what are the odds that Garrison's photocopier would have been previously used to copy the writing of one of his key suspects? At first glance, this seems extremely unlikely. There were 195 million people in America at the time, so the likeliness of two coming together in such a way must be extremely small.

To a mathematician, however, the issue is not so strange. They would point out that the photocopier link is arbitrary. We artificially assume a greater level of importance to the photocopier link because we know of a connection there, when in fact there are countless other possible connections between any two people. Had it been, for example, that Garrison had once bought a car from Thornley, or perhaps that Thornley's had once dated Garrison's niece, then we would have ignored the photocopier and invested these links with the same level of relevance. The true issue is not the photocopier, but whether there any connection between the two men at all, and the odds of this are considerably smaller than the odds of a specific connection. When you factor in that the two men were both based in New Orleans, and that Garrison's job made him very active in the community, then the odds fall even more. They are still high, of course, but not so high that mathematicians would find unusual.

There were many more strange co-incidences at play than this, however, and these were what Sciambra was alluding to. These include Oswald moving to New Orleans when Thornley was writing a book about him there, or people that knew them both mistakenly identifying Thornley with Oswald, or the pair never meeting despite frequenting the same places, or Thornley's friendship with people who had discussed the idea of assassinating the president. The odds against all these are individually very high, and when all such coincidences are considered together, they multiply. A mathematician, however, would see such high odds are interesting, but not inexplicable. The amount of different connections between all the different elements of our world are so huge, and so many different things happen at any one time, that finding a set of events that have such unimaginable odds is not strange. In fact, when the full enormity of actual events in this world is considered, such unlikely strings of events are guaranteed to happen. Mathematicians such as Persi Diaconis and Frederick Mosteller call this the law of truly large numbers.

Those who find themselves at the centre of such a storm of coincidence, however, rarely find this simple numerical analysis satisfying. They would argue that it does not differentiate between irrelevant coincidence and strange events that seem to possess their own innate meaning. More specifically, there can often appear to be a distinct sense of humour at work, behind the onslaught of coincidence, that mathematics isn't a suitable tool to appreciate.

Thornley would have dismissed the mathematician's claims of coincidence, and instead viewed these events as what Carl Jung called 'synchronicity.' Jung defined synchronicity as a "meaningful coincidence" or an "acausal connecting principle", where "acausal" means a string of events that cannot be fully explained by simple cause and effect. Or, to put it another way, if something is behind these events, then we don't know what. Jung has come to be regarded as one of the giants of modern psychology, comparable to his colleague and rival Freud, but there are many who dismiss his ideas about synchronicity as little more than 'magical thinking'. For Thornley and many other Discordians who found their lives spiralling out in strange and impossibly unlikely ways, however, Jung's ideas seemed an accurate description of the world around them. They were being buffeted by events beyond their control, and they thought that something was behind it.

For the early Discordians it was tempting to believe that when Greg Hill used D.A. Garrison's photocopier to produce the first edition of Principia Discordia, something, some spirit of Discord and Chaos, somehow emerged, or returned, or arrived in the world we know. Of course, Greg Hill was an atheist. He intended Discordianism to be a satire of religion, and did not take the idea of goddesses or spirits seriously. By the late 70s, however, he was convinced that his Discordian adventures had stirred up something that he was unable to explain. As he told his friend Margot Adler, "If you do this type of thing well enough, it starts to work. I started out with the idea that all gods are an illusion. By the end I had learnt that it is up to you to decide whether gods exist, and if you take the goddess of confusion seriously enough, it will send you through as profound and valid a metaphysical trip as taking a god like Yahweh [The Jewish/Christian/Muslim God] seriously." The effects of invoking a made-up god, in other words, were no different to sincerely invoking a 'proper' one. This was going to be an eventful realisation for those that invoke Eris. As Thornley once remarked to Hill, "You know, if I had realised that all of this was going to come true, I'd have chosen Venus."

In the Summer of 1983, Bill Drummond walked to Matthew Street and, at the exact time that the Bunnymen went on stage in Reykjavik, he stood on the manhole cover.

Drummond's personal mythology had grown considerably since he saw Echo in the record sleeve. He had come to view the different personalities of his two bands as alchemical opposites. The Bunnymen were cold, aloof and impenetrable, whereas the Teardrops were dangerous, wild and burning. He had come to associate both bands with places that had had a hold on his imagination as a child. The Bunnymen evoked similar feelings to his memory of Iceland, which he had visited as a boy. He had stood on the edge of an immense glacier, and been overawed by the scale and cold grandeur of the place. The thought of the Teardrops, in contrast, conjured up images of Papua New Guinea. He had never been to Papua New Guinea, but he had heard the story of how a great-great uncle of his had once gone there as a missionary, and been eaten by natives. His childhood mind imagined it as a wild, uncontrollable place, burning hot and dangerous, with thick forests bristling with dreadful things without name. Not too dissimilar, in other words, to how he had come to view Julian Cope.

In Drummond's mind Iceland, Papua New Guinea and Liverpool were linked in a manner that made sense emotionally, if not rationally. He could imagine a great flow of some form of energy flowing through space and powering into the Earth. It poured into Iceland, flowed just under Matthew Street, and emerged back out into space again at Papua New Guinea. This was an idea that he entertained, rather than believed. It was a mental folly, in other words, constructed for amusement rather than practical use. But something about it appealed in a way he couldn't dismiss outright, and a plan bubbled up from his subconscious.

His idea was to arrange for the Bunnymen to play a gig in Iceland at exactly the same time as the Teardrops played in Papua New Guinea. He would remain in Liverpool and, at the correct time, he would go and stand on the manhole cover. Quite why he would do this, though, was another matter. He had a vague feeling that something would happen, but exactly what was hard to define. Perhaps he would somehow absorb the energy of the two bands? Perhaps he would gain some form of enlightenment? It was completely mad, of course, he knew that. But that wasn't a good reason to not do it.

There was a big problem, though. His relationship with Julian Cope had deteriorated to the point where he could no longer influence him. Cope's ego had broken loose following a little fame and a lot of LSD. As Drummond later wrote, "Cope was careering from being pop pin-up to great acid casualty pop eccentric, somewhere between Sky Saxon and Syd Barrett but with an ego telling him he was Lord Byron, Jim Morrison and the son of a very unchristian god all at once. Great stuff and I loved it, but how was I to persuade him he should do a concert in the highland jungles of Papua New Guinea when I couldn't even tell him to have a bath?" 

The Bunnymen were not as difficult. He had previously arranged a Bunnymen tour which went up and down the country in a seemingly random way, playing unlikely and bizarre venues. What the band hadn't realised was this was all part of Drummond's attempt to evoke Echo, who had been conspicuous in his absence from later Bunnymen record sleeves. If you drew a line between the gigs on a map, they formed a pair of rabbit ears. Arranging a gig in Reykjavik was fairly normal in comparison.

So as the band took to the stage Drummond duly went down to Matthew Street. It was not the same as if the Teardrops were involved, but it was the best he could do. He stood on the manhole cover.

A short while later, after he had satisfied himself that absolutely nothing was happening, he wandered off and got the bus home.

It was time to move on, both from his bands and from Liverpool. He had put a lot into Zoo records. He'd re-mortgaged his house on two occasions to pay for tours and studio time. The end result, however, had not lived up to his aspirations. He was not proud of the records he made, and he found himself having to make decisions that caused bad feelings among his friends and colleagues. More importantly, it was not fair of him to indulge his inner fantasies at the expense of the careers of these bands. They were just not driven by the same forces that he was, and it was not fair to play with their careers for his own internal amusement.

Before long the Teardrops collapsed, the Bunnymen found more professional management, and Drummond was offered a job working for a major label. He moved to London and became an A&R man at WEA.

His inner life, though, still churned.

On July 23rd 1973 Robert Anton Wilson began hearing voices in his head. They appeared to him to be communication from an alien life form somewhere in the vicinity of Sirius.

This was not that unusual for heavy drug users in California during the early 1970s. Philip K. Dick, for example, began receiving similar communication from the alien entity that he christened VALIS in February 1975, and Timothy Leary was also channelling aliens at around the same time, to help pass the time while incarcerated in Folsom Prison. What was significant about Wilson's experience, however, was how he came to interpret it.

Wilson was sane enough to know that just because it appeared as if aliens from Sirius were talking to him, it did not follow that this was what was actually happening. He turned to the medical literature and searched for an explanation. Perhaps there was a known process where a chemical imbalance causes randomly firing neurons to connect in an unusual way, for example, which would explain what he was experiencing? The trouble was, he couldn't find anything. The schizophrenic family of illnesses were very poorly understood back in the 1970s, as indeed they still are now. They may have been named and described, but a name was not an explanation, nor did it tell him what was going on. Neuroscience has made some remarkable discoveries about the brain, but when it comes down to explaining issues of awareness and the actuality of experience it is still struggling in the dark. Science could slap a label on what was happening to him, Wilson discovered, but it could not explain it.

This being California in the 1970s, Wilson decided to tell a psychic about what was happening to him. She told him that he had it all wrong. He was not hearing voices from aliens from Sirius at all. What was really happening, she explained, was that he was in communication with the spirit of an ancient Chinese philosopher.

Wilson thought about this. It seemed to him to be just as plausible as the Sirius explanation. Either explanation fitted the data just as well as the other. But which explanation should he favour? How could he find out whether he was receiving information from aliens from the star Sirius or an ancient Chinese philosopher? He decided to get another opinion. He asked another psychic. This psychic was adamant that both the Sirius and the Chinese philosopher explanations were nonsense. In actual fact, Wilson was told, he was in touch with the spirit of a medieval Irish bard.

This was getting confusing, and lesser men would have given up and gone quite mad at this point. Wilson, however, made one the most important philosophical leaps of the twentieth century, although, admittedly, it is not yet generally recognised as such.

As well as undergoing drug-induced schizophrenia, Wilson had been raised as a Catholic and had also been a communist in his earlier years. He had fully accepted these two powerful belief systems, before rejecting them both. Thanks to this background, he was able to recognise what he would later call a self-referential reality tunnel. This was a philosophy, religion or ideology that was complete and satisfying and which fully explained all the details of the world, assuming that you did not question its central tenet. This central tenet was an idea, and often an appealing idea, for which there was no evidence at all, such as the idea that there was a judgemental patriarchal creator God or that a property-less communal utopia would be the final stage of society. The rest of the ideology boiled down to an elaborate commentary which supported and protected the central concept. All the theory and education that is needed to fully understand an '-ism' or religion functioned like a sophisticated defence mechanism which protected this central tenet from crashing and burning on the rocks of reality. The reason these ideological defences were so painstakingly built up over time was because, once inside a self-referential reality tunnel, you had a model that made sense of the rest of the world. This could be extremely appealing situation, and one that you could happily stay in for the rest of your life.

The idea that a hyper-evolved intelligence from the stars had selected Wilson to receive great founts of admittedly confusing cosmic wisdom, and hence help mankind evolve into a higher state of being, did seem an appealing notion and one that would explain a great deal. But Wilson could see that it was just another self-referential reality tunnel, like Catholicism or Marxism, and that it was vitally important that he did not come to believe the bugger.

It was around this time that Wilson watched the Jimmy Stewart movie Harvey. In the film, Stewart plays an amiable small-town drunk called Elwood P. Dowd, who stumbles out of a bar and meets an invisible 6' 3½" rabbit named Harvey. "How are you this evening, Mr. Dowd?" asked Harvey. Dowd was not too surprised by this. "It's a small town, everyone knows my name," he reasons, and strikes up a friendship with the rabbit. The other characters in the film, however, are more concerned about Dowd's relationship with the giant invisible rabbit, and do not accept Dowd's explanation that Harvey is actually a Pooka, an ancient rabbit spirit from County Derry.

A psychiatrist called Marvin Wilson attempts to treat Dowd, but in doing so cracks up himself. The turning point is a scene where he looks up Dowd's word 'Pooka' in a dictionary. He reads aloud: "Pooka, noun. A Celtic elf or vegetation spirit, wise but mischievous, fond of rum plots, crack pots, and how are you today Mr. Wilson?"

"Oh that's all I need," thought Robert Anton Wilson.  "Now the television is talking to me."

Still, the idea that an ancient rabbit spirit from Western Europe was communicating with him had a certain appeal, and now Wilson thought about it, it seemed just as plausible as the other explanations he had. Indeed, it offered something that the aliens and bards and philosophers lacked. There was absolutely no danger that he might take the idea literally.

As Wilson saw it, we all need models in order to deal with the world around us. We need models that fit the existing facts and which have some ability to predict what will happen next. This is what all the best ideologies, religions and philosophies offer us. What we shouldn't do is confuse these models with the real world, for the map is not the territory and the menu is not the meal. Once this is understood, the need to fight to protect the 'truth' of the model falls away and we are free to use different and contradictory models as circumstances change. So it was that as Robert Anton Wilson's consciousness kept producing strange and dazzling feats of awareness, Wilson comforted himself with the idea that a giant invisible European rabbit spirit was currently intent on trying to tell him something, and by and large he felt much better about the whole thing.

This is, as no doubt you have noticed, the second time in our story that a giant invisible rabbit spirit has appeared. This is of course a coincidence.

It also has all the hall marks of what Jung would call synchronicity. Giant invisible rabbit spirits are extremely rare, so when two come along at once it is hard not to sit up and take notice. Indeed, it is hard to think of other occasions where giant invisible rabbit spirits might appear. Cryptozoologists and Forteans do possess accounts of sightings of giant rabbit creatures, but not in any great number. Apart from the film Harvey, they make very few appearances in our culture. The only example that springs readily to mind is Donnie Darko, a movie made in 2001 by Richard Kelly. What then – if anything – should we make of the fact that the film opens to a montage set to The Killing Moon by Echo & the Bunnymen?

The Killing Moon is a song that was written after singer Ian McCulloch woke from a dream with the lyric 'Fate, up against your will' in his head. It was never supposed to appear at the beginning of the film. The director wanted to use Never Break Us Apart by INXS, but financial and licensing issues got in the way and the Echo & the Bunnymen song somehow barged its way to the front. (The director was later given the chance to make a Director's Cut of the movie, where he was able to shove the song back to a later, Halloween party scene and start with the INXS song as he originally intended.)

What should we make of this? We shouldn't make anything of it. We should forget it and move on. If it makes it any easier, this author can assure you that there will be no other appearances in this story by giant invisible rabbit spirits. As our story takes us deeper into the music industry, the rabbit spirit either flees or evolves into something else. Just for now, picture this spirit in your head – tall, powerful, with long ears upright on the top of his head. How does he strike you? Mischievous and lusty? Or something more sinister?

But now – forget him. He's gone.

Bill Drummond, as may already be apparent, is an unusual man.

A good illustration of the odder aspects of his personality can be seen in a May 2012 interview he did with The Guardian's Tim Jonze. Jonze talked to Drummond about his attempts to turn simple acts into art. The example he quoted was how, when walking to and from a fishing spot, Drummond would walk in a route which, if drawn on a map, formed the outline of a fish.

"It may be a form of OCD or just an attempt to give life more meaning than it seems to have," Drummond replied, "but as far back as I can remember I have had a habit of trying to create patterns in the games that I played or the things that I was doing. In my childhood this could be climbing 10 different trees before the sun passed the spire of the parish church or walking out the shape of a square on the map of our town when going to the shops and back to get the messages for my mum. I was never that interested in organised games or religion because someone else had already worked out what all the patterns were."

While this does indeed sound like “a form of OCD”, it's worth putting it in the context of his Presbyterian upbringing. Drummond's father was a minister in The Church of Scotland and the strong work ethic of that faith runs through his career. It is particularly evident in the art that he has produced in the twenty-first century. Art for Drummond is not spontaneous carefree play, but work that needs to be scheduled and completed. The fact that Drummond is a fastidious grafter, by both nature and nurture, made him a potent subject to absorb Ken Campbell's ideas about achieving the impossible.

Drummond also told Jonze that "using a word such as ritual may be too loaded for my liking, but I guess it is from these motivations in us that ritual is born. In the past dozen or so years, I have tried not to suppress or hide these urges in me and let them openly be the central driving force in my stuff."

It is this aspect of his behaviour that has led to suggestions that his actions are not art, but magic. "[Bill] Drummond is many things," Charles Shaar Murray wrote in The Independent, "and one of those things is a magician. Many of his schemes [...] involve symbolically-weighted acts conducted away from the public gaze and documented only by Drummond himself and his participating comrades. Nevertheless, they are intended to have an effect on a world of people unaware that the act in question has taken place. That is magical thinking. Art is magic, and so is pop. Bill Drummond is a cultural magician..."

Does Drummond view himself in this way? He doesn't make any claims to be consciously practising a form of magic, or to have a significant interest in the subject. That said, the location of one screening of the film Watch The K Foundation Burn A Million Quid is suggestive.

Most of the venues for these screenings were arts centres or clubs, although there were more unusual locations such as schools, jails and St. Michael’s Tower on top of Glastonbury Tor. One venue does jump out of the list of tour dates as distinctly different from the others, however. On 7th March 1996, they screened the film in Alan Moore's house in Northampton.

Alan Moore is a comic book writer. He has been called the greatest ever comic book writer so often that it is most probably true. He found fame in the 1980s with works like V for Vendetta and Watchmen and continues to write prolifically in his native Northampton. Besides this work he is known for his disdain of Hollywood, his extraordinary beard, and for his interest in magic. It is this last point which appears to be why Moore was the only individual who the KLF actively sought out to screen the film for, in order to hear his opinion. If you want to know about magic in the modern era, Moore is the man to ask.

To understand his take on the burning, however, we first need to grasp what Moore means by the slippery word 'magic'. The place to start is in the early days of his fame, when fans would turn up in droves at conventions and signings and ask him questions. One of the questions that kept coming up was, "where do you get your ideas from?"

Most writers hate this question because they can't answer it. Like everyone else, Moore would fudge an answer as best he could. But unlike most writers he recognised that it was actually a very good question and one that he would very much like an answer to. Where did he get his ideas from? By now he had a family to support. Earning money for them depended on the regular arrival of new ideas, which he seemed to have no control over. What would he do if they stopped? Most writers fear even talking about this, seemingly scared that they may offend their muse and be robbed of their talent. If it works, they think, leave it alone and whatever you do don't ruin it. But this didn't sit well with Moore. His imagination was part of the tools of his craft. A taxi driver, for example, would know how to get under the bonnet of his car and repair it if it broke down. Shouldn't a working writer should be able to do the same to their imagination?

What is imagination? It is the creation of original thought from your own consciousness. But then, what is thought and what is consciousness? Here he ran into what is known as the 'hard problem' of neuroscience, how the experience of awareness springs from a lump of damp matter like a brain. If the cosmos is just a bunch of inanimate particles flung out of the chaos of a Big Bang, how exactly did it become aware of itself?

Moore could not find anything approaching an answer to this. The beauty of science is that it strips the subjectivity and bias out of observation and allows us to probe the real world objectively. This is an elegant and extremely useful approach, but not one designed for understanding an intrinsically subjective process such as consciousness. Science can study neurons and brain matter. It can discover how they link together, how they grow, and how they fire electrical impulses at each other. But it cannot put a thought under the microscope. We can scan the brain and see what regions are active when a person looks at a field of grass, but we cannot isolate the experience of being aware of grass. We cannot find awareness, or store it, or cut it up and find out what it is made of. Many scientists, faced with this, take the view that consciousness doesn't actually exist; it is an illusion. This illusion is an emergent property of the brain. Patterns of activity across the billions of neurons in the brain fool the brain into believing that it is a 'mind', but that 'mind' has no actual existence in any real sense.

This subject was a hot topic in the early 1990s following the publication of Daniel Dennett's remarkable book Consciousness Explained in 1991. The book skewered many of our false assumptions about how thought and the mind work. For many people, however, its argument collapsed at the final hurdle - the point when Dennett attempted to show that consciousness doesn't actually exist. The reader could hear Dennett's voice shifting in the book's final sections, becoming hectoring and bullying as his argument seemed to get weaker. To be fair to Dennett, this argument was always going to be a difficult sell. Most people, especially non-neuroscientists, reject the argument instinctively (his book is referred to as Consciousness Explained Away in certain circles, or Consciousness Ignored). This is especially true of those who have had experience of expanded states of awareness, such as heavy meditators. Moore was one of those who was unconvinced. He was damn sure that his consciousness existed.

His argument went like this: Dennett's arguments were rooted in the impressive work of neurobiology. This in turn sits on some very solid foundations. Biology is supported by chemistry, which itself is supported by physics. We have a good understanding of these fields of study, and their conclusions look secure. But physics itself rests on the smaller scale world of quantum physics, and in quantum physics the world is affected by an observer – or in other words, consciousness. The train of logic that claims that consciousness doesn't exist, therefore, itself requires the existence of consciousness.

We should be slightly cautious with this argument. Quantum physics is so alien and baffling that it can be trotted out by non-scientists to justify all sorts of freaky claims. In this instance we should be careful about what we mean when we refer to 'the observer'. In quantum physics, the observer is entangled with the observed in such a way that choices made by the observer can alter the object that is being observed. The passage of information between the pair is the important element here, but does the observer have to be 'conscious' as we understand it? When you put a cold thermometer in a glass of hot water, the thermometer both measures the temperature of the water but it also affects it: it cools it down a little. Here the final measurement produced is a product of both the observer and the observed, but a thermometer is not conscious, or if it is, it hides it well.

Still, the need for awareness in an observer is a moot point. If it turns out not to be necessary, consciousness will hardly have been disproved, having instead wiggled out of the picture again. Regardless, Moore was satisfied with his own logic. He took the position that consciousness does actually exist. Ideas are real things. A different type of real, admittedly, but real nonetheless.

Moore was mulling over these issues when he was writing From Hell in the early 1990s. From Hell – another of his masterpieces – is a dense, multi-layered examination of the Jack the Ripper legend, one which doesn't just concern itself with the crimes, but with the society they emerged from. Victorian London is evoked using psychogeography, a technique based on the derives of the Situationists in which the history and associations of places are understood to have an effect on those who visit them. Moore's Ripper is the royal surgeon Sir William Gull, who is murdering prostitutes to cover up a royal scandal but who realises that this 'work' has considerably greater implications and power.

In one scene, Gull is eating with his coach driver. In the cause of the conversation Moore gives him the line, "The one place that gods unarguably exist is in our minds where they are real beyond refute, in all their grandeur and monstrosity." Having written the line, Moore later returned to it and thought it over. As far as he could see, if he was being honest with himself, what he had written was true. Try as he might, he wasn't able to produce an argument that honestly refuted the idea. This came as something as a shock.

"The one place that Gods unarguably exist is in our minds where they are real beyond refute." If the line was true, what were the implications of it?

Moore understood that while we assume that we live firmly in the real, physical world, in actuality we live in a mental model of that world. This model is produced by our minds based on memories and information from the senses. It is a very detailed and convincing model, so much so that it is difficult to accept how unreal it is. If you look at an object, for example, you see colour and assume that the object is that colour. But colour as we experience it is an invention of our minds which does not exist in the real world. It is a mental interpretation of whichever wavelengths of light the object we are looking at cannot absorb and so bounces back to us. This is something that the Buddhists worked out early on. They used to ask students "What makes the grass green?", and expected them to discover through meditation that the answer was themselves.

But even if we accept that we only know the physical world through a mental approximation, we rarely acknowledge how much of the physical world is actually the product of the mental. For example, consider these words that you are reading – where did they come from? What about the language that they are written in? What about the shape of the letters themselves? What about the font? If you reading them on paper, then how is paper created, and where did the idea to create paper come from in the first place? If you are sitting in a chair, who designed that chair? Or the floor on which it sits? Look around the room that you are in. Is there anything there that didn't first appear as an idea in the head of another person? Think about the aims of the job you do or the ideology of your preferred political party. Thinks about the recipes of the food you eat or the music you listen to. The world we actually live in is made of ideas that have left human minds and entered the physical world. Indeed, the story of our evolution is essentially the story of us retreating from the natural world into the mental one.

The reason we have a hard time understanding this, Moore realised, is because we lack a model of what the mental world is. The 'I' of awareness is our blind spot, to the extent that the consciousnesses of some of our cleverest and best educated minds, such as Dennett, will deny that consciousness even exists. The first task in getting a grip on the world of ideas, Moore thought, was to create a practical model to describe and understand it.

Moore set out to build a model of the mental world, a place sometimes referred to as the noosphere but which Moore calls Ideaspace. As the '...space' part of his name implies, he chose a spatial metaphor. This seemed reasonable, he thought, for we naturally talk of ideas being at the back of our minds or at the forefront of our thinking, we can be deep or high-minded, and so forth. Ideas, then, were placed in a 'space' in this model. The ideas could be small or large; our most detailed and complicated ideas, such as religions, ideologies or Robert Anton Wilson's self-referential reality tunnels might make up entire continents of Ideaspace. Where this differs from the physical world, however, is that the normal rules of time and space do not apply. Lands End and John O'Groats, for example, are physically very separate in the real world, but very close in Ideaspace because they are so often linked in our thinking. In a similar way, we can just as easily think of something that is happening now, something that happened a few years ago or imagine what will happen in the future. Ideas in this model are connected more like hyperlinks on the internet than geographical locations in the real world. This concept of being linked via connections rather than geography is, of course, similar to how neuroscientists view the storage of memories.

So far, so uncontroversial. But where this becomes interesting is when we consider our own relationship to that world. Moore thought that we each had our own little corner of Ideaspace, our own home in the mental land. Something personal like Drummond's idea of Echo would live in Drummond's own section of Ideaspace. Many ideas, however, are shared, and while we may have our own personal version of them, they are more usefully said to exist in communal space. Concepts such as ‘Madonna’, ‘Sherlock Holmes’ or ‘Hitler’, for example, are shared by almost everybody. For Moore, these communal ideas existed beyond our own personal corners of the mental world.

Could we then wander out of our little territories, go further afield and explore the rest of Ideaspace? Here Moore's model is describing something very similar to Jung's collected unconscious. Moore thought that yes, we could open the doors of our individual homes and walk out into this shared landscape beyond. Indeed, he thought that artists had to, for it was their job to wander furthest from their own patch of the imagination and return with truly rare and exotic ideas which they had to use and make something out of. In this way the world we live in becomes increasingly changed by the mental world.

It is this process – the way thoughts exist and alter the world – that Moore uses the word 'magic' to describe.

What Moore had done was to raise the importance of the mental world of imagination and lower that of the physical. Indeed, you could argue that he has reversed them, claiming more importance for the imagination than the physical to the extent where the physical world is the product of the mental. This approach, in which the material is dependent on the immaterial, echoes Charles Fort’s belief that, "A tree cannot find out, as it were, how to blossom, until comes blossom-time. A social growth cannot find out the use of steam engines, until comes steam-engine-time.” This was the phenomena of why, after millennia of inventions such as the electric light, calculus or steam engines not existing, several people would invent the exact same thing at much the same time (at which point there’s a mad race down to the patent office, with the winner being the one who is celebrated by history whilst the others forgotten). As Moore saw it, the idea had been discovered in a shared area of Ideaspace, and several wanderers had stumbled upon it shortly afterwards.

Moore then took this one stage further, and it is at this stage that the model becomes more controversial. When biological things in the physical world evolve to a certain level of complexity, they become living, conscious, self-determined individuals. Could the same be true for ideas in the non-physical world? Could sufficiently complex ideas evolve into a form of life, and wander Ideaspace as they saw fit? If this was the case, it would explain all those stories of ghosts, aliens, fairies, angels, elves, giant invisible rabbit spirits, the Goddess Eris and all the other unreal creatures that appear throughout cultures and history. This idea would be a leap of faith for most people, but it was a leap that Moore took. Moore has said that he and his friend Steve Moore conjured up a demon in his living room around this time and had a long conversation with it. First-hand experience such as this would no doubt make that leap easier to make.

Carl Jung had also made a similar leap, although his terminology was different. In 1913 he had been troubled by a recurring dream that was both sinister and disturbing. He dreamt of a terrible flood that covered "all the northern and low-lying lands between the North Sea and the Alps." In this flood, which stretched from England to Russia, he saw "yellow waves, swimming rubble and the death of countless thousands." When the dream re-occurred, it was accompanied by an 'inner voice' which said, "Look at it, it is completely real, and it will come to pass. You cannot doubt this."

When the First World War followed, Jung had no choice but to see his dream vision as a premonition. For a scientist, this was deeply troubling. It challenged him to come up with a theory or explanation as to how a major event in world history could have been represented in his mind before it had actually happened. This trail of thought would lead, decades later, to his theories on the 'acausal connecting principal' of synchronicity. For our purposes, however, we should note that such an occurrence fits Moore's model of mental phenomena. The contents of Moore's Ideaspace exist outside of the physical world's relationship to time. Events that are about to happen - or rather, the idea of events that are about to happen - could well be discovered in this immaterial realm by deep wanderers such as Jung. Although these events have yet to occur in the physical world, the idea of them may be found forming, like an early warning alarm, in this strange mental landscape that Moore calls Ideaspace and Jung called the collective unconscious.

This was the background to Moore's thinking when he viewed the film of Drummond and Cauty burning the million quid. "I thought it was awesome in some ways, very funny in others. It burned well – very clean flames," he told them.

What was more significant, though, was that the idea of burning the money had been found in their local area of Ideaspace in the first place. The idea had bewitched Drummond and Cauty so strongly that they had been compelled to act upon it, despite not knowing why they did so. Of course, there was no reason why they should understand what it meant: their reaction to it was largely irrelevant. What was important was that the idea had found them in the first place. Its very violence and its shocking nature indicated that something significant was happening, deep down in the depths of our shared mental world. It was like a volcano that heralds an imminent shift of the tectonic plates. If the physical manifestation of this eruption was anything to go by, it seemed to be linked to one of the most powerful magical ideas we have: money.

"It was a powerful magical event," Moore told them afterwards. "I can't see any other explanation for it. You're dealing with a form of language, a conversation – but you're not sure what the conversation is... you're waiting for a reply."

As noted earlier, neither Cauty nor Drummond claim that their actions are magical, nor do they adopt the trappings, clothing, and affectations of the occult world. Nevertheless, Drummond's behaviour consistently displays a strong resonance with Moore's belief that the mental world is more important than the physical, that ideas possess validity in themselves and that they can affect the physical world. His visit to the manhole cover and his obsession with Echo are good examples of this.

Moore's opinion of the burning, that it was a conversation and that they were waiting for a reply, also seems to have resonated. As noted earlier, Drummond still waves away questions about the burning by saying that they are 'still waiting for a response.' So while Moore's ideas about the nature of magic may not help us to understand Cauty and Drummond's personal motivations, they are a valid way to view actions that were the product of magical thinking.

Alan Moore would also later say, "I like Bill Drummond a lot, I really do, but you have to understand that he's totally mad."

On New Year's Day 1987, Bill Drummond was visiting his parents and went for a walk in the morning. He had left the music industry.

On July 21st the previous summer, at the symbolic age of 33 and a third (or near enough), he had issued a press release to announce that he was quitting his job as A&R man at WEA records. It was, he said, "time for a revolution in my life." His time would now be dedicated to writing, art and climbing mountains. But first, he'd mark both this totemic age and his retirement from the music industry by releasing a solo album.

The album was called 'The Man.' It was, somewhat unexpectedly, an album of low-key, acoustic Scottish folk in which Drummond sang songs of love and music in a pronounced Scottish accent over blissful slide guitar. Recorded in five days and released on Creation, song titles such as I Believe in Rock & Roll, I'm The King Of Joy and the opening instrumental True To The Trail reaffirmed his dedication to the potential of music. This was no bitter dismissal of his career or the music industry that he was leaving. Still, it was an deeply odd affair. His voice brought Ivor Cutler to mind, the closing track featured his father reciting Burns and the cover showed Drummond sitting on a Scottish dock holding a guitar whilst dressed in an outfit of blue jeans, white socks and brown shoes. It is remembered mainly for the track Julian Cope Is Dead. After the demise of The Teardrop Explodes, Cope had gone on to have a long, erratic solo career in which he combined moments of visionary genius with a considerable amount of pig-headed noodling. Julian Cope Is Dead was seen by many as Drummond’s response to a song of Cope's called Bill Drummond Said, and it gives some insight into Drummond's complicated relationship with Cope. Its jaunty chorus begins, 'Julian Cope is dead / I shot him in the head.'

With that record made, Drummond was out of the music industry. He sat down and began to work on a book entitled Why Andy Warhol Is Shite.

But work on the book did not go well. Two things distracted him. One was listening to Schooly D. The other was his decision to start re-reading Illuminatus! 

Drummond returned from his New Year’s Day walk and phoned Jimmy Cauty. He told Cauty that they should form a hip-hop group called The Justified Ancients of Mu Mu (the misspelling appears to be accidental, for it wasn't until 2007 that Drummond realised that Wilson's spelling was 'Mummu'). Drummond knew that Cauty would understand what he meant by the name. The other reason he called him was because Cauty had recently bought a sampler.

Cauty did indeed instantly understand where Drummond was coming from. The act of taking that name, of adopting the mantle of The Justified Ancients of Mummu, may have seemed a simple, trivial act at the time. That day, the 1st January 1987, was the official birth of the JAMs. The Justified Ancients of Mummu had stepped from fiction into reality.

Drummond and Cauty became partners. The fact that this version of their story talks more about Drummond than Cauty should not be taken to imply that Cauty was in any way a junior partner. Had this account been a traditional music biography, filled with details about what track was recorded in what studio when, then Cauty could have had a more prominent role. A simplified description of their partnership would portray Cauty as the musician and Drummond as the strategist, but this view doesn’t hold up to scrutiny. All the products of their partnership, whether musical or otherwise, came out of mutual agreement. Cauty is just as capable of burning stuff as Drummond.

Any difference in their roles comes down to their own individual characters. Cauty is practical and above all curious, quick to get his hands dirty, experiment and see what happens. He is a catalyst. Drummond, on the other hand, is not so much curious but driven. The difficulty of defining exactly how he is driven is what makes this narrative spend more time on him.

Drummond met Cauty in 1985. Cauty played guitar in a band called Brilliant, alongside Youth from Killing Joke and the singer June Montana. Drummond had signed Brilliant to WEA where they had made an album with the pop producer Pete Waterman. "It was a complete failure," Drummond has said. "It was an artistically bankrupt project. And financially deaf. We spent £300,000 on making an album that was useless. Useless artistically, useless... commercially." Still, the pair had learnt a lot about making pop records by watching Pete Waterman work. More importantly, they seemed to understand each other. Cauty and Drummond had what the writer Richard King describes as "an almost telepathic way of communicating."

"We'd never had to discuss anything because we knew we both liked exactly the same thing," Cauty has said. "There was never any disagreement on music or anything. It was quite weird, actually."

 So when Drummond mentioned The Justified Ancients of Mu Mu to Cauty, he understood exactly what that meant. Cauty had seen the Ken Campbell's production of Illuminatus! at the National Theatre. He knew that the name would represent the principle of chaos working against the corporate music industry, a guerrilla band of musical anarchists who existed to disrupt, confuse and destroy. Taking on that name certainly appealed.

In this context, hip-hop was a good fit. This new, emerging form of music had no need for 'proper' bands. It wasn't interested in songs and it wasn't even interested in singing. It certainly had no need for virtuoso musicians. It was quite prepared to take a chunk of someone else’s record and use that for its own ends. To many, it almost seemed to be anti-music. Drummond may have been of the opinion that hip-hop was the only music "fit for these modern times," but this was a minority view at that point. Rap and hip-hop had yet to become the all-conquering commercial and cultural force that we know today. If anything, it seemed like a novelty or a brief fad at best, especially when older white Brits tried their hand at it. Many of the bestselling rap records in the UK were spoofs, such as Roland Rat's Rat Rapping or Stutter Rap by Morris Minor and the Majors. There was still a considerable body of opinion that dismissed rappers as people who talked over a record because they couldn't sing.

But taken together, the ideas of sampling, hip-hop and Discordianism made a strange sort of sense. Drummond could see that. Cauty could see it also. There was no need for further discussion. They got to work.

The Justified Ancients of Mu Mu - the JAMs - existed for one year. They released an album (1987: What the Fuck is Going On?) and split exactly twelve months to the day after forming. Or at least, that's the official narrative. The actual history is messier, for there was a posthumous album in 1988 (Who Killed The JAMs?), a greatest hits compilation (Shag Times), and the It's Grim Up North single in 1991. But in broad terms the story of the JAMs, and Drummond and Cauty's interest in hip hop, took place in 1987.

If and when the JAMs are remembered today, it is usually for their pioneering role in establishing sampling as a legitimate creative act in modern music. In many ways, however, that misses what it was that they were doing.

Sampling, as we now understand it, consists of taking individual parts of an existing record - a drum beat, perhaps, or a melody line - and making something new out of them. It is about finding a loop or a beat that is good in itself, and using that to build something else. The JAMs, on the other hand, took whole sections of someone else's record and used them as they were. They took things not for how they sounded, but for what they represented. When they took parts of ABBA and The Beatles it was not because of the quality of the sound, but very specifically because they were records by ABBA and The Beatles.

The bluntness of the JAMs musical thefts can be seen as being an unsophisticated, early attempt at sampling. With the art or craft of sampling still being developed, this argument suggests, it is not surprising that these pioneering records have a naive quality. Again, this misses the intention behind what they were doing. A more useful model would be to view them as what the Situationists called détournements.

The Situationists were a group of thinkers and critics who were active in the 1950s and 60s, mainly in France. At the heart of their thinking was the concept of the spectacle. The spectacle can be thought of as the overwhelming representation of all that is real. In the simplest possible terms it can be understood as being mass media, but that simple definition should really be expanded to include our entire culture and our social relations. The spectacle is both the end result of, and the justification for, our consumerist society.

The spectacle draws our attentions away from what is real to what is merely a representation. The Situationists saw in our culture a shift in our focus from being to having, and then from having to appearing to have. This is a process that the users of Facebook will probably grasp immediately. This absorption in the image of things, they felt, was the cause of our modern alienation. The Situationists were not keen on the spectacle, needless to say, yet it is the central idea at the heart of their self-referential reality tunnel.

The thinking behind Situationist détournements goes like this: every day we are bombarded by adverts, images, songs or videos. They are part of the spectacle of the system, distractions that keep us numb and alienated. Importantly, we get these whether we want them or not, for it is almost impossible to live in the modern world and not be subject to this bombardment. They are a form of psychic pollution, one which is forced on us by capitalists. As we cannot escape from this onslaught, the Situationists argued, our only honourable response is to fuck with it.

Détournement, then, involves taking the cultural images that are forced on us and using them for our own ends. It involves changing the text or context of an image in order to subvert its meaning. The Situationists altered cultural images in the pages of their pamphlets, perhaps by taking a newspaper advert for a consumer product and replacing the text with quotes from Sartre about alienation. These days it is more frequently seen in graffiti, or across the internet on Tumblr blogs and social networks like Facebook, where it is known as 'culture jamming.' Company logos are a frequent target. The idea, as the Situationists put it, is to "turn the expressions of the capitalist system against itself." The aim is to break their spell.

In this context, consider the first JAMs single All You Need Is Love. As its title suggests, this begins with a steal from The Beatles' song of the same name. The Beatles, of course, are the highest expression of the 'proper band' model and generally considered to be the unarguable kings of modern pop music. The highest point of The Beatles, many would argue, was their psychedelic explosion in 1967 and the highest point of this was All You Need Is Love. This song was the UK's contribution to Our World, the first live global television programme. This event was made possible by the recent invention of communication satellites. For the first time in history, people around the world would come together and watch the same thing at the same time. For such a symbolic event the Beatles boiled down the message of the age into a simple melody and the beautifully sung refrain "Love, love, love." Then, surrounded by flowers and the beautiful people of Swingin' London, they sent that message, in the form of pop music, around the entire globe.

So when the JAMs started their first record with 15 seconds of All You Need Is Love, this was no mere sampling. The way they ended the sample, by slowing down the final 'love, love, love' refrain until it collapsed into nothing, can only be seen as a rejection. This was a statement of intent. It was about claiming - and then dismissing - the height of the Beatles and, by extension, pop music as a whole. Such were the ambitions and the acts of the two men who had taken on the name The Justified Ancients of Mu Mu.

That intro was followed by an MC5 sample, the shout of 'Kick out the JAMs, motherfuckers!' which Robert Anton Wilson had mentioned in Illuminatus! This was followed by a sampled voice which states 'Sexual intercourse - no known cure,' and introduces the lyrical theme of the track. This is a song about AIDS, a disease which had only become known to the general public a few years earlier and which brought to an end to the sexual liberation of the 1960s and 70s. The Beatles' historic expression of the 1967 summer of love had been détourned and subverted into an opposite, more contemporarily relevant message.

This basic principle, that you have the right to do what you like with whatever culture is thrust at you, is made explicit in their reworking of the Dave Brubeck Quartet's Take Five, which the JAMs retitled Don't Take Five (Take What You Want). The idea would later take on a more political tone in the internet copyright wars of the early twenty-first century. It is the (frequently unspoken) heart of the philosophy behind torrent sites such as The Pirate Bay and related political organisations such as the Pirate Party. It is an argument that is still being digested by our culture.

The finished record was shit, of course. There are very few people who could listen to it today and say, with their hand on heart, that as a record it has merit. This is all the more apparent if you play it after listening to The Beatles' All You Need Is Love, which retains its innate quality to this day. As Drummond and Cauty's press agent Mick Houghton told the writer Richard King, "[Drummond] came up and played me the JAMs and I thought it was absolute rubbish... I just couldn't take it seriously because it was a racket. It was Bill Drummond pretending to be some kind of Glaswegian dock worker over a load of Abba samples, and I thought it was complete tosh, seriously, I really did and I may or may not have said that to him."

Faced with the difficulty of promoting such a band, Houghton made it clear to the press exactly who the JAMs were. The pair had adopted pseudonyms - King Boy D for Drummond and Rockman Rock for Cauty - and were trying to hide behind the persona of Scottish dock workers, rapping in the pronounced accent that Drummond used on his solo record. The revelation of their true identities was a wise move on Houghton's part, for the press knew of Drummond and Cauty and knew enough to be curious about what they were up to.

The press were also intrigued by the mystique that the JAMs were beginning to weave around themselves. Drummond's first lyric on All You Need Is Love was "We're back again," not a typical opening line for a debut single by a band that only formed a few months earlier. The rap continues, "They never kicked us out, 20,000 years of 'shout, shout, shout'." Again, it is not usual for rap artists to announce themselves as a continuation of a 20,000 year history. The line "They never kicked us out," is a clue here. It is a direct reference to Illuminatus!, and to the Illuminati's attempts to kick out the Discordian splinter group The Justified Ancients of Mummu.

By 1987, however, Illuminatus! was not widely read. Even those who had heard of it were unlikely to read it, for by then it had the unacceptable air of a hippy text. Yet without knowledge of this book, the JAMs' lyrics appeared to be extraordinarily enigmatic, and certainly unlike anything else around. Even their name was otherworldly - 'Justified?' 'Ancient?' These were not words used in pop music. Their strange mystique seemed to have an internal logic to it. It wasn't meaningless or surreal nonsense, but it somehow meant something on its own terms. Even when their name was explained as being taken from Wilson and Shea's books, as it was in almost every article written about the band, this didn't reduce the mystery, for very few people went on to read the books. Discordianism was largely unknown then, as indeed it remains to this day. In this context wherever the JAMs were coming from - wherever that was - seemed to be somewhere new.

For the music press, this was all good. The music press are, by necessity, more drawn to something that is good to write about rather than something that is good to listen to. And there was much about the JAMs that made them good to write about. Their habit of publicising themselves using graffiti - another nod to the Situationists - was something that the press approved of, for the resulting story would automatically be more interesting than an announcement made by a press release.

It did not hurt, of course, that many of their records quickly became unobtainable. Within a month of the independent release of All You Need Is Love, three major record labels had taken out injunctions. The court order they obtained required the record to not merely be withdrawn, but that all existing copies had to be destroyed. In this instance, they were too late. Only 500 copies had been pressed, and they had all been sold. All of this created great publicity for the release of a subsequent version, which had reworked or re-recorded all the samples in order to make them more-or-less legal. This legal attention took The JAMs by surprise. "We just thought that no-one was going to take any notice of [the record]," Drummond has said.

The JAM’s legal problems reached a head with the release of their album 1987: What The Fuck Is Going On?, which included ABBA on the track The Queen & I. 'Included' is probably not the correct word here, for so liberal were The JAMs with their use of long chunks of Dancing Queen that it would be more accurate to call it an ABBA track that featured contributions from the JAMs. ABBA's lawyers, needless to say, were having none of it. Shortly after the album was released Drummond and Cauty were contacted by the Mechanical Copyright Protection Society, or MCPS. "One of our members, whose work is used substantially on the 1987 album, is not prepared to grant a license in respect of their work," the MCPS wrote. "We must therefore insist that in respect of this record you (i) cease all manufacture and distribution, (ii) take all possible steps to recover copies of the album which are then to be delivered to MCPS or destroyed under the supervision of the MCPS, and (iii) deliver up the master tape, mothers, stampers, and any other parts commensurate with manufacture of the record."

Drummond and Cauty took legal advice and were informed that it would cost them £20,000 to fight this in court. And that they would lose.

Publicity wise, of course, this was terrific. Drummond had initially thought that if he met with ABBA and explained his reasons, then they would be able to come to an agreement as artists. It had quickly become clear, however, that no meeting would ever be granted. Nevertheless, Cauty and Drummond headed to Sweden with the NME journalist James Brown in tow. Here they played the offending song outside ABBA's publishing company and presented a fake gold disk (marked 'for sales in excess of zero') to a prostitute who, they argued, looked a bit like one of the women from ABBA. They then destroyed most of the remaining copies of the album by setting fire to them in a field and were promptly shot at by a farmer for their troubles. On the ferry home they threw the remaining copies into the North Sea and performed an improvised set on the ferry, the only known JAMs live performance, in exchange for a large Toblerone.

This was the start of Drummond and Cauty's reputations as being masters of the publicity stunt. It is worth noting, however, the gulf between this reputation and how they actually behaved. The traditional role of media manipulator is a scheming, cynical one, where intricate plans are mapped out in advance and followed to the letter. The archetype of the manipulative producer is perhaps best embodied in the Sex Pistols film The Great Rock n' Roll Swindle. This presents the story of the Sex Pistols as a grand scheme by their manager, Malcolm McLaren, who is shown manipulating the band like a sinister puppet master for his own financial gain.

In contrast The JAMs, on adventures such as the Swedish trip and others, are simply winging it. The impetus here was that they had to destroy their stock of the album and they wanted to make that act a thing in itself, something symbolic and interesting. Beyond that however, they were scrabbling around for ideas and just trying to make something happen. Hindsight may fix these events into a narrative that makes them appear symbolic or almost pre-ordained, in the way that the bonfire of their debut album mirrors the later bonfire of their money. But whilst they are being enacted, they are chaotic. They lack aim and purpose. To quote one of their press releases, “The plot has been mislaid.”

Drummond now had a band that had the mystique he looked for in Echo & the Bunnymen or The Teardrop Explodes. But there was still something missing from the picture, and that was the very something that had seduced him into the music industry in the first place. This was the magic of a perfect single, the creation of a single slice of plastic containing a song so universally appealing that it speaks to everyone, outlives its creators, and makes the world a better place. Critical mystique was nothing to be sniffed at, of course, but it was a shame that their records were so shit.

You can see this lingering love of the great pop single in the second JAMs single Whitney Joins The JAMs. This begins with the Mission: Impossible theme, with the impossible mission presented by the song being persuading Whitney Houston to join their band. During the early parts of the track Drummond pleads with Houston over a bog-standard dance rhythm ("Whitney, please! Please, please join the JAMs. You saw our reviews, didn't you? Please Whitney, please!") This builds until Houston's biggest pop single I Wanna Dance With Somebody is dropped into the mix. Again, this is no normal sample, but a wholesale stealing of the track. But that is not how it is presented by the logic of the song. On The JAMs terms, this is Whitney Houston deciding to join their band, and Drummond sells this angle by whooping "Whitney Houston has joined The JAMs!" with such excitement that you can't help but feel delighted for him.

It is tempting to see this as a turning point, the moment when the anti-music hip hop band The Justified Ancients of Mu Mu started to turn towards the pro-music dance band The KLF. Certainly, you can no longer see the Houston sample as an act of détournement in the style of the 1987 album. Unlike the Beatles or ABBA samples, this is no subverting the meaning of the spectacle. It is about celebrating how brilliant the song they are stealing is. Many critics viewed this lauding of Houston's single as ironic, but it was nothing of the sort.

It grew out of an attempt to make a credible record that sampled the Theme From Shaft. They booked a studio for five days and Drummond went to the record shop to buy the Isaac Hayes record. "In the window [of the record shop was] a big cut-out of Whitney Houston," Drummond has said. "I love that track, and I loved Whitney Houston then, and I just said 'Wow', and bought the album... We just played that track over and over again, and we just thought, 'There's no point us making records when such fantastic records as this have been made.' And that's how that track [...] grew into a celebration of Whitney Houston."

And just before 1987 ended and the JAMs were disbanded, they very nearly made a fantastic record of their own. The song was their third and final single of that year, Downtown. Apart from samples from the Petula Clark song of the same name, it had far fewer stolen elements than other JAMs records. It also featured a specially recorded carol sung by the London Gospel Community Choir. Drummond's lyrics revolve around homelessness, to contrast with Petula Clark's romanticising of London ("Neon lights are pretty," she sings whilst Drummond snarls "In Leicester Square, did you do it clean?")

But it is Drummond's interaction with the Gospel Choir that makes Downtown so interesting. The choir start the song with a burst of "Jesus Christ is born today!", and power through the rest of the song, never appearing phased or threatened by the blunt drum beat that keeps everything moving. Drummond starts addressing his lyrics at them in a similar way to his conversation with Whitney Houston, like a drunk shouting a monologue at passers-by. In response to their chant of "Glory!", for example, he asks "What glory? In a wine bar world?" Finally, however, he succumbs to their vision and begrudgingly asks "Okay, let’s hear it," just as they shift up a gear, change key and deliver the chorus. And the chorus is pure Christmas Christianity, a song of Hallelujahs, Glory, Angels looking down and Jesus Christ being born. The combination of the single minded drum machine and the joy in the voices of the London Gospel Community Choir transcends anything else that The JAMs produced. It is hard not to get swept along by the uncynical religious outpouring.

It was not a hit, nor was it going to be with Drummond's aggressive Scottish rap and the abrupt placing of the samples. But it was a good record and, more importantly, it showed that perhaps they were capable of producing the great pop record that Drummond had for so long been bewitched by after all. But to do so they would have to produce something that matched the religious spirit of the London Gospel Community Choir. How, exactly, could they repeat that transcendence?

A significant upturn in Cauty and Drummond's financial circumstances occurred in June 1988, when they accidentally produced a hit single. It was called Doctorin' The TARDIS and they released it under the name The Timelords.

It was a novelty record.

It started with a desire to make a credible dance record based around the theme music of the science fiction series Doctor Who. Lovers of electronic music consider this theme to be something of a classic, and the pioneering work of its creators, the BBC Radiophonic Workshop, is much admired.

 The problem was that Cauty couldn't get a standard 4-4 dance beat to work with it. After some experimentation, he came to the conclusion that the only drum beat that would fit was the Glitter Beat. As a result, samples of Gary Glitter's Rock n' Roll (Part Two), plus the odd bit of Blockbuster! by Sweet, were added to the mix. "Not until a couple of days into it did we realise how terrible it was," Cauty admitted to the writer Richard King. Yet by the time they had added samples of Daleks quoting Harry Enfield's Loadsamoney character, it was clear that they a potential hit on their hands. "We justified it all by saying to ourselves 'We're celebrating a very British thing here... you know'," Drummond told BBC Radio 1, "Something that Timmy Mallett understands."

Having accidentally created a potentially massive selling novelty record, the question then became how to publicise it. Drummond and Cauty themselves were both in their mid-thirties and neither were natural front men for a mainstream pop record. They decided to claim that the record had been made by Cauty's car. This was a huge American cop car that looked like a beaten-up version of the Blues Brothers' Bluesmobile. It was, if nothing else, an original idea. No car had ever had a hit record before.

Drummond and Cauty thought that this gimmick would make a nice little gift for the newspapers, handing them an easy little story on a plate. The press did not agree, by and large, finding the idea idiotic and wondering, perhaps for the first time, if Cauty and Drummond were taking the piss. Regardless, the single sleeve was printed featuring a photograph of the car, now renamed Ford Timelord, complete with a speech bubble saying "Hi! I'm Ford Timelord. I'm a car, and I've made a record." The name 'Ford Timelord' was an echo of Ford Prefect, a character in The Hitchhiker's Guide To The Galaxy by the Doctor Who script editor Douglas Adams. This was nicely fitting, as Ken Campbell's follow up to Illuminatus! was a production of The Hitchhiker's Guide To The Galaxy.

In three weeks, despite not being playlisted by Radio 1, the record reached the fabled position of number one in the charts. It would go on to sell more than a million copies. A video was shot showing the car driving around locations in Wiltshire, including the Avebury stone circles. It included a couple of home-made Daleks which avoided legal problems by being so poorly constructed that no one could claim they contravened copyright with a straight face.

Another problem was that the producers of Top of the Pops believed that a car sitting by itself on stage for three minutes, flashing its lights in time to the music, would not make an interesting performance. The solution was to recruit Gary Glitter himself to front the performance, for which he donned a silver cape and hammed it up for all he was worth. His reward was to find himself on the cover of the NME for the first time in his career.

The car itself, a 1968 Ford Galaxy, had originally been shipped to England by Pinewood Studios and it had been used as a prop in a number of films, including the first Superman movie. It was then bought from Pinewood by an young artist named Gary Mitchell, who painted it to resemble a police car, attached a pirate flag to its aerial and largely trashed it off-roading and driving doughnuts in the fields around Godstone in Surrey. Mitchell then sold the battered wreck to Cauty for a few hundred pounds.

Mitchell himself then moved to Avebury in Wiltshire, where he worked as a tour guide around the same Neolithic stone circles that his old car had driven past in the video. He then met Julian Cope and the pair became close for a short period in the early 90s. Cope was writing a book about the Stone Circles of the British Isles and, as he could not drive at that point, Mitchell drove him around the country to research stone circles, and he also accompanied him on his solo Highlands and Islands tours of Scotland.

Drummond's influence over Cope at this point was complex, to say the least. Cope, who saw no humour in Drummond's Julian Cope Is Dead song, had taken to wearing a 'Julian Cope is Dead' T-shirt on stage every night, but he wore it inside out so as not to display the slogan to the audience. He also felt the need to make a pilgrimage to Drummond's home town, where he spent a night walking around, thinking about Bill.

Mitchell was with Cope on the Isle of Lewis undertaking research for the stone circles book when Cope received a phone call, and was told that Drummond was planning to flatten Silbury Hill with earth moving equipment. Silbury Hill is a massive man-made Neolithic mound at Avebury, of intense personal importance to Cope. Mitchell recalls how shaken up by this threat Cope was. "He went white [after the call], it was a shock to see him like that actually. No-one else had that power over Julian. Bill was the only person that he was scared of."

Mitchell, now going by the name Flinton Chalk, moved to London and ran the Tom Tom Gallery in New Compton Street, the first gallery to display and sell the works of Banksy. This was opposite the old Ministry of Defense building, which was frequently visited by the Duke of Westminster around the time of the Iraq war. The Billionaire Duke, a cousin of the Queen and the wealthiest man in Britain, was then the head of the Territorial Army (and, according to the Daily Mail, a serial user of prostitutes who used to brag about knowing the whereabouts of Osama Bin Laden). He would often park outside the Tom Tom Gallery when visiting the Ministry, arriving in full military uniform with a huge SAS-trained chauffeur and bodyguard, only to be confronted with the shop's window display. It was for this reason that Chalk used to display a large Banksy canvas in the window called Monkey Queen, which, as the name suggests, featured the queen as a monkey.

Around this time, in 2003, Chalk also stocked prints by Jimmy Cauty, including a series of stamps featuring the Queen wearing a gas mask which was intended as a comment on the Iraq war. These resulted in legal action against Cauty and Chalk from the Royal Mail, and led to Chalk defending Cauty's work in the Evening Standard.

All of this is, of course, a string of random coincidences, for there is no reasons why the man who sold Ford Timelord to Cauty should go on to have so many KLF related connections. Synchronicities seem to prefer some stories more than others, and this is one that they flock to. We can see this clearly if we look a little closer at the use of Doctor Who for their novelty record.

From the perspective of the early 21st Century, making a Doctor Who record appears to be an obvious populist choice. It is, after all, one of the most successful and best-loved series on British TV. This was not the case in 1988, however, when Doctorin' The TARDIS was released. At that time, Doctor Who was largely considered to be an embarrassment, by both the BBC and the viewing public at home. If Drummond and Cauty had been drawn to it for populist reasons, their timing was way out.

Doctor Who began way back in 1963. Its first episode was broadcast on the Discordian holy day of November 23rd, a date the Discordians honour because it is also Harpo Marx's birthday. The day before, November 22nd 1963, brought the assassination of JFK and the deaths of C.S. Lewis and Aldous Huxley. Huxley, through his relationship with Timothy Leary and his book The Doors of Perception, had been a big influence on Robert Anton Wilson. We have already noted the role of the Justified Ancients of Mummu in Kennedy's assassination in fiction, as well as how the real-world assassination impacted on the growth of Discordianism. C.S. Lewis, meanwhile, was a big influence on Doctor Who itself, for the wardrobe in his Narnia books was a simple wooden box that was also a gateway to another world. Right from the start, then, the programme seems tangled up in many of the threads in this narrative.

For roughly the first twenty years of its life, Doctor Who was generally thought of fondly. It could be cheap and it could be daft, but it brought families together and it had imagination, charm and a clear moral centre which made its faults easy to forgive. It had the ability to change all its actors and behind the scenes staff every few years, which kept it fresh. But eventually, towards the end of Peter Davison's time in the role, something started to go wrong.

It wasn't just one thing, of course. There were many factors. The Star Wars films had upped the bar for special effects so high that the BBC could not compete. The rise of Michael Grade, from Controller of BBC1 to Director of Programmes, effectively turned the BBC against the series. Grade disliked sci-fi in general and Doctor Who in particular, and as is usual in hierarchical organisations the boss' prejudices were soon reflected by those they manage. The series' budget, in real terms, was dwindling away into almost nothing.

There were creative problems too. Peter Davison was replaced by Colin Baker as the sixth Doctor. Baker was a good actor but he was not someone who possessed the 'kid appeal' necessary for the role. Or at least, that was the view of Michael Grade, who said that his portrayal of the Doctor was "utterly unlikeable, absolutely god-awful in fact." It didn't help that Baker was dressed in a deranged multi-coloured clown outfit. With the benefit of hindsight, some art historians now claim this costume as a postmodern classic, but it did not help the casual viewer take the programme seriously. The producer's pantomime-esque tastes in casting meant that the likes of the musical theatre star Bonnie Langford joined the cast, while a new script editor moved the show away from the family and kids audience by painting a darker, bleaker, violent universe at odds with the earlier spirit of the show. The whole thing had become a mess.

As a result the show was put on a very public hiatus for eighteen months in 1986, and ordered to pull itself together. When it returned, for its 23rd series, it was distinctively unimproved. The programme had had, in essence, its final warning. Michael Grade ordered that Colin Baker be replaced.

It is here that our Discordian threads return to the show. A number of actors were auditioned to replace Baker, but it very quickly came down to a choice between two: our good friend Ken Campbell, and Sylvester McCoy (whose first job in showbiz involved sticking ferrets down his trousers as part of the Ken Campbell Road Show.) Campbell auditioned by performing a speech about the nature of time modelled on Alan Moore's Dr. Manhattan character, wearing a long coat, sleeveless cartoon t-shirt and wide brimmed hat. The producer thought that he was too weird, an opinion probably enforced by the strange message that had been left on the answerphone the previous day which he suspected was from Campbell.  The message was actually a quote from Charles Fort’s book Lo!, and begins “A naked man in a city street - the track of a horse in volcanic mud - the mystery of the reindeer's ears - a huge, black form, like a whale, in the sky, and it drips red drops as if attacked by celestial swordfishes - an appalling cherub appears in the sea - Confusions.”

The production team were unaware that this quote was Campbell’s personal mantra, which he would recite in the wings before any performance as a centring exercise, and finding it on the answering machine was deeply unsettling.

As McCoy remembers, "The executive producer of BBC Series and Serials wanted Ken, but the producer of Doctor Who wanted me, and his argument was that he thought Ken would frighten the children, and I think he was right. The producer in fact threatened to resign if Ken got the job. So I got it."

Campbell may have been too weird for Doctor Who, but that didn’t mean our Discordian synchronicities would leave the show behind. With the money they made from their Doctor Who record Drummond and Cauty made a film called The White Room, as will be discussed later. There was one major role in the film that required a 'name' actor, and for this role they cast Paul McGann, then well known for his roles in The Monocled Mutineer and Withnail and I. A few years after this McGann took over from Sylvester McCoy and became the eighth Doctor. There was only one person in the entire world who would be cast as the next Doctor, and for Drummond and Cauty to select that very same man for their Doctor Who-funded film is... well, the odds are pretty high. Clearly this is a story that the synchronicities can’t get enough of.

With McCoy cast, the series returned compete with new star, new titles, new music and a new script editor. And it was, if anything, worse than before. At that point, its fate was sealed. The programme wasn't cancelled immediately, for the BBC did not want to attract the sort of press which that would generate. Instead, it was scheduled against the ratings powerhouse of Coronation Street for its last two years where its long, painful death was less visible. After the failure of the first McCoy series, it was not going to be given another chance. It was a dead show walking.

It was at this point, between the first and second McCoy seasons when the series' problems looked terminal and the mercurial character of the Doctor was at his lowest point, that Drummond and Cauty called themselves The Timelords and released Doctorin' The TARDIS.

Doctor Who had lost its connection to a wide, family audience of young children and amused parents. It was no longer fun. It needed to remind people of how good it could be, and of what they used to love about it. Then Drummond and Cauty arrived with a single that was camp, and silly, and ludicrously enjoyable. It was, in the words of critic Peter Paphides, "the one novelty record that most people admit to liking." It sold well over a million copies. It was full of energy and anarchy.

It was, in other words, exactly what Doctor Who needed at that point in time.

Then the programme returned later in that year, and suddenly it was brilliant again. McCoy had worked out how to play the role, a new companion created chemistry and the script editor had a clear sense of purpose and direction. Over the next couple of years, as it moved towards cancellation, the character mutated again to become manipulative and mysterious. True, this did not win back the child audience, but it did attract people who would be far more useful for its coming dark ages - writers. Once it was off the air Doctor Who continued as a series of novels, and many of the people who wrote Doctor Who fiction in this period - Russell T. Davies, Mark Gatiss, Paul Cornell and Steven Moffat to name a few - were responsible for resurrecting Doctor Who in 2005. Indeed a number of these people, and many British writers of their generation, have gone on record as saying that they only became writers in the first place because of Doctor Who.

When Russell T. Davies brought the series back to television he reinvigorated the character by using the narrative device of surviving a great 'Time War.' The 'Time War' idea originally came from Alan Moore, who wrote a number of Doctor Who comic scripts in 1981 about a '4D War' which had two time-travelling armies attacking each other at increasingly earlier points in time so that neither side had any idea about what the war was about, or who started it.

If we take Alan Moore’s model of Ideaspace seriously - if only for a moment - and look at the idea of Doctor Who, we see an extremely detailed fiction. The Doctor is one of the great line of British folk heroes; characters in the tradition of Robin Hood, Sherlock Holmes or James Bond. Whereas American folk heroes tend towards cowboys or gangsters who take what they want from the world and end up either rich or winners, British equivalents are very different. They are anti-establishment figures, even when they work with the establishment, and they save the day not for personal gain, but because it is the right thing to do. For generations of British school kids, Doctor Who was the myth that they grew up with. They had only the most superficial knowledge of the likes of Zeus, Odin or Jesus, but they knew all there was to know about Davros, The Master and Cybermen.

The Doctor is the first British folk hero of the TV age, and the nature of his TV origins make him unusual. There is no definitive creator standing behind him, no Arthur Conan Doyle, J. R. R. Tolkien, Ian Fleming or J. K. Rowling. Instead, he popped out from the space between many minds. There was a succession of different actors, writers and producers who all invigorated the character for a short while before moving on or burning out. The character is defined by his ability to regenerate and change his personality. He can change all his friends and companions. He can go anywhere, at any time. He is, essentially, the perfect never-ending story. He will survive long after you, me or anyone currently involved in making the series has died. He adapts, grows, mutates and endures. In this he fulfils much of the standard definitions for a living thing. This is not bad going, for a fiction.

Already, there are many thousands of Doctor Who stories which, for a character of fiction, is almost unheard of. There have been hundreds of stories on TV, and countless more available as novels, audio CDs, comic books, films, stage plays, webcasts, fanfics and radio programmes. The growth of the story, compared to any other fiction from the same period, is deeply unusual. Indeed, it has become arguably the most expansive and complex non-religious fiction ever created.

According to Moore’s model of Ideaspace, this fiction may be complicated enough to act like a living thing. Note that this is not to say that Doctor Who is a living thing, for that would sound crazy. It is to say that it behaves as if it were a living thing, which is a much more reasonable observation. Of course, if you then go on to try and define the difference between something that is living and something that behaves like it is living, you will be a brave soul indeed.

The programme’s spread through all possible media was begun by its first script editor, David Whitaker. Although Doctor Who has no definitive 'creator', Whitaker can be said to be the man who nurtured the heart of the series, sculpting the peculiar mix of humour, morality and wide-eyed imagination that makes the series so unique. He was involved in the creation of most of the iconography of the show, from introducing the Daleks, to making the TARDIS be in some way alive and the Doctor able to regenerate into a different actor. He also spread the life of the character beyond television, for he wrote the first novels and annuals and co-wrote the Peter Cushing 'Dr. Who' movies from the 1960s.

Whitaker's work on Doctor Who was particularly influenced by alchemy, a subject that he claimed to be "very fond of". The basic alchemical principle, where a physical object can be affected by the manipulation of a symbol of that object - the idea of it, if you prefer - is used explicitly in his 1967 story The Evil of the Daleks (which is also a strong contender for the story that invented steampunk.) The Evil of the Daleks is about a pair of Victorian scientists who accidentally build a time machine out of 144 mirrors (the number '144,' or 12 squared, being alchemically significant). This basic alchemical principle is still used in the programme today, for example in Steven Moffat’s claim about his monsters The Weeping Angels: "The image of an Angel is an Angel."

In Whitaker's Doctor Who, when the TARDIS broke down because of a problem with the “mercury in the fluid links,” there was specific alchemical symbolism in the choice of mercury. When the first Doctor, William Hartnell, was replaced by the second, Patrick Troughton, Whitaker gave him a flute and an obsession with hats in order to echo the classical god Mercury (or Hermes to the Greeks). All this would have meant little to the children watching in the 1960s, of course. Nevertheless, Whitaker seems to have been consciously shaping the character of the Doctor into a mercurial, Trickster figure.

When the current Doctor Who writers claim that they only became writers because of Doctor Who, they usually credit the series of novels which Whitaker started and which young boys devoured during the 1970s. There is another explanation, however, which comes from the very format of the programme. In the original series, episodes built towards a climax and ended on a cliff hanger in which the Doctor or his friends appeared to be in inescapable danger. Of course, the children watching knew that the Doctor would somehow survive. He always did. The question, then was not would he escape, but how? What could possibly happen to get the Doctor out of that situation? There would be much debate about this in school playgrounds after each episode. And as the kids thought about the problem, their imaginations were being stoked. They were thinking like writers. Indeed, they were trying to write the next episode themselves.

What we have here, then, is character of fiction, neither created or 'owned' by any one imagination, who is actively creating the very environment – writers’ minds - that it needs to survive into the future. Not only is Doctor Who a fictitious character that acts like a living thing by constantly evolving and surviving, it is also a self-sustaining living thing that creates the one thing that it needs to survive. From an evolutionary point of view, that's impressive.

There is no requirement for those affected by an idea to be aware of any of this, of course. When the writer and media critic Philip Sandifer writes that "David Whitaker, at once the most important figure in Doctor Who's development and the least understood, created a show that is genuinely magical and this influence cannot be erased from within the show," he does not mean that any of the hundreds of actors and writers who went on to work on the programme saw it in those terms. Or as Sandifer so clearly puts it, "I don't actually believe that the writers of Doctor Who were consciously designing a sentient metafiction to continually disrupt the social order through a systematic process of détournement. Except maybe David Whitaker."

From Drummond and Cauty's perspective, the story of Doctor Who is irrelevant. All that was happening was that they were exploring their mental landscape, and they were fulfilling their duty as artists by doing so more deeply than normal people. This is a landscape with many unseen, unknown areas where who-knows-what might be found. The KLF explored further than most and, if we were to accept Moore's model, it would perhaps not be surprising that a fiction as complex as Doctor Who could encounter them in Ideaspace and, being at its lowest point and in dire need of help, use them for its own ends.

For Moore, and other artists such as David Lynch who use similar models, the role of the artist is like that of a fisherman. It is their job to fish in the collective unconscious and use all their skill to best present their catch to an audience. Drummond and Cauty, on the other hand, appear to have been caught by the fish. Lacking any clear sense of what they were doing, they dived in as deeply as Moore and Lynch. They did not have a specific purpose for doing so. They just needed to make something happen - anything really, such is the path of chaos. "It was supposed to be a proper dance record, but we couldn't fit the four-four beat to it, so we ended up with the glitter beat, which was never really our intention but we had to go with it," Cauty has said. "It was like an out of control lorry, you know, you're just trying to steer it, and that track took itself over really, and did what it wanted to do. We were just watching."

This lack of intention is significant, from a magical point of view. One of the most important aspects of magical practice is the will. Aleister Crowley defined magic as being changes in the world brought about by the exercise of the will, hence his maxim 'Do what thou Will shall be the whole of the Law.' The will or intention of a magical act is important because the magician opens himself up to all sorts of strange powers and influences and he must avoid being controlled by them. Drummond and Cauty were not exerting any control on the process, and so they made themselves vulnerable to the who-knows-whats that live out of sight in the depths of Ideaspace. For this reason, you could understand why Moore would think that Bill Drummond was “totally mad."

All this only applies if you're prepared to accept the notion of magic, of course.

Nevertheless, all this is worth noting because there is another fiction that is important in Drummond and Cauty's story. This one is more significant, because this is the fiction that they became, taking on its title and performing their actions in its name. It is also the source of our whirlwind of synchronicities. We are talking, of course, about The Justified Ancients of Mummu. The question then becomes did Cauty and Drummond choose The JAMs, or did The JAMs choose Cauty and Drummond? A possible to clue will come later, when we look at what the founding purpose of The Justified Ancients of Mummu actually was.

The huge success of the independently released Doctorin' The TARDIS gave Drummond and Cauty plenty to chew on. It seemed to them that we were at a new stage in the history of music, one where all the previous gatekeepers could be bypassed. For the first time, it was possible for anyone who wanted a hit record to go ahead and make one. This, it seemed clear, was a significant change and one that should be encouraged.

Drummond and Cauty's reaction to this was to write a book. Called The Manual (How To Have A Number One The Easy Way), it contained a set of instructions which promised to allow anyone to repeat their success, regardless of musical talent. It came with a money-back guarantee: anyone who followed the instructions within to the letter, and didn't have a number one hit, would get their £5.99 back.

The Manual was a distillation of everything that the pair had learnt about the music industry, filtered through the 'just do it you bastard' approach of Ken Campbell and the anti-pretension pop sensibility they learnt from watching Pete Waterman work. Due to the rapid technological change in music recording, much of the practical information it contains dated very quickly, making it a historical snapshot of a very brief period. The Campbell and Waterman influences, however, have not dated, and it is for this reason that the book is still read by musicians today. Jamie Reynolds of the Klaxons, for example, told Philip Sherburne that they followed the book religiously in order to make their Mercury award-winning first album. "That's what I did! That's genuinely it. I read that, I noted down the golden rules of pop, and applied that to what we're doing and made sure that that always applies to everything we do." The Klaxons then went on to drop acid and perform with Rihanna in a laser-and-neon pyramid at the 2008 Brit awards, something which suggests that they are a band ideally suited to follow this Discordian-influenced path.

The Manual can best be seen as a modern update of the famous punk-era fanzine illustration that showed the fingering for the chords E, A and B7 with the words, "This is a chord. This is another. This is a third. Now form a band." In general though, that's not how its intentions were perceived. The book gives the false impression that Doctorin' The TARDIS was planned, that Drummond and Cauty knew what they were doing and that they set out to deliberately make a number one record.

Perhaps more than anything they did, The Manual led to the pair being perceived as cynical media manipulators rather than random followers of chaos. In a sense, this was always inevitable when they became successful because the public narrative believed that success comes from knowing what you are doing. The equally common phenomenon of stumbling upwards is rarely recognised and, even if it is noticed, it tends to be dismissed as an anomaly, something that 'doesn't count,' rather than an example of how things actually work. Few people are comfortable with accepting the extent in which blind chance affects our lives.

The fact that Drummond and Cauty were becoming successful was a clear sign that they knew what they were doing, or so the public narrative went. How then should they explain the strangeness of their behaviour? Clearly, it is all part of their plan. It was calculated media manipulation, 'scams' or 'pranks' aimed at generating publicity.

With that narrative in place, Drummond and Cauty were in a unique position where they could follow and enact strong occult currents in full public view without comment. No-one took the role of the little boy in The Emperor's New Clothes who stated clearly how odd things were, not when the entire country was watching and acting like everything was normal.

Rave happened.

You only had to look at the crowd to see why rave was different to anything that had come before. At rock concerts and other large scale musical events, every member of the crowd faced in the same direction. The focus and attention of the entire audience was directed at the stage, where it glorified the musicians who performed there. It can be argued that this was actually the purpose of the event, to focus thousands of minds on a small group of people and in doing so to elevate them, in the words of Robert Plant, to the status of 'Golden Gods.'

Compare that to the early orbital raves of the late 1980s, when first thousands and then tens of thousands of kids found their way to outdoor dance parties on the outskirts of London. The crowd point in any direction they damn well please. That original focus, the band on stage or (later) the 'superstar DJs' on an elevated platform, is absent. Instead, the crowd's focus is turned into itself. It is not on an artist presenting the audience with an experience, but on an audience that is creating its own performance. The crowd are generating, rather than observing. The result is that they were not elevating someone like Robert Plant to the status of Golden Gods, they were elevating themselves.

It helped to be on the right drugs, of course.

Rave emerged spontaneously, neither planned or designed. It was a genuine grass roots phenomenon, egalitarian and welcoming. Thousands danced in fields all through the night, out under the moon, in order to achieve a trance-like, ecstatic state. It was a form of communion and it was pagan as fuck. Needless to say, it couldn't last. The press and the government, appalled by such non-violent having-of-a-good-time, moved quickly to crush it. Ultimately, though, they weren't quick enough. Rave grew too big too quickly, and it attracted the attention of those who felt they could make money from such events. Once this happened and the superstar DJs and the superclubs arrived, the focus shifted from the raw crowd back to the event itself. Rave's spell was broken.

But while it lasted, that spell was powerful and it worked its glamour on Cauty and Drummond.

Once the pair began attending raves and clubs like Heaven, Hip-hop was quickly dropped. They knew that they weren't very good at it in any case. Clearly, dance music was where it was at. This was evident in their work from a very early point. Even the 'posthumous' JAMs records from 1988 onwards are more dance than hip-hop.

After the success of their Doctor Who record, Drummond and Cauty suddenly had money, and with money came options and possibilities. It allowed them to build a recording studio of their own, in the basement of the South London squat where Cauty had lived for over a decade. The squat was known as Transcentral and achieved near-mythical status in KLF lore, but Cauty was not keen on it. "I hate the place," he has said, "I've no alternative but to live here."

The pair set themselves a task of releasing a string of club-orientated dance records which were known as the Pure Trance series. The idea was to release one a month for five months, although only the first two, What Time Is Love? and 3am Eternal, saw the light of day. "This was Jimmy and my response to the urge to make music that had no message other than how it existed on the dance floor," Drummond said in 2012. "We wanted to make a minimal masterpiece. What Time Is Love? in its original Pure Trance version is the closest we came to it." The title came when Drummond turned to Cauty at a rave, intending to ask when the MDMA they had taken would kick in, but found himself phrasing the question in the words 'What time is love?' At which point, they both understood that it had started to work.

The Pure Trance records were not expected to be a commercial success but their influence spread slowly through the clubs of Europe, selling continuously, and they brought Cauty and Drummond a great deal of credibility in the dance world, away from the London-based music press.

They were released under the name The KLF. Drummond and Cauty had had this name from the start: The label they had created to release The JAMs records was called KLF Communications. They had a logo which was known as the 'pyramid blaster.' This was based on the 'eye in the pyramid' symbol which features heavily in Illuminatus! The KLF removed the eye from the top of the pyramid and replaced it with a ghetto blaster; their pyramid no longer observed, it broadcast.

The name The KLF worked well within dance culture. It was minimal and anonymous, offering nothing that might overshadow the music. Stories varied as to whether it stood for anything or not. Sometimes it was claimed that it had no meaning, while other times it was claimed that the meaning was transient and shifted over time.

Drummond and Cauty had first released a record under the name The KLF in March 1988, a few months before they found success with their Doctor Who themed single, although it sounded more like a JAMs track than a KLF one. Its name was prophetic, however. The first ever KLF record was a twelve-inch dance track called Burn The Bastards.

The KLF made a few live appearances at raves during this period. 'Live appearances' may be an exaggeration, as they usually played a tape rather than actually performed. At the 1989 Helter Skelter rave in Chipping Norton the pair climbed a lighting gantry and emptied out a bin-bag containing £20,000 in Scottish one pound notes - their appearance fee - over the dancing crowd beneath them.

This idea of giving something tangible to the audience runs through many of their live appearances. At an appearance at the Liverpool Festival of Comedy in 1991, the pair distributed ice creams to the crowd from an ice cream van. At a 1990 appearance at the Paradiso Club in Amsterdam, meanwhile, the pair performed a 23 minute long version of What Time Is Love?, during which they gave most of the instruments and mixing equipment to the crowd. None of this actually belonged to the band, however. It was the property of the club itself. They were not asked back.

Given Drummond's love of great, euphoric pop and The KLF's later mainstream success, The KLF's initial involvement with rave culture took a surprising turn. Despite the appeal of the dance floor, their attention became focused more on the post-rave come down. The first KLF album was aimed at the chill out room. Indeed, it even named it, for that album was called Chill Out.

This was Ambient House. Devoid of beats and anything resembling song structure, it owed more to the ambient music created by Brian Eno in the late seventies and early eighties than it did to high-bpm music of the raves. Eno, who coined the phrase 'Ambient Music,' described his ambient albums as being "on the cusp between melody and texture" which could be "actively listened to with attention or as easily ignored, depending on the choice of the listener." Eno produced a string of such records, in particular four albums entitled Ambient 1, Ambient 2, Ambient 3 and Ambient 4.

Another Ambient House pioneer was Alex Patterson. Inspired by Paul Oakenfold's Land of Oz nights at the Heaven nightclub, Cauty formed The Orb with Patterson as a side project. Although their collaboration was short-lived and Cauty soon left The Orb to focus on The KLF, their early experiments married the potential of the sampler to Eno's ambient music and paved the way for a genre that continues to this day.

For Chill Out, Drummond and Cauty added the sound of sheep and slide guitar from Drummond's solo album The Man to samples of Elvis Presley, Acker Bilk and Fleetwood Mac. These faded in and out, as if from far distant radio stations or as if the listener was drifting in and out of sleep. It was presented as a journey through a mythical part of America, with song titles like Pulling Out Of Ricardo And The Dusk Is Falling Fast or The Lights Of Baton Rouge Pass By. The song names were the result of plucking place names out of an atlas - Drummond always did like his maps. Cauty has dismissed it recently, saying "mostly it's just a list of places. It was another disaster, really," and many ravers saw it as unlistenable new age noodling, boring in the extreme.

The album certainly has its supporters, however. The imagery of the journey across vast spaces in America during the twilight hours of dawn and dusk, so full of space and potential, is a perfect fit for this type of music.

Ultimately, though, ambient is an odd genre, it either works or it doesn't. There may be a critical consensus which rates Eno's Ambient 2 and Ambient 4 above Ambient 1 and Ambient 3, but it would take a brave man to define why. The KLF were more than aware that this wasn't for everyone. As they described their work at the time, this was music that "loves you even if you don't love it." Ambient house was "the amorphous unconscious," which "might only make sense to those who made it to the furthest reaches of dance music." After Chill Out, they left the genre behind, feeling that there was little more that needed to be said.

Yet it's tempting to say that the state of mind that Ambient House captured continued to fascinate them. It was all about the end of the rave, when all your energy had been dissipated and all that is left is an unearthly glow, a sense of euphoria that has somehow risen from the worn out body. It is a feeling of exhaustion where you also feel extraordinarily awake. It's a sense of expanded awareness, the sense that you can see for miles even when you are lying in a dark corner. It is that moment, in the small hours before dawn, that seems to hang outside of time. The lyrics and song titles of their later commercial successes, such as 3am Eternal or The Last Train to Transcentral, continued to echo this state of mind. This mental state seemed to interest them far more than the music it inspired.

During this period Drummond and Cauty also experimented with ambient video. They took a portable recording studio up to the Isle of Jura in spring 1990, with the intention of recording a minimalist techno record called The Gate. The record never happened, and instead they spent eight days on the island recording sounds and being videotaped by their collaborator Bill Butt. This footage was eventually released as a 42-minute 'ambient movie,' called Waiting. Even among committed and die-hard KLF fans, Waiting is considered to be unacceptably boring.

'Waiting' was what occurred instead of recording. As they later wrote, they were, "Waiting for the tide to turn on the almost motionless sea. Waiting for the sun to sink beyond the mountains of the Western Isles. Waiting for the stars to stud the darkening sky. Waiting for the dawn to creep in from the East. But maybe more importantly, waiting as emotions within themselves shifted and changed, stirred and settled. Along with this poetic stuff they continued to wait for all the trivial things in life that we seem to spend so much of life waiting for; kettles to boil, phones to ring, baths to run, moods to pass, something to happen, or at least some sort of explanation."

Towards the end of this period they assembled their speakers on the beach and played music out to sea while they sat in deckchairs at the water’s edge, like Canute, and waited for this explanation. It never arrived.

They were waiting to discover what they were going to do next. This is an occupational hazard for those who are not driven by clearly defined goals or a sense of purpose, but instead follow the path of chaos. In the lulls between bursts of energy and action you become purposeless and have no choice but to wait and see what direction you will be pulled in next. So they sat in their deckchairs and waited, until the encroaching sea put an end to their vigil.

Whatever they were waiting for on Jura, they did not find it that time.

On Summer Solstice 1991 a few dozen journalists from across Europe were asked to arrive at Heathrow airport with their passports. Here they boarded a specially chartered plane which would take them, they were told, to a ceremony at the lost kingdom of Mu.

The plane actually took them to the isle of Jura in the Scottish Hebrides. The customs officer at their destination was Bill Drummond. He sat behind a desk dressed in a fake moustache and customs uniform, and stamped each of their passports with the 'pyramid blaster' logo.

The journalists were then dressed in robes and led across the island in a silent procession. At the head of this procession was a figure in white with a single horn emerging from his hood. He led them towards their final destination: a 60 foot tall wicker man, surrounded by a hidden sound system.

They formed a circle around the figure. Here they were addressed by Drummond, although his identity was masked by the robe and horn. Thanks to a microphone under his hood, his words were being mixed into the trance-like rave music that the sound system was pumping out. The circle of robed journalists chanted while Drummond preached at them in an improvised and meaningless language of his own devising. "I had a little radio mic on Bill, and I was working the mix," Cauty told the writer Richard King. "He was up on a sort of platform in front of the wicker man, dressed with this horn, and did the whole speech in a foreign language he'd just made up. It was totally, totally brilliant, everyone was completely gobsmacked."

At the finale of what Cauty called "this whole sort of fake Pagan ceremony," the wicker man was lit. Their wicker man was a powerful looking figure. It did not stand to attention like the one in the The Wicker Man film or those seen in historical woodcut illustrations. It had both arms thrust aloft and its leg spaced heroically apart, giving it the aspect of a four pointed star about to pounce. It didn't smoulder or smoke, but instead blazed straight upwards in huge column of fire.

Wicker men had been rare in western culture up until that point. They were first recorded in the writings of Caesar, who claimed that the Gauls used them to as part of ritual human sacrifice. They did not really arrive in popular culture until Robin Hardy's 1973 film The Wicker Man, staring Edward Woodward and Christopher Lee. The 1991 Summer Solstice, however, was marked not only by the KLF's wicker man on Jura, but the first solstice wicker man burning in Black Rock Desert in Nevada, an event that has grown into the Burning Man festival. This event, planned by its founders as a 'dadaist temporary autonomous zone,' had grown out of solstice burnings on a San Francisco beach which were apparently started spontaneously, rather than inspired by the film. These had been disrupted the previous year by official concerns, resulting in a move out into the desert and the test burning of a figure on Labor Day 1990. Like on Jura, these first Burning Man effigies also forwent the traditional stance and stood with arms stretched aloft.

The coincidental arrival of both of these wicker men on the 1991 Summer Solstice was unusual because, apart from the release of the film nearly twenty years before, there was an absence of any other wicker men in our culture up until that point. Now, of course, they are more common and appear everywhere from Iron Maiden records to the Wickerman festival in south-west Scotland. For Alan Moore, this would signify the arrival of the wicker man concept in a more accessible area of Ideaspace. Or to paraphrase Charles Fort, ‘wicker men come when it's wicker men time.’

The Burning Man festival's description as being a “dadaist temporary autonomous zone” is also interesting in light of the glossolalia, or speaking in tongues, that Drummond performed on Jura. Talking in meaningless words like this was common at the birth of Dada. The Cabaret Voltaire in Zurich, 1916, included performances of what they called 'sound poetry.' One such example is Hugo Ball's Karawane, the text of which in part reads, 'hollaka hollala / anlogo bung / blago bung / blago bung.' From Ball's perspective, the impulse to stand on stage and address an audience with sounds and gibberish was a reaction to the society that led to World War I. Such a bankrupt society deserved meaningless poetry. What Drummond's impulse was, however, is less clear.

Speaking in tongues is a strange but relatively common aspect of religious practice around the world, and is found in cultures as varied as Haitian Voodoo and Indian Fakirs. It is best known in the West through Pentecostal Christianity, where it is believed that the possessed speaker has received the Grace of the Holy Spirit and is being controlled by an aspect of the divine. It certainly has a powerful effect on an audience, who suddenly find that all the normal rules of human connection have been dispensed with and that something unknowable has taken its place.

Despite Cauty's description of this as a "sort of fake Pagan ceremony," the trance music, chanting, glossolalia and burning effigy of the Jura ceremony did have an effect on those present, just as the use of the London Gospel Community Choir affected those who listened to Downtown. It was very much a real “fake Pagan” ceremony, and it had a very real effect on those present.

The music of The KLF is marked by a noticeable increase in religious imagery compared to the music of The JAMs - or rather, by a noticeable increase in religious yearning. Certainly the invitations to attend this Solstice ritual, called The Rites of Mu, were rich in such imagery: "The KLF have invited you to join them in a celebration of the Rites of Mu this summer solstice, during which the fall of Mankind may be reversed - returning him to the garden where the rest of creation awaits." The problem, the invites explained, was that mankind had been distracted from its true nature by the questions Who, Where, Why and What - questions which they described as the "four beautiful handmaidens of Lucifer."

Four graceful, elegant models were hired to play the role of these handmaidens of Lucifer. The surviving video images, showing them emerging from the waters around Jura in flowing white gowns as the sun sets, are some of the most powerful images from this ceremony. They are a direct visual reflection of the scene in Illuminatus! when angels appear out of Lake Ingolstadt, an event which triggers the grand climax of the book - the beginning of the end of the world.

Of course, the Wicker Man ceremony was preferable to how people were initiated into the 'original' Justified Ancients of Mummu. According to Robert Anton Wilson's book, initiates had to take part in a satanic black mass that climaxed with a manifestation of the Devil. Satanic black masses were generally considered to be a step too far by musicians in the late twentieth century, even by Bill Drummond.

"[The musician Mark Manning] and I realised that we had sold our souls to the Devil," Bill Drummond wrote in 2005, "and that if we wanted to retrieve them we should we should head for darkest Africa, confront Satan and demand our souls back." This was the impetus for a journey to Zaire that Drummond made with Manning and Alan “Gimpo” Goodrick in 1996, after he had stopped working with Cauty. It was not the first time Drummond had made reference to the status of his soul. The contract written on the Nissan Bluebird and pushed over Cape Wrath and into the sea, for example, began "For the sake of our souls."

These days it is rare to hear anyone state that they have sold their soul to the Devil.

Mark Manning, better known as the rock musician Zodiac Mindwarp, is the author of a number of books including Get Your Cock Out(2000) and Fucked By Rock(2001). For anyone familiar with his work, the idea that he has sold his soul to the Devil seems plausible. Yet the idea that Drummond has done the same is harder to accept.

Drummond grew up in a religious family and his father was a minister, but it is a stretch to call him religious in the traditional sense. He did burn a million pounds, after all, and there are very few people who view that as a Christian act. Nevertheless religious, or at least spiritual, themes run through his work. In The Manager's Speech, a spoken word track from same period as his solo album The Man, he states that the problem with the music industry is not that it is financially broke or artistically spent, but that it is "spiritually bankrupt." Drummond then offered his services as manager, not just of bands, but of the entire music industry itself, in the belief that he could cure it of this affliction.

Generally speaking, no-one really believes in the Devil anymore. The idea that you can meet him in person and discuss contracts is far-fetched, even for devout Christians and regular churchgoers. Drummond's claim to have sold his soul to the Devil must be seen, at best, as a metaphor.

Of course, this all does hinge on what is meant by 'the Devil'.

For a Christian, there is a simple definition. The Devil is evil. He's the Big Bad, the one to avoid. You don't need to know anything more than that. If anything, it is better not to know anything more. The Horned One is big on temptation and lies, and keeping as far away as possible is the best possible option. What, though, does the name mean outside the Christian reality tunnel?

Here things get a little more complicated. Whereas Christians are happy to consider various names such as Lucifer, Satan, Beelzebub, or Mephistopheles as all the same thing, they often have very specific meanings. Rudolph Steiner, for example, made much of the contrast between two different aspects of the Devil, namely Lucifer and Ahriman. 'Ahriman' is something of an archaic name these days, but we know this critter better as Mephistopheles.

To Steiner, Lucifer and Mephistopheles are opposite principals. At their simplest, they can be thought of as energy and matter. Lucifer is the light-bringer. He represents thought, creativity and spiritual desire. Mephistopheles, meanwhile, represents the physical world. He is matter, solidification, boundaries and limitations. They are both considered to be necessary, for without Lucifer there is no motion, and without Mephistopheles there is no form. Yet they are both considered to be dangerous, and negative. It is necessary to avoid lusting after Lucifer's promise of spiritual bliss, or Mephistopheles' gift of worldly desires. To Steiner, the Christ figure was the mid-point between these two extremes, and this was the state to aspire to. Beyond that mid-point the world would alternate between the negative influences of one or the other.

This definition of Mephistopheles is the context that explains the Satanic associations of the inverted five-pointed star. The five points of a non-inverted star are said to represent the four worldly elements (air, water, earth and fire) as well as the spirit, the fifth element that arises from the physical world. This star has the 'spirit' point at the top, and if the star is imagined as a human figure with their limbs splayed, like Da Vinci's 'Vitruvian Man', then the head is the spirit. Satanists invert this symbol, however, so that this point is down, as if the figure had fallen. In this context, the four physical elements are crushing the spirit, trapping it under the physical.

In the medieval Faust legend, the Devil also takes the form of Mephistopheles. It is worldly success and wealth that he is offering to Faust, in return for his immortal soul. The Faust legend is the basis for one of the founding myths of modern music. In this telling, the great Delta bluesman Robert Johnson met the Devil at a Crossroads. The Devil tuned his guitar and gave him mastery of the instrument in return for his soul.

From here, it is possible to trace the influence of the Devil on 20th Century music, in particular the Rock n' Roll that grew out of the Blues. Rock is the 'Devil's music,' and proudly so, for the Devil has the best tunes. The connection is, at times, pretty overt. Bands like Black Sabbath, Metallica and the Jimi Hendrix Experience all made us of a musical interval called the tritone, unaware it had for centuries been condemned as 'the Devil's chord' or 'the Devil in music' by the Church. Indeed, even today the shorthand symbol or emoticon for 'this rocks!' is based on hands forming the devil horns symbol, \m/ \m/.

"KLF are gonna rock ya! \m/ \m/.” That sort of thing.

Robert Johnson got a better deal than Faust. His Devil offered him both his Luciferian aspect and his Mephistophelean side. Johnson was seduced by the creative mastery of music that Lucifer offers, even though that gift attracted the worldly rewards of Mephistopheles. Poor Faust had to make do with understanding and academic knowledge for his Luciferian aspect, which does not sound half as much fun. Faust basically gave his soul for a medieval version of Wikipedia.

Here, then, is the Devil's bargain to musicians. It is Lucifer that they crave, but it is Mephistopheles that destroys them.

We can tell this story without the help of the Devil, if it makes you more comfortable. Consider the story of the Greek Titan Prometheus. Prometheus stole fire from the Gods and gave it to mankind. As a punishment, Zeus chained him to a rock and he had his liver eaten out by a giant eagle. Then the liver grew back, and the eagle feasted again. In this way Prometheus was tortured for eternity. All of which illustrates a profound truth, which is that Gods are bastards.

It seems, at first, an odd story. The 'fire' of the Gods is spirit, imagination, knowledge, or consciousness itself. It is the spiritual yearning that Lucifer represents. Prometheus gained this, and gifted it to mankind. In return he was chained to a rock, or trapped by the physical, solid, manifest world of Mephistopheles. The eagle and the liver would have had a symbolic significance that has been lost over the centuries, but we can still understand how they mean pain and torture for Prometheus.

This, then, is the flipside of inspired creativity or the achievement of spiritual ecstasy: a fall from that high state to the base jail of the physical world. This is Prometheus' torture, or the damnation of the soul. Those that glimpse divine wonder will not be able to bear returning to the material world. The simplest way to understand this is to speak to a recovering heroin addict. Alternatively, look at the Romantic poets, or the story of Icarus.

Or consider Led Zeppelin's Jimmy Page. During the peak of his success he was often rumoured to be in league with the Devil, not least because of his obsession with Aleister Crowley. But look at his astonishing creativity in the early 70s, the drugs, money, groupies and fame that followed, and his complete creative impotence afterwards. If we leave aside the Christian associations of the Devil and allow that name to refer to Steiner's two opposing forces, then we have an accurate metaphor for what happened to Page. He lost his soul to the Devil.

In this context, Drummond's claim that he had sold his soul to the Devil makes more sense. As the JAMs, he and Cauty were spontaneous, creative and inspired. They embraced the chaos, ignored rules and were free to do whatever they wanted. But when they became the KLF, they resonated with the world. The world reacted, and embraced them. They accumulated success, fame, critical approval and money. They were no longer above the music industry, subverting it from afar. They were inside it, sinking deeper.

What then, of Drummond's trip to the heart of Africa to 'confront Satan' and get his soul back? Drummond and Manning took with them on their journey, of all things, Punch and Judy puppets. There was a symbolic reason for this. In all our literary history and shared culture, Punch is the only figure who triumphs over the Devil.

And if Punch can do it, then it can be done.

So there was hope, after all. They were not broken. If Drummond really did think that he had lost his soul to the Devil, he was still seeking a way out. Nothing is impossible. Perhaps if Faust had spent time with Ken Campbell, he wouldn't have given up so easily.

Religious imagery was common amongst the euphoria of the rave world. "This is my church," proclaimed Maxi Jazz in Faithless' 1998 single God Is A DJ, and it was clear that he was referring to the rave itself. The religious imagery of The KLF was most pronounced on their post-Chill Out album The White Room, which featured the track The Church of The KLF. The lyrical themes in The White Room, however, were subtly different than those used by other rave bands. They were not a recognition of the transcendent aspect of rave. Rather, they concerned seeking and yearning, a journey or a pilgrimage on The Last Train To Transcentral to a place known as the White Room.

In many ways the story of The White Room - from its original planned release in 1989 to its eventual release in a radically different form in 1991 - is the story of The KLF. Before we look at it in detail, however, it is worth noting one decision that was made halfway through that project. That was the decision, made in 1990, to make hit singles.

Cauty has linked this decision with the success of Guru Josh's hit Infinity, a forgettable rave hit based around a saxophone melody that the passing of time has not been kind to. "I thought, 'It's come to this, we're in competition with Guru Josh'", Cauty told the writer Richard King, "and I remember saying to Bill, 'Well, come on, let's have a hit single then because we know how to do it. We haven't really been trying that hard."

The time felt right. "By the time we'd started becoming the KLF we'd got ourselves together a bit more, we could sort of try and work out a bit more of a long term strategy," Cauty has said, "We were just winging it from day to day, but we could see slightly further into the future and sort of plan things a bit."

The first step was to go back into the studio and rework What Time Is Love? into a radio-friendly single. The result would be the first of a string of mainstream hit records. It would also be the first of a string of reworked versions of What Time Is Love? and, indeed, reworked versions of much of what they had already recorded.

This was the moment - the point when they consciously decided that The KLF would make hit singles - that the creative flow of the past two years stopped. The continuous outpouring of new material since the formation of the JAMs came to a sudden and abrupt halt. There would be no new songs written from here on in. Instead, the fruits of their previous labours would be picked over. Old songs were reversioned, remixed and re-released. Playful creativity was replaced by hard work, and art was replaced by craft.

In many ways, this was the making of them. Wild, uninhibited creativity is essentially self-indulgent if it is not followed by the hard work involved in manifesting that inspiration into something that connects to other people. The decision to hone their material into something universal produced work that towered over anything that they had done before. It created singles that were as wonderful as the ones Drummond dreamed about back in Liverpool in the 1970s. The material created in their early, mercurial phase was rich indeed, and the skill with which they then distilled and presented it was inspired. But they were entering a different phase at this point, and the fire that had marked the initial stages had snuffed itself out.

In 1989 the KLF made a film. It was not released, or even properly finished. But they made it. It was called The White Room.

Many successful musicians made films in the 1980s, from Madonna or Prince to The Pet Shop Boys. The KLF's was very different to these. The version that exists is a dialogue-free ambient road movie just under an hour in length.

It starts at a rave in the basement of Transcentral, Cauty's South London squat. Drummond and Cauty leave and get into their car, the 1968 Ford Galaxie of Doctorin' The TARDIS fame. In the back sits a solicitor, played by their real-life solicitor David Franks. He hands them a contract, which they sign without reading it. Franks exits and Drummond and Cauty drive off.

Pretty much most of the rest of the film is them driving.

First, they drive around London at night. Then, they drive around the Sierra Nevada region of Spain. This goes on for some time. Not much happens, although they do find a dead eagle, and at one point they stop for petrol.

Eventually the pair stop and build a camp fire. This occurs twice in the film. At each point, their solicitor is seen in the smoke from the fire, studying the contract - a distinctly Satanic image. Eventually, the solicitor discovers something in one of the contract's clauses. He writes 'Liberation Loophole!' on the contract.

At this point, events in the film gain more momentum. Drummond is seen throwing the contract into the air, obviously delighted. He has, by this point, changed into a pair of plus-fours and is dressed not unlike an Edwardian mountaineer. Cauty then paints the car white and they drive, past a burning bush, up into the snow-peaked mountains. When the car gets stuck in the snow they abandon it and continue up on foot. Cauty has not joined Drummond in sporting the Edwardian mountaineer look and instead wears a more sensible white parka. Much of this climbing sequence, it must be said, is particularly beautifully shot. Eventually they reach the summit, where they find a large white building with a radio telescope. They go in.

They find themselves in a white, smoke-filled void - the White Room. They find a pair of fake moustaches on a pedestal, and put them on. Then they find the solicitor, sitting at a white table. He shows them the clause he has found in the contract. They nod. The pair then walk away, dissolving into the smoke and vanishing into the void. The End.

Visually, it looked terrific. It was a clear step up from the VHS-quality of the Waiting ambient film. It had been shot with a professional crew, and it shows. On the down side, it cost them around £250,000.

It was, all in all, an odd thing to spend £250,000 on.

Anyone who has been in a position which involves reading record company press releases will know that they contain more unreadable bullshit than any other literary medium. An awkward amalgam of romantic fawning and angry political manifestos, music industry releases are frequently a stream-of-consciousness outpouring of rare and unlikely superlatives, written by people without first-hand knowledge of the music they refer to. The releases issued by Drummond and Cauty do not, at first glance, appear to be much different.

The statement issued in February 1990 and called 'Information Sheet 8,' is a typical example. It begins with a classic summation of their debt to Robert Anton Wilson: "THE JUSTIFIED ANCIENTS OF MUMU are an organization (or disorganization) who are at least as old as the ILLUMINATI. They represent the primeval power of Chaos. As such they are diametrically opposed to the order that the Illuminati try to oppress on mankind and on mankind's understanding of the Universe."

It goes on to explain how Drummond and Cauty took on that mantle in order to make records without "anyone telling them how it should be done. [...] But within days of their first record being released," it continues, "they began to receive mail and messages from very strange sources. The information they were getting was varied and confusing. They were being warned not to get involved with what they could never understand. They were being threatened. They were being congratulated in taking The War above ground. They were being welcomed on board as 'brothers in arms' in the only war that was ever justified, I quote; 'To finally separate Time from Space, thus enabling Chaos once again to reign supreme.'"

Most readers of music press releases would have skipped all this, under the assumption that it was bullshit. To anyone familiar with Operation Mindfuck, however, it seems extremely familiar. This raises the question as to whether Discordians were still engaging in those tactics in the 1980s, and directing them at Cauty and Drummond.

There is good evidence that Discordians did target the pair with hoax letters. In Pete Robinson's well regarded JAMs history/fanzine Justified And Ancient History, he records a 1987 letter from an American called 'Don Lucknowe' who threatened them with 'Deep Shit' if they continued using that name. Drummond and Cauty were worried that they faced legal action from Wilson and they did not reply to the letter because, according to Robinson, they were "shit scared."

Robinson did make contact on their behalf, however. The address was for a now-defunct parody news magazine called Yossarian Universal. The editor, Paul Fericano, replied to Robinson and told him that "we now believe" that the Yossarian Universal contributing editor James Wallis was responsible for the original letter. Wallis was a big Three Stooges fan, and the name 'Don Lucknowe' is based on a Stooges' catchphrase “Don't look now.” This interest in Three Stooges-style comedy was a typical Discordian touch, as Discordians are the type of people who consider Harpo Marx's birthday a Holy day. According to Fericano, Wallis was "somewhat of a hoaxer, in our YU tradition (it's one of our trademarks - and that's an understatement.)"

Assigning any particular hoax letter to Operation Mindfuck is by definition extremely difficult. Wilson and Shea have explained that no Discordian "knows for sure who is or who is not involved in any phase of Operation Mindfuck or what activities they are or are not engaged in as part of that project. Thus, the outsider is immediately trapped in a double-bind: the only safe assumption is that anything a Discordian does is somehow related to Operation Mindfuck, but, since this leads directly to paranoia, this is not a 'safe' assumption after all, and the 'risky' hypothesis that whatever the Discordians are doing is harmless may be 'safer' in the long run." There is a good reason to consider Yossarian Universal's letter to the JAMs to be part of the Operation Mindfuck, however. 'Yossarian' is the protagonist in Joseph Heller's Catch 22 and is also, according to Illuminatus!, a Discordian Saint.

Fericano's letter ends, "Sorry if all this caused anxiety, etc. Tell the members of the KLF that I wish them well, and would love to hear their music. Have never been able to find [music by The JAMs] out here." All this seems highly plausible. The British music press was widely available in the US, and a story about how ABBA's lawyers demanded the destruction of albums by The Justified Ancients of Mu Mu due to copyright issues was widely reported. The records themselves, however, did not cross the Atlantic in any numbers (indeed, most copies of their debut album were burnt in a field in Sweden). All that American Discordians knew about The JAMs would have been what they saw in the press, and all the adverts that Drummond and Cauty placed in the music press included a PO Box address. It seems likely, then, that American Discordians began sending strange and bewildering letters to Cauty and Drummond, believing that their adoption of the name 'Justified Ancients of Mu Mu' made them clear and deserving targets for Operation Mindfuck.

With that in mind, a further claim in Information Sheet 8 is worth noting. Drummond and Cauty claimed that their solicitor was sent "A contract with an organization or individual calling themselves "Eternity". The wording of this contract was that of standard music business legal speak, but the terms discussed and the rights required and granted were of a far stranger kind."

"Whether The Contract was a very clever and intricate prank by a legal minded JAMS fan was of little concern to Drummond and Cauty," Information Sheet 8 continues. "For them it was as good a marker as anything as to what direction their free style career should take next. [...] In the first term of The Contract they, Drummond and Cauty, were required to make an artistic representation of themselves on a journey to a place called THE WHITE ROOM. The medium they chose to make this representation was up to them. Where or what THE WHITE ROOM was, was never clearly defined. Interpretation was left to their own creativity. The remuneration they are to receive on completion of this work of art was supposed to be access to THE "real" WHITE ROOM."

The pair claim that they went on to sign this contract, despite the advice of their solicitor to have nothing to do with it. It is worth noting here that Cauty and Drummond were ignorant of Operation Mindfuck. Their sole knowledge of Discordianism comes from Illuminatus!, which Cauty had never read and which Drummond had not, at that time, ever finished. By signing any such contract they were not simply 'playing along', for they would have had no context for what the contract was or where it had come from.

In this reading of events, Drummond and Cauty appear to have taken a Discordian Operation Mindfuck prank letter at face value, and spent hundreds of thousands of pounds making a piece of work that would fulfil their part of a hoax contract that they chose to sign.

As to what the 'real' White Room which the contract alluded to was, Drummond and Cauty were typically candid: "Your guess is as good as anybody's." In Discordian terms, however, the meaning is relatively clear. The White Room refers to illumination, or enlightenment. The word 'room,' however, is interesting. The use of a spatial metaphor to define enlightenment as a place that can be travelled to, or sought in a quest. The search for the White Room becomes a pilgrimage, with the White Room itself taking on the character of the Holy Grail. Drummond and Cauty's film, when seen in this light, becomes a means to an end. The White Room was not intended as a film that would make money or enhance their careers. It was, instead, a step along the path in a search for enlightenment.

The phrase 'Liberation Loophole' recurs throughout the work of The KLF, most notably in the lyrics to The Last Train To Transcentral. Drummond defined what he meant by the term in a 2010 interview for BLOWN magazine. He talked about the way ideas form in his mind, vague and unformed at first but slowly growing and persisting. Should a budding notion be subjected to his objective and critical mind, however, "all you learn are all its faults and weaknesses and the reasons why you should not be doing it." The unformed idea will be riddled with contradictions, and a critical eye will use these contradictions as a reason to kill the idea off.

The liberation loophole, then, is giving yourself permission to accept those contradictions and to allow the idea to grow under its own logic, protected from the withering scorn of rationality. Drummond has used the phrase 'accept the contradictions,' as a form of artistic mantra throughout his career. He wrote about how he came to adopt that approach in his book 17. Although he was not interested in the conspiracy theories that run through Illuminatus!, the way they were presented resonated with him. The appeal was in how "something may appear to be one thing but then turn out to be the opposite, or how something could be what it is and its opposite at the same time. This chimed with a contradiction I had long felt to be at the heart of human existence: that we are totally trapped and totally free at the same time."

This is the contradiction between the material world of causality and the idea of free will. According to causality, if you put the details of all the atoms at the beginning of time into a sufficiently impressive computer, it could calculate all of future history. This does not, instinctively, fit well with our sense of ourselves as independent agents. Drummond adopted the mantra 'accept the contradictions' in order not to worry about this. As he wrote in 2007, "from that moment in June 1973 I decided to accept the total contradiction that everything from the Big Bang to the end of time is preordained in every sense and that we are totally free to do whatever the fuck we want."

The first hint that the film was not going to be released came in an information sheet from December 1989. "As you may already know the film was finished this summer and release was planned for autumn," it said. "However, some strange things have happened to the KLF and they have decided to dramatically re-enact these events for inclusion in the film. For this further filming they need to lay their hands on a million pounds."

The story goes that, following a gig at Heaven, they were accosted by a homeless guy called Mickey McElwee. McElwee told them that, before his life fell apart, he used to do occasional jobs for an international arms dealer called Silverman. Silverman recruited McElwee to follow Drummond and Cauty to Spain during the filming of The White Room, he claimed, in order to observe them at a distance. Silverman believed that Drummond and Cauty had been contacted by the actual Justified Ancients of Mummu, a secret organisation who not only existed but whose intention was to bring about nuclear war for shits and giggles. As McElwee watched the filming from a distance, he realised that a third party was also watching. This person, who McElwee believed was working for the British Government and who also knew of the existence of the 'real' Justified Ancients of Mummu, was intending to assassinate Drummond and Cauty with a sniper's rifle. Drummond was apparently nearly shot during the filming of a scene where he walks up to a large Spanish castle. His life was saved, or the so the story went, because McElwee killed the assassin before he could fire.

When Drummond and Cauty retold this story, they stressed that McElwee was probably a deranged fan who had made the whole thing up but, nevertheless, the incident had scared the living crap out of them.

A more cynical interpretation, such as the one held by this author, is that they made this part of the story up. The 'ambient road movie' version of The White Room, it was acknowledged, was largely perceived as being very boring. It was hard to see why any viewer would care about the two directionless seekers on screen. Weaving a conspiracy-based version of the JAMs mythology into things, however, allowed them to keep the expensive footage that they had already shot and, at the same time, deliver a more traditional conspiracy thriller about two men who had become way out of their depth.

There were a few problems with this approach, however. The first is that all the Discordian humour had somehow become lost in translation, resulting in the fatal mistake of taking the whole thing seriously. The moment it is supposed that The Justified Ancients of Mummu is a real secret organisation that actually exists, then all that is interesting about them evaporates. In a related problem, the script for this version of the film was terrible. It would have resulted in something far worse than what they already had. The ambient road movie version may have been considered too boring for many to sit through, but it did at least succeed on its own terms.

Nevertheless the new script, which now included a dramatic recreation of McElwee's story intercut with the existing footage, was budgeted. Paul McGann, as we have already noted, was cast in the role of McElwee (and aficionados of that piece of synchronicity may enjoy the fact that in 24 Hour Party People, a film about the Manchester music scene during that same period, a similar 'crazed tramp' role was played by Christopher Eccleston, the actor who took over from Paul McGann as the ninth Doctor Who.)

All that they had to do was raise the extra million pounds that filming this new script would entail.

To do this, they attempted to recreate the success of the Timelords and produce another number one record. Cauty and Drummond emerged from the studio with a cheesy pop single called Kylie Said To Jason. Like Whitney Joins The JAMs, it was a product of Drummond's unapologetic love for pure pop and, also like Whitney Joins The JAMs, this was completely misinterpreted. Largely perceived as ironic or sarcastic, the single failed to even enter the top 100. The spontaneous creativity of Doctorin' The TARDIS, it seemed, had been more effective than deliberate, planned intent. Without the money they expected Kylie Said To Jason to bring in, they had no way of funding the rest of the film.

A soundtrack album for The White Room movie, however, did finally emerge in 1991. It was a critical and commercial hit and is still be found in many '100 best albums' lists to this day. It contains versions of their string of hit singles - 3am Eternal, What Time Is Love, and Last Train to Transcentral - that lifted the duo into a position of global success.

The film, though, was dead. The existing version was never released, and the finished script was never shot. As Drummond once remarked, "[completing] that road movie thing, it can only end in death. We're not ready for that yet."

Drummond and Cauty climbed into the submarine.

They were dressed in hooded, deep red robes and each of them had a large fat horn, over a foot long, emerging from their foreheads and pointing upwards at forty five degrees. They looked pretty damn funny, squashed inside the submarine with only their covered heads and emerging horns poking out of the submarine's turret.

Behind them was the lost continent of Mu, and on the lost continent of Mu there was a temple.

In front of the temple were a troupe of African dancers, another group of six dancers in yellow robes, and a scattering of the KLF’s musical collaborators.

Near the top of the temple was a throne. Sat around the foot of this throne, dressed in flowing robes of white, sat the Four Handmaidens of Lucifer. On the throne, wearing a golden crown, sat Tammy Wynette.

Tammy Wynette, the Four Handmaidens of Lucifer, the dancers and the musicians all swayed from side to side, waving goodbye to Drummond and Cauty. The pair were journeying onwards in their submarine. They were leaving the lost continent behind them.

It was a hell of a music video.

It was also a hell of a song. The single was Justified and Ancient (Stand By The JAMs.) If you can overlook a limited mail order 7" and the staggered release of their previous American single resulting in a later UK release, then this was the last KLF record. With hindsight, you can read the slogan 'Warning! The Fall of the Empire and the Death of Little Mu are imminent...', which was flashed across the screen in the video, as foreshadowing this.

The song Justified And Ancient itself was a thread that ran through their entire career. It was originally planned as the opening track on the debut JAMs album 1987 (What The Fuck Is Going On?), and although that didn't happen a chunk of the song was used later in that album, towards the end of the track Hey Hey (We Are Not The Monkeys). A similar snippet drifted into the Chill Out album, accompanied by the sound of chirping crickets and running water, in a track called Justified And Ancient Seems A Long Time Ago. The White Room album both opened with a snippet of the song, as a lead in to What Time Is Love, and closed with their first complete version. With the creation of this single version, the song was finally finished.

It was a record that was entirely their own creation, and one which ultimately achieved all their musical objectives. On one hand it is entirely traditional, the song where Drummond and Cauty finally resort to a chorus-verse-chorus structure, and it was built without the theft of major samples from other artists. Lyrically, on the other hand, it is completely detached from reality, existing only in the realms of its own myth - "They're justified / And they're ancient / And they drive an ice-cream van." If the JAMs were an attack on an industry obsessed with authentic songs and authentic groups, then Justified And Ancient can be seen as the conclusion to the project. Looking at it from the outside, not a line of it makes any sense. Internally however, if you allow it to have its own myth on its own terms, then it seems valid and complete. Instead of putting the boot into the classic pop single, Cauty and Drummond absorbed its magic and claimed it as their own. In Situationist terms, it was pure spectacle.

The most striking thing about the single, of course, is that it features a lead vocal by Tammy Wynette. This is leagues ahead of fantasising about Whitney Houston joining the JAMs. Wynette, the first lady of country, is as sincere and authentic a vocalist as the twentieth century has produced. There is nothing detached or ironic in Wynette's performance of songs like her biggest hit, Stand By Your Man. When she sings, she means every word. Here, however, Drummond and Cauty take this voice of authentic honesty and bring it inside their myth, reclaiming the emotional power of modern music for their own ends. "They're Justified, and they're ancient, and they like to roam the land," she sings, accepting the lyrics at face value. "All bound for Mummu Land, when someone starting singing 'Turn up the strobe!'"

"I really don't know why they chose me," Wynette said. "I was apprehensive at first, but I'm really excited with the way it's all turned out." The song would do wonders for her career, hitting number one in eighteen countries and number 11 on the Billboard Hot 100 in America. This was Wynette's first top 40 hit in the mainstream, non-Country music charts since 1969.

The idea was originally Cauty's. "What this song needs, Bill, is Tammy Wynette," he had said as they worked without inspiration on an earlier version. Drummond immediately recognised that he was right, adopted his best Ken Campbell attitude, and went to find a phone. Twenty minutes later, Drummond was playing the song down the line to Tammy Wynette while she sat backstage at a Tennessee concert hall. She told him she loved it, and suddenly one of the least plausible or likely collaborations in music appeared to be effortless and almost pre-ordained. Drummond flew to Nashville and recorded her vocals, and Cauty somehow made her loose, country vocals work around their rigid dance beat.

A true professional, we can only wonder what she really thought about the lyrics she was given to sing or the imagery of the video. It seems unlikely that she would have interpreted a line like, "We don't want to upset the applecart" as a reference to the Discordian's Golden Apple of Discord. It seems equally unlikely that she was aware that the four white-robed women around her represented the Four Handmaidens of Lucifer. By the time Drummond and Cauty donned their blood-red robes, she had probably long stopped questioning what was going on. So it was that the pair strapped horns to their heads - a single horn for each man, making The KLF a two-horned beast - and marched up and down in front of her throne while the subliminal message 'Horned Men!' was flashed across them in the video.

A few months later Wynette collapsed while on tour of Australia. She blamed this on overwork caused by all her promotional work on this single. "Tammy Lays Blame On The KLF," as the headline in The Sun newspaper had it.

The finished video incorporated the following scrolling text detailing Wynette's history and many achievements: "Miss Tammy Wynette: 25 years in the business. 11 consecutive No 1 albums. 20 No 1 singles. 5 times voted C.M.A. Female Vocalist of the Year. Stand By Your Man still the biggest selling country single of all time. 2 Grammies, 5 Marriages, 3 Children, The first lady to sell more than 1 million copies of one album."

When the video was released, this seemed to be one of the more unusual things about it. Music wasn't judged in terms like that in those days, and musicians did not think to present themselves in such a light. To the modern eye, of course, it is exactly how the guest performers on TV talent shows such as The X Factor are introduced. This modern juxtaposition gives the video a strange quality when viewed today. Everything in it - the music, lyrics, imagery, costumes and personnel - was the result of Drummond and Cauty's idiosyncratic vision. Nothing in it would have survived a committee, or the controlling influence of a manager like Simon Cowell.

Today, X Factor contestants are unable to get a haircut without permission. Nothing is left to chance. The approach taken by Simon Cowell and his ilk is the exact opposite of the path pursued by Drummond and Cauty. Which is preferable is, of course, a matter of personal judgement, but you are free to hold up Justified And Ancient (Stand By The JAMs) against any X Factor-related record that you choose to see how they compare.

Inside the submarine, Drummond and Cauty turned away from the lost continent of Mu. The submarine was a reference to the Lief Erickson, the golden Discordian submarine that featured heavily in the Illuminatus! trilogy. It was named after the Norwegian or Icelandic explorer who had been the first European to discover North America, around 500 years before Christopher Columbus.

This was relevant because 1992 was the five hundredth anniversary of Christopher Columbus' 1492 voyage, an anniversary that was being widely celebrated in the United States at the time. Drummond and Cauty responded by issuing their final (UK) single in 1992 as a celebration of 'the one thousandth anniversary of the discovery of North America by the Justified Ancients of Mummu.' The JAMs had been searching for the lost continent of Mu, it was explained, in the year 992AD. They failed to find Mu, but they did discover America by accident.

That song was yet another reworking of What Time Is Love, which they called America: What Time Is Love. The video recreated The JAM’s mythical voyage. Shot in black and white and drenched by an ocean storm, it showed the KLF on a Viking longboat of the type used by Lief Ericson. The Handmaidens of Lucifer appear as Sirens on the rocks, pointing the way forward. Glenn Hughes of Deep Purple is also on board.

The video ends, needless to say, with the Viking longboat being burned.

It had been an extraordinary, exhausting couple of years. They had produced a string of hit singles and videos, most notably the 'stadium house trilogy' of What Time Is Love, 3am Eternal and Last Train To Transcentral. They had made both the unreleased film and the soundtrack album of The White Room. They had burnt a wicker man in a pagan ceremony on the Isle of Jura, recorded Tammy Wynette in Nashville and fulfilled all the promotional duties that come with being one of the best-selling bands in the country. All of this, they did independently. There was never a point, Drummond has remarked, when he was not unloading boxes of CDs from the back of vans.

John Dyer of Mute Records told Richard King about negotiations that occurred when Rough Trade Records went into administration. The KLF's records were distributed by Rough Trade and Drummond and Cauty were at one point owed over a million pounds by the company. "So in the middle of a meeting we'd say, 'So you agree to that Bill? KLF represents 13 percent of the debt?'" Dyer told King. "And Bill would say. 'Yeah, just a minute,' and then he's on the end of the phone going ‘Yeah, bit more bombastic Jimmy, bit more bombastic,' so he's having to do a mix-down with Jimmy Cauty who's in the studio at the other end of the phone. Then he'd ring up Pinewood and would spend a hundred grand on the video. He was hiring the sound stages saying, 'No, we don't need the submarine stage today.' Incredible, visionary behaviour." Drummond, in particular, looks noticeably older at the end of his five-year partnership with Cauty than he did before.

And what, in the end, was it for? Drummond and Cauty looked out of the submarine at the waving figures on the lost continent of Mu. They had achieved what they had set out to do. They had made a record, a fantastic record, which satisfied all Drummond's punk-era demands on what a single piece of 7" vinyl should be. Justified And Ancient (Stand By The JAMs) was a record that you could play to anyone, from seven year old kids to fifty year old country music superstars, and they would all immediately get it. It didn't need explaining, or placing in a certain context. It is universal. It will still sound great in a hundred years. And they did this entirely on their own terms, swimming against the industry instead of with it, creating out of nothing but their own myth.

So, what now?

The submarine sailed away. It did not sink under the waters, however, because it wasn't a real submarine. Nor was it in a real sea, being a sound-stage at Pinewood studios where Cauty's old car had once appeared in the Superman movies. Cauty had looked into buying a real submarine but this didn't prove to be practical, so he consoled himself by buying a number of armoured vehicles instead. As Drummond said in 1991, "We want to buy ships, have submarines. They really are stupid things I know, but I feel confident that in the event of us selling ten million albums we would definitely go out and buy a submarine... Just to be able to say 'Look we've got a submarine and 808 State haven't."

In Robert Anton Wilson's book, the Discordians could always travel on to further adventures in their submarine, but Drummond and Cauty could not disappear in this fashion. Their achievement was not physical. It was intangible, playing out in the minds of the audience, becoming part of the Situationists’ spectacle and anchoring itself in Moore's Ideaspace. It was very hard, in other words, to see what they had achieved. What, exactly, was all that hard work for?

And what, if Justified And Ancient was everything that they had been aiming to create, could they do now?

With hindsight, it was Jonathan King that killed the KLF. His fatal blow was an innocent-sounding comment. His words may not have split the group immediately, because Cauty and Drummond had too much momentum to stop straight away. But it was only a matter of time, as the implications of what he had said could not be ignored for long. The KLF staggered on for another three months, too stunned to realise that they were already dead.

It was February 1992 and the KLF had just won the 'Best Band' award at the Brits. Jonathan King was the producer of the awards show, and he had been asked what he thought of the KLF's live performance at the show.

"I enjoyed it", he said.

He enjoyed it. There was nothing else for it. It had to end.

King is a music producer, TV presenter and a recording artist who has sold over 40 million records under various pseudonyms, most of them novelty singles. As he busied himself backstage at the Hammersmith Odeon organising the 1992 Brits Awards, he was forty eight years old and dressed in a garish shell suit and a baseball cap with 'KING' stamped in metal across the front. In the coming decade he was named 'Man of the Year' by the BPI, praised by Tony Blair and convicted of multiple sexual offences on underage boys, so in many ways Jonathan King could be said to personify the music industry. King's acceptance had, on a symbolic level, signified the music industry claiming Drummond and Cauty for itself.

Drummond and Cauty's problem with the music industry wasn't the usual adolescent anti-authoritarian posturing that is so common among musicians. It was the result of bitter experience. By that point Cauty and Drummond had twenty-five years’ experience in the industry between them, from running record labels to producing, working in A&R, being in unsuccessful bands and being pop stars. They knew what the music industry did to people, and they also knew what it had done to them. But by then they also knew how much they had been formed by it. It had shaped their lives and left them feeling corrupted, but it was also an integral part of who they were.

It's still surprising that they were asked to provide the opening performance for that year's Brit Awards show. They had been asked to appear the previous year, but negotiations had broken down following their plans to fill a stage with angels and Zulus and arrive on the back of elephants. The deal breaker, with hindsight, was probably their plan to chain-saw the legs off one of the elephants. The elephant, they said, represented the music industry. The organisers understandably walked away at this point, but they should have realised then that they were not dealing with stable individuals.

Cauty and Drummond were never going to stand on stage and entertain an audience of music industry insiders with one of their crowd-pleasing number one hit singles. They did not desire the acclaim of their peers, nor were they focused on using the event as a showcase to further their careers. They were more concerned with the implications of the invitation. The music industry was finally reacting to them, recognising what they had achieved, and attempting to embrace them. It was an invitation that demanded a response, and that response needed to be a summation of their feelings about the industry. In the end they did not quite achieve this, but there is no doubt that they tried.

The show began. The audience were seated in rows, dressed as fabulously as their status demanded and looking effortlessly nonchalant whenever a TV camera turned towards them. The KLF were announced as the opening act and the audience cheered and applauded, seemingly delighted. Bill and Jimmy walked out onto the stage. They were accompanied by Extreme Noise Terror, a grindcore band from Ipswich.

 At the time, the existence of such extreme metal bands was all but unknown to the mainstream audience. Bands like Extreme Noise Terror and Slayer had been played on John Peel's radio show, and the Midlands band Napalm Death had appeared in a BBC Arena documentary, but beyond a small group of serious music fans most people had no idea that such an extreme type of music even existed. To those unfamiliar with the genre, it did not even appear to be music. It was noise, and it was a shock to realise just how deeply unpleasant noise could be. In an age when speed metal is used to sell energy drinks, it is perhaps hard to appreciate just how incomprehensible bands like Extreme Noise Terror were at that time. With all due respect, they were not how the British Music Industry wanted to showcase British music to a watching TV audience of nine million people in the UK alone.

The band erupted into a thrash metal version of 3am Eternal, although there were few in the audience who recognised it. Extreme Noise Terror had two vocalists, each barking lyrics in incomprehensible, atavistic grunts that sounded somewhere between Beelzebub and the Cookie Monster. Between them stood Bill Drummond, leaning on a crutch and smoking a fat cigar. He wore a kilt of Drummond tartan that he received on his 21st birthday and the battered leather overcoat that Martin Boorman wore when he escaped to Bolivia. He meant business. He spat out new lyrics, full of references to the BPI and the Brits, but the exact words were indecipherable under the volume, speed and sheer presence of the music.

Drummond's interest in Extreme Noise Terror came after he heard them on the John Peel show. He and Cauty had been planning a hard rock follow up to The White Room called The Black Room, and had approached Motörhead about a collaboration. Motörhead declined, knowing full well that their solid metal audience would never forgive them for working with a 'dance music' band. Drummond then called Extreme Noise Terror but the message he left, "from Bill of The KLF," was initially ignored as it was misheard as "Bill from the ALF", or the Animal Liberation Front. Extreme Noise Terror were deeply into the animal rights scene and were considerably more likely to be called by the ALF than The KLF. Eventually, though, they connected, and the two bands started working on The Black Room sessions. That album was never finished.

Earlier that morning, Drummond had driven to an abattoir in Alan Moore's home town of Northampton and bought a dead sheep and eight gallons of blood. The plan was that he and Cauty would dismember the corpse on stage. The KLF had used sheep imagery throughout their career, ever since they appeared on the cover of Chill Out, so destroying one like this had obvious symbolic meaning. They had huge butchers knives ready, and planned to throw hunks of carcass into the audience. It was intended to be an act so appalling that they would never have been forgiven for it. Jimmy also goaded Bill by suggesting that Drummond could cut his own hand off as well. This was dangerous talk, given how psyched the pair were. They both knew as they suggested ideas that there was a danger that they would carry them out.

Cauty's suggestion reminded Drummond of the Red Hand of Ulster. In Irish legend there was a race across the sea from Scotland, and the first competitor to touch the land was to be declared the King of Ireland. One potential king was behind in the race, so he cut his hand off and threw it ahead of his rivals, onto the shore, and in doing so claimed the land as his own. When Cauty suggested that Drummond could cut his own hand off and throw it into the audience, the idea interested Drummond because he immediately saw it as in some way claiming the music industry for himself. Drummond's actions were being dictated by his symbolic interpretation of events, as always, but this potent form of internal logic seemed to be pushing them into darker and more dangerous territory. Drummond's train of thought was, needless to say, not a normal reaction to being asked to cut off your own hand.

Rumours about the dead sheep had spread during the day, thanks to their publicist Mick Houghton wisely informing the press in order to sabotage their plans. Jonathan King and the BBC were horrified and made it clear that no such act could be allowed, and certainly not televised. Extreme Noise Terror weren't too impressed either, being extreme vegetarians who were known to vandalise butcher shops. The sheep remained in the van during the performance, only to reappear later that night dumped on the steps outside the aftershow party tagged with a note that read, 'I died for ewe'. The prompt arrival of the police prevented the eight gallons of blood joining the sheep on the hotel steps. Like so many other times, Drummond and Cauty had failed to implement their plans and been left with no choice but to improvise.

Still, while Drummond may not have butchered a sheep on stage, he did have an antique machine gun. As the song ended he clenched his cigar between his teeth and sprayed bullet after bullet into the audience, the music industry itself. The gun only fired blanks, of course, but it was cathartic.

In a strange way, something about the music industry did die around that point. Music in the twentieth century had shown an incredible ability for invention. New musical genres were constantly created and explored - so much so, in fact, that this was considered normal. The first half of the century had given us such distinctive new genres as Blues or Jazz. The Fifties gave us Rock n' Roll, and the Sixties gave us Psychedelia and Soul. The Seventies gave us Reggae, Heavy Metal, Disco and Punk, and the Eighties had delivered Hip-Hop, Techno, Acid House and Indie.

The assumption was that this level of creativity was normal and would continue indefinitely.

Each of those new genres was a major musical movement, a continent of sound the likes of which had never been heard before. They were usually forged in the crucible of new technology, new drugs or a combination of both. Musicologists have their technical definitions of each of these genres, of course, but non-musicians define them more simply. Each genre makes us feel differently. We know the mood that a Blues record creates in us, and we know that those feelings are different to the ones generated by Jazz, Heavy Metal or Reggae. The musical genres, in other words, map out the various moods and states that the human mind is capable of experiencing.

This constant invention of major new genres was believed to be normal in 1994, and those in the Brits audience had personally seen the rise of Disco, Punk, Hip-Hop, Rave, Madchester and Indie in their own lifetimes. The fact that these genres had appeared alongside other creative bursts, such as the invention of videogames or street art, also helped to normalise them. Grunge had just happened and, while it may not have staked out as much new territory as its Punk or Metal parents, it still felt like a distinct and valid invention. It would never have occurred to anyone in those seats, as the blank bullets from Drummond's gun sprayed across their peers, that such invention had come to an end.

In the years ahead, the journalists and A&R men of the industry busied themselves seeking the next new thing. Britpop was presented as such a thing, despite being a coked-up combination of Indie music and nostalgia. It appeared that music which sounded like music used to could be a new thing, if you were having too much of a good time to think about it. But, as the decade rolled on and the twenty-first century began, it slowly became apparent that major new genres weren't arriving any more. Sure, genres split into sub-genres as they were explored more fully, and the space between different genres were colonised by crossover artists. Yet these hundreds of subgenres, from Drum ‘n’ Bass to Black Metal, were considerably more limited than the genres being founded just a few decades early. They were noticeably less fertile.

None of this meant that music got worse, of course. There were still great songs being written and great performances given. Recording became cheap, the ability to record music and reach an audience became more democratic, and access to the entire history of recorded music became easy. But the idea that there were major new continents of unexplored music slowly faded away. The frontier had been colonised. We had discovered the edges of the territory.

Bill Drummond did not know this at the time. Despite machine gunning the music industry at the point its engines of creativity died, he did not imagine that he really was killing it. Correlation does not imply causation, after all. But regardless of what he thought he was doing, he was still the one man in the room whose actions were in sync with the wider picture.

As the band left the stage a voice declared over the PA that "The KLF have left the music industry." It was only meant as a joke. They didn't realise at the time that it was true.

There were many people in the crowd who were appalled by the performance. Trevor Horn, who was there to pick up the award for best producer, announced that the performance was "disgraceful". WEA chairman Rob Dickens said the gesture was "pathetic, silly and childish." The classical composer Sir George Solti tried to leave the auditorium and had to be persuaded back to his seat. This was the only reaction from a member of the audience, Drummond and Cauty band felt, that showed any understanding of what they had done. The press were deeply unimpressed, and it can be assumed that many of the watching millions at home were baffled. But there was something about Jonathan King, and the way that he seemed to personify the entire industry, that made his claim that he enjoyed the performance so damning. As the NME has remarked, the music industry would let you sexually abuse its grandmother as long as you continue to make it money. It can absorb any attack, no matter how heartfelt, because it simply doesn't care about anything except the bottom line. As the Situationists put it, "opposition to the spectacle can produce only the spectacle of opposition." Or to quote Raoul Vaneigem, "pissing on the altar is still a way of paying homage to the Church." In this way the music of The Sex Pistols was eventually played to the Queen at the opening ceremony of the London 2012 Olympics, and the music of Kurt Cobain was eventually covered by The Muppets.

To add to the insult, the KLF were then awarded the Best Band award, but they were awarded it jointly with Simply Red. Simply Red were at the time at the height of their commercial success, following their multi-platinum 'Stars' album. It was not a good time for the industry to tell Drummond and Cauty that it considered them to be the best that they could possibly be, which was just as good as Simply Red. Such an accolade is easy to misinterpret.

Drummond and Cauty had left immediately after their performance, so a motorcycle courier collected the award on their behalf. The statue was later discovered by a farmer in Wiltshire, who found it buried in a field near Stonehenge. The farmer returned the statue, so Cauty and Drummond had to go back to Wiltshire and bury it deeper.

Jonathan King was not known, at that point, as a paedophile. He was jailed in 2001 for the sexual assault of five teenage boys. This makes King the third person in this story to be jailed for sexual offences related to minors. Gary Glitter, who appeared with Cauty and Drummond on Top Of The Pops, was jailed for possessing thousands of images of child pornography and charged with have sexual relations with a 14 year old child. Chris Langham, the Thick Of It actor and co-author with Ken Campbell of the Illuminatus! stage play, was jailed in 2007 for possessing child pornography.

You might think this a remarkably high instance of such crimes for one story, and you would be correct. It becomes more uncomfortable in light of a character in Illuminatus! called Padre Pederastia, a paedophile priest who initiates new recruits into the Justified Ancients of Mummu by leading a satanic black mass. Not all the co-incidences that flock around this story are light and funny.

After the Brit awards, the actions of The KLF were quickly rationalised by journalists as 'pranks' or 'scams.' They were nothing of the sort. They were an honest expression from the very core of Drummond and Cauty. As Drummond told the journalist Danny Kelly the next day, "There is humour in what we do, and in the records, but I really hate it when people go on about us being 'schemers' and 'scammers'. We do all this stuff from the very depths of our soul and people make out its some sort of game. It depresses me." Once again they had reacted instinctively on the deepest level they knew, and found their actions misinterpreted as some sophisticated Machiavellian media manipulation.

They could not wound the industry, and they could not fight it. When they first decided to take on the mantle of The Justified Ancients of Mummu their intention had been to claim the music industry for themselves. Instead, it had swallowed them up.

They had failed.

They were in a very dark place. As Drummond told Danny Kelly, "Looking back, we realise we don't really know what our motivation was. All we know is we've got, as well as everything else, this dark side to our personality. We looked into our souls and entered into the same area that Manson must have entered... and that bloke who shot up Hungerford." Kelly challenged him on this because, if it was hyperbole, then it was in terrible taste. He asked Drummond if he really meant it. "I do actually. Yes I do," Drummond said. "It is the same area. Somebody recently used the phrase ‘corporate rebels’ - about the Manic Street Preachers, I think - and both Jimmy and I didn't want to be just corporate rebels because there's just so much of that, shameless, in the music business. We felt we were headbutting... headbutting... trying to push at what's acceptable. It was completely pointless and you don't know why you're doing it but it has to be done. And that's what Michael Ryan did; he just woke up one morning and thought ‘right, today's the day I go out and get the bastards’ and went out and shot the bastards..." A number of journalists from this period came away from interviews speculating whether Drummond was on the edge of a breakdown.

What next? Where could they go from there? They had been on a journey deep into the very heart of the beast. They had failed, and they may never feel clean again. They had to get away, but was it possible for a group that successful to escape from the industry? In 1992, the KLF were massive. The previous year they had sold more singles globally than any other UK act. They had had a string of number one records around the world. They had hits in America. The critics adored them. How could they escape from the industry? How could they become forgotten?

How could they reclaim their souls?

The first step was to stop. The Black Room sessions were ended and Extreme Noise Terror paid off. Then they killed the KLF. A full page advert announced the fact in the press (and was largely considered to be a clever marketing ploy to promote the forthcoming The Black Room.) They left the country, spending time in Mexico. Still this wasn't enough, so they took an even more drastic step. They deleted all their records.

Being completely independent, they were one of the few acts to be in a position to do this. True, they couldn't do anything about the records that had already been sold, and they were unable to delete their catalogue in non-UK territories where they had licensed their work. But in the UK at least, there would be no KLF records in shops, no special edition re-issues, no songs licensed to compilation albums, adverts or videogames. This act, in many ways, was far more brutal than the later money burning. In pure financial terms, it has been roughly estimated that this would have cost them something like five million pounds in future earnings.

They were removing their body of work, the result of extraordinary risks and effort, from the public sphere. This was a cost that went far beyond the financial. Yet they thought it necessary, for what they wanted to get back was far more valuable.

The K Foundation, as Drummond and Cauty called themselves after they stopped being The KLF, burned their money in August 1994. The period of the early 1990s is far more potent and significant than it is usually given credit for. In order to understand what this means it is necessary to consider what was so strange about that period, and why an act like theirs needed to have happened at such a time.

Our mental landscape was very different a century or so earlier. Victorian England had been, on the surface at least, a bastion of certainty. The Victorians had three unshakable beacons with which they could orientate themselves and their society by, the pillars of Church, Empire, and Crown. This, of course, was not to last. The botanist Charles Darwin had a developed a scientific model that was ingenious and ground breaking, but which had implications. Perhaps wisely, he kept it hidden away in a drawer for twenty years. But in 1859 he published.

The Victorians had believed that they understood how things were, and where they themselves belonged in the natural order of things. But Darwin's work, in combination with breakthroughs made in the field of geology regarding the age of the planet, caused one of the unshakable pillars of Victorian certainty to crack. The teaching of the church about the origins of the life on this planet had been shown to be wrong. This was a severe failing for an organisation which exists to proclaim an infallible understanding of truth.

The Church didn't react to the new understanding well. In 1870, eleven years after Darwin published On The Origin Of The Species, the Vatican formalised the doctrine of papal infallibility. This dogma asserted that the action of the Holy Spirit can remove even the possibility of error from the Pope. The Pope was right, in other words, because he was the Pope, who was right. This was clearly a form of circular logic, another of Robert Anton Wilson’s self-referential reality tunnels, and once that had been recognised the Darwinists found themselves outside of the Church's logic. They could no longer submerge themselves inside the church and unquestioningly accept what it had to say. Calls for the need to have "Faith" could no longer be met with reverent acceptance. Indeed, they were increasingly met with knowing smirks. Nietzsche was one who was brave enough to publicly articulate this change in the world. "God is dead", he wrote, "and we have killed him".

This change in understanding may have been unsettling, but it was just a warm up for the goodies that the twentieth century had in store. New ideas came thick and fast from the likes of Einstein, Planck, Freud, Picasso and Joyce. Every breakthrough seemed to be pulling in the same direction, that of undermining certainty. Things were no longer anywhere near as simple as they had been. Our most fundamental bedrocks - time, space, matter, the rational mind - were discovered to be nothing like as dependable they appeared. We were steaming ahead into uncharted territory.

The First World War erupted, and shattered any notion that there was glory in Empire. As Church and Crown eroded in our mental orientation, the need for an unarguable authority gave momentum to politicians, who quickly offered up the state as a candidate. They differed in the details, or course – the fascists thought the population should serve the state while the communists thought that the state was the servant of the people – but the methods used to enforce the centralisation of power were essentially the same. These ideas played themselves out to their horrendous conclusions during the Second World War. The notion that the state should be the central authority in our lives has never seemed credible since.

As the decades rolled on the search for an unarguable touchstone to replace Church, Crown or Empire in our lives took on an ever more urgent air. For populations still traumatised by the wars of the 1940s, enforcing social conformity in the 1950s made a lot of sense, yet this was stifling for the generation coming of age after the war. In the 1960s they sought liberation, but the philosophies that made so much sense on a personal level did not scale up well to the level of society. In the 1970s the attention shifted to the self, but the hedonistic self-indulgence grew to such unbearable levels that Punk was needed to tear it down. In the 1980s they believed that money and the pursuit of material possessions was the answer. Wealth was pursued, but it did not have the power to properly satisfy us, and that too was soon discarded as a candidate for our unassailable personal omphalos.

So what next? By then we had reached 1990. By this time all options had been tried and found wanting. We could return to the Church, the state, politics, material greed, personal liberation or hedonism if we wished, but we could no longer see them without being aware of their faults. They were damaged goods, still significant but no longer permanent and secure. But what other options did we have? Did we have any? It appeared not. We were out of ideas.

And so there arose a global, existential gasp of generational fear. There was nothing to believe in. This awful period was brief, and we can date it quite precisely. It arrived in mainstream culture in 1991, fully formed and simultaneously emanating from many different art forms. Douglas Coupland's debut novel Generation X was published in March that year, and the generation it described suddenly found themselves with a name. Another label arrived in July, when Richard Linklater's no-budget indie movie Slacker arrived in cinemas. The comedian Bill Hicks’ career suddenly started taking off in the UK, and the generation found their philosopher. Then in September, their anthem arrived. Nirvana released the single Smells Like Teen Spirit, and the story of alternative music was changed forever.

Slackers were not well dressed, because there was no reason to dress smartly. Their uniform was old jeans, Converse trainers and warm, practical lumberjack shirts. They were not career minded, for there was no reason to pursue the corporate dream. They were seen largely as apathetic, but it was an apathy born of a logical assessment of the options, rather than just innate laziness. They were often well educated and creative, and are usually portrayed as being talkative and self-obsessed. If they had a mission, of sorts, it was to work out how to move forward from where they were.

With the Berlin Wall down and Thatcher and Reagan out of office, there was a clear sense that the old order had finished. Modern historians also draw a line at this point. The historian Eric Hobsbawn has coined the phrase 'the short twentieth century' to cover the period 1914 to 1991, from the start of the First World War to the end of the Cold War. This is a useful timeframe for a historian because it works as a complete narrative.

The question that needed to be answered was, 'what next?' Looking to the past didn't help; it didn't have any answers and it was all out of ideas. The past shrugged as if to say, 'Good luck. You're on your own.'

At first, Generation X was linked to a sense of relief and a feeling that they had overcome the blind spots of the past and were now facing up to things with a refreshing honesty. But as '91 rolled into '92 and '93, this honesty became less invigorating and increasingly unbearable. It started to become apparent that they were not going to find a focus for their narrative, or a way to repair the damage to their mental landscape. The sense of mounting horror came closer and closer to the surface. The nihilism reached its peak in 1994, the period of Kurt Cobain's suicide, the burning of the million pounds, and the year Bill Hicks died. This was the point when the constant creation of new musical genres, as noted earlier, came to an end. That era was over. By this point there was a desperate need for a way out. Any way out.

By the end of 1994 the gears that cycle the eras could be heard to shift. Tony Blair and Gordon Brown had taken control of the Labour party and launched their New Labour Project. John Major wrote in his memoirs that his victory in the 1992 UK election "killed socialism in Britain." Margaret Thatcher was of a similar opinion, as was, it seems, Tony Blair, whose first concern upon gaining leadership of the Labour Party was to remove the socialist 'clause IV' from the party's constitution. After Blair, politics would not be led by ideology, but by opinion polls. This was his 'third way,' a political discourse dominated by spin, where it was not what you did that was important, but how that played in the press.

In Europe, the Maastricht treaty paved the way for the modern European Union and, ultimately, the Euro. Over in America, George W. Bush entered political life in 1994 as Governor of Texas. Netscape released the first version of their Navigator software that year, the first popular web browser, and Microsoft followed with a high profile launch of their Windows 95 operating system the following year. The modern digital era began. The world of Google, Wikipedia and Facebook was starting. The old order was being ripped up. The Age of Networks was being born.

As the blogger Neuroskeptic notes, during the period from 1945 to 1990 new cults, religions and sects were springing up all over the place. This period gave us the likes of Scientology, the Hare Krishnas, Transcendental Meditation, the Moonies, Jesus Freaks, the Manson Family, Heaven's Gate, Jonestown, the Kabbalah Centre, the Nation of Islam, the New Age, Neopaganism and Wicca. Why, he asks, did that outpouring of new religious groups dry up so abruptly and decisively, with hardly any popularly known groups forming after the Waco siege of 1993? The question points to a deep change in our culture, and once again marks the early years of the 1990s as the end of an era. It was not just new musical genres, it seems that stopped appearing at that point in time.

If we can date the end of the previous era, what the historian Eric Hobsbawm called the 'Age of Extremes,' to the end of the Cold War in 1991, and we can date the start of the Information era to the first popular web browser in 1994, what should we make of those years in between? They are boundary years, comparable to what anthropologists call a liminal state. They were a period when the old rules were gone, but before the new order was formed. They were a period, in other words, when normal certainties did not apply, when anything was possible and the strange was commonplace. As John C. Calhoun, the 7th Vice President of the United States once wrote, "The interval between the decay of the old and the formation and the establishment of the new, constitutes a period of transition which must always necessarily be one of uncertainty, confusion, error, and wild and fierce fanaticism."

Being innate storytellers, we neglect this brief, confusing period and prefer instead the clearer narratives that surround it. If you Google each year in the last quarter of the twentieth century, you'll find that each successive year has an increasing number of mentions online, as you would expect given the growth of the Internet during this period. The only exception to this upward trend is the period between 1991 and 1994, when the number of mentions declines. The age of John Major and George Bush Senior, it seems, does not attract our attention. Our cultural narrative skips from the Stock, Aitken and Waterman late-eighties to the Britpop and the Spice Girls mid-nineties quite happily. Even the Adrian Mole diaries skip these years. This boundary period is a cultural blind spot; we choose not to look at it.

But there is much that can be learnt from such a time, and great art can be found there. In The KLF's field of music, for example, this brief period brought albums such as Loveless by My Bloody Valentine, Primal Scream's Screamadelica, Nirvana's Nevermind, Automatic For The People by REM, Peggy Suicide by Julian Cope, U2's Achtung Baby and Oasis' Definitely Maybe - all records that are considered the career best, or thereabouts, for those musicians. Considering the long careers of many of those bands, the fact that their highest achievements all fall in that narrow period does suggest that there was something in the water at that time, so to speak.

In the moments that followed the withdrawal of one wave of history you can see, if you chose to look, a brief glimpse of the undercurrents at work in the late twentieth century. It did not last long, for the next grand narrative arrived and drowned out these subtle workings with energy and noise. And that next wave was noisy.

The escape route from the nihilism of the early 1990s was, in the end, mindless optimism. Things could only get better. Adopting this belief entailed not worrying about the details. And it was fun! This, then, became the 1990s that we choose to remember, a time of Cool Britannia, the Millennium Dome and the Dot Com bubble. Ego-fuelling cocaine became the drug of choice, BritPop and the Spice Girls were on hand to entertain us, and the modern digital world created itself anew. Times were exciting again. We could not help but be swept along with that tide, and we found that it supported us to the extent that we no longer felt the need to worry about our foundations.

How does this liminal period compare to the change of eras that preceded it? Hobsbawn pinpointed the beginning of that era, the 'short twentieth century' of 1914 -1991, as the beginning of the First World War. This was when the age of empires collapsed upon itself and the political realities of the twentieth century began. It coincides roughly to what the writer Susan Cain calls a shift from a culture of character to a culture of personality.

This era's birth couldn't have been more different from its death in the 1990s when, having exhausted itself, it quietly lay down and died. The period of the First World War was a brutal, violent explosion, when the collapse of the Victorian narrative engulfed the whole world in sheer bloody horror. Everything - from our social structures to our relationship with technology and the nature of the human condition - was shredded before the unstoppable firestorm. Nothing survived. A time of mud, gas, and unimagined mechanised slaughter, it is no exaggeration to call this what it was: the darkest point in human history. True, the death toll was higher in the Second World War, but that war had been psychologically prepared for and made sense in the context of the time. No-one was in any way prepared for the actuality of World War One, and there is no horror greater than the arrival of the unthinkable.

This was the period that spawned the Cabaret Voltaire. As has already been noted, the six members of this group share with Cauty and Drummond a sense of being haunted by what they did and an inability to explain or come to terms with their actions. This makes a strange sort of sense when we view this period as the liminal gap between eras. There was no narrative context at that point to explain their actions, because the preceding narrative had ended and the new one had not begun. If Cauty and Drummond had burnt their money earlier in the twentieth century, it would have been seen as a surrealist act, or perhaps a Situationist one. If they had done it ten years later it would have been understood in terms of the global anti-capitalist movement. But nothing is really explainable in liminal periods, as anyone who has attempted to understand the First World War using the Victorian worldview will have discovered. How can you explain an act, except as part of an ongoing narrative?

The movement that the Cabaret Voltaire created is known as 'Dada' - a meaningless, idiotic word which showed their contempt for art itself. Art, as they saw it, was the product of the society which gave birth to it. It was the finest aspect of that society, its highest expression, and by the nature of its transcendent qualities it could glorify and even justify that society. What, though, when that society was rotten to the core? What if you lived in a world so misguided, flawed and terrible that it could create the unthinkable slaughter of the Somme? Any art it produced would have to be treated with contempt. Any beautiful expression that could in some way redeem the society that formed it would be unacceptable. It had to go, all of it. The sensual Art Nouveau style that had so defined the preceding decades collapsed almost overnight.

Dada was anti-art. It was negation, a creation that saw itself as destruction. Its very nature makes it seem impossible to define or pin down, but its echoes can be heard throughout the twentieth century in movements such as Situationism, Discordianism and Punk. The word itself oscillates between being a verb and a noun, between having meaning and no meaning, between being an established movement of many years standing to being a spent force the moment the Cabaret closed. It cloaks itself in gnomic pronouncements that make it appear more of a disembodied conscious presence more than an art style. "Before there was Dada, Dada was there..." the artist Hans Arp has said. This is usually about as clear as it gets.

The more you look at the Dadaists’ attempts to define Dada, however, the more you are reminded of Daoists attempts to define the concept of the Dao. The Dao is the central concept in ancient Chinese thought, usually translated as the 'way' or the 'path.' It also oscillates between being a verb and a noun, between having meaning and having no meaning. The Dao de Jing, the Daoist central text, begins by declaring that the Dao that can be named is not the Dao. As first lines go, this can throw the reader a little. What it means by this is that the Dao is everything and, because a name or definition is a small part of everything, that name therefore cannot be the thing itself. The all cannot be accurately defined, as any definition is limiting. Dao is, by definition, beyond definition, beyond 'is' and 'is not.'

When Arp said that "Before there was Dada, Dada was there," he echoed the Dao De Jing which says that the Dao is all heaven and earth, and that the Dao existed before heaven and earth. In light of these comparisons, the Dadaists attempts to describe Dada appear as if they are describing something fundamentally similar to the Dao. This may initially appear counter-intuitive, of course, because the Dao is associated with peaceful acceptance whereas Dada is violent negation. But Dada emerged during the First World War. The Dao, at that point, would also have been violent negation.

One point that many commentators make about Dada is that, whilst its intention is to destroy or negate, it is still the product of the very thing that it is fighting against. It is a creation of the society that it rejects, and can only exist alongside that society. In the words of the writer Greil Marcus, "Dada was a protest against its time; it was also the bird on the rhinoceros, peeping and chirping, but along for the ride." Marcus also discusses the philosopher Henri Lefebvre, "...an old man, whose life's work had been the investigation of 'modernity,' he said so queerly that what was truly modern about modernity, what was actually new, what was really interesting, was not its works - technology, abundance, the welfare state, mass communication, and so on - but the peculiar character of the opposition modernity created against itself: an opposition he still called 'Dada.'"

A Daoist would be amused by Lefebvre's observation, for a thing to carry its own opposition is anything but modern. This is one of their most fundamental principles and it is depicted in the best known Daoist symbol, the Yin/Yang. This icon shows a circle, half white and half black and seemingly rotating as if the black and white elements where continually replacing each other. This constant flow between opposites is, in Daoist thought, the fundamental nature of the world. In the centre of the black there is a white dot, and in the centre of the white there is a black dot. This symbolises that each state carries the seed of its opposite - that the Yin always contains the birth of the Yang that replaces it, and vice versa, just as Robert Anton Wilson's Illuminati carried the seed of the Discordians and the music industry gave birth to the Justified Ancients of Mu Mu. Mathematicians also recognised this truth, once they gained a grasp on the nature of chaos. Whenever they looked inside chaos, they found order, and wherever they looked closely at order they found it to be riddled with chaos.

Dada can be thought of as a form of Dark Dao, a path that was as sick and feverish as the era that formed it. Dao is an ungraspable concept that contains both the very nature of the world and also the way the world will unfurl. In this context it is no wonder that Dadaists could not define what they had done, as Dao both contains and is more than any single definition. In this liminal period, in this time between eras as the old ways destroyed themselves and before the new order emerged there was only this fundamental nature of the world remaining, an unnameable Dao that could only be implied by the meaningless noise 'dada'.

The subsequent liminal period of the early 1990s was a mirror opposite, a small quiet death that has almost disappeared from history. It was here that the K Foundation, with their meaningless name, performed the act that they could never explain or get over. How different, then, was the fundamental nature of their act of destruction? How close to the underlying nature of the world were they working? The undercurrents that were so briefly visible in the breath between two eras were still exposed. And because the money was burnt in this liminal period between two waves of history, the meaning of the act was not absorbed or dissipated by either of them. The timing, in other words, was perfect. The subconscious was fully exposed when the deed was done.

“Abandon all art now,' proclaimed the adverts in the broadsheet press, 'Major rethink in progress. Await further announcements.” It was August 1993, over a year since the end of the KLF. The adverts were placed by Drummond and Cauty's latest alias, The K Foundation. After they stopped making music, Drummond and Cauty formed an art foundation.

This in itself is unusual. There is no precedent for musicians working together in a non-music related capacity after their band has split up. At best, you can point to members of bands who have later married. Cauty and Drummond's continued working relationship may even be unique in musical history. It suggests that their work was not actually about music, and that the music was a means to an end rather than the ultimate goal of their partnership. Even when the music stopped, the work continued.

In general, the art world took a dim view of The K Foundation. Their activities began shortly after The KLF split, when a series of adverts were placed in the press complete with Illuminatus!-style pyramid symbols and cryptic slogans such as 'Time Is Running In' or 'Divide and Kreate.' They were initially concerned with the nature of time, and promised a move away from our current understanding of time into a more 'eternal' state. These adverts were frequently described as being Situationist inspired, but The K Foundation were not détourning existing advertisements. They were paying many thousands of pounds to create new advertisements. They may not have been advertising anything, other than themselves, but it was a noticeably different approach than the one the Situationists took.

The 'Abandon All Art Now' advert of August 1993 was the first that concerned itself with the subject of art rather than time. It was followed two weeks later by another, which read, "It has come to our attention that you did not abandon all art now. Further direct action is thus necessary." They went on to announce a short-list of four artists for their 'worst artist of the year prize,' whose work would be exhibited at the Tate. As that short-list was the same as that year's Turner prize, which was the reason for their work appearing at the Tate, this was first assumed to be nothing more than a joke.

It soon became apparent, however, that this was not the end of it. The K Foundation prize was £40,000, exactly twice that awarded by the Turner Prize. On the day of the Turner award, 23rd November, they bought TV advertisements around the broadcast of the ceremony on Channel 4. They announced that their 'winner' was the artist Rachael Whiteread, seemingly before it was announced that Whiteread had also won the Turner Prize. Their forty grand prize was nailed to a board and chained to the railings outside the Tate. Whiteread refused to come and collect it, and was informed that if she didn't claim it by 11pm, it would be burnt.

11pm arrived and Whiteread still didn't show. The money was doused in petrol. Gimpo fumbled with the matches. It was just about to be torched when Whiteread appeared, deeply irritated, and said that she would donate the money to young artists.

If she had been delayed, then Drummond and Cauty's futures could have been very different. The burning money on the steps of the Tate would have had a far greater impact on the art world than anything else the pair had planned, and the later burning of the million pounds would probably never have happened. As it was, their actions produced a lot of comment and discussion, but also a deeper sense of annoyance and dismissal.

The art world assumed an air of polite remove from the activities of the K Foundation from then on in, and it soon became apparent that no suitable gallery was going to host their inaugural exhibition. This was called Money: A Major Body of Cash, and largely consisted of what money the pair still had from The KLF years nailed to things. The key piece was called Nailed To The Wall, and consisted of a million pounds in fifty pound notes nailed to a board. The reserve price for this was going to be half a million pounds. The purchaser could therefore double their money by simply taking it apart. If they hung it on the wall, however, the value of the notes would decrease over time, but the value of the art might well increase. The exhibition, then, raised many thorny issues about the relationship between art and money. Or at least it would have done, if a gallery had been found to put it on.

The art world is a very different place to the music industry. It is considerably less sure of itself. The music industry knows that the power of a perfect song is universal and that there is no way to deny this. This is why, as previously noted, it can absorb any attack. The art world is on far shakier ground. To generalise, the products of the art world can be very easy to deny. The importance of the strange magical glamours of context and reputation are paramount, for it is only with context and reputation that careers are built. The attack on the Turner Prize came dangerously close to damaging these vital spells, so the art world had no choice but to close ranks and keep them out.

A crucial tool in this respect is the art world's ability to declare who is or is not an artist. In their view, the K Foundation were not artists. As a gallery owner put it in the BBC documentary about the burning, "I just don't think you can want to be an artist, you're either an artist or you're not an artist." The remains of the burnt money, in this context "would have been art - if they had been made by an artist." To be accepted as an artist, it is usual to be young, dedicated and fresh from a good art school. It is not acceptable to have done a different job and become an artist later in life. Of course, galleries can usually be found to put on exhibitions by 'dabbling' musicians, but the art world sees these much the same way as the music world sees novelty singles. They're not what it's about, basically, and while they can be a bit of fun and can bring in useful foot traffic to a gallery, they are not worth risking context or reputation over.

Lacking a gallery or art world acceptance, The K Foundation did what they could. They exhibited the work to the press in a field near Heston Service Station, while armoured cars painted orange drove around blasting out ABBA's 'Money, Money, Money.' But lacking a gallery called for a rethink, and that rethink led to the decision to simply take the million pounds and burn it.

That was how this was always going to end, wasn't it? From the first KLF record Burn The Bastards onwards, it was always going to end with flames.

There was some thought about staging this burning at a gallery but that was quickly dismissed. If it was done at a gallery, people would look at it as art. It may be bad art or good art, but it would definitely be art. And that felt wrong, somehow, even to an art foundation. That wasn't what this was about.

Was it Art? That was the key question on the adverts to promote screenings of Watch The K Foundation Burn A Million Quid. The K Foundation was, after all, an art foundation. Cauty and Drummond may not have been actively working in the art world after the KLF, but they were certainly hectoring and bothering it from the sidelines. Even for those who felt that what they did didn't cut it as art, it still appeared that they were trying to make art.

Of course, the question of 'was it art?' is complicated by the general lack of agreement about what 'art' actually is.

It is interesting to remember what Charles Shaar Murray wrote, when he reviewed Drummond's book 45 for The Independent. "Drummond is many things, and one of those things is a magician. Many of his schemes [...] involve symbolically-weighted acts conducted away from the public gaze and documented only by Drummond himself and his participating comrades. Nevertheless, they are intended to have an effect on a worldful of people unaware that the act in question has taken place. That is magical thinking. Art is magic, and so is pop. Bill Drummond is a cultural magician..."

'Art is magic...' This is also a quote from Illuminatus!, as those are words used by a Discordian called Mavis in the first volume of the book. It is Alan Moore's view as well. He does not mean this as a vague generalisation or a touchy-feely feel-good slogan. He means it literally. Magic is not a science and it is not a religion, despite the efforts of people to define it as such. Magic is art - or the Art, if you prefer. Writing a book or painting a picture is like pulling a rabbit out of a hat - you are producing something out of nothing. A thing now exists in the world that was not there before.

Viewed in this context, the history of magic suddenly starts to make a lot more sense. A grimoire was a grammar. A spell is to spell. In the beginning was the Word. The trappings of magic can be equally read as the trappings of creation. Song, dance, performance, recitals, music and pantomime can all be seen to have their roots in the magical practices of tribal shamen. Opera itself was the creation of alchemical thinking, an art form that included all other art forms within it.

After all, what was magic for, exactly? It doesn't produce any useful scientific discoveries. For all its talk of great power, those who dedicate their lives to it have a notable tendency to end up alone and in dire poverty. On the other hand, there is an abundance of great art that has been produced by those with magical interests, be they Mozart, W.B. Yeats, William Blake, Dali, Elgar, Mondrian and so on.

As everyone from magicians like Moore to the most rational scientist will tell you, magic is only in the mind. But this, of course, is also the realm of art - it's the role of art to explore and illuminate and express this very territory. In Moore's view, re-establishing and clarifying the association between art and magic would be beneficial in two main aspects. Firstly, it would give the practice of magic a purpose. And secondly, it would give the art world a shot in the arm and produce art of greater wonder and illumination than the half-arsed fumblings it has been content with of late.

The question “Is it art?”, then, should more meaningfully be looked as “Is it magic?” And in this respect, Moore was very clear. The answer was ‘yes’. The money burning "was a powerful magical event," he said. "I can't see any other explanation for it. You're dealing with a form of language, a conversation – but you're not sure what the conversation is... you're waiting for a reply."

The negation of the money, in this context, can be seen as a sacrifice. A sacrifice is a statement of intent. It serves to focus the mind and the more valuable the object sacrificed is, the greater the focus. You are offering up something of worth in the hope of receiving or achieving something different.

Of all the unsettling questions you can wrestle with, the question of what modern money actually is is a real humdinger. Of course, we know that money is a token of value that can be used as a medium of exchange. That tells us what money does, but not what it is.

Modern money is no longer a representation of some physical value such as an amount of gold or silver. Some of it has a physical form, such as pieces of paper or small round pieces of metal, but the vast majority does not. Most of the money supply is virtual, existing only as a pattern of bits inside a computer. Our money system is known as 'fiat money,' which means that it is created out of thin air. But if money is created out of nothing, then how can it have value?

To answer that, it is more useful to look at Alan Moore's definition of magic than  to study economic textbooks. Money is a perfect example of something that doesn't exist, but acts like it does. Money has value only because we say it has. This is an agreed illusion shared by people and governments alike, and surrounded by institutions and laws in the same way that theology surrounds a central idea in one of Robert Anton Wilson's self-justifying reality tunnels. It is an extremely practical belief, which is why it endures. Believing in the value of money is necessary for almost all our modern society and culture. Nevertheless, there isn't anything underpinning the value of our money system other than the fact that the other guy believes it too.

Money is also designed to move. It does not matter to what ends the movement of money is used, for there is no inherent morality to the system. The only important factor is that the money keeps sloshing around, being used and reused. From the point of view of the money system there is only one perversion, which is to permanently remove money from circulation.

The reason for this goes to the very core of the financial system, and the practice of charging interest. Today, all money is loaned into existence. A central bank will only physically create money, in other words, if some individual or organisation has asked to borrow it. The bank will then loan the money, and charge a small percentage – the interest rate – for its efforts.

This system is so widely accepted that it sounds perfectly normal. It does, however, raise the question of where the money to pay the interest charge comes from.

This is best illustrated with an example. Imagine that a new bank opens in a new country, and imagine that it produces a currency that we will call shillings. Now imagine that this bank then attracts ten customers, all of whom wish to borrow ten shillings. The bank charges interest at 10%, so that everyone has to return 11 shillings to the bank. But how can these ten people all return 11 shillings when they not only don't have that amount, but there isn't even enough money in existence? The debtors will have to find a way to get the extra money from each other. Competition, therefore, suddenly becomes necessary. Should one debtor have all his money taken from him by the rest, then nine people will be able to return the 11 shillings to the bank, while the losing debtor will have no option but to borrow more money from the bank. More money is thus created, and the economy grows.

It was not always like this. For most of history such a system was utterly forbidden. The word 'usury' is now used to mean the charging of excessive interest for loans, but the original use of the word meant making any charge at all for lending money. Writing developed after money, so it is not possible to know how far back into history this taboo goes, or why our Bronze Age ancestors were so set against the idea. We do know, however, that the earliest recorded laws explicitly forbid usury. In the New Testament, when Jesus overturned the tables at the temple, his anger grew from the fact that the moneylenders were engaging in usury. Jesus, it is generally accepted, was a pretty non-violent type of guy, so when you note how all the other sins, cruelties and injustices of the world failed to tip him over into anger you get a glimpse at just how taboo usury was. Others in the ancient world who denounced usury include Plato, Moses, Muhammad, Aristotle and Buddha. When a line-up like that is in agreement, it is perhaps worth thinking twice about our acceptance of it.

Why was making money from financial loans so unacceptable in the Ancient World? This is open to interpretation, but one possibility is that it appeared to go against the natural order of things. Work created wealth, so wealth accumulating without work was unnatural. It was seen as a form of tyranny, or theft. Usury was a corruption, a financial cancer, and one that could draw economies out of balance and bring them crashing down.

But if usury, in the original meaning of the word, was so taboo, how did it become acceptable and establish itself as a cornerstone of modern economics? Much of the answer to this question involves the behaviour of different religions. Usury is still forbidden under Islamic law so a complicated system of Islamic banking was developed which does not include interest, but instead has many charges. It doing so it manages to remain true to the letter of the anti-usury law, if perhaps not the spirit. In Judaism, they took the approach that usury was only forbidden between Jews, so charging interest on loans to non-Jews was religiously acceptable. Jews were then able to travel to non-Jewish communities and act as money lenders, a trade that brought them wealth but also a great deal of historical resentment. In Christianity, usury was banned by Papal decree, but when Henry VIII split with Rome and established the Church of England in 1534 he took a different view. Henry made usury religiously accepted, a move which some economists view as key to the Elizabethan Golden Age that followed.

Technically speaking the charging of interest on loans is still forbidden in the Catholic world, but in practice no-one pays a blind bit of notice to this.

In The Eye In The Pyramid, the first volume of the Illuminatus! trilogy, the character of Joseph Malick is told the history of the formation of The Justified Ancients of Mummu. The story stretches back to a time when series of stones called The Seven Tablets of Creation were carved, around 2500BC, at which time the chief deity was called Marduk and "the official religion of Marduk [...] was based on usury. The priests monopolized the land, and extracted tribute for renting it. It was the beginning of what we laughingly call civilisation, which has always rested on rent and interest."

It is at this point that the JAMs were formed. "When the first anarchist group arose, they called themselves Justified Ancients of Mummu. Like Lao-Tse and the Daoists in China, they wanted to get rid of usury and monopoly and all the other pigshit of civilization." Here, then, is the raison d'être of the JAMs. They are anarchists, representing the forces of chaos in the war against order. That order is civilisation and civilisation is based on usury, or the system of interest on loans. The Justified Ancients of Mummu, then, were formed to destroy usury.

This is not something that has been widely noted. Should you talk to even the most obsessive KLF fan, one who has gone to the lengths of reading Robert Anton Wilson's 800+ page novel a number of times, they will probably be unaware that the destruction of usury is the reason that The Justified Ancients of Mummu were established. It is stated clearly, as the quotes above show, but the book is such a torrent of information that, unless you are looking for it, a detail like that is unlikely to stick in your mind. Nevertheless the fact remains that the fictitious organisation The Justified Ancients of Mummu, who became a physical group when Drummond and Cauty took on their name and philosophy, exist to bring about the destruction of the usury that is at the heart of our system of money.

Interest is not a fundamental quality of economies. It is an idea that has been projected onto the work and wealth of the physical world. The reason our economic system incorporates concepts such as interest and usury is nothing more than historical choice. There have been eras when negative interest economies have been tried instead, for example. In these systems, your money depreciated over time, slowly losing value. This concept is similar to the practicalities of keeping a store of grain stockpiled over winter because, thanks to the action of mice and other pests, the amount of grain you had come spring would be less than you started with. Negative interest currencies have the advantage of encouraging the use of money. Instead of hoarding it, it makes more sense to use it in a productive way, such as repairing buildings or starting businesses. Under this model the currency circulates more readily and freely, and saving is discouraged.

The reason why a positive-interest currency has been favoured is because it encourages economic growth. Indeed, it demands it, for the system would collapse if there was no growth to pay the interest charges to the bank. Bankers are very keen on economic growth because, without having to do anything else, it automatically translates into more wealth for them. For this reason, a steady-state economy is unacceptable. It may seem reasonable for a tradesman to wish to perform a regular amount of work each year, enough to pay them sufficient money to live on, but our system cannot work like that. The existence of interest charges - usury, by the original definition - requires that economy must continually grow, which means that more work must be undertaken, year in, year out.

The belief that endless growth is natural, inevitable and possible has become universally accepted. It has done so by building around itself one of Wilson's self-referential reality tunnels to protect it. But there is a problem here, and it's a significant one. Perpetual growth is not possible, regardless of what economists say.

This issue is often couched in environmental terms, such as the statement that perpetual growth is not possible in a finite world of non-renewable resources. This argument was made strongly as far back as 1972 by The Limits Of Growth, a book produced by the Club of Rome. The Limits Of Growth has been roundly attacked over the years by politicians and economists inside the 'perpetual growth' reality tunnel, usually with arguments about the inexhaustible supply of human ingenuity and so forth.

In fact, the basic point does not even need the environmental focus. Growth is exponential, so even small rates such as 2% or 3% a year cause doubling in a generation and soon become absurd. The physicist Tom Murphy has calculated that projected rates of energy growth, for example, have the Earth using the same amount of energy as the Sun in about 1400 years, and more than the entire galaxy of 100 billion suns in 2500 years. In human terms, 2500 years isn't that long. We are still reading books that were written 2500 years ago.

This, of course, is not going to happen.

For a more fundamental example of why this is, consider a particle being accelerated through space. As we know from Einstein, energy and matter are intimately linked. As the particle gains energy to move faster, its mass increases. This increase in mass means that it requires more energy to keep accelerating, which further increases its mass and further increases the amount of energy needed for it to accelerate, and so on. It is for this reason that the speed of light is fixed and finite. Photons can't accelerate indefinitely.

Put more simply, the increase in a quantity affects the forces that were causing that increase. This simple law seems to affect everything. This is the main reason why economies can't grow indefinitely, any more than photons can go faster than the speed of light.

In the late twentieth century, however, an argument like that was heresy. Global economic collapse was unthinkable. The global economy was believed to be solid, healthy and self-repairing. A magical 'invisible hand' protected the markets and ensured that they would forever continue to function. With one eye on the short term and the other on the self-referential reality tunnel that claims perpetual growth is both possible and normal, economists and politicians could see no flaws in their economic model. This was apparent in the somewhat stunned testimony of Alan Greenspan, the former chair of the Federal Reserve, when he appeared before a U.S. House of Representatives committee to be questioned about the great economic collapse of the early 21st century. “I made a mistake in presuming that the self-interests of organizations, specifically banks and others, were such as that they were best capable of protecting their own shareholders and their equity in the firms,” he said. When the chair of the committee, Henry Waxman, suggested to Greenspan that “you found that your view of the world, your ideology, was not right, it was not working?” he replied, “Absolutely, precisely. You know, that's precisely the reason I was shocked, because I have been going for 40 years or more with very considerable evidence that it was working exceptionally well.”

The absurdity of perpetual growth, however, was unaffected by our leaders' inability to consider or discuss it. It lurked hidden, somewhere in the depths of the collective unconscious or the unexplored wild spaces of Alan Moore's Ideaspace. Eventually, some unwary explorer would stumble too close, and actualise it.

Years after the K Foundation had ended, Drummond had a flash of insight. "Most of the people who wrote about what we did, and the TV programme that was made about it, made a mistake," he said. "I was only able to articulate it to myself afterwards with hindsight. They thought we were using our money to make a statement about art, and really what we were doing was using our art to make a statement about money."

This tallies with comments made by Cauty at the time. "We nail [the money] to a bit of wood so that it can't function as it wants to. It's to do with controlling the money. Money tends to control you if you've got it, it dictates what you do have to do with it, you either spend it, give it away, invest it... We just wanted to be in control of it."

The K Foundation had been set up to dispose of the money that remained from the KLF days. Drummond and Cauty behaved as if this money was tainted in some way, and that it had to be disposed of in a safe, artistically pure way. The aim of the K Foundation, then, was to cleanse it. In doing so, we can surmise, they might recover their souls which they lost in the music industry.

Cauty and Drummond initially described the K Foundation as an 'art foundation,' which led to their actions being viewed from the perspective of the art world. With hindsight, it is easy to see how they fell into this position. With The KLF over, they knew they still had work to do together but they did not have a framework to define what that work was. It was not music, that was clear, for those days were behind them. But if not music, then what? There is no established tradition of tainted money cleansing and dispersal foundations. 'Art', meanwhile, was a vague enough term with which to hide all sorts of strange behaviour. What else could they call themselves, then, but an art foundation?

And how else could they do it? They couldn't give it away or spend it, because that's what money wants. It wants to circulate. That's what gives it power. Even if you nail it to a piece of wood, someone will come along sooner or later to steal it and set it free. Physically destroying it is the only way to stop it. Before it can be stopped there first needs to be the idea that it that it can be stopped, and that it is not invincible. Up until then, this was largely unthinkable.

The burning of the million quid should not be seen from the perspective of art. It was never about art. It was much more than that, and much more obvious. It was about the destruction of money.

It was about the idea that money could be defeated.

Discordians have something of an obsession with the number twenty three.

Robert Anton Wilson first heard about the strangeness of the number from William Burroughs. Burroughs met a sea captain called Captain Clark in Algiers in 1960, who boasted to him that he had never had an accident in 23 years. Later that day Clark's boat sank, killing him and everyone on board. Burroughs was thinking about this and reflecting on the nature of fate when he heard a radio report about a plane crash in Florida. The plane's pilot was called Captain Clark and the plane was flight 23.

Burroughs began noting down incidents of the number 23, and soon Wilson was doing the same. It seemed that wherever there was a significant incident, frequently linked to birth or death, the number 23 would appear. Babies get 23 chromosomes from each parent, for example. In the I-Ching, 23 means 'breaking apart'. The most common psalm at funerals is psalm 23. An unnatural number of anarchists seemed to have died on the 23rd. There was nothing too unusual about any individual occurrence of the number, but the way they kept turning up was unsettling. There was a certain unnerving quality about the places they tended to appear. Wilson filled the Illuminatus! books with the 23 Enigma, as it became known. It fitted in well with a Discordian principle called the Law of Fives, because 2+3=5. The Law of Fives states that everything is related to the number five, assuming that you look hard enough.

As an example of how the 23s mount up, and deliberately limiting ourselves only to things discussed in this book, we can make a list like the following:

Bill Drummond was 23 when he worked on the Illuminatus! play, which had 23 cast members. Jung's dream about Liverpool that inspired O’Hallighan and Campbell was on page 223 of Carl Jung's Dreams, Memories and Reflections (Jung, of course, was the man who coined the word 'synchronicity.') Robert Anton Wilson's oldest daughters were born on 23rd August and the 23rd of February, and he first started hearing voices in his head on 23rd July. Drummond and Cauty burnt the million pounds on August 23rd 1994 (1+9+9+4 = 23). Doctorin' The Tardis was released on 23rd May, the car had 23 painted on its roof and the Turner Prize incident occurred on November 23rd. November 23rd was also a Discordian Holy Day (being Harpo Marx's birthday), the date when Ken Campbell's Illuminatus! was first performed, the date this book was published and, in 1963, the date that Doctor Who was first broadcast. That first episode of Doctor Who was 23 minutes long, and it would be the disastrous 23rd series of Doctor Who that resulted in Ken Campbell and his protégé Sylvester McCoy auditioning for the role.

There were 23 years between Stand By Your Man and Justified And Ancient (Stand By The JAMs). The 'Devil Horns' hand symbol has 2 digits up and three clenched, while 2 divided by 3 is 0.666 recurring. The catalogue number of Drummond and Cauty's first record was JAMS23, and their rare live performances usually lasted for 23 minutes. The final KLF Communications info sheet was number 23. The video for It’s Grim Up North was filmed on the M23. The agreement that Drummond and Cauty signed on the Nissan Bluebird was to not discuss the burning for 23 years. The name 'Justified Ancients of Mu Mu' (accidentally misspelled by Cauty and Drummond from Wilson's 'Mummu') has 23 letters.

And so on.

All this, of course, is magical thinking. There is no physical link between any of the dates or incidents mentioned. The link is mental. A recognition that the number is somehow significant leads to a connection between unrelated occurrences of the number.

Magical thinking is also the level which Drummond works on. This has been clear from the very start, with his preoccupation with the rabbit spirit of Echo. Magical thinking is a universal practise – it is, essentially, how our brains work – but it is usually tempered with a practical materialism. What makes Drummond remarkable is that it seems to be his over-riding working level, something he achieves by applying his 'liberation loophole' and accepting the contradictions. The actions of The KLF can only really be understood as magical thinking being manifest by punk bloody-mindedness.

If you look at the 23s associated with Drummond and Cauty, they fall into two distinct types. The first are 'genuine' occurrences, where the number spontaneously manifests itself in unexpected ways. Examples of this would include the Turner Prize being announced on November 23rd, Drummond being 23 when he first read Illuminatus!, or the 23 you’ll inevitably notice shortly after putting this book down. The second category is 'forced' occurrences. These are a deliberate use of the number by someone who is aware of the 23 Enigma and feels drawn to somehow further it. Examples of these are the 23 painted on the roof of the cop car, or using it in a catalogue number. There is nothing mysterious or supernatural about these occurrences. What they do reveal, however, is a desire for synchronicities and magical occurrences. They are a form of sympathetic magic, which acts out the synchronicity on a ritual level in the hope it will conjure up the actual thing.

Drummond and Cauty did this. They did this a lot. They hammered away at it, trying to generate a response. Alan Moore said that the money burning was, "a form of language, a conversation – but you're not sure what the conversation is... you're waiting for a reply," and this was no different from what they had done in The KLF. They were kicking off on a magical level. They were demanding attention. From a magical perspective they were a pair of attention seeking arseholes, demanding to get fucked.

The 23 Enigma is the best known aspect of Discordianism, and Cauty and Drummond used it very deliberately. As should be clear by now, the myth they wrapped around themselves was taken very blatantly from the Illuminatus! books. Taking the name The Justified Ancients of Mu Mu is the most obvious example of this, but there are many more. Their first album included a song called The Porpoise Song, after Howard the Porpoise in the books. The use of lines such as “Kick out the jams motherfuckers,” “immanentized the Eschaton” and “everybody lie down on the floor and keep calm” are all taken from the book.

But how well did they know Wilson's work? In his 2008 book 17, Drummond writes about being asked to appear at an event at the South Bank Centre in London to commemorate the death of Robert Anton Wilson the previous year. Drummond agreed after hearing that Alan Moore would also be appearing, but he was unsure what he should do at the event. For inspiration, he decided to read Illuminatus!

He claims that he had never read the whole thing before. When Campbell gave him a copy to help him design sets, he read little more than the first volume because that was where most of the play was taken from. He was not particularly impressed by what he read. He was more impressed in 1986 when he picked it up again and it inspired him to form The JAMs with Jimmy Cauty, but even then he only read as far as page 138 in a trilogy of over 800 pages. Cauty, although he had seen the play, never read the book at all.

Reading the whole thing, in 2007, was something of a shock.

Because it was in there, all of it - rabbit spirits, Lucifer, submarines, the angels in the lake, even, to his horror, money burning. It seemed like his life had been mapped out in this one book. It went far beyond the obvious stuff he stole from the first volume. At the time he was involved in a choir called The17, for example, not realising that the number 17 kept appearing in the book at the same places as the number 23.

This was a similar situation to how he learnt about the Situationists, for he only really learnt what they were about, and why his actions kept being described as Situationist, in 1995.

Seeing his own history sketched out in the book was deeply unsettling.

Rationally, you can argue that he must have seen later sections back in 1976 and, while he had no conscious memory of them, they could have hung around in his subconscious somehow. Those familiar with the book, however, may wonder if there is more to it than that. I had written 90% of this book before I finally got round to reading Illuminatus! myself, despite having a copy on my shelf for twenty years. Upon reading it, I was startled to discover that it contained a number of subjects which I had already been writing about, unaware of their inclusion in Illuminatus! and unsure if I could justify their inclusion in this book. I had written about usury unaware that the founding reason for The JAMs was to destroy usury, and I had written about Lucifer unaware that a Satanic mass was the initiation into The JAMs. I had noted the surprising number of paedophiles in this story whilst unaware of the character of Padre Pederastia. Such is the way with this particular novel. Reading it almost seems superfluous; it is possible to be swept along just by the idea of it. It is a novel that is perfectly content to sit on a shelf for decades waiting for you to be ready for it.

When the K Foundation were burning their money, Alan Moore was at work in Northampton finishing his version of the Jack The Ripper myth, From Hell. Moore's Ripper, the insane royal surgeon Sir William Gull, viewed his Whitechapel Murders as a magical act. He, like Drummond and Cauty, had no sense of exactly what he was doing. It didn't matter to him. He was just aware of how powerful his actions were, and how deeply they would affect the world. Moore's Ripper, of course, is a fictional creation. While he may not have known the reasons for his actions, his creator had a very clear idea.

In From Hell, Moore claimed that the Ripper murders were a magical act that gave birth to the twentieth century itself - a century with all the horror and violence of the world wars, but also a century of fame and celebrity. And indeed in this Moore may have a point - the public fascination with the Ripper murders was such that it is frequently claimed to have started our current tabloid culture. It is plausible to view the Ripper murders as a microcosm of the century that followed.

There have been many serial killers since then. The killing of five poor women now would not now have the impact that it had then, in that it would not be remembered or talked about over a hundred years later. Back in 1888, it was an extraordinarily powerful and shocking event. It negated everything that was accepted about what Victorian culture was capable of creating. Now, it would be a depressingly familiar item on the news, forgotten in weeks. Our children calmly channel-hop past descriptions of events on the news that would make the people of earlier ages faint.

What, in the modern age, would be equally unthinkable? Not horrible or evil or sick, but unthinkable?

What, other than the negation of money?

Not manipulating the symbols of money, but actually negating money itself? Making money itself cease to exist is, if viewed as a sacrificial offering, an extraordinarily potent act.

We have a choice now. We can either look at these events rationally, or use magical thinking. If we look at these events using magical thinking, and in particular the style of magical thinking that we’ve borrowed from Alan Moore, then a narrative emerges. That story goes like this:

Once upon a time, in the late 1950s, Greg Hill and Kerry Thornley had a conversation in a Californian bowling alley. From that conversation, the idea of Eris, the Goddess of Chaos, arrived in the twentieth century.

The idea of Eris led to the creation of the religion of Discordianism, and to the mass disinformation campaign known as Operation Mindfuck.

The spirit of Eris entered a trilogy of books called Illuminatus!, and via a play based on those books, it reached Bill Drummond.

Bill Drummond was particularly receptive. He did not have a detailed conscious understanding of Eris or Discordianism, but that doesn't matter. What was more important was that not only were Drummond's actions dominated by thinking on a magical level, but that Ken Campbell had taught him that the trick to doing the impossible was to just go ahead and do it.

Drummond's magical thinking, however, was dominated by a pure, unarguable love of pop music. This turned him towards the music industry, although it was always the power of music, the effect it had on people, which interested him more than the making of music itself.

The corporate music industry was perhaps no place for someone like Drummond, but it did allow him to meet Jimmy Cauty. Drummond and Cauty understood each other, even if nobody else understood them. Cauty was more deeply involved in the actual creation of music than Drummond was. He was also someone who you could rely on to get things done. The pairing was a positive feedback loop. With each justifying the other, they would go far further together than they would apart. Sometimes all you need is for someone to see what you are planning and not look bemused.

At this point the spirit of Eris offered the pair a direction. Drummond and Cauty took on the name and objectives of The Justified Ancients of Mummu. True, they weren't aware of what those objectives are. They were distracted by the throwaway line which linked the JAMs to the music industry to the extent that they missed their founding principle, namely the destruction of order by an attack on the very heart of the economic system.

The Justified Ancients of Mu Mu launched a suicide attack on the music industry. They are defeated by the forces of order and control, in the form of ABBA's lawyers. This defeat lead to a bonfire of vinyl in a Scandinavian field.

The KLF rose from the ashes of the bonfire, with their first record Burn The Bastards being a directly reference to the incident. This act of burning became a constant thread in The KLF, from the wicker man on Jura to the Viking longboat that failed to reach Mu.

News of the Scandinavian bonfire reached the Discordian heartland of northern California. The disciples of Eris responded by spreading confusion and paranoia to Drummond and Cauty through the tried and tested means of Operation Mindfuck. Cauty and Drummond start to become nicely unbalanced.

Open as they were to non-material influences, Drummond and Cauty provided a life-saving service to the fictional character of Doctor Who. They had no knowledge of this, of course. In return they receive the freedom of money and the taste of success. Clearly, this can be a double-edged sword. To their credit, however, they did not fall for the glamour of money and pissed it away on a road movie, as suggested by the followers of Eris. They were True To The Trail. Although they did not know that The JAM’s original aim was to attack our current money system, their actions here revealed themselves to be remarkably suited to that task. They had not been seduced by the bullshit glamour of wealth. If the thought of Eris, hidden away in Moore's Ideaspace, could be pleased, then Eris was pleased.

The KLF get serious. They enter the belly of the beast. Drummond and Cauty collide with the music industry. It's hardly a fair fight. They lose their souls. They gain a large amount of money.

Drummond and Cauty would much rather have their souls than a large amount of money.

Regaining your soul from the Devil is supposed to be impossible, but Ken Campbell taught them how you do the impossible. You take the first step. Then you take the second, and you don't stop until you've done it.

They stopped being The KLF. They did all they could to remove themselves from music history.

That just left a pile of money. That, too, was part of The KLF and if they wanted their souls back, it would have to go. But money is tricky. Spending it or giving it away wouldn't destroy it. Rather, that would allow it to escape. How could it be destroyed? There was no precedent for such an act. There was no precedent for such a thought. That money might not be invulnerable was unthinkable. To defeat it was impossible.

Nevertheless, that is what they did. They took it to a boathouse on Jura in the liminal period between eras and torched it. The money burnt, like it was nothing more than pieces of paper.

Whatever quality it had that made it more than paper was also burnt.

Did this save Cauty and Drummond's souls? That is really a question for them, but between you and me the answer is yes, it did.

Did it achieve the aims of the Justified Ancients of Mummu, to destroy the usury based money system? On a magical, rather than a practical, level it was the toppling of the first domino. The idea that the economy was not invulnerable was established in Ideaspace.

Drummond and Cauty had done well. They had now finished what they set out to do and could remove the name Justified Ancients of Mummu from their shoulders and retire with honour.

A new era began, the age of networks, and the dot com world it created immediately announced its arrival by creating a massive economic bubble. Thus, the guiding narrative of this era was declared. The global economic collapse began in earnest in 2008. It was always going to, because continuous economic expansion is not possible. And it is still in the process of collapsing, in no way prepared for the energy crisis and the climate crisis that are gathering speed.  When Drummond and Cauty started work, however, such a collapse was unthinkable. It resided in the darkest corner of human thought, unvisited and ignored. It needed to come to light. It needed to be actualised. And, in its purest form, that is what Cauty and Drummond did.

They may have intended to save their souls from the Devil of the music industry. They may have been in the process of a mental breakdown and making a last cry for help. They may have been attention seeking arseholes after all. But, in burning a million pounds, Drummond and Cauty performed the magical act which set the scene for a global economic collapse and, in doing so, created the twenty-first century.

That then, is our story for those who are prepared to entertain magical thinking. If you liked this explanation, and found the narrative in this book satisfying, you should click here to move on to the epilogue.

If you are unwilling to entertain magical thinking, or found this narrative unsatisfying, you should click here to continue with this chapter.

So that was the story for those who allowed themselves the luxury of magical thinking. It is tempting to do so, for our minds work that way and completely denying the irrational is surprisingly difficult. Concepts as diverse as marriage, the monarchy or the Olympic Torch can only be understood in this light, and training your brain not to use magical thinking is both extremely difficult and no fun at all. The fact that our thoughts and the world of matter operate under completely different rules is basically something that we have to put up with.

If we stay rational, however, the idea that Drummund and Cauty performed a magical act that kindled the modern world is total bullshit.

From the rational perspective, there is no material connection between the events in the Jura boathouse and the larger changes in the world, and this lack of causality means that anyone who suggests otherwise is the worst kind of fool. Even exploring the idea for entertainment’s sake is highly suspect. From the rational materialist perspective, all we can really say about the money burning is that it occurred because Cauty and Drummond are a pair of attention seeking arseholes, and note that the path of chaos is always going to lead to a meaningless ending.

This divide between the rational and the irrational is something of fault line in our current culture wars, and with good reason. As we have noted, the mind essentially runs on a form of magical thinking which processes things in a manner unlike how the material world behaves. Concepts like time, space, connection and energy work in fundamentally different ways in the mental and physical realms. This has been something of a sore point for philosophers over the centuries. Much effort has been expended by people trying to convince themselves that, because only one of these contradictory models can be valid, the other is invalid. Rationalists have attempted to train their minds to work in a whole new way, one that permits as little magical thinking as possible. Others have claimed that the material world is basically a plaything of God and only behaves as it does because that is the sort of thing He is into.

Alan Moore has a nice little dodge to avoid this problem. He claims that magic is not real, if we define 'real' as meaning something that unarguably exists in time and space. Magic, he points out, only exists in the mind. This does not mean that it cannot explain the larger world, for there is an established tradition of things which are best explained with things that don't exist.

The mathematical concept of imaginary numbers is a useful example here. As the laws of maths make explicit, imaginary numbers not only don't exist, they can't exist. The basic imaginary number, known as i, is defined as the square root of minus one. This cannot exist because there is no possible number, minus or positive, which will produce a minus answer when multiplied by itself. Regardless, mathematicians in the eighteenth century played around with imaginary numbers for the fun of it and found them to be surprisingly useful. Over time their properties became understood and they became an important tool for engineers. Our understanding of phenomena such as radio waves or electricity is reliant on them.

This is not to say that electricity behaves as it does because of something that doesn’t exist. Instead, it says that our most practical and useful models for understanding electricity rely on something that doesn't exist. Likewise magic (or art, if you prefer) doesn't exist but then again, it doesn't need to.  In a narrative driven by people who practise magical thinking, magical thinking gives us a tool for appreciating that story.

This still leaves us stuck with a question, though - which is the best model to view these events, the magical thinking perspective which offers a descent into nonsense or a rational perspective which shrugs and gives up? For an answer to this we need to return to Robert Anton Wilson, and plunge back into the heart of Discordianism. For such a Discordian-influenced story, it is fitting that we should make sense of it using Discordian eyes.

Many people have been asked to explain quantum physics over the years, but Robert Anton Wilson had perhaps the best answer. He explained how, after he left LA, he moved into a little apartment in Santa Cruz. After something was stolen from his car he called the police, and they told him that he didn't live in Santa Cruz after all, but lived in a place called Capitola. The post office disagreed, however, and assured him that he did live in Santa Cruz. Wilson then spoke to a reporter on the local paper to see if he could shed any light on this, and the reporter explained that he did not live in either Santa Cruz or Capitola, but in an unincorporated area known as Live Oak.

Wilson was delighted to discover that he lived in three different places at the same time. His apartment didn't move, of course. What happened was different authorities had drawn different lines on their maps. Each authority had a system that worked well enough for their own purposes, so they had no reason to change it. The problem with quantum physics, Wilson argued, is that many people fail to realise that it is we who draw the lines on the map. "It seems hard to understand how a particle can be in three places at the same time without being anywhere at all," he said, "but when you remember that we invented all the boundaries [...], then quantum mechanics is no more mysterious than the fact that I live in three places at the same time."

Hence we have experiments that that show that light travels as a wave, and we have experiments that show that light travels as a particle. This strange dual nature of light, where it behaves as a wave when treated as a wave but behaves like a particle when treated as a particle, baffled many of the greatest physicists for many years. Wilson's point, however, is that both the 'wave model' and the 'particle model' are our own inventions, the lines that we have drawn on the map. Both models are elegant and useful, but they are not light itself. Light is not affected by our attempts to understand it. Like Wilson's apartment, it remains its own thing, removed from the models we use to understand it.

This recognition, that we habitually confuse our models with what they describe, is central to Wilson's thinking. Instinctively, we feel it is possible to know the nature of things themselves, and there is a natural resistance to accepting that we can only know our models. Wilson's work was dedicated to wearing down that resistance. His philosophy was one of multiple-model agnosticism - not simply agnosticism about the existence of God, but agnosticism about everything. With multiple-model agnosticism there is no point getting hung up on the models themselves, because that's all they are - models. Models are by definition smaller and simpler facsimiles of whatever it is that they are trying to describe. The models are not 'true', but they do vary in usefulness depending on how accurate they are in different cultures and circumstances. Once this is recognised, we no longer attach our sense of personal identity to the models we use, and we lose our resistance to swapping between different models when necessary.

Personally identifying with models that we don't realise are models is the cause of much discord. An obvious example of this is the furious arguments which erupt on the internet between people who, although they don’t realise it, are largely in agreement. These nasty, vitriolic clashes occur between people who both agree that people should try to be nice to each other, that the economy is important, that freedom is a good thing and that family should be protected. What is happening is that both sides in the argument are using different models (typically, different political models) and those models are clashing in much the same way that the particle and wave models of light clash. Sadly, these internet ranters do not realise that they are confusing their models with the actuality, and that their argument is about the models, not about the thing-in-itself. No true communication can occur in such instances. As Wilson wrote in Illuminatus!, "You cannot understand a man's actions unless you understand his beliefs."

The twentieth century was a continuous retreat from the notions of certainty and absolute truth. Einstein, Joyce, Heisenberg, Jung, Edward Lorenz, Tim Leary and Kurt Gödel repeatedly demonstrated that what had once been ordered was actually uncertain and what had once been true was really only true from a particular point of view. Our culture made a brave stab at absorbing this new perspective but its response - postmodernism - left a lot to be desired. Postmodernism was the collision of unrelated forms, all of which were given equal validity. This, clearly, was something of a dead end. Postmodern theorists may have convinced themselves that the statement "the sun will rise tomorrow" was as valid as the statement "the sun will not rise tomorrow," but they would have bankrupted themselves trying to prove it to a bookmaker.

The result was a retreat away from postmodernism and a return to models that promised certainty. This, unfortunately, ignored what we learnt in the twentieth century and the reasons why these certainties had been discredited in the first place. The resulting cultural battleground forced people even deeper into their self-referential reality tunnels, and those who believed in one great self-evident truth were forced into long, bitter warfare with others who favoured a slightly different great self-evident truth.

This is a great shame, because there was another option. The other option was Wilson's multiple-model agnosticism, where neither "the sun will rise tomorrow" nor "the sun will not rise tomorrow" would be confused with reality, the thing-in-itself, but both would be seen as models that could be assessed to see which was preferable in the current situation. In this example, the "sun will rise tomorrow" model appears to be pretty useful, while the alternative appears to be rubbish and should probably be put into storage. This is the reason why I earlier described Wilson's decision to adopt a 'giant invisible rabbit' model to explain why he was hearing voices in his head as "one the most important philosophical leaps of the twentieth century, if, admittedly, it is not yet generally recognised as such."

Multiple-model agnosticism, then, is a way out of postmodernism which doesn't lead into the belief that, out of all the billions of people in the world, you are the only one who really gets it and everyone else are idiots. The problem is, however, that our models are too damned convincing, and it is a struggle to remember that they are models and not reality. Hence much of the work of the Discordians - bar the stuff included purely for shits and giggles - is aimed at shocking people into realising the extent to which they confuse their models with the actuality. The 23 Enigma is a good case in point. Wilson was basically training his readers to notice 23s everywhere and, as any Discordian will tell you, he did this very well indeed. The point is, however, that there is nothing special about the number in itself. It is the fact that it has been singled out and had meaning applied to it, and that Discordians have been trained to recognise it, which is significant. Had it been the number 47, or 18, or 65, the effect would have been the same. Indeed, in his later years Wilson admitted that it would have been much better if he had trained his readers to spot quarters on the ground instead of number 23s.

Of course, Multiple-model agnosticism also allows you to consider the model which states that the above paragraph is mistaken, and that the number 23 is significant. Many Discordians have explored this model at length. As I understand it, that model doesn't lead to anywhere pleasant, but the curious are encouraged to explore it for themselves to see if that's true.

The reason that the 23 Enigma is useful is because it demonstrates the amount of information that our models filter out. In actuality, the coincidental and synchronistic appearances of the number 23 are matched by coincidental and synchronistic appearances of every other number, even though our models fail to react to these. They are just models, after all, and models are significantly less detailed than what they represent. Reality itself is ablaze with infinite connections: every particle in the cosmos affects every other particle. It's Too Much, it really is, and seeing reality in all its innate finery would be so overpowering that you'd be in no state to nip down the shops when you need a pint of milk.

Understanding just how simplified and restrictive our personal models are is a useful tool to prevent you from confusing them with reality. A narrative, such as the one presented in this book, is a perfect example of this. From the near-infinite set of data points that were created by Cauty and Drummond's activities, one particular path was selected by this author to serve as a model for what occurred. The decisions which dictated which data points were ignored and which were presented as significant were made in an attempt to create a narrative that was (a) a good yarn, and (b) something that would mess with the reader's head on as deep a level as possible.  Neither of those reasons is concerned with uncovering some profound and unarguable ‘truth’ about what happened, even if all the actual facts are true.

There are many other possible narratives that could have been presented and which would have been equally valid. The idea that this chosen narrative is the 'correct' one is only plausible if you forget that this narrative is just a simplified model of what happened back in the 1990s, and confuse it with the thing itself.

Wilson put it better. As he used to say, "All statements are true in some sense, false in some sense, meaningless in some sense, true and false in some sense, true and meaningless in some sense, false and meaningless in some sense, and true and false and meaningless in some sense." The statement that 'Cauty and Drummond's burning of a million pounds was a magical act that created the 21st Century' is a perfect example of this.

Alan Moore’s magical thinking and the materialist rational perspective, we must remember, are both models. They’re both pretty interesting models, to be fair, and there are a lot of good things about both of them. Artists couldn’t create without magical thinking, just as engineers couldn’t work without rational materialism. It is easy to see how both artists and engineers could confuse their models with the real world, knowing as they do how useful and reliable they are. But neither of these perspectives gives a complete picture. A musician is not going to be able to create a sampler using magical thinking. Or to demonstrate the blind spot of materialism, find a photograph of Johnny Rotten in 1976 and look into his eyes: as a human being, you will know that there is something extraordinary going on, something that the rational materialist model cannot even hope to explain.

When you are dealing with models, it is necessary to remember that they have limits. Even the best only work at certain times and on certain scales. Newton’s laws are so reliable and accurate on human scales that we trust our lives to them when we climb into aeroplanes, yet they break down at larger or smaller scales. They are unable to predict the orbit of Mercury, for example, for which we need the models created by Einstein, and they are little use on a subatomic scale. Communism, some have claimed, is the most effective model for social order, but only in tribes of around thirty people or less. Alan Greenspan’s economic model, likewise, was only useful under certain conditions. Magical and objective materialism are both models, even if this is often forgotten. And being models, they too have limits beyond which they are little use.

The magical thinking of the mind fails, more often than not, when it tries to move beyond the immaterial and affect the material world. Likewise, objective materialism has proved to be a fat lot of good at explaining or predicting the mental worlds that we inhabit. Once we are aware of those limits, the idea that these two models are incompatible falls away. Using multiple-model agnosticism, we no longer have to take sides and nail our colours to one or the other. We simply have to remember which model works in which circumstances and ensure that we apply the correct model for the projects we undertake, be they writing love poems or predicting earthquakes.

The need to use multiple models comes about because we do not possess one perfect, unarguable model that works in all situations and which everyone agrees is functionally perfect. If one is discovered it will be a cause for much celebration, but that day has yet to come and it seems optimistic to assume that it is around the corner. As a result we make do with a variety of competing explanations which we need to hop between and assess in order to see which is the most useful, on either practical or aesthetic levels. This is more work, but it keeps things interesting.

From a multiple-model perspective, the burning of a million quid in the boathouse in Jura can be said to be both a meaningless act by two attention seeking arseholes which was in no way connected to the wider changes in the world at large, and also a magical act that forged the twenty-first century. This makes it far more interesting than if it was just one or the other, for when the irrational magical narrative and the unconnected real world narrative dovetail, when they tell much the same story from incompatible viewpoints, there is a rush of insight and aesthetic harmony. We are like Picasso during his Cubist period, seeing his subject from multiple perspectives and producing a single image that is both nonsensical and also full of understanding.

Bill Drummond, it seems, was clearly on to something when he advises that we accept the contradictions.

That is my preferred take on the situation, anyway. You are free to consider other models. Perhaps this chapter was intended as an elaborate 'banishing ritual,' intended to dispel any troublesome energies that the writing of this book may have stirred up? Multiple-model agnosticism does challenge you to work these things out yourself. To quote Illuminatus! for the last time, "Think for yourself, schmuck!"

A few years ago I visited the primary school of one of my children. She has since moved up to secondary school, where a teacher told her that the father of a recent pupil had been a pop star who burnt a million pounds yet "was a really nice guy." But enough of coincidences.

I was looking at a poster of the solar system on the wall of a classroom when a teacher came up and spoke to me. "I get so many parents complaining about that poster," he said, as if fearful that I was going to do the same and hoping to confront me before I had the chance.

"Why's that, I asked?" The poster showed nine planets and their relative sizes, complete with other information such as number of moons and so forth. It seemed uncontroversial to me. The planets went, from left to right, Mercury, Venus, Earth, Mars, Jupiter, Saturn, Uranus, Neptune and Pluto.

The teacher tapped at the blue circle on the right, the ninth planet. "Pluto isn't a planet anymore," he said. This was true. In 2006, an international body reclassified Pluto as not a planet, but a dwarf planet. Pluto has many defenders, however, and this has proved to be a controversial decision. The poster, clearly, was printed before any of this happened. From the teacher's comments, it appeared that some smart-arsed parents had been showing off their knowledge of astronomy at the poor poster's expense.

"It's a dwarf planet," the teacher continued, "so it makes sense to include it on a poster showing all the proper planets." He seemed happy with this conclusion.

"What about Eris?" I asked.

He looked blankly at me. "Eris?" he questioned.

"Eris is also a dwarf planet," I explained. "It's the biggest actually, bigger than Pluto. It's the ninth biggest thing in the solar system. If you're going to have Pluto on there, shouldn't you have Eris?"

There was a pause. "I've never heard of it," he said, and walked off to find a less-irritating parent to talk to.

There's no reason he should have heard of it, of course. It's big enough to have a moon of its own, Dysnomia, but it is a very distant thing. It was only discovered in 2005, and it has a wantonly elongated orbit that usually places it much further from the Sun than Pluto. It has been recently re-measured and found to be almost identical in size to Pluto, so my claim that it was the ninth biggest thing in the Solar System was actually wrong. The arguments that it generated in the astronomical community following its discovery led to the controversial classification of what was and wasn't a planet, and this led to poor Pluto being demoted. It was these arguments and the discord that they generated which resulted in it being given the name Eris. That, and the fact that Eris was the "favourite Goddess" of its finder Mike Brown.

I wonder what Hill and Thornley would have made of this? They invoked Eris, and brought her into the twentieth century after being forgotten for a couple of thousand years. The concept of chaos then spread through academia and the counter culture, those being the two places where new ideas are explored, and the results range from the chaos mathematics that drive our climate models, to the events in this story. Then Eris is discovered in the heavens, circling our Sun, bringing argument and upset. ‘As above, so below’, as the saying goes.

Eris is out there, somewhere, following her messy orbit. She may be ignored by those who simplify the solar system into a neat, orderly model. She may not be taught in schools. She may never be well known, or discussed in everyday conversation.

But she is out there. Synchronicities are only synchronicities if you choose to notice them. Paying attention to them is entirely optional, and it makes no differences to dwarf planets like Eris.

Regardless of if or how you think about her, she remains out there.

The global economy lies in tatters. While fiscal and monetary stimulus of unprecedented scale has prevented the financial meltdown of 2008 from turning into a total collapse of the global economy, the 2008 global crash still remains the second-largest economic crisis in history, after the Great Depression. At the time of writing (March 2010), even as some people declare the end of the recession, a sustained recovery is by no means certain. In the absence of financial reforms, loose monetary and fiscal policies have led to new financial bubbles, while the real economy is starved of money. If these bubbles burst, the global economy could fall into another (‘double-dip’) recession. Even if the recovery is sustained, the aftermath of the crisis will be felt for years. It may be several years before the corporate and the household sectors rebuild their balance sheets. The huge budget deficits created by the crisis will force governments to reduce public investments and welfare entitlements significantly, negatively affecting economic growth, poverty and social stability – possibly for decades. Some of those who lost their jobs and houses during the crisis may never join the economic mainstream again. These are frightening prospects.

This catastrophe has ultimately been created by the free-market ideology that has ruled the world since the 1980s. We have been told that, if left alone, markets will produce the most efficient and just outcome. Efficient, because individuals know best how to utilize the resources they command, and just, because the competitive market process ensures that individuals are rewarded according to their productivity. We have been told that business should be given maximum freedom. Firms, being closest to the market, know what is best for their businesses. If we let them do what they want, wealth creation will be maximized, benefiting the rest of society as well. We were told that government intervention in the markets would only reduce their efficiency. Government intervention is often designed to limit the very scope of wealth creation for misguided egalitarian reasons. Even when it is not, governments cannot improve on market outcomes, as they have neither the necessary information nor the incentives to make good business decisions. In sum, we were told to put all our trust in the market and get out of its way.

Following this advice, most countries have introduced free-market policies over the last three decades – privatization of state-owned industrial and financial firms, deregulation of finance and industry, liberalization of international trade and investment, and reduction in income taxes and welfare payments. These policies, their advocates admitted, may temporarily create some problems, such as rising inequality, but ultimately they will make everyone better off by creating a more dynamic and wealthier society. The rising tide lifts all boats together, was the metaphor.

The result of these policies has been the polar opposite of what was promised. Forget for a moment the financial meltdown, which will scar the world for decades to come. Prior to that, and unbeknown to most people, free-market policies had resulted in slower growth, rising inequality and heightened instability in most countries. In many rich countries, these problems were masked by huge credit expansion; thus the fact that US wages had remained stagnant and working hours increased since the 1970s was conveniently fogged over by the heady brew of credit-fuelled consumer boom. The problems were bad enough in the rich countries, but they were even more serious for the developing world. Living standards in Sub-Saharan Africa have stagnated for the last three decades, while Latin America has seen its per capita growth rate fall by two-thirds during the period. There were some developing countries that grew fast (although with rapidly rising inequality) during this period, such as China and India, but these are precisely the countries that, while partially liberalizing, have refused to introduce full-blown free-market policies.

Thus, what we were told by the free-marketeers – or, as they are often called, neo-liberal economists – was at best only partially true and at worst plain wrong. As I will show throughout this book, the ‘truths’ peddled by free-market ideologues are based on lazy assumptions and blinkered visions, if not necessarily self-serving notions. My aim in this book is to tell you some essential truths about capitalism that the free-marketeers won’t.

This book is not an anti-capitalist manifesto. Being critical of free-market ideology is not the same as being against capitalism. Despite its problems and limitations, I believe that capitalism is still the best economic system that humanity has invented. My criticism is of a particular version of capitalism that has dominated the world in the last three decades, that is, free-market capitalism. This is not the only way to run capitalism, and certainly not the best, as the record of the last three decades shows. The book shows that there are ways in which capitalism should, and can, be made better.

Even though the 2008 crisis has made us seriously question the way in which our economies are run, most of us do not pursue such questions because we think that they are ones for the experts. Indeed they are – at one level. The precise answers do require knowledge on many technical issues, many of them so complicated that the experts themselves disagree on them. It is then natural that most of us simply do not have the time or the necessary training to learn all the technical details before we can pronounce our judgements on the effectiveness of TARP (Troubled Asset Relief Program), the necessity of G20, the wisdom of bank nationalization or the appropriate levels of executive salaries. And when it comes to things like poverty in Africa, the workings of the World Trade Organization, or the capital adequacy rules of the Bank for International Settlements, most of us are frankly lost.

However, it is not necessary for us to understand all the technical details in order to understand what is going on in the world and exercise what I call an ‘active economic citizenship’ to demand the right courses of action from those in decision-making positions. After all, we make judgements about all sorts of other issues despite lacking technical expertise. We don’t need to be expert epidemiologists in order to know that there should be hygiene standards in food factories, butchers and restaurants. Making judgements about economics is no different: once you know the key principles and basic facts, you can make some robust judgements without knowing the technical details. The only prerequisite is that you are willing to remove those rose-tinted glasses that neo-liberal ideologies like you to wear every day. The glasses make the world look simple and pretty. But lift them off and stare at the clear harsh light of reality.

Once you know that there is really no such thing as a free market, you won’t be deceived by people who denounce a regulation on the grounds that it makes the market ‘unfree’ (see Thing 1). When you learn that large and active governments can promote, rather than dampen, economic dynamism, you will see that the widespread distrust of government is unwarranted (see Things 12 and 21). Knowing that we do not live in a post-industrial knowledge economy will make you question the wisdom of neglecting, or even implicitly welcoming, industrial decline of a country, as some governments have done (see Things 9 and 17). Once you realize that trickle-down economics does not work, you will see the excessive tax cuts for the rich for what they are – a simple upward redistribution of income, rather than a way to make all of us richer, as we were told (see Things 13 and 20).

What has happened to the world economy was no accident or the outcome of an irresistible force of history. It is not because of some iron law of the market that wages have been stagnating and working hours rising for most Americans, while the top managers and bankers vastly increased their incomes (see Things 10 and 14). It is not simply because of unstoppable progress in the technologies of communications and transportation that we are exposed to increasing forces of international competition and have to worry about job security (see Things 4 and 6). It was not inevitable that the financial sector got more and more detached from the real economy in the last three decades, ultimately creating the economic catastrophe we are in today (see Things 18 and 22). It is not mainly because of some unalterable structural factors – tropical climate, unfortunate location, or bad culture – that poor countries are poor (see Things 7 and 11).

Human decisions, especially decisions by those who have the power to set the rules, make things happen in the way they happen, as I will explain. Even though no single decision-maker can be sure that her actions will always lead to the desired results, the decisions that have been made are not in some sense inevitable. We do not live in the best of all possible worlds. If different decisions had been taken, the world would have been a different place. Given this, we need to ask whether the decisions that the rich and the powerful take are based on sound reasoning and robust evidence. Only when we do that can we demand right actions from corporations, governments and international organizations. Without our active economic citizenship, we will always be the victims of people who have greater ability to make decisions, who tell us that things happen because they have to and therefore that there is nothing we can do to alter them, however unpleasant and unjust they may appear.

This book is intended to equip the reader with an understanding of how capitalism really works and how it can be made to work better. It is, however, not an ‘economics for dummies’. It is attempting to be both far less and far more.

It is less than economics for dummies because I do not go into many of the technical details that even a basic introductory book on economics would be compelled to explain. However, this neglect of technical details is not because I believe them to be beyond my readers. 95 per cent of economics is common sense made complicated, and even for the remaining 5 per cent, the essential reasoning, if not all the technical details, can be explained in plain terms. It is simply because I believe that the best way to learn economic principles is by using them to understand problems that interest the reader the most. Therefore, I introduce technical details only when they become relevant, rather than in a systematic, textbook-like manner.

But while completely accessible to non-specialist readers, this book is a lot more than economics for dummies. Indeed, it goes much deeper than many advanced economics books in the sense that it questions many received economic theories and empirical facts that those books take for granted. While it may sound daunting for a non-specialist reader to be asked to question theories that are supported by the ‘experts’ and to suspect empirical facts that are accepted by most professionals in the field, you will find that this is actually a lot easier than it sounds, once you stop assuming that what most experts believe must be right.

Most of the issues I discuss in the book do not have simple answers. Indeed, in many cases, my main point is that there is no simple answer, unlike what free-market economists want you to believe. However, unless we confront these issues, we will not perceive how the world really works. And unless we understand that, we won’t be able to defend our own interests, not to speak of doing greater good as active economic citizens.

 

 

Markets need to be free. When the government interferes to dictate what market participants can or cannot do, resources cannot flow to their most efficient use. If people cannot do the things that they find most profitable, they lose the incentive to invest and innovate. Thus, if the government puts a cap on house rents, landlords lose the incentive to maintain their properties or build new ones. Or, if the government restricts the kinds of financial products that can be sold, two contracting parties that may both have benefited from innovative transactions that fulfil their idiosyncratic needs cannot reap the potential gains of free contract. People must be left ‘free to choose’, as the title of free-market visionary Milton Friedman’s famous book goes.

 

The free market doesn’t exist. Every market has some rules and boundaries that restrict freedom of choice. A market looks free only because we so unconditionally accept its underlying restrictions that we fail to see them. How ‘free’ a market is cannot be objectively defined. It is a political definition. The usual claim by free-market economists that they are trying to defend the market from politically motivated interference by the government is false. Government is always involved and those free-marketeers are as politically motivated as anyone. Overcoming the myth that there is such a thing as an objectively defined ‘free market’ is the first step towards understanding capitalism.

 

In 1819 new legislation to regulate child labour, the Cotton Factories Regulation Act, was tabled in the British Parliament. The proposed regulation was incredibly ‘light touch’ by modern standards. It would ban the employment of young children – that is, those under the age of nine. Older children (aged between ten and sixteen) would still be allowed to work, but with their working hours restricted to twelve per day (yes, they were really going soft on those kids). The new rules applied only to cotton factories, which were recognized to be exceptionally hazardous to workers’ health.

The proposal caused huge controversy. Opponents saw it as undermining the sanctity of freedom of contract and thus destroying the very foundation of the free market. In debating this legislation, some members of the House of Lords objected to it on the grounds that ‘labour ought to be free’. Their argument said: the children want (and need) to work, and the factory owners want to employ them; what is the problem?

Today, even the most ardent free-market proponents in Britain or other rich countries would not think of bringing child labour back as part of the market liberalization package that they so want. However, until the late nineteenth or the early twentieth century, when the first serious child labour regulations were introduced in Europe and North America, many respectable people judged child labour regulation to be against the principles of the free market.

Thus seen, the ‘freedom’ of a market is, like beauty, in the eyes of the beholder. If you believe that the right of children not to have to work is more important than the right of factory owners to be able to hire whoever they find most profitable, you will not see a ban on child labour as an infringement on the freedom of the labour market. If you believe the opposite, you will see an ‘unfree’ market, shackled by a misguided government regulation.

We don’t have to go back two centuries to see regulations we take for granted (and accept as the ‘ambient noise’ within the free market) that were seriously challenged as undermining the free market, when first introduced. When environmental regulations (e.g., regulations on car and factory emissions) appeared a few decades ago, they were opposed by many as serious infringements on our freedom to choose. Their opponents asked: if people want to drive in more polluting cars or if factories find more polluting production methods more profitable, why should the government prevent them from making such choices? Today, most people accept these regulations as ‘natural’. They believe that actions that harm others, however unintentionally (such as pollution), need to be restricted. They also understand that it is sensible to make careful use of our energy resources, when many of them are non-renewable. They may believe that reducing human impact on climate change makes sense too.

If the same market can be perceived to have varying degrees of freedom by different people, there is really no objective way to define how free that market is. In other words, the free market is an illusion. If some markets look free, it is only because we so totally accept the regulations that are propping them up that they become invisible.

 

Like many people, as a child I was fascinated by all those gravity-defying kungfu masters in Hong Kong movies. Like many kids, I suspect, I was bitterly disappointed when I learned that those masters were actually hanging on piano wires.

The free market is a bit like that. We accept the legitimacy of certain regulations so totally that we don’t see them. More carefully examined, markets are revealed to be propped up by rules – and many of them.

To begin with, there is a huge range of restrictions on what can be traded; and not just bans on ‘obvious’ things such as narcotic drugs or human organs. Electoral votes, government jobs and legal decisions are not for sale, at least openly, in modern economies, although they were in most countries in the past. University places may not usually be sold, although in some nations money can buy them – either through (illegally) paying the selectors or (legally) donating money to the university. Many countries ban trading in firearms or alcohol. Usually medicines have to be explicitly licensed by the government, upon the proof of their safety, before they can be marketed. All these regulations are potentially controversial – just as the ban on selling human beings (the slave trade) was one and a half centuries ago.

There are also restrictions on who can participate in markets. Child labour regulation now bans the entry of children into the labour market. Licences are required for professions that have significant impacts on human life, such as medical doctors or lawyers (which may sometimes be issued by professional associations rather than by the government). Many countries allow only companies with more than a certain amount of capital to set up banks. Even the stock market, whose under-regulation has been a cause of the 2008 global recession, has regulations on who can trade. You can’t just turn up in the New York Stock Exchange (NYSE) with a bag of shares and sell them. Companies must fulfil listing requirements, meeting stringent auditing standards over a certain number of years, before they can offer their shares for trading. Trading of shares is only conducted by licensed brokers and traders.

Conditions of trade are specified too. One of the things that surprised me when I first moved to Britain in the mid 1980s was that one could demand a full refund for a product one didn’t like, even if it wasn’t faulty. At the time, you just couldn’t do that in Korea, except in the most exclusive department stores. In Britain, the consumer’s right to change her mind was considered more important than the right of the seller to avoid the cost involved in returning unwanted (yet functional) products to the manufacturer. There are many other rules regulating various aspects of the exchange process: product liability, failure in delivery, loan default, and so on. In many countries, there are also necessary permissions for the location of sales outlets – such as restrictions on street-vending or zoning laws that ban commercial activities in residential areas.

Then there are price regulations. I am not talking here just about those highly visible phenomena such as rent controls or minimum wages that free-market economists love to hate.

Wages in rich countries are determined more by immigration control than anything else, including any minimum wage legislation. How is the immigration maximum determined? Not by the ‘free’ labour market, which, if left alone, will end up replacing 80–90 per cent of native workers with cheaper, and often more productive, immigrants. Immigration is largely settled by politics. So, if you have any residual doubt about the massive role that the government plays in the economy’s free market, then pause to reflect that all our wages are, at root, politically determined (see Thing 3).

Following the 2008 financial crisis, the prices of loans (if you can get one or if you already have a variable rate loan) have become a lot lower in many countries thanks to the continuous slashing of interest rates. Was that because suddenly people didn’t want loans and the banks needed to lower their prices to shift them? No, it was the result of political decisions to boost demand by cutting interest rates. Even in normal times, interest rates are set in most countries by the central bank, which means that political considerations creep in. In other words, interest rates are also determined by politics.

If wages and interest rates are (to a significant extent) politically determined, then all the other prices are politically determined, as they affect all other prices.

 

We see a regulation when we don’t endorse the moral values behind it. The nineteenth-century high-tariff restriction on free trade by the US federal government outraged slave-owners, who at the same time saw nothing wrong with trading people in a free market. To those who believed that people can be owned, banning trade in slaves was objectionable in the same way as restricting trade in manufactured goods. Korean shopkeepers of the 1980s would probably have thought the requirement for ‘unconditional return’ to be an unfairly burdensome government regulation restricting market freedom.

This clash of values also lies behind the contemporary debate on free trade vs. fair trade. Many Americans believe that China is engaged in international trade that may be free but is not fair. In their view, by paying workers unacceptably low wages and making them work in inhumane conditions, China competes unfairly. The Chinese, in turn, can riposte that it is unacceptable that rich countries, while advocating free trade, try to impose artificial barriers to China’s exports by attempting to restrict the import of ‘sweatshop’ products. They find it unjust to be prevented from exploiting the only resource they have in greatest abundance – cheap labour.

Of course, the difficulty here is that there is no objective way to define ‘unacceptably low wages’ or ‘inhumane working conditions’. With the huge international gaps that exist in the level of economic development and living standards, it is natural that what is a starvation wage in the US is a handsome wage in China (the average being 10 per cent that of the US) and a fortune in India (the average being 2 per cent that of the US). Indeed, most fair-trade-minded Americans would not have bought things made by their own grandfathers, who worked extremely long hours under inhumane conditions. Until the beginning of the twentieth century, the average work week in the US was around sixty hours. At the time (in 1905, to be more precise), it was a country in which the Supreme Court declared unconstitutional a New York state law limiting the working days of bakers to ten hours, on the grounds that it ‘deprived the baker of the liberty of working as long as he wished’.

Thus seen, the debate about fair trade is essentially about moral values and political decisions, and not economics in the usual sense. Even though it is about an economic issue, it is not something economists with their technical tool kits are particularly well equipped to rule on.

All this does not mean that we need to take a relativist position and fail to criticize anyone because anything goes. We can (and I do) have a view on the acceptability of prevailing labour standards in China (or any other country, for that matter) and try to do something about it, without believing that those who have a different view are wrong in some absolute sense. Even though China cannot afford American wages or Swedish working conditions, it certainly can improve the wages and the working conditions of its workers. Indeed, many Chinese don’t accept the prevailing conditions and demand tougher regulations. But economic theory (at least free-market economics) cannot tell us what the ‘right’ wages and working conditions should be in China.

 

In July 2008, with the country’s financial system in meltdown, the US government poured $200 billion into Fannie Mae and Freddie Mac, the mortgage lenders, and nationalized them. On witnessing this, the Republican Senator Jim Bunning of Kentucky famously denounced the action as something that could only happen in a ‘socialist’ country like France.

France was bad enough, but on 19 September 2008, Senator Bunning’s beloved country was turned into the Evil Empire itself by his own party leader. According to the plan announced that day by President George W. Bush and subsequently named TARP (Troubled Asset Relief Program), the US government was to use at least $700 billion of taxpayers’ money to buy up the ‘toxic assets’ choking up the financial system.

President Bush, however, did not see things quite that way. He argued that, rather than being ‘socialist’, the plan was simply a continuation of the American system of free enterprise, which ‘rests on the conviction that the federal government should interfere in the market place only when necessary’. Only that, in his view, nationalizing a huge chunk of the financial sector was just one of those necessary things.

Mr Bush’s statement is, of course, an ultimate example of political double-speak – one of the biggest state interventions in human history is dressed up as another workaday market process. However, through these words Mr Bush exposed the flimsy foundation on which the myth of the free market stands. As the statement so clearly reveals, what is a necessary state intervention consistent with free-market capitalism is really a matter of opinion. There is no scientifically defined boundary for free market.

If there is nothing sacred about any particular market boundaries that happen to exist, an attempt to change them is as legitimate as the attempt to defend them. Indeed, the history of capitalism has been a constant struggle over the boundaries of the market.

A lot of the things that are outside the market today have been removed by political decision, rather than the market process itself – human beings, government jobs, electoral votes, legal decisions, university places or uncertified medicines. There are still attempts to buy at least some of these things illegally (bribing government officials, judges or voters) or legally (using expensive lawyers to win a lawsuit, donations to political parties, etc.), but, even though there have been movements in both directions, the trend has been towards less marketization.

For goods that are still traded, more regulations have been introduced over time. Compared even to a few decades ago, now we have much more stringent regulations on who can produce what (e.g., certificates for organic or fair-trade producers), how they can be produced (e.g., restrictions on pollution or carbon emissions), and how they can be sold (e.g., rules on product labelling and on refunds).

Furthermore, reflecting its political nature, the process of re-drawing the boundaries of the market has sometimes been marked by violent conflicts. The Americans fought a civil war over free trade in slaves (although free trade in goods – or the tariffs issue – was also an important issue). The British government fought the Opium War against China to realize a free trade in opium. Regulations on free market in child labour were implemented only because of the struggles by social reformers, as I discussed earlier. Making free markets in government jobs or votes illegal has been met with stiff resistance by political parties who bought votes and dished out government jobs to reward loyalists. These practices came to an end only through a combination of political activism, electoral reforms and changes in the rules regarding government hiring.

Recognizing that the boundaries of the market are ambiguous and cannot be determined in an objective way lets us realize that economics is not a science like physics or chemistry, but a political exercise. Free-market economists may want you to believe that the correct boundaries of the market can be scientifically determined, but this is incorrect. If the boundaries of what you are studying cannot be scientifically determined, what you are doing is not a science.

Thus seen, opposing a new regulation is saying that the status quo, however unjust from some people’s point of view, should not be changed. Saying that an existing regulation should be abolished is saying that the domain of the market should be expanded, which means that those who have money should be given more power in that area, as the market is run on one-dollar-one-vote principle.

So, when free-market economists say that a certain regulation should not be introduced because it would restrict the ‘freedom’ of a certain market, they are merely expressing a political opinion that they reject the rights that are to be defended by the proposed law. Their ideological cloak is to pretend that their politics is not really political, but rather is an objective economic truth, while other people’s politics is political. However, they are as politically motivated as their opponents.

Breaking away from the illusion of market objectivity is the first step towards understanding capitalism.

 

 

Shareholders own companies. Therefore, companies should be run in their interests. It is not simply a moral argument. The shareholders are not guaranteed any fixed payments, unlike the employees (who have fixed wages), the suppliers (who are paid specific prices), the lending banks (who get paid fixed interest rates), and others involved in the business. Shareholders’ incomes vary according to the company’s performance, giving them the greatest incentive to ensure the company performs well. If the company goes bankrupt, the shareholders lose everything, whereas other ‘stakeholders’ get at least something. Thus, shareholders bear the risk that others involved in the company do not, incentivizing them to maximize company performance. When you run a company for the shareholders, its profit (what is left after making all fixed payments) is maximized, which also maximizes its social contribution.

 

Shareholders may be the owners of corporations but, as the most mobile of the ‘stakeholders’, they often care the least about the long-term future of the company (unless they are so big that they cannot really sell their shares without seriously disrupting the business). Consequently, shareholders, especially but not exclusively the smaller ones, prefer corporate strategies that maximize short-term profits, usually at the cost of long-term investments, and maximize the dividends from those profits, which even further weakens the long-term prospects of the company by reducing the amount of retained profit that can be used for re-investment. Running the company for the shareholders often reduces its long-term growth potential.

 

You have probably noticed that many company names in the English-speaking world come with the letter L – PLC, LLC, Ltd, etc. The letter L in these acronyms stands for ‘limited’, short for ‘limited liability’ – public limited company (PLC), limited liability company (LLC) or simply limited company (Ltd). Limited liability means that investors in the company will lose only what they have invested (their ‘shares’), should it go bank-rupt.

However, you may not have realized that the L word, that is, limited liability, is what has made modern capitalism possible. Today, this form of organizing a business enterprise is taken for granted, but it wasn’t always like that.

Before the invention of the limited liability company in sixteenth-century Europe – or the joint-stock company, as it was known in its early days – businessmen had to risk everything when they started a venture. When I say everything, I really mean everything – not just personal property (unlimited liability meant that a failed businessman had to sell all his personal properties to repay all the debts) but also personal freedom (they could go to a debtors’ prison, should they fail to honour their debts). Given this, it is almost a miracle that anyone was willing to start a business at all.

Unfortunately, even after the invention of limited liability, it was in practice very difficult to use it until the mid nineteenth century – you needed a royal charter in order to set up a limited liability company (or a government charter in a republic). It was believed that those who were managing a limited liability company without owning it 100 per cent would take excessive risks, because part of the money they were risking was not their own. At the same time, the non-managing investors in a limited liability company would also become less vigilant in monitoring the managers, as their risks were capped (at their respective investments). Adam Smith, the father of economics and the patron saint of free-market capitalism, opposed limited liability on these grounds. He famously said that the ‘directors of [joint stock] companies … being the managers rather of other people’s money than of their own, it cannot well be expected that they would watch over it with the same anxious vigilance with which the partners in a private copartnery [i.e., partnership, which demands unlimited liability] frequently watch over their own’.

Therefore, countries typically granted limited liability only to exceptionally large and risky ventures that were deemed to be of national interest, such as the Dutch East India Company set up in 1602 (and its arch-rival, the British East India Company) and the notorious South Sea Company of Britain, the speculative bubble surrounding which in 1721 gave limited liability companies a bad name for generations.

By the mid nineteenth century, however, with the emergence of large-scale industries such as railways, steel and chemicals, the need for limited liability was felt increasingly acutely. Very few people had a big enough fortune to start a steel mill or a railway singlehandedly, so, beginning with Sweden in 1844 and followed by Britain in 1856, the countries of Western Europe and North America made limited liability generally available – mostly in the 1860s and 70s.

However, the suspicion about limited liability lingered on. Even as late as the late nineteenth century, a few decades after the introduction of generalized limited liability, small businessmen in Britain ‘who, being actively in charge of a business as well as its owner, sought to limit responsibility for its debts by the device of incorporation [limited liability]’ were frowned upon, according to an influential history of Western European entrepreneurship.

Interestingly, one of the first people who realized the significance of limited liability for the development of capitalism was Karl Marx, the supposed arch-enemy of capitalism. Unlike many of his contemporary free-market advocates (and Adam Smith before them), who opposed limited liability, Marx understood how it would enable the mobilization of large sums of capital that were needed for the newly emerging heavy and chemical industries by reducing the risk for individual investors. Writing in 1865, when the stock market was still very much a side-show in the capitalist drama, Marx had the foresight to call the joint-stock company ‘capitalist production in its highest development’. Like his free-market opponents, Marx was aware of, and criticized, the tendency for limited liability to encourage excessive risk-taking by managers. However, Marx considered it to be a side-effect of the huge material progress that this institutional innovation was about to bring. Of course, in defending the ‘new’ capitalism against its free-market critics, Marx had an ulterior motive. He thought the joint-stock company was a ‘point of transition’ to socialism in that it separated ownership from management, thereby making it possible to eliminate capitalists (who now do not manage the firm) without jeopardizing the material progress that capitalism had achieved.

 

Marx’s prediction that a new capitalism based on joint-stock companies would pave the way for socialism has not come true. However, his prediction that the new institution of generalized limited liability would put the productive forces of capitalism on to a new plane proved extremely prescient.

During the late nineteenth and early twentieth centuries limited liability hugely accelerated capital accumulation and technological progress. Capitalism was transformed from a system made up of Adam Smith’s pin factories, butchers and bakers, with at most dozens of employees and managed by a sole owner, into a system of huge corporations hiring hundreds or even thousands of employees, including the top managers themselves, with complex organizational structures.

Initially, the long-feared managerial incentive problem of limited liability companies – that the managers, playing with other people’s money, would take excessive risk – did not seem to matter very much. In the early days of limited liability, many large firms were managed by a charismatic entrepreneur – such as Henry Ford, Thomas Edison or Andrew Carnegie – who owned a significant chunk of the company. Even though these part-owner-managers could abuse their position and take excessive risk (which they often did), there was a limit to that. Owning a large chunk of the company, they were going to hurt themselves if they made an overly risky decision. Moreover, many of these part-owner-managers were men of exceptional ability and vision, so even their poorly incentivized decisions were often superior to those made by most of those well-incentivized full-owner-managers.

However, as time wore on, a new class of professional managers emerged to replace these charismatic entrepreneurs. As companies grew in size, it became more and more difficult for anyone to own a significant share of them, although in some European countries, such as Sweden, the founding families (or foundations owned by them) hung on as the dominant shareholders, thanks to the legal allowance to issue new shares with smaller (typically 10 per cent, sometimes even 0.1 per cent) voting rights. With these changes, professional managers became the dominant players and the shareholders became increasingly passive in determining the way in which companies were run.

From the 1930s, the talk was increasingly of the birth of managerial capitalism, where capitalists in the traditional sense – the ‘captains of industry’, as the Victorians used to call them – had been replaced by career bureaucrats (private sector bureaucrats, but bureaucrats nonetheless). There was an increasing worry that these hired managers were running the enterprises in their own interests, rather than in the interests of their legal owners, that is, the shareholders. When they should be maximizing profits, it was argued, these managers were maximizing sales (to maximize the size of the company and thus their own prestige) and their own perks, or, worse, engaged directly in prestige projects that add hugely to their egos but little to company profits and thus its value (measured essentially by its stock market capitalization).

Some accepted the rise of the professional managers as an inevitable, if not totally welcome, phenomenon. Joseph Schumpeter, the Austrian-born American economist who is famous for his theory of entrepreneurship (see Thing 15), argued in the 1940s that, with the growing scale of companies and the introduction of scientific principles in corporate research and development, the heroic entrepreneurs of early capitalism would be replaced by bureaucratic professional managers. Schumpeter believed this would reduce the dynamism of capitalism, but thought it inevitable. Writing in the 1950s, John Kenneth Galbraith, the Canadian-born American economist, also argued that the rise of large corporations managed by professional managers was unavoidable and therefore that the only way to provide ‘countervailing forces’ to those enterprises was through increased government regulation and enhanced union power.

However, for decades after that, more pure-blooded advocates of private property have believed that managerial incentives need to be designed in such a way that the managers maximize profits. Many fine brains had worked on this ‘incentive design’ problem, but the ‘holy grail’ proved elusive. Managers could always find a way to observe the letter of the contract but not the spirit, especially when it is not easy for shareholders to verify whether poor profit performance by a manager was the result of his failure to pay enough attention to profit figures or due to forces beyond his control.

 

And then, in the 1980s, the holy grail was found. It was called the principle of shareholder value maximization. It was argued that professional managers should be rewarded according to the amount they can give to shareholders. In order to achieve this, it was argued, first profits need to be maximized by ruthlessly cutting costs – wage bills, investments, inventories, middle-level managers, and so on. Second, the highest possible share of these profits needs to be distributed to the shareholders – through dividends and share buybacks. In order to encourage managers to behave in this way, the proportion of their compensation packages that stock options account for needs to be increased, so that they identify more with the interests of the shareholders. The idea was advocated not just by shareholders, but also by many professional managers, most famously by Jack Welch, the long-time chairman of General Electric (GE), who is often credited with coining the term ‘shareholder value’ in a speech in 1981.

Soon after Welch’s speech, shareholder value maximization became the zeitgeist of the American corporate world. In the beginning, it seemed to work really well for both the managers and the shareholders. The share of profits in national income, which had shown a downward trend since the 1960s, sharply rose in the mid 1980s and has shown an upward trend since then. And the shareholders got a higher share of that profit as dividends, while seeing the value of their shares rise. Distributed profits as a share of total US corporate profit stood at 35–45 per cent between the 1950s and the 1970s, but it has been on an upward trend since the late 70s and now stands at around 60 per cent. The managers saw their compensation rising through the roof (see Thing 14), but shareholders stopped questioning their pay packages, as they were happy with ever-rising share prices and dividends. The practice soon spread to other countries – more easily to countries like Britain, which had a corporate power structure and managerial culture similar to those of the US, and less easily to other countries, as we shall see below.

Now, this unholy alliance between the professional managers and the shareholders was all financed by squeezing the other stakeholders in the company (which is why it has spread much more slowly to other rich countries where the other stakeholders have greater relative strength). Jobs were ruthlessly cut, many workers were fired and re-hired as non-unionized labour with lower wages and fewer benefits, and wage increases were suppressed (often by relocating to or outsourcing from low-wage countries, such as China and India – or the threat to do so). The suppliers, and their workers, were also squeezed by continued cuts in procurement prices, while the government was pressured into lowering corporate tax rates and/or providing more subsidies, with the help of the threat of relocating to countries with lower corporate tax rates and/or higher business subsidies. As a result, income inequality soared (see Thing 13) and in a seemingly endless corporate boom (ending, of course, in 2008), the vast majority of the American and the British populations could share in the (apparent) prosperity only through borrowing at unprecedented rates.

The immediate income redistribution into profits was bad enough, but the ever-increasing share of profit in national income since the 1980s has not been translated into higher investments either (see Thing 13). Investment as a share of US national output has actually fallen, rather than risen, from 20.5 per cent in the 1980s to 18.7 per cent since then (1990–2009). It may have been acceptable if this lower investment rate had been compensated for by a more efficient use of capital, generating higher growth. However, the growth rate of per capita income in the US fell from around 2.6 per cent per year in the 1960s and 70s to 1.6 per cent during 1990–2009, the heyday of shareholder capitalism. In Britain, where similar changes in corporate behaviour were happening, per capita income growth rates fell from 2.4 per cent in the 1960s–70s, when the country was allegedly suffering from the ‘British Disease’, to 1.7 per cent during 1990–2009. So running companies in the interest of the shareholders does not even benefit the economy in the average sense (that is, ignoring the upward income redistribution).

This is not all. The worst thing about shareholder value maximization is that it does not even do the company itself much good. The easiest way for a company to maximize profit is to reduce expenditure, as increasing revenues is more difficult – by cutting the wage bill through job cuts and by reducing capital expenditure by minimizing investment. Generating higher profit, however, is only the beginning of shareholder value maximization. The maximum proportion of the profit thus generated needs to be given to the shareholders in the form of higher dividends. Or the company uses part of the profits to buy back its own shares, thereby keeping the share prices up and thus indirectly redistributing even more profits to the shareholders (who can realize higher capital gains should they decide to sell some of their shares). Share buybacks used to be less than 5 per cent of US corporate profits for decades until the early 1980s, but have kept rising since then and reached an epic proportion of 90 per cent in 2007 and an absurd 280 per cent in 2008. William Lazonick, the American business economist, estimates that, had GM not spent the $20.4 billion that it did in share buybacks between 1986 and 2002 and put it in the bank (with a 2.5 per cent after-tax annual return), it would have had no problem finding the $35 billion that it needed to stave off bankruptcy in 2009. And in all this binge of profits, the professional managers benefit enormously too, as they own a lot of shares themselves through stock options.

All this damages the long-run prospect of the company. Cutting jobs may increase productivity in the short run, but may have negative long-term consequences. Having fewer workers means increased work intensity, which makes workers tired and more prone to mistakes, lowering product quality and thus a company’s reputation. More importantly, the heightened insecurity, coming from the constant threat of job cuts, discourages workers from investing in acquiring company-specific skills, eroding the company’s productive potential. Higher dividends and greater own-share buybacks reduce retained profits, which are the main sources of corporate investment in the US and other rich capitalist countries, and thus reduce investment. The impacts of reduced investment may not be felt in the short run, but in the long run make a company’s technology backward and threaten its very survival.

But wouldn’t the shareholders care? As owners of the company, don’t they have the most to lose, if their company declines in the long run? Isn’t the whole point of someone being an owner of an asset – be it a house, a plot of land or a company – that she cares about its long-run productivity? If the owners are letting all this happen, defenders of the status quo would argue, it must be because that is what they want, however insane it may look to outsiders.

Unfortunately, despite being the legal owners of the company, shareholders are the ones who are least committed among the various stakeholders to the long-term viability of the company. This is because they are the ones who can exit the company most easily – they just need to sell their shares, if necessary at a slight loss, as long as they are smart enough not to stick to a lost cause for too long. In contrast, it is more difficult for other stakeholders, such as workers and suppliers, to exit the company and find another engagement, because they are likely to have accumulated skills and capital equipment (in the case of the suppliers) that are specific to the companies they do business with. Therefore, they have a greater stake in the long-run viability of the company than most shareholders. This is why maximizing shareholder value is bad for the company, as well as the rest of the economy.

 

Limited liability has allowed huge progress in human productive power by enabling the amassing of huge amounts of capital, exactly because it has offered shareholders an easy exit, thereby reducing the risk involved in any investment. However, at the same time, this very ease of exit is exactly what makes the shareholders unreliable guardians of a company’s long-term future.

This is why most rich countries outside the Anglo-American world have tried to reduce the influence of free-floating shareholders and maintain (or even create) a group of long-term stakeholders (including some shareholders) through various formal and informal means. In many countries, the government has held sizeable share ownership in key enterprises – either directly (e.g., Renault in France, Volkswagen in Germany) or indirectly through ownership by state-owned banks (e.g., France, Korea) – and acted as a stable shareholder. As mentioned above, countries like Sweden allowed differential voting rights for different classes of shares, which enabled the founding families to retain significant control over the corporation while raising additional capital. In some countries, there are formal representations by workers, who have a greater long-term orientation than floating shareholders, in company management (e.g., the presence of union representatives on company supervisory boards in Germany). In Japan, companies have minimized the influence of floating shareholders through cross-shareholding among friendly companies. As a result, professional managers and floating shareholders have found it much more difficult to form the ‘unholy alliance’ in these countries, even though they too prefer the shareholder-value-maximization model, given its obvious benefits to them.

Being heavily influenced, if not totally controlled, by longer-term stakeholders, companies in these countries do not as easily sack workers, squeeze suppliers, neglect investment and use profits for dividends and share buybacks as American and British companies do. All this means that in the long run they may be more viable than the American or the British companies. Just think about the way in which General Motors has squandered its absolute dominance of the world car industry and finally gone bankrupt while being on the forefront of shareholder value maximization by constantly downsizing and refraining from investment (see Thing 18). The weakness of GM management’s short-term-oriented strategy has been apparent at least from the late 1980s, but the strategy continued until its bankruptcy in 2009, because it made both the managers and the shareholders happy even while debilitating the company.

Running companies in the interests of floating shareholders is not only inequitable but also inefficient, not just for the national economy but also for the company itself. As Jack Welch recently confessed, shareholder value is probably the ‘dumbest idea in the world’.

 

 

In a market economy, people are rewarded according to their productivity. Bleeding-heart liberals may find it difficult to accept that a Swede gets paid fifty times what an Indian gets paid for the same job, but that is a reflection of their relative productivities. Attempts to reduce these differences artificially – for example, by introducing minimum wage legislation in India – lead only to unjust and inefficient rewarding of individual talents and efforts. Only a free labour market can reward people efficiently and justly.

 

The wage gaps between rich and poor countries exist not mainly because of differences in individual productivity but mainly because of immigration control. If there were free migration, most workers in rich countries could be, and would be, replaced by workers from poor countries. In other words, wages are largely politically determined. The other side of the coin is that poor countries are poor not because of their poor people, many of whom can out-compete their counterparts in rich countries, but because of their rich people, most of whom cannot do the same. This does not, however, mean that the rich in the rich countries can pat their own backs for their individual brilliance. Their high productivities are possible only because of the historically inherited collective institutions on which they stand. We should reject the myth that we all get paid according to our individual worth, if we are to build a truly just society.

 

A bus driver in New Delhi gets paid around 18 rupees an hour. His equivalent in Stockholm gets paid around 130 kronas, which was, as of summer 2009, around 870 rupees. In other words, the Swedish driver gets paid nearly fifty times that of his Indian equivalent.

Free-market economics tells us that, if something is more expensive than another comparable product, it must be because it is better. In other words, in free markets, products (including labour services) get paid what they deserve. So, if a Swedish driver – let’s call him Sven – is paid fifty times more than an Indian driver – let’s call him Ram – it must be because Sven is fifty times more productive as a bus driver than Ram is.

In the short run, some (although not all) free-market economists may admit, people may pay an excessively high price for a product because of a fad or a craze. For example, people paid ludicrous prices for those ‘toxic assets’ in the recent financial boom (that has turned into the biggest recession since the Great Depression) because they were caught in a speculative frenzy. However, they would argue, this kind of thing cannot last for long, as people figure out the true value of things sooner or later (see Thing 16). Likewise, even if an underqualified worker somehow manages to get a well-paid job through deceit (e.g., fabricating a certificate) or bluffing in an interview, he will soon be fired and replaced, because it will quickly become apparent that he does not have the productivity to justify his wage. So, the reasoning goes, if Sven is getting paid fifty times what Ram is paid, he must be producing fifty times more output than Ram.

But is this what is really going on? To begin with, is it possible that someone drives fifty times better than another? Even if we somehow manage to find a way to measure quantitatively the quality of driving, is this kind of productivity gap in driving possible? Perhaps it is, if we compare professional racing drivers like Michael Schumacher or Lewis Hamilton with some particularly uncoordinated eighteen-year-old who has just passed his driving test. However, I simply cannot envisage how a regular bus driver can drive fifty times better than another.

Moreover, if anything, Ram would likely be a much more skilled driver than Sven. Sven may of course be a good driver by Swedish standards, but has he ever had to dodge a cow in his life, which Ram has to do regularly? Most of the time, what is required of Sven is the ability to drive straight (OK, give or take a few evasive manoeuvres to deal with drunken drivers on Saturday nights), while Ram has to negotiate his way almost every minute of his driving through bullock carts, rickshaws and bicycles stacked three metres high with crates. So, according to free-market logic, Ram should be paid more than Sven, not the other way round.

In response, a free-market economist might argue that Sven gets paid more because he has more ‘human capital’, that is, skills and knowledge accumulated through education and training. Indeed, it is almost certain that Sven has graduated from high school, with twelve years of schooling under his belt, whereas Ram probably can barely read and write, having completed only five years of education back in his village in Rajahstan.

However, little of Sven’s additional human capital acquired in his extra seven years of schooling would be relevant for bus driving (see Thing 17). He does not need any knowledge of human chromosomes or Sweden’s 1809 war with Russia in order to drive his bus well. So Sven’s extra human capital cannot explain why he is paid fifty times more than Ram is.

The main reason that Sven is paid fifty times more than Ram is, to put it bluntly, protectionism – Swedish workers are protected from competition from the workers of India and other poor countries through immigration control. When you think about it, there is no reason why all Swedish bus drivers, or for that matter the bulk of the workforce in Sweden (and that of any other rich country), could not be replaced by some Indians, Chinese or Ghanaians. Most of these foreigners would be happy with a fraction of the wage rates that Swedish workers get paid, while all of them would be able to perform the job at least equally well, or even better. And we are not simply talking about low-skill workers such as cleaners or street-sweepers. There are huge numbers of engineers, bankers and computer programmers waiting out there in Shanghai, Nairobi or Quito, who can easily replace their counterparts in Stockholm, Linköping and Malmö. However, these workers cannot enter the Swedish labour market because they cannot freely migrate to Sweden due to immigration control. As a result, Swedish workers can command fifty times the wages of Indian workers, despite the fact that many of them do not have productivity rates that are higher than those of Indian workers.

 

Our story of bus drivers reveals the existence of the proverbial elephant in the room. It shows that the living standards of the huge majority of people in rich countries critically depend on the existence of the most draconian control over their labour markets – immigration control. Despite this, immigration control is invisible to many and deliberately ignored by others, when they talk about the virtues of the free market.

I have already argued (see Thing 1) that there really is no such thing as a free market, but the example of immigration control reveals the sheer extent of market regulation that we have in supposedly free-market economies but fail to see.

While they complain about minimum wage legislation, regulations on working hours, and various ‘artificial’ entry barriers into the labour market imposed by trade unions, few economists even mention immigration control as one of those nasty regulations hampering the workings of the free labour market. Hardly any of them advocates the abolition of immigration control. But, if they are to be consistent, they should also advocate free immigration. The fact that few of them do once again proves my point in Thing 1 that the boundary of the market is politically determined and that free-market economists are as ‘political’ as those who want to regulate markets.

Of course, in criticizing the inconsistency of free-market economists about immigration control, I am not arguing that immigration control should be abolished – I don’t need to do that because (as you may have noticed by now) I am not a free-market economist.

Countries have the right to decide how many immigrants they accept and in which parts of the labour market. All societies have limited capabilities to absorb immigrants, who often have very different cultural backgrounds, and it would be wrong to demand that a country goes over that limit. Too rapid an inflow of immigrants will not only lead to a sudden increase in competition for jobs but also stretch the physical and social infrastructures, such as housing and healthcare, and create tensions with the resident population. As important, if not as easily quantifiable, is the issue of national identity. It is a myth – a necessary myth, but a myth nonetheless – that nations have immutable national identities that cannot be, and should not be, changed. However, if there are too many immigrants coming in at the same time, the receiving society will have problems creating a new national identity, without which it may find it difficult to maintain social cohesion. This means that the speed and the scale of immigration need to be controlled.

This is not to say that the current immigration policies of the rich countries cannot be improved. While any society’s ability to absorb immigrants is limited, it is not as if the total population is fixed. Societies can decide to be more, or less, open to immigrants by adopting different social attitudes and policies towards immigration. Also in terms of the composition of the immigrants, most rich countries are accepting too many ‘wrong’ people from the point of view of the developing countries. Some countries practically sell their passports through schemes in which those who bring in more than a certain amount of ‘investment’ are admitted more or less immediately. This scheme only adds to the capital shortage that most developing countries are suffering from. The rich countries also contribute to the brain drain from developing countries by more willingly accepting people with higher skills. These are people who could have contributed more to the development of their own countries than unskilled immigrants, had they remained in their home countries.

 

Our story about the bus drivers not only exposes the myth that everyone is getting paid fairly, according to her own worth in a free market, but also provides us with an important insight into the cause of poverty in developing countries.

Many people think that poor countries are poor because of their poor people. Indeed, the rich people in poor countries typically blame their countries’ poverty on the ignorance, laziness and passivity of their poor. If only their fellow countrymen worked like the Japanese, kept time like the Germans and were inventive like the Americans – many of these people would tell you, if you would listen – their country would be a rich one.

Arithmetically speaking, it is true that poor people are the ones that pull down the average national income in poor countries. Little do the rich people in poor countries realize, however, that their countries are poor not because of their poor but because of themselves. To go back to our bus driver example, the primary reason why Sven is paid fifty times more than Ram is that he shares his labour market with other people who are way more than fifty times more productive than their Indian counterparts.

Even if the average wage in Sweden is about fifty times higher than the average wage in India, most Swedes are certainly not fifty times more productive than their Indian counterparts. Many of them, including Sven, are probably less skilled. But there are some Swedes – those top managers, scientists and engineers in world-leading companies such as Ericsson, Saab and SKF – who are hundreds of times more productive than their Indian equivalents, so Sweden’s average national productivity ends up being in the region of fifty times that of India.

In other words, poor people from poor countries are usually able to hold their own against their counterparts in rich countries. It is the rich from the poor countries who cannot do that. It is their low relative productivity that makes their countries poor, so their usual diatribe that their countries are poor because of all those poor people is totally misplaced. Instead of blaming their own poor people for dragging the country down, the rich of the poor countries should ask themselves why they cannot pull the rest of their countries up as much as the rich of the rich countries do.

Finally, a word of warning to the rich of the rich countries, lest they become smug, hearing that their own poor are paid well only because of immigration control and their own high productivity.

Even in sectors where rich country individuals are genuinely more productive than their counterparts in poor countries, their productivity is in great part due to the system, rather than the individuals themselves. It is not simply, or even mainly, because they are cleverer and better educated that some people in rich countries are hundreds of times more productive than their counterparts in poor countries. They achieve this because they live in economies that have better technologies, better organized firms, better institutions and better physical infrastructure – all things that are in large part products of collective actions taken over generations (see Things 15 and 17). Warren Buffet, the famous financier, put this point beautifully, when he said in a television interview in 1995: ‘I personally think that society is responsible for a very significant percentage of what I’ve earned. If you stick me down in the middle of Bangladesh or Peru or someplace, you’ll find out how much this talent is going to produce in the wrong kind of soil. I will be struggling thirty years later. I work in a market system that happens to reward what I do very well – disproportionately well.’

So we are actually back to where we started. What an individual is paid is not fully a reflection of her worth. Most people, in poor and rich countries, get paid what they do only because there is immigration control. Even those citizens of rich countries who cannot be easily replaced by immigrants, and thus may be said to be really being paid their worth (although they may not – see Thing 14), are as productive as they are only because of the socio-economic system they are operating in. It is not simply because of their individual brilliance and hard work that they are as productive as they are.

The widely accepted assertion that, only if you let markets be, will everyone be paid correctly and thus fairly, according to his worth, is a myth. Only when we part with this myth and grasp the political nature of the market and the collective nature of individual productivity will we be able to build a more just society in which historical legacies and collective actions, and not just individual talents and efforts, are properly taken into account in deciding how to reward people.

 

 

The recent revolution in communications technologies, represented by the internet, has fundamentally changed the way in which the world works. It has led to the ‘death of distance’. In the ‘borderless world’ thus created, old conventions about national economic interests and the role of national governments are invalid. This technological revolution defines the age we live in. Unless countries (or companies or, for that matter, individuals) change at corresponding speeds, they will be wiped out. We – as individuals, firms or nations – will have to become ever more flexible, which requires greater liberalization of markets.

 

In perceiving changes, we tend to regard the most recent ones as the most revolutionary. This is often at odds with the facts. Recent progress in telecommunications technologies is not as revolutionary as what happened in the late nineteenth century – wired telegraphy – in relative terms. Moreover, in terms of the consequent economic and social changes, the internet revolution has (at least as yet) not been as important as the washing machine and other household appliances, which, by vastly reducing the amount of work needed for household chores, allowed women to enter the labour market and virtually abolished professions like domestic service. We should not ‘put the telescope backward’ when we look into the past and underestimate the old and overestimate the new. This leads us to make all sorts of wrong decisions about national economic policy, corporate policies and our own careers.

 

According to an American friend, the Spanish textbook that she used in her school in the 1970s had a sentence saying (in Spanish, of course) that ‘everyone in Latin America has a maid’.

When you think about it, this is a logical impossibility. Do maids also have maids in Latin America? Perhaps there is some kind of maid exchange scheme that I have not heard of, where maids take turns in being each other’s maids, so that all of them can have a maid, but I don’t think so.

Of course, one can see why an American author could come up with such a statement. A far higher proportion of people in poor countries have maids than in rich countries. A schoolteacher or a young manager in a small firm in a rich country would not dream of having a live-in maid, but their counterparts in a poor country are likely to have one – or even two. The figures are difficult to come by, but, according to ILO (International Labour Organisation) data, 7–8 per cent of the labour force in Brazil and 9 per cent of that in Egypt are estimated to be employed as domestic servants. The corresponding figures are 0.7 per cent in Germany, 0.6 per cent in the US, 0.3 per cent in England and Wales, 0.05 per cent in Norway and as low as 0.005 per cent in Sweden (the figures are all for the 1990s, except for those of Germany and Norway, which are for the 2000s). So, in proportional terms, Brazil has 12–13 times more domestic servants than the US does and Egypt has 1,800 times more than Sweden. No wonder that many Americans think ‘everyone’ has a maid in Latin America and a Swede in Egypt feels that the country is practically overrun with domestic servants.

The interesting thing is that the share of the labour force working as domestic servants in today’s rich countries used to be similar to what you find in the developing countries today. In the US, around 8 per cent of those who were ‘gainfully employed’ in 1870 were domestic servants. The ratio was also around 8 per cent in Germany until the 1890s, although it started falling quite fast after that. In England and Wales, where the ‘servant’ culture survived longer than in other countries due to the strength of the landlord class, the ratio was even higher – 10–14 per cent of the workforce was employed as domestic servants between 1850 and 1920 (with some ups and downs). Indeed, if you read Agatha Christie novels up to the 1930s, you would notice that it is not just the press baron who gets murdered in his locked library who has servants but also the hard-up old middle-class spinster, even though she may have just one maid (who gets mixed up with a good-for-nothing garage mechanic, who turns out to be the illegitimate son of the press baron, and also gets murdered on p. 111 for being foolish enough to mention something that she was not supposed to have seen).

The main reason why there are so much fewer (of course, in proportional terms) domestic servants in the rich countries – although obviously not the only reason, given the cultural differences among countries at similar levels of income, today and in the past – is the higher relative price of labour. With economic development, people (or rather the labour services they offer) become more expensive in relative terms than ‘things’ (see also Thing 9). As a result, in rich countries, domestic service has become a luxury good that only the rich can afford, whereas it is still cheap enough to be consumed even by lower-middle-class people in developing countries.

 

Now, whatever the movements in the relative prices of ‘people’ and ‘things’, the fall in the share of people working as domestic servants would not have been as dramatic as it has been in the rich countries over the last century, had there not been the supply of a host of household technologies, which I have represented by the washing machine. However expensive (in relative terms) it may be to hire people who can wash clothes, clean the house, heat the house, cook and do the dishes, they would still have to be hired, if these things could not be done by machines. Or you would have to spend hours doing these things yourselves.

Washing machines have saved mountains of time. The data are not easy to come by, but a mid 1940s study by the US Rural Electrification Authority reports that, with the introduction of the electric washing machine and electric iron, the time required for washing a 38 lb load of laundry was reduced by a factor of nearly 6 (from 4 hours to 41 minutes) and the time taken to iron it by a factor of more than 2.5 (from 4.5 hours to 1.75 hours). Piped water has meant that women do not have to spend hours fetching water (for which, according to the United Nations Development Program, up to two hours per day are spent in some developing countries). Vacuum cleaners have enabled us to clean our houses more thoroughly in a fraction of the time that was needed in the old days, when we had to do it with broom and rags. Gas/electric kitchen stoves and central heating have vastly reduced the time needed for collecting firewood, making fires, keeping the fires alive, and cleaning after them for heating and cooking purposes. Today many people in rich countries even have the dishwasher, whose (future) inventor a certain Mr I. M. Rubinow, an employee of the US Department of Agriculture, said would be ‘a true benefactor of mankind’ in his article in the Journal of Political Economy in 1906.

The emergence of household appliances, as well as electricity, piped water and piped gas, has totally transformed the way women, and consequently men, live. They have made it possible for far more women to join the labour market. For example, in the US, the proportion of married white women in prime working ages (35–44 years) who work outside the home rose from a few per cent in the late 1890s to nearly 80 per cent today. It has also changed the female occupational structure dramatically by allowing society to get by with far fewer people working as domestic servants, as we have seen above – for example, in the 1870s, nearly 50 per cent of women employed in the US were employed as ‘servants and waitresses’ (most of whom we can take to have been servants rather than waitresses, given that eating out was not yet big business). Increased labour market participation has definitely raised the status of women at home and in society, thus also reducing preference for male children and increasing investment in female education, which then further increases female labour market participation. Even those educated women who in the end choose to stay at home with their children have higher status at home, as they can make credible threats that they can support themselves should they decide to leave their partners. With outside employment opportunities, the opportunity costs of children have risen, making families have fewer children. All of these have changed the traditional family dynamics. Taken together, they constitute really powerful changes.

Of course, I am not saying that these changes have happened only – or even predominantly – because of changes in household technologies. The ‘pill’ and other contraceptives have had a powerful impact on female education and labour market participation by allowing women to control the timing and the frequency of their childbirths. And there are non-technological causes. Even with the same household technologies, countries can have quite different female labour market participation ratios and different occupation structures, depending on things like social conventions regarding the acceptability of middle-class women working (poor women have always worked), tax incentives for paid work and child rearing, and the affordability of childcare. Having said all this, however, it is still true that, without the washing machine (and other labour-saving household technologies), the scale of change in the role of women in society and in family dynamics would not have been nearly as dramatic.

 

Compared to the changes brought about by the washing machine (and company), the impact of the internet, which many think has totally changed the world, has not been as fundamental – at least so far. The internet has, of course, transformed the way people spend their out-of-work hours – surfing the net, chatting with friends on Facebook, talking to them on Skype, playing electronic games with someone who’s sitting 5,000 miles away, and what not. It has also vastly improved the efficiency with which we can find information about our insurance policies, holidays, restaurants, and increasingly even the price of broccoli and shampoo.

However, when it comes to production processes, it is not clear whether the impacts have been so revolutionary. To be sure, for some, the internet has profoundly changed the way in which they work. I know that by experience. Thanks to the internet, I have been able to write a whole book with my friend and sometime co-author, Professor Ilene Grabel, who teaches in Denver, Colorado, with only one face-to-face meeting and one or two phone calls. However, for many other people, the internet has not had much impact on productivity. Studies have struggled to find the positive impact of the internet on overall productivity – as Robert Solow, the Nobel laureate economist, put it, ‘the evidence is everywhere but in numbers’.

You may think that my comparison is unfair. The household appliances that I mention have had at least a few decades, sometimes a century, to work their magic, whereas the internet is barely two decades old. This is partly true. As the distinguished historian of science, David Edgerton, said in his fascinating book The Shock of the Old – Technology and Global History Since 1900, the maximum use of a technology, and thus the maximum impact, is often achieved decades after the invention of the technology. But even in terms of its immediate impact, I doubt whether the internet is the revolutionary technology that many of us think it is.

 

Just before the start of the trans-Atlantic wired telegraph service in 1866, it took about three weeks to send a message to the other side of the ‘pond’ – the time it took to cross the Atlantic by sail ships. Even going ‘express’ on a steamship (which did not become prevalent until the 1890s), you had to allow two weeks (the record crossings of the time were eight to nine days).

With the telegraph, the transmission time for, say, a 300-word message was reduced to 7 or 8 minutes. It could even be quicker still. The New York Times reported on 4 December 1861 that Abraham Lincoln’s State of the Union address of 7,578 words was transmitted from Washington, DC to the rest of the country in 92 minutes, giving an average of 82 words per minute, which would have allowed you to send the 300-word message in less than 4 minutes. But that was a record, and the average was more like 40 words per minute, giving us 7.5 minutes for a 300-word message. A reduction from 2 weeks to 7.5 minutes is by a factor of over 2,500 times.

The internet reduced the transmission time of a 300-word message from 10 seconds on the fax machine to, say, 2 seconds, but this is only a reduction by a factor of 5. The speed reduction by the internet is greater when it comes to longer messages – it can send in 10 seconds (considering that it has to be loaded), say, a 30,000-word document, which would have taken more than 16 minutes (or 1,000 seconds) on the fax machine, giving us an acceleration in transmission speed of 100 times. But compare that to the 2,500-time reduction achieved by the telegraph.

The internet obviously has other revolutionary features. It allows us to send pictures at high speed (something that even telegraph or fax could not do and thus relied on physical transportation). It can be accessed in many places, not just in post offices. Most importantly, using it, we can search for particular information we want from a vast number of sources. However, in terms of sheer acceleration in speed, it is nowhere near as revolutionary as the humble wired (not even wireless) telegraphy.

We vastly overestimate the impacts of the internet only because it is affecting us now. It is not just us. Human beings tend to be fascinated by the newest and the most visible technologies. Already in 1944, George Orwell criticized people who got overexcited by the ‘abolition of distance’ and the ‘disappearance of frontiers’ thanks to the aeroplane and the radio.

 

Who cares if people think wrongly that the internet has had more important impacts than telegraphy or the washing machine? Why does it matter that people are more impressed by the most recent changes?

It would not matter if this distortion of perspectives was just a matter of people’s opinions. However, these distorted perspectives have real impacts, as they result in misguided use of scarce resources.

The fascination with the ICT (Information and Communication Technology) revolution, represented by the internet, has made some rich countries – especially the US and Britain – wrongly conclude that making things is so ‘yesterday’ that they should try to live on ideas. And as I explain in Thing 9, this belief in ‘post-industrial society’ has led those countries to unduly neglect their manufacturing sector, with adverse consequences for their economies.

Even more worryingly, the fascination with the internet by people in rich countries has moved the international community to worry about the ‘digital divide’ between the rich countries and the poor countries. This has led companies, charitable foundations and individuals to donate money to developing countries to buy computer equipment and internet facilities. The question, however, is whether this is what the developing countries need the most. Perhaps giving money for those less fashionable things such as digging wells, extending electricity grids and making more affordable washing machines would have improved people’s lives more than giving every child a laptop computer or setting up internet centres in rural villages. I am not saying that those things are necessarily more important, but many donors have rushed into fancy programmes without carefully assessing the relative long-term costs and benefits of alternative uses of their money.

In yet another example, a fascination with the new has led people to believe that the recent changes in the technologies of communications and transportation are so revolutionary that now we live in a ‘borderless world’, as the title of the famous book by Kenichi Ohmae, the Japanese business guru, goes. As a result, in the last twenty years or so, many people have come to believe that whatever change is happening today is the result of monumental technological progress, going against which will be like trying to turn the clock back. Believing in such a world, many governments have dismantled some of the very necessary regulations on cross-border flows of capital, labour and goods, with poor results (for example, see Things 7 and 8). However, as I have shown, the recent changes in those technologies are not nearly as revolutionary as the corresponding changes of a century ago. In fact, the world was a lot more globalized a century ago than it was between the 1960s and the 1980s despite having much inferior technologies of communication and transportation, because in the latter period governments, especially the powerful governments, believed in tougher regulations of these cross-border flows. What has determined the degree of globalization (in other words, national openness) is politics, rather than technology. However, if we let our perspective be distorted by our fascination with the most recent technological revolution, we cannot see this point and end up implementing the wrong policies.

Understanding technological trends is very important for correctly designing economic policies, both at the national and the international levels (and for making the right career choices at the individual level). However, our fascination with the latest, and our under-valuation of what has already become common, can, and has, led us in all sorts of wrong directions. I have made this point deliberately provocatively by pitting the humble washing machine against the internet, but my examples should have shown you that the ways in which technological forces have shaped economic and social developments under capitalism are much more complex than is usually believed.

 

 

Adam Smith famously said: ‘It is not from the benevolence of the butcher, the brewer, or the baker that we expect our dinner, but from their regard to their own interest.’ The market beautifully harnesses the energy of selfish individuals thinking only of themselves (and, at most, their families) to produce social harmony. Communism failed because it denied this human instinct and ran the economy assuming everyone to be selfless, or at least largely altruistic. We have to assume the worst about people (that is, they only think about themselves), if we are to construct a durable economic system.

 

Self-interest is a most powerful trait in most human beings. However, it’s not our only drive. It is very often not even our primary motivation. Indeed, if the world were full of the self-seeking individuals found in economics textbooks, it would grind to a halt because we would be spending most of our time cheating, trying to catch the cheaters, and punishing the caught. The world works as it does only because people are not the totally self-seeking agents that free-market economics believes them to be. We need to design an economic system that, while acknowledging that people are often selfish, exploits other human motives to the full and gets the best out of people. The likelihood is that, if we assume the worst about people, we will get the worst out of them.

 

In the mid 1990s, I was attending a conference in Japan on the ‘East Asian growth miracle’, organized by the World Bank. On one side of the debate were people like myself, arguing that government intervention had played a positive role in the East Asian growth story by going against market signals and protecting and subsidizing industries such as automobiles and electronics. On the other side, there were economists supporting the World Bank, who argued that government intervention had at best been an irrelevant sideshow or at worst done more harm than good in East Asia. More importantly, they added, even if it were true that the East Asian miracle owed something to government intervention, that does not mean that policies used by the East Asian countries can be recommended to other countries. Government officials who make policies are (like all of us) self-seeking agents, it was pointed out, more interested in expanding their own power and prestige rather than promoting national interests. They argued that government intervention worked in East Asia only because they had exceptionally selfless and capable bureaucrats for historical reasons (which we need not go into here). Even some of the economists who were supporting an active role for government conceded this point.

Listening to this debate, a distinguished-looking Japanese gentleman in the audience raised his hand. Introducing himself as one of the top managers of Kobe Steel, the then fourth-largest steel producer in Japan, the gentleman chided the economists for misunderstanding the nature of modern bureaucracy, be it in the government or in the private sector.

The Kobe Steel manager said (I am, of course, paraphrasing him): ‘I am sorry to say this, but you economists don’t understand how the real world works. I have a PhD in metallurgy and have been working in Kobe Steel for nearly three decades, so I know a thing or two about steel-making. However, my company is now so large and complex that even I do not understand more than half the things that are going on within it. As for the other managers – with backgrounds in accounting and marketing – they really haven’t much of a clue. Despite this, our board of directors routinely approves the majority of projects submitted by our employees, because we believe that our employees work for the good of the company. If we assumed that everyone is out to promote his own interests and questioned the motivations of our employees all the time, the company would grind to a halt, as we would spend all our time going through proposals that we really don’t understand. You simply cannot run a large bureaucratic organization, be it Kobe Steel or your government, if you assume that everyone is out for himself.’

This is merely an anecdote, but it is a powerful testimony to the limitations of standard economic theory, which assumes that self-interest is the only human motivation that counts. Let me elaborate.

 

Free-market economics starts from the assumption that all economic agents are selfish, as summed up in Adam Smith’s assessment of the butcher, the brewer and the baker. The beauty of the market system, they contend, is that it channels what seems to be the worst aspect of human nature – self-seeking, or greed, if you like – into something productive and socially beneficial.

Given their selfish nature, shopkeepers will try to over-charge you, workers will try their best to goof off from work, and professional managers will try to maximize their own salaries and prestige rather than profits, which go to the shareholders rather than themselves. However, the power of the market will put strict limits to, if not completely eliminate, these behaviours: shopkeepers won’t cheat you if they have a competitor around the corner; workers would not dare to slack off if they know they can be easily replaced; hired managers will not be able to fleece the shareholders if they operate in a vibrant stock market, which will ensure that managers who generate lower profits, and thus lower share prices, risk losing their jobs through takeover.

To free-market economists, public officials – politicians and government bureaucrats – pose a unique challenge in this regard. Their pursuit of self-interest cannot be restrained to any meaningful degree because they are not subject to market discipline. Politicians do face some competition from each other, but elections happen so infrequently that their disciplinary effects are limited. Consequently, there is plenty of scope for them to pursue policies that heighten their power and wealth, at the cost of national welfare. When it comes to the career bureaucrats, the scope for self-seeking is even greater. Even if their political masters, the politicians, try to make them implement policies that cater to electoral demands, they can always obfuscate and manipulate the politicians, as was so brilliantly depicted in the BBC comedy series Yes, Minister and its sequel, Yes, Prime Minister. Moreover, unlike the politicians, these career bureaucrats have high job security, if not lifetime tenure, so they can wait out their political masters by simply delaying things. This is the crux of the concerns that the World Bank economists were expressing in the meeting in Japan that I mentioned at the beginning of this Thing.

Therefore, free-market economists recommend, the portion of the economy controlled by politicians and bureaucrats should be minimized. Deregulation and privatization, in this view, are not only economically efficient but also politically sensible in that they minimize the very possibility that public officials can use the state as a vehicle to promote their own self-interests, at the cost of the general public. Some – the so-called ‘New Public Management’ school – go even further and recommend that the management of the government itself should be exposed to greater market forces: a more aggressive use of performance-related pay and short-term contracts for bureaucrats; more frequent contracting-out of government services; a more active exchange of personnel between the public and the private sectors.

 

The assumption of self-seeking individualism, which is at the foundation of free-market economics, has a lot of resonance with our personal experiences. We have all been cheated by unscrupulous traders, be it the fruit seller who put some rotten plums at the bottom of the paper bag or the yoghurt company that vastly exaggerated the health benefits of it products. We know too many corrupt politicians and lazy bureaucrats to believe that all public servants are solely serving the public. Most of us, myself included, have goofed off from work ourselves and some of us have been frustrated by junior colleagues and assistants who find all kinds of excuses not to put in serious work. Moreover, what we read in the news media these days tells us that professional managers, even the supposed champions of shareholder interest such as Jack Welch of GE and Rick Wagoner of GM, have not really been serving the best interests of the shareholders (see Thing 2).

This is all true. However, we also have a lot of evidence – not just anecdotes but systematic evidence – showing that self-interest is not the only human motivation that matters even in our economic life. Self-interest, to be sure, is one of the most important, but we have many other motives – honesty, self-respect, altruism, love, sympathy, faith, sense of duty, solidarity, loyalty, public-spiritedness, patriotism, and so on – that are sometimes even more important than self-seeking as the driver of our behaviours.

Our earlier example of Kobe Steel shows how successful companies are run on trust and loyalty, rather than suspicion and self-seeking. If you think this is a peculiar example from a country of ‘worker ants’ that suppresses individuality against human nature, pick up any book on business leadership or any autobiography by a successful businessman published in the West and see what they say. Do they say that you have to suspect people and watch them all the time for slacking and cheating? No, they probably talk mostly about how to ‘connect’ with the employees, change the way they see things, inspire them, and promote teamwork among them. Good managers know that people are not tunnel-visioned self-seeking robots. They know that people have ‘good’ sides and ‘bad’ sides and that the secret of good management is in magnifying the former and toning down the latter.

Another good example to illustrate the complexity of human motivation is the practice of ‘work to rule’, where workers slow down output by strictly following the rules that govern their tasks. You may wonder how workers can hurt their employer by working according to the rule. However, this semi-strike method – known also as ‘Italian strike’ (and as ‘sciopero bianco’, or ‘white strike’, by Italians themselves) – is known to reduce output by 30 –50 per cent. This is because not everything can be specified in employment contracts (rules) and therefore all production processes rely heavily on the workers’ goodwill to do extra things that are not required by their contracts or exercise initiatives and take shortcuts in order to expedite things, when the rules are too cumbersome. The motivations behind such non-selfish behaviours by workers are varied – fondness of their jobs, pride in their workmanship, self-respect, solidarity with their colleagues, trust in their top managers or loyalty to the company. But the bottom line is that companies, and thus our economy, would grind to a halt if people acted in a totally selfish way, as they are assumed to do in free-market economics.

Not realizing the complex nature of worker motivation, the capitalists of the early mass-production era thought that, by totally depriving workers of discretion over the speed and the intensity of their work and thus their ability to shirk, the conveyor belt would maximize their productivity. However, as those capitalists soon found out, the workers reacted by becoming passive, un-thinking and even uncooperative, when they were deprived of their autonomy and dignity. So, starting with the Human Relations School that emerged in the 1930s, which highlighted the need for good communications with, and among, workers, many managerial approaches have emerged that emphasize the complexity of human motivation and suggest ways to bring the best out of workers. The pinnacle of such an approach is the so-called ‘Japanese production system’ (sometimes known as the ‘Toyota production system’), which exploits the goodwill and creativity of the workers by giving them responsibilities and trusting them as moral agents. In the Japanese system, workers are given a considerable degree of control over the production line. They are also encouraged to make suggestions for improving the production process. This approach has enabled Japanese firms to achieve such production efficiency and quality that now many non-Japanese companies are imitating them. By not assuming the worst about their workers, the Japanese companies have got the best out of them.

 

So, if you look around and think about it, the world seems to be full of moral behaviours that go against the assumptions of free-market economists. When they are confronted with these behaviours, free-market economists often dismiss them as ‘optical illusions’. If people look as if they are behaving morally, they argue, it is only because the observers do not see the hidden rewards and sanctions that they are responding to.

According to this line of reasoning, people always remain self-seekers. If they behave morally, it is not because they believe in the moral code itself but because behaving in that way maximizes rewards and minimizes punishments for them personally. For example, if traders refrain from cheating even when there is no legal compulsion or when there are no competitors ready to take away their businesses, it does not mean that they believe in honesty. It is because they know that having a reputation as an honest trader brings in more customers. Or many tourists who behave badly would not do the same at home, not because they suddenly become decent people when they go back home but because they do not have the anonymity of a tourist and therefore are afraid of being criticized or shunned by people they know and care about.

There is some truth in this. There are subtle rewards and sanctions that are not immediately visible and people do respond to them. However, this line of reasoning does not work in the end.

The fact is that, even when there are no hidden reward-and-sanction mechanisms at work, many of us behave honestly. For example, why do we – or at least those of us who are good runners – not run away without paying after a taxi ride? The taxi driver cannot really chase us far, as he cannot abandon his car for too long. If you are living in a big city, there is virtually no chance that you will meet the same driver again, so you need not even be afraid of the taxi driver retaliating in some way in the future. Given all this, it is quite remarkable that so few people run away without paying after a taxi ride. To take another example, on a foreign holiday some of you may have come across a garage mechanic or a street vendor who did not cheat you, even when there really was no way for you to reward her by spreading her reputation for honest dealings – particularly difficult when you cannot even spell the Turkish garage’s name or when your Cambodian noodle lady, whose name you cannot remember anyway, may not even trade in the same place every day.

More importantly, in a world populated by selfish individuals, the invisible reward/sanction mechanism cannot exist. The problem is that rewarding and punishing others for their behaviours costs time and energy only to the individuals taking the action, while their benefits from improved behavioural standards accrue to everyone. Going back to our examples above, if you, as a taxi driver, want to chase and beat up a runaway customer, you may have to risk getting fined for illegal parking or even having your taxi broken into. But what is the chance of you benefiting from an improved standard of behaviour by that passenger, who you may not meet ever again? It would cost you time and energy to spread the good word about that Turkish garage, but why should you do that if you will probably never visit that part of the world ever again? So, as a self-seeking individual, you wait for someone foolish enough to spend his time and energy in administering private justice to wayward taxi passengers or honest out-of-the-way garages, rather than paying the costs yourself. However, if everyone were a self-interested individual like you, everyone would do as you do. As a result, no one would reward and punish others for their good or bad behaviour. In other words, those invisible reward/sanction mechanisms that free-market economists say create the optical illusion of morality can exist only because we are not the selfish, amoral agents that those economists say we are.

Morality is not an optical illusion. When people act in a non-selfish way – be it not cheating their customers, working hard despite no one watching them, or resisting bribes as an underpaid public official – many, if not all, of them do so because they genuinely believe that that is the right thing to do. Invisible rewards and sanctions mechanisms do matter, but they cannot explain all – or, in my view, even the majority of – non-selfish behaviours, if only for the simple reason that they would not exist if we were entirely selfish. Contrary to Mrs Thatcher’s assertion that ‘there is no such thing as society. There are individual men and women, and there are families’, human beings have never existed as atomistic selfish agents unbound by any society. We are born into societies with certain moral codes and are socialized into ‘internalizing’ those moral codes.

Of course, all this is not to deny that self-seeking is one of the most important human motivations. However, if everyone were really only out to advance his own interest, the world would have already ground to a halt, as there would be so much cheating in trading and slacking in production. More importantly, if we design our economic system based on such an assumption, the result is likely to be lower, rather than higher, efficiency. If we did that, people would feel that they are not trusted as moral agents and refuse to act in moral ways, making it necessary for us to spend a huge amount of resources monitoring, judging and punishing people. If we assume the worst about people, we will get the worst out of them.

 

 

Until the 1970s, inflation was the economy’s public enemy number one. Many countries suffered from disastrous hyperinflation experiences. Even when it did not reach a hyperinflationary magnitude, the economic instability that comes from high and fluctuating inflation discouraged investment and thus growth. Fortunately, the dragon of inflation has been slain since the 1990s, thanks to much tougher attitudes towards government budget deficits and the increasing introduction of politically independent central banks that are free to focus single-mindedly on inflation control. Given that economic stability is necessary for long-term investment and thus growth, the taming of the beast called inflation has laid the basis for greater long-term prosperity.

 

Inflation may have been tamed, but the world economy has become considerably shakier. The enthusiastic proclamations of our success in controlling price volatility during the last three decades have ignored the extraordinary instability shown by economies around the world during that time. There have been a huge number of financial crises, including the 2008 global financial crisis, destroying the lives of many through personal indebtedness, bankruptcy and unemployment. An excessive focus on inflation has distracted our attention away from issues of full employment and economic growth. Employment has been made more unstable in the name of ‘labour market flexibility’, destabilizing many people’s lives. Despite the assertion that price stability is the precondition of growth, the policies that were intended to bring lower inflation have produced only anaemic growth since the 1990s, when inflation is supposed to have finally been tamed.

 

In January 1923, French and Belgian troops occupied the Ruhr region of Germany, known for its coal and steel. This was because, during 1922, the Germans seriously fell behind the reparation payments demanded of them by the Versailles Treaty, which had concluded the First World War.

Had they wanted money, however, the French and the Belgians should have occupied the banks – after all, ‘that’s where the money is’, as the famous American bank robber Willie Sutton allegedly said, when asked why he robbed banks – rather than a bunch of coal mines and steel mills. Why didn’t they do that? It was because they were worried about German inflation.

Since the summer of 1922, inflation in Germany had been getting out of control. The cost of living index rose by sixteen times in six months in the second half of 1922. Of course, the hyperinflation was at least in part caused by the onerous reparation demands by the French and the Belgians, but once it started, it was entirely rational for the French and the Belgians to occupy the Ruhr in order to make sure that they were paid their war reparations in goods, such as coal and steel, rather than in worthless paper, whose value would diminish rapidly.

They were right to do so. German inflation got completely out of control after the occupation of the Ruhr, with prices rising by another 10 billion times (yes, billion, not thousand or even million) until November 1923, when Rentenmark, the new currency, was introduced.

The German hyperinflation has left big and long-lasting marks on the evolution of German, and world, history. Some claim, with justification, that the experience of hyperinflation laid the grounds for the rise of the Nazis by discrediting the liberal institutions of the Weimar Republic. Those who take this view are then implicitly saying that the 1920s German hyperinflation was one of the main causes of the Second World War. The German trauma from the hyperinflation was such that the Bundesbank, the West German central bank after the Second World War, was famous for its excessive aversion to loose monetary policy. Even after the birth of the European single currency, the euro, and the consequent de facto abolition of national central banks in the Eurozone countries, Germany’s influence has made the European Central Bank (ECB) stick to tight monetary policy even in the face of persistently high unemployment, until the 2008 world financial crisis forced it to join other central banks around the world in an unprecedented relaxation of monetary policy. Thus, when talking about the consequences of the German hyperinflation, we are talking about a shockwave lasting nearly a century after the event and affecting not just German, but other European, and world, histories.

 

Germany is not the only country that has experienced hyperinflation. In the financial press Argentina has become a byword for hyperinflation in modern times, but the highest rate of inflation it experienced was only around 20,000 per cent. Worse than the German one was the Hungarian inflation right after the Second World War and that in Zimbabwe in 2008 in the last days of President Robert Mugabe’s dictatorship (now he shares power with the former opposition).

Hyperinflation undermines the very basis of capitalism, by turning market prices into meaningless noises. At the height of the Hungarian inflation in 1946, prices doubled every fifteen hours, while prices doubled every four days in the worst days of the German hyperinflation of 1923. Price signals should not be absolute guides, as I argue throughout this book, but it is impossible to have a decent economy when prices rise at such rates. Moreover, hyperinflation is often the result or the cause of political disasters, such as Adolf Hitler or Robert Mugabe. It is totally understandable why people desperately want to avoid hyperinflation.

However, not all inflation is hyperinflation. Of course, there are people who fear that any inflation, if left alone, would escalate into a hyperinflation. For example, in the early 2000s, Mr Masaru Hayami, the governor of the central bank of Japan, famously refused to ease money supply on the ground that he was worried about the possibility of a hyperinflation – despite the fact that his country was at the time actually in the middle of a deflation (falling prices). But there is actually no evidence that this is inevitable – or even likely. No one would argue that hyperinflation is desirable, or even acceptable, but it is highly questionable whether all inflation is a bad thing, whatever the rate is.

Since the 1980s, free-market economists have managed to convince the rest of the world that economic stability, which they define as very low (ideally zero) inflation, should be attained at all costs, since inflation is bad for the economy. The target inflation rate they recommended has been something like 1–3 per cent, as suggested by Stanley Fischer, a former economics professor at MIT and the chief economist of the IMF between 1994 and 2001.

However, there is actually no evidence that, at low levels, inflation is bad for the economy. For example, even studies done by some free-market economists associated with institutions such as the University of Chicago or the IMF suggest that, below 8–10 per cent, inflation has no relationship with a country’s economic growth rate. Some other studies would even put the threshold higher – 20 per cent or even 40 per cent.

The experiences of individual countries also suggest that fairly high inflation is compatible with rapid economic growth. During the 1960s and 70s, Brazil had an average inflation rate of 42 per cent but was one of the fastest-growing economies in the world, with its per capita income growing at 4.5 per cent a year. During the same period, per capita income in South Korea was growing at 7 per cent per year, despite having an annual average rate of inflation of nearly 20 per cent, which was actually higher than that found in many Latin American countries at the time.

Moreover, there is evidence that excessive anti-inflationary policies can actually be harmful for the economy. Since 1996, when Brazil – having gone through a traumatic phase of rapid inflation, although not quite of hyperinflationary magnitude – started to control inflation by raising real interest rates (nominal interest rates minus the rate of inflation) to some of the highest levels in the world (10–12 per cent per year), its inflation fell to 7.1 per cent per year but its economic growth also suffered, with a per capita income growth rate of only 1.3 per cent per year. South Africa has also had a similar experience since 1994, when it started giving inflation control top priority and jacked up interest rates to the Brazilian levels mentioned above.

Why is this? It is because the policies that are aimed to reduce inflation actually reduce investment and thus economic growth, if taken too far. Free-market economists often try to justify their highly hawkish attitude towards inflation by arguing that economic stability encourages savings and investment, which in turn encourage economic growth. So, in trying to argue that macroeconomic stability, defined in terms of low inflation, was a key factor in the rapid growth of the East Asian economies (a proposition that does not actually apply to South Korea, as seen above), the World Bank argues in its 1993 report: ‘Macroeconomic stability encourages long-term planning and private investment and, through its impact on real interest rates and the real value of financial assets, helped to increase financial savings.’ However, the truth of the matter is that policies that are needed to bring down inflation to a very low – low single-digit – level discourage investment.

Real interest rates of 8, 10 or 12 per cent mean that potential investors would not find non-financial investments attractive, as few such investments bring profit rates higher than 7 per cent. In this case, the only profitable investment is in high-risk, high-return financial assets. Even though financial investments can drive growth for a while, such growth cannot be sustained, as those investments have to be ultimately backed up by viable long-term investments in real sector activities, as so vividly shown by the 2008 financial crisis (see Thing 22).

So, free-market economists have deliberately taken advantage of people’s justified fears of hyperinflation in order to push for excessive anti-inflationary policies, which do more harm than good. This is bad enough, but it is worse than that. Anti-inflationary policies have not only harmed investment and growth but they have failed to achieve their supposed aim – that is, enhancing economic stability.

 

Since the 1980s, but especially since the 1990s, inflation control has been at the top of policy agendas in many countries. Countries were urged to check government spending, so that budget deficits would not fuel inflation. They were also encouraged to give political independence to the central bank, so that it could raise interest rates to high levels, if necessary against popular protests, which politicians would not be able to resist.

The struggle took time, but the beast called inflation has been tamed in the majority of countries in recent years. According to the IMF data, between 1990 and 2008, average inflation rate fell in 97 out of 162 countries, compared to the rates in the 1970s and 80s. The fight against inflation was particularly successful in the rich countries: inflation fell in all of them. Average inflation for the OECD countries (most of which are rich, although not all rich countries belong to the OECD) fell from 7.9 per cent to 2.6 per cent between the two periods (70s–80s vs. 90s–00s). The world, especially if you live in a rich country, has become more stable – or has it?

The fact is that the world has become more stable only if we regard low inflation as the sole indicator of economic stability, but it has not become more stable in the way most of us experience it.

One sense in which the world has become more unstable during the last three decades of free-market dominance and strong anti-inflationary policies is the increased frequency and extent of financial crises. According to a study by Kenneth Rogoff, a former chief economist of the IMF and now a professor at Harvard University, and Carmen Reinhart, a professor at the University of Maryland, virtually no country was in banking crisis between the end of the Second World War and the mid 1970s, when the world was much more unstable than today, when measured by inflation. Between the mid 1970s and the late 1980s, when inflation accelerated in many countries, the proportion of countries with banking crises rose to 5–10 per cent, weighted by their share of world income, seemingly confirming the inflation-centric view of the world. However, the proportion of countries with banking crises shot up to around 20 per cent in the mid 1990s, when we are supposed to have finally tamed the beast called inflation and attained the elusive goal of economic stability. The ratio then briefly fell to zero for a few years in the mid 2000s, but went up again to 35 per cent following the 2008 global financial crisis (and is likely to rise even further at the time of writing, that is, early 2010).

Another sense in which the world has become more unstable during the last three decades is that job insecurity has increased for many people during this period. Job security has always been low in developing countries, but the share of insecure jobs in the so-called ‘informal sector’ – the collection of unregistered firms which do not pay taxes or observe laws, including those providing job security – has increased in many developing countries during the period, due to premature trade liberalization that destroyed a lot of secure ‘formal’ jobs in their industries. In the rich countries, job insecurity increased during the 1980s too, due to rising (compared to the 1950s–70s) unemployment, which was in large part a result of restrictive macroeconomic policies that put inflation control above everything else. Since the 1990s, unemployment has fallen, but job insecurity has still risen, compared to the pre-1980s period.

There are many reasons for this. First, the share of short-term jobs has risen in the majority of rich countries, although not hugely as some people think. Second, while those who keep their job may stay in the same job almost (although not quite) as long as their pre-1980s counterparts used to, a higher proportion of employment terminations have become involuntary, at least in some countries (especially the US). Third, especially in the UK and the US, jobs that had been predominantly secure even until the 1980s – managerial, clerical and professional jobs – have become insecure since the 1990s. Fourth, even if the job itself has remained secure, its nature and intensity have become subject to more frequent and bigger changes – very often for the worse. For example, according to a 1999 study for the Joseph Rowntree Foundation, the British social reform charity named after the famous Quaker philanthropist businessman, nearly two-thirds of British workers said they had experienced an increase in the speed or the intensity of work over the preceding five-year period. Last but not least, in many (although not all) rich countries, the welfare state has been cut back since the 1980s, so people feel more insecure, even if the objective probability of job loss is the same.

The point is that price stability is only one of the indicators of economic stability. In fact, for most people, it is not even the most important indicator. The most destabilizing events in most people’s lives are things like losing a job (or having it radically redefined) or having their houses repossessed in a financial crisis, and not rising prices, unless they are of a hyperinflationary magnitude (hand on heart, can you really tell the difference between a 4 per cent inflation and a 2 per cent one?). This is why taming inflation has not quite brought to most people the sense of stability that the anti-inflationary warriors had said it would.

Now, the coexistence of price stability (that is, low inflation) and the increase in non-price forms of economic instability, such as more frequent banking crises and greater job insecurity, is not a coincidence. All of them are the results of the same free-market policy package.

In the study cited above, Rogoff and Reinhart point out that the share of countries in banking crises is very closely related to the degree of international capital mobility. This increased international mobility is a key goal for free-market economists, who believe that a greater freedom of capital to move across borders would improve the efficiency of the use of capital (see Thing 22). Consequently, they have pushed for capital market opening across the world, although recently they have been softening their position in this regard in relation to developing countries.

Likewise, increased job insecurity is a direct consequence of free-market policies. The insecurity manifested in high unemployment in the rich countries in the 1980s was the result of stringent anti-inflationary macroeconomic policies. Between the 1990s and the outbreak of the 2008 crisis, even though unemployment fell, the chance of involuntary job termination increased, the share of short-term jobs rose, jobs were more frequently redefined and work intensified for many jobs – all as a result of changes in labour market regulations that were intended to increase labour market flexibility and thus economic efficiency.

The free-market policy package, often known as the neo-liberal policy package, emphasizes lower inflation, greater capital mobility and greater job insecurity (euphemistically called greater labour market flexibility), essentially because it is mainly geared towards the interests of the holders of financial assets. Inflation control is emphasized because many financial assets have nominally fixed rates of return, so inflation reduces their real returns. Greater capital mobility is promoted because the main source of the ability for the holders of financial assets to reap higher returns than the holders of other (physical and human) assets is their ability to move around their assets more quickly (see Thing 22). Greater labour market flexibility is demanded because, from the point of view of financial investors, making hiring and firing of the workers easier allows companies to be restructured more quickly, which means that they can be sold and bought more readily with better short-term balance sheets, bringing higher financial returns (see Thing 2).

Even if they have increased financial instability and job insecurity, policies aimed at increasing price stability may be partially justified, had they increased investment and thus growth, as the inflation hawks had predicted. However, the world economy has grown much more slowly during the post-1980s low-inflation era, compared to the high-inflation period of the 1960s and 70s, not least because investment has fallen in most countries (see Thing 13). Even in the rich countries since the 1990s, where inflation has been completely tamed, per capita income growth fell from 3.2 per cent in the 1960s and 70s to 1.4 per cent during 1990–2009.

All in all, inflation, at low to moderate levels, is not as dangerous as free-market economists make it out to be. Attempts to bring inflation down to very low levels have reduced investment and growth, contrary to the claim that the greater economic stability that lower inflation brings will encourage investment and thus growth. More importantly, lower inflation has not even brought genuine economic stability to most of us. Liberalizations of capital and labour markets that form integral parts of the free-market policy package, of which inflation control is a key element, have increased financial instability and job insecurity, making the world more unstable for most of us. To add insult to injury, the alleged growth-enhancing impact of inflation control has not materialized.

Our obsession with inflation should end. Inflation has become the bogeyman that has been used to justify policies that have mainly benefited the holders of financial assets, at the cost of long-term stability, economic growth and human happiness.

 

 

After their independence from colonial rule, developing countries tried to develop their economies through state intervention, sometimes even explicitly adopting socialism. They tried to develop industries such as steel and automobiles, which were beyond their capabilities, artificially by using measures such as trade protectionism, a ban on foreign direct investment, industrial subsidies, and even state ownership of banks and industrial enterprises. At an emotional level this was understandable, given that their former colonial masters were all capitalist countries pursuing free-market policies. However, this strategy produced at best stagnation and at worst disaster. Growth was anaemic (if not negative) and the protected industries failed to ‘grow up’. Thankfully, most of these countries have come to their senses since the 1980s and come to adopt free-market policies. When you think about it, this was the right thing to do from the beginning. All of today’s rich countries, with the exception of Japan (and possibly Korea, although there is debate on that), have become rich through free-market policies, especially through free trade with the rest of the world. And developing countries that have more fully embraced such policies have done better in the recent period.

 

Contrary to what is commonly believed, the performance of developing countries in the period of state-led development was superior to what they have achieved during the subsequent period of market-oriented reform. There were some spectacular failures of state intervention, but most of these countries grew much faster, with more equitable income distribution and far fewer financial crises, during the ‘bad old days’ than they have done in the period of market-oriented reforms. Moreover, it is also not true that almost all rich countries have become rich through free-market policies. The truth is more or less the opposite. With only a few exceptions, all of today’s rich countries, including Britain and the US – the supposed homes of free trade and free market – have become rich through the combinations of protectionism, subsidies and other policies that today they advise the developing countries not to adopt. Free-market policies have made few countries rich so far and will make few rich in the future.

 

Here are the profiles of two developing countries. You are an economic analyst trying to assess their development prospects. What would you say?

Country A: Until a decade ago, the country was highly protectionist, with an average industrial tariff rate well above 30 per cent. Despite the recent tariff reduction, important visible and invisible trade restrictions remain. The country has heavy restrictions on cross-border flows of capital, a state-owned and highly regulated banking sector, and numerous restrictions on foreign ownership of financial assets. Foreign firms producing in the country complain that they are discriminated against through differential taxes and regulations by local governments. The country has no elections and is riddled with corruption. It has opaque and complicated property rights. In particular, its protection of intellectual property rights is weak, making it the pirate capital of the world. The country has a large number of state-owned enterprises, many of which make large losses but are propped up by subsidies and government-granted monopoly rights.

Country B: The country’s trade policy has literally been the most protectionist in the world for the last few decades, with an average industrial tariff rate at 40–55 per cent. The majority of the population cannot vote, and vote-buying and electoral fraud are widespread. Corruption is rampant, with political parties selling government jobs to their financial backers. The country has never recruited a single civil servant through an open, competitive process. Its public finances are precarious, with records of government loan defaults that worry foreign investors. Despite this, it discriminates heavily against foreign investors. Especially in the banking sector, foreigners are prohibited from becoming directors while foreign shareholders cannot even exercise their voting rights unless they are resident in the country. It does not have a competition law, permitting cartels and other forms of monopoly to grow unchecked. Its protection of intellectual property rights is patchy, particularly marred by its refusal to protect foreigners’ copyrights.

Both these countries are up to their necks in things that are supposed to hamper economic development – heavy protectionism, discrimination against foreign investors, weak protection of property rights, monopolies, lack of democracy, corruption, lack of meritocracy, and so on. You would think that they are both headed for developmental disasters. But think again.

Country A is China today – some readers may have guessed that. However, few readers would have guessed that Country B is the USA – that is, around 1880, when it was somewhat poorer than today’s China.

Despite all the supposedly anti-developmental policies and institutions, China has been one of the world’s most dynamic and successful economies over the last three decades, while the USA in the 1880s was one of the fastest-growing – and rapidly becoming one of the richest – countries in the world. So the economic superstars of the late nineteenth century (USA) and of today (China) have both followed policy recipes that go almost totally against today’s neo-liberal free-market orthodoxy.

How is this possible? Hasn’t the free-market doctrine been distilled out of two centuries of successful development experiences by today’s two dozen rich countries? In order to answer these questions, we need to go back in history.

 

Some Americans call their dollar bills ‘dead presidents’, or ‘dead prez’. Not quite accurately. They are all dead all right, but not all the politicians whose portraits adorn the dollar bills are former presidents of the US.

Benjamin Franklin – who features on the best-known paper money in human history, the $100 bill – never was president. However, he could well have been. He was the oldest of the Founding Fathers and arguably the most revered politician of the new-born country. Although he was too old and George Washington’s political stature too great for him to run for the first presidency in 1789, Franklin was the only person who could possibly have challenged Washington for the job.

The real surprise in the pantheon of presidents on the greenback is Alexander Hamilton, who features on the $10 bill. Like Franklin, Hamilton was never a president of the US. But unlike Franklin, whose life story has become American legend, he was, well, not Franklin. Hamilton was a mere Treasury Secretary, even though he was the very first one. What is he doing among the presidents?

Hamilton is there because, unbeknown to most Americans today, he is the architect of the modern American economic system. Two years after becoming Treasury Secretary in 1789 at the outrageously young age of thirty-three, Hamilton submitted to the Congress the Report on the Subject of Manufactures, where he set out the economic development strategy for his young country. In the report, he argued that ‘industries in their infancy’, like the American ones, need to be protected and nurtured by government before they can stand on their own feet. Hamilton’s report was not just about trade protectionism – he also argued for public investment in infrastructure (such as canals), development of the banking system, promotion of a government bond market – but protectionism was at the heart of his strategy. Given his views, were Hamilton finance minister of a developing country today, he would have been heavily criticized by the US Treasury Department for his heresy. His country might even have been refused a loan from the IMF and the World Bank.

The interesting thing, however, is that Hamilton was not alone in this. All the other ‘dead presidents’ would have met with the same disapproval from the US Treasury, the IMF, the World Bank and other defenders of the free-market faith today.

On the $1 bill is the first president, George Washington. At his inauguration ceremony, he insisted on wearing American clothes – specially woven in Connecticut for the occasion – rather than higher-quality British ones. Today, this would have been a violation of the proposed WTO rule on transparency in government procurement. And let’s not forget that Washington was the one who appointed Hamilton as Treasury Secretary, and in full knowledge of what his view on economic policy was – Hamilton was Washington’s aide-de-camp during the American War of Independence and his closest political ally after that.

On the $5 bill, we have Abraham Lincoln, a well-known protectionist, who during the Civil War raised tariffs to their highest level ever. On the $50 bill, we have Ulysses Grant, the Civil War hero-turned president. In defiance of the British pressure on the USA to adopt free trade, he once remarked that ‘within 200 years, when America has gotten out of protection all that it can offer, it too will adopt free trade’.

Benjamin Franklin did not share Hamilton’s infant industry doctrine, but he insisted on high tariff protection for another reason. At the time, the existence of almost-free land in the US made it necessary for American manufacturers to offer wages around four times higher than the European average, as otherwise the workers would have run away to set up farms (this was no idle threat, given that many of them were farmers in their previous lives) (see Thing 10). Therefore, Franklin argued, the American manufacturers could not survive unless they were protected from low-wage competition – or what is known as ‘social dumping’ today – from Europe. This is exactly the logic that Ross Perot, the billionaire-turned-politician, used in order to oppose the NAFTA (North American Free Trade Agreement) in the 1992 presidential election campaign – a logic that 18.9 per cent of the American voters were happy to endorse.

But surely, you may say, Thomas Jefferson (on the rarely seen $2 bill) and Andrew Jackson (on the $20 bill), the patron saints of American free-market capitalism, would have passed the ‘US Treasury Test’?

Thomas Jefferson may have been against Hamilton’s protectionism but, unlike Hamilton, who supported the patent system, he argued strongly against patents. Jefferson believed that ideas are ‘like air’ and therefore should not be owned by anyone. Given the emphasis that most of today’s free-market economists put on the protection of patents and other intellectual property rights, his views would have gone down like a lead balloon among them.

Then how about Andrew Jackson, that protector of the ‘common man’ and fiscal conservative (he paid off all federal government debts for the first time in US history)? Unfortunately for his fans, even he would not pass the test. Under Jackson, average industrial tariffs were in the region of 35–40 per cent. He was also notoriously anti-foreign. When in 1836 he cancelled the licence for the semi-public (second) Bank of the USA (it was 20 per cent owned by the US federal government), one of the main excuses was that it was ‘too much’ owned by foreign (mainly British) investors. And how much was too much? Only 30 per cent. If some developing country president today cancelled the licence for a bank because it was 30 per cent owned by the Americans, it would send the US Treasury into a fit.

So there we go. Every day, tens of millions of Americans go through the day paying for their taxis and buying their sandwiches with a Hamilton or a Lincoln, getting their change with Washingtons, not realizing that these revered politicians are nasty protectionists that most of their country’s news media, conservative and liberal alike, love to lambast. New York bankers and Chicago university professors tut-tut through articles criticizing the anti-foreign antics of Hugo Chavez, the Venezuelan president, in copies of the Wall Street Journal bought with an Andrew Jackson, without realizing that he was far more anti-foreign than Chavez.

The dead presidents don’t talk. But if they could, they would tell Americans and the rest of the world how the policies that their successors promote today are the exact opposite of what they used in order to transform a second-rate agrarian economy dependent on slave labour into the world’s greatest industrial power.

 

When reminded of the protectionist past of the US, free-market economists usually retort that the country succeeded despite, rather than because of, protectionism. They say that the country was destined to grow fast anyway, because it had been exceptionally well endowed with natural resources and received a lot of highly motivated and hard-working immigrants. It is also said that the country’s large internal market somewhat mitigated the negative effects of protectionism, by allowing a degree of competition among domestic firms.

But the problem with this response is that, dramatic as it may be, the US is not the only country that has succeeded with policies that go against the free-market doctrine. In fact, as I shall elaborate below, most of today’s rich countries have succeeded with such policies. And, when they are countries with very different conditions, it is not possible to say that they all shared some special conditions that cancelled out the negative impacts of protectionism and other ‘wrong’ policies. The US may have benefited from a large domestic market, but then how about tiny Finland or Denmark? If you think the US benefited from abundance of natural resources, how do you explain the success of countries such as Korea and Switzerland that had virtually no natural resources to speak of? If immigration was a positive factor for the US, how about all those other countries – from Germany to Taiwan – that lost some of their best people to the US and other New World countries? The ‘special conditions’ argument simply does not work.

Britain, the country which many people think invented free trade, built its prosperity on the basis of policies similar to those that Hamilton promoted. This was not a coincidence. Although Hamilton was the first person to theorize the ‘infant industry’ argument, many of his policies were copied from Robert Walpole, the so-called first British Prime Minister, who ran the country between 1721 and 1742.

During the mid eighteenth century, Britain moved into the woollen manufacturing industry, the high-tech industry of the time that had been dominated by the Low Countries (what are Belgium and the Netherlands today), with the help of tariff protection, subsidies, and other supports that Walpole and his successors provided to the domestic woollen manufacturers. The industry soon provided Britain’s main source of export earnings, which enabled the country to import the food and raw materials that it needed to launch the Industrial Revolution in the late eighteenth and the early nineteenth centuries. Britain adopted free trade only in the 1860s, when its industrial dominance was absolute. In the same way in which the US was the most protectionist country in the world during most of its phase of ascendancy (from the 1830s to the 1940s), Britain was one of the world’s most protectionist countries during much of its own economic rise (from the 1720s to the 1850s).

Virtually all of today’s rich countries used protectionism and subsidies to promote their infant industries. Many of them (especially Japan, Finland and Korea) also severely restricted foreign investment. Between the 1930s and the 1980s, Finland used to classify all enterprises with more than 20 per cent foreign ownership officially as ‘dangerous enterprises’. Several of them (especially France, Austria, Finland, Singapore and Taiwan) used state-owned enterprises to promote key industries. Singapore, which is famous for its free-trade policies and welcoming attitudes towards foreign investors, produces over 20 per cent of its output through state-owned enterprises, when the international average is around 10 per cent. Nor did today’s rich countries protect foreigners’ intellectual property rights very well, if at all – in many of them it was legal to patent someone else’s invention as long as that someone else was a foreigner.

There were exceptions of course. The Netherlands, Switzerland (until the First World War) and Hong Kong used little protectionism, but even these countries did not follow today’s orthodox doctrines. Arguing that patents are artificial monopolies that go against the principle of free trade (a point which is strangely lost on most of today’s free-trade economists), the Netherlands and Switzerland refused to protect patents until the early twentieth century. Even though it did not do it on such principled grounds, Hong Kong was until recently even more notorious for its violation of intellectual property rights than the former countries. I bet you know someone – or at least have a friend who knows someone – who has bought pirated computer software, a fake Rolex watch or an ‘unofficial’ Calvin & Hobbes T-shirt from Hong Kong.

Most readers may find my historical account counter-intuitive. Having been repeatedly told that free-market policies are the best for economic development, they would find it mysterious how most of today’s countries could use all those supposedly bad policies – such as protectionism, subsidies, regulation and state ownership of industry – and still become rich.

The answer lies in the fact that those bad policies were in fact good policies, given the stage of economic development in which those countries were at the time, for a number of reasons. First is Hamilton’s infant industry argument, which I explain in greater detail in the chapter ‘My six-year-old son should get a job’ in my earlier book Bad Samaritans. For the same reason why we send our children to school rather than making them compete with adults in the labour market, developing countries need to protect and nurture their producers before they acquire the capabilities to compete in the world market unassisted. Second, in the earlier stages of development, markets do not function very well for various reasons – poor transport, poor flow of information, the small size of the market that makes manipulation by big actors easier, and so on. This means that the government needs to regulate the market more actively and sometimes even deliberately create some markets. Third, in those stages, the government needs to do many things itself through state-owned enterprises because there are simply not enough capable private sector firms that can take up large-scale, high-risk projects (see Thing 12).

Despite their own history, the rich countries make developing countries open their borders and expose their economies to the full forces of global competition, using the conditions attached to their bilateral foreign aid and to the loans from international financial institutions that they control (such as the IMF and the World Bank) as well as the ideological influence that they exercise through intellectual dominance. In promoting policies that they did not use when they were developing countries themselves, they are saying to the developing countries, ‘Do as I say, not as I did.’

 

When the historical hypocrisy of the rich countries is pointed out, some defenders of the free market come back and say: ‘Well, protectionism and other interventionist policies may have worked in nineteenth-century America or mid twentieth-century Japan, but haven’t the developing countries monumentally screwed up when they tried such policies in the 1960s and 70s?’ What may have worked in the past, they say, is not necessarily going to work today.

The truth is that developing countries did not do badly at all during the ‘bad old days’ of protectionism and state intervention in the 1960s and 70s. In fact, their economic growth performance during the period was far superior to that achieved since the 1980s under greater opening and deregulation.

Since the 1980s, in addition to rising inequality (which was to be expected from the pro-rich nature of the reforms – see Thing 13), most developing countries have experienced a significant deceleration in economic growth. Per capita income growth in the developing world fell from 3 per cent per year in the 1960s and 70s to 1.7 per cent during the 1980–2000 period, when there was the greatest number of free-market reforms. During the 2000s, there was a pick-up in the growth of the developing world, bringing the growth rate up to 2.6 per cent for the 1980–2009 period, but this was largely due to the rapid growth of China and India – two giants that, while liberalizing, did not embrace neo-liberal policies.

Growth performances in regions that have faithfully followed the neo-liberal recipe – Latin America and Sub-Saharan Africa – have been much inferior to what they had in the ‘bad old days’. In the 1960s and 70s, Latin America grew at 3.1 per cent in per capita terms. Between 1980 and 2009, it grew at a rate just above one-third that – 1.1 per cent. And even that rate was partly due to the rapid growth of countries in the region that had explicitly rejected neo-liberal policies sometime earlier in the 2000s – Argentina, Ecuador, Uruguay and Venezuela. Sub-Saharan Africa grew at 1.6 per cent in per capita terms during the ‘bad old days’, but its growth rate was only 0.2 per cent between 1980 and 2009 (see Thing 11).

To sum up, the free-trade, free-market policies are policies that have rarely, if ever, worked. Most of the rich countries did not use such policies when they were developing countries themselves, while these policies have slowed down growth and increased income inequality in the developing countries in the last three decades. Few countries have become rich through free-trade, free-market policies and few ever will.

 

 

The real hero of globalization has been the transnational corporation. Transnational corporations, as their name implies, are corporations that have gone beyond their original national boundaries. They may be still headquartered in the country where they were founded, but much of their production and research facilities are outside their home country, employing people, including many top decision-makers, from across the world. In this age of such nation-less capital, nationalistic policies towards foreign capital are at best ineffective and at worst counterproductive. If a country’s government discriminates against them, transnational corporations will not invest in that country. The intention may be to help the national economy by promoting national firms, but such policies actually harm it by preventing the most efficient firms from establishing themselves in the country.

 

Despite the increasing ‘transnationalization’ of capital, most transnational companies in fact remain national companies with international operations, rather than genuinely nation-less companies. They conduct the bulk of their core activities, such as high-end research and strategizing, at home. Most of their top decision-makers are home-country nationals. When they have to shut down factories or cut jobs, they usually do it last at home for various political and, more importantly, economic reasons. This means that the home country appropriates the bulk of the benefits from a transnational corporation. Of course, their nationality is not the only thing that determines how corporations behave, but we ignore the nationality of capital at our peril.

 

Carlos Ghosn was born in 1954 to Lebanese parents in the Brazilian city of Porto Velho. At the age of six, he moved with his mother to Beirut, Lebanon. After finishing secondary school there, he went to France and earned engineering degrees from two of the country’s most prestigious educational institutions, École Polytechnique and École des Mines de Paris. During his eighteen years at the French tyre-maker Michelin, which he had joined in 1978, Ghosn acquired a reputation for effective management by turning the company’s unprofitable South American operation around and by successfully managing the merger of its US subsidiary with Uniroyal Goodrich, which doubled the size of the company’s US operation.

In 1996, Ghosn joined the state-owned French car-maker Renault and played a key role in reviving the company, affirming his reputation for ruthless cost-cutting and earning the sobriquet ‘le cost killer’, although his actual approach was more consensual than that name suggests. When Renault acquired Nissan, the loss-making Japanese car-maker, in 1999, Ghosn was sent to Japan to put Nissan back into shape. Initially, he faced stiff resistance to his un-Japanese way of management, such as sacking workers, but he turned the company completely around in a few years. After that, he has been so totally accepted by the Japanese that he has been made into a manga (comic book) character, the Japanese equivalent of beatification by the Catholic Church. In 2005, he stunned the world once again by going back to Renault as CEO and president, while staying on as a co-chairman of Nissan – a feat compared by some to a football coach managing two teams at the same time.

Carlos Ghosn’s life story sums up the drama that is globalization. People migrate in search of a better life, sometimes literally to the other side of the world, as Ghosn’s family did. Some of the migrants, like Ghosn’s mother, go back home. This is a big contrast to the days when, for example, Italian immigrants to the US refused to teach their children Italian, as they were so determined not to go back to Italy and wanted their children totally assimilated. Many youngsters from poorer countries with ambition and brains now go to a richer country to study, as Ghosn did. These days, many managers work for a company based in a foreign country, which often means living and working in yet another foreign country (or two) because your company is transnational. Ghosn, a Lebanese Brazilian return-migrant, worked in Brazil, the US and Japan for two French companies.

In this globalized world, the argument goes, nationality of capital is meaningless. Corporations may have started and still be headquartered in a particular country, but they have broken out of their national borders. They now locate their activities wherever the return is the greatest. For example, Nestlé, the Swiss food giant, may be headquartered in the Swiss city of Vevey, but less than 5 per cent of its output is produced in Switzerland. Even if we consider Nestlé’s ‘home’ to be Europe, rather than Switzerland, its home base accounts for only around 30 per cent of its earnings. It is not just the relatively low-grade activities such as production that transnational corporations are conducting outside their home countries. These days, even top-end activities such as R&D are often located outside the home country – increasingly in developing countries, such as China and India. Even their top managers are drawn, like Ghosn, from an international pool of talent, rather than from exclusively national pools.

The upshot is that a company has no national loyalty any more. A business will do what it has to do in order to increase its profit, even if it means hurting its home country by shutting plants down, slashing jobs, or even bringing in foreign workers. Given this, many people argue, it is unwise to put restrictions on foreign ownership of companies, as many governments used to. As long as the company generates wealth and jobs within its borders, the country should not care whether the company is owned by its citizens or foreigners. When all major companies are ready to move anywhere in search of profit opportunities, making investment by foreign companies difficult means that your country is not going to benefit from those foreign companies that have identified good investment prospects in your country. It all makes sense, doesn’t it?

 

In 1998, Daimler-Benz, the German automobile company, and Chrysler, the US car-maker, were merged. It was really a takeover of Chrysler by Daimler-Benz. But when the merger was announced, it was depicted as a marriage of two equals. The new company, Daimler-Chrysler, even had equal numbers of Germans and Americans on the management board. That was, however, only for the first few years. Soon, the Germans vastly outnumbered the Americans on the board – usually ten to twelve to just one or two Americans, depending on the year.

Unfortunately, the takeover was not a great success, and in 2007 Daimler-Benz sold Chrysler off to Cerberus, an American private equity fund. Cerberus, being an American company, made up Chrysler’s board of directors mostly with Americans (with some representation from Daimler, which still held a 19.9 per cent stake).

In the event, Cerberus failed to turn the company around and Chrysler went bankrupt in 2009. It was restructured with US federal government financial aid and a major equity investment by Fiat, the Italian car-maker. When Fiat became the leading shareholder, it made Sergio Marchionne, the CEO of Fiat, also the new CEO of Chrysler and appointed another Fiat manager to Chrysler’s nine-member board of directors. Given that Fiat has only a 20 per cent stake at the moment but has the option to increase it to 35 per cent and eventually to 51 per cent, it is highly likely that the proportion of Italians on the board will increase over time, with the increase in Fiat’s ownership share.

So Chrysler, once one of the quintessential American companies, has in the last decade come to be run by Germans, Americans (again) and (increasingly) Italians. There is no such thing as ‘nation-less’ capital. When taken over by a foreign company, even mighty (former-)American firms end up being run by foreigners (but then that is what takeover means, when you think about it). In most companies, however transnational their operations may seem, the top decision-makers still remain the citizens of the home country – that is, the country where ownership resides – despite the fact that long-distance management (when the acquiring company does not dispatch top managers to the acquired firm) can reduce management efficiency, while dispatching top managers to a foreign country is expensive, especially when the physical and the cultural distances between the two countries are great. Carlos Ghosn is very much an exception that proves the rule.

It is not just in terms of the appointment of top decision-makers that corporations have a ‘home bias’. Home bias is also very strong in research and development, which are at the core of a company’s competitive strengths in most advanced industries. Most of a corporation’s R&D activities stay at home. Insofar as they are relocated abroad, it is usually to other developed countries, and at that with a heavy ‘regional’ bias (the regions here meaning North America, Europe and Japan, which is a region unto itself in this respect). Recently an increasing number of R&D centres have been set up in developing countries, such as China and India, but the R&D they conduct tends to be at the lowest levels of sophistication.

Even in terms of production, arguably the easiest thing that a company does and therefore the most likely candidate for relocation abroad, most transnational corporations are still firmly based in their home countries. There are odd examples of firms, for instance Nestlé, which produce most of their outputs abroad, but they are very much the exception. Among US-based transnational corporations, less than one-third of the output of manufacturing firms is produced overseas. In the case of Japanese companies, the ratio is well below 10 per cent. In Europe, the ratio has risen fast recently, but most overseas production by European firms is within the European Union, so it should be understood more as a process of creating national firms for a new nation called Europe than as a process of European firms going truly transnational.

In short, few corporations are truly transnational. The vast majority of them still produce the bulk of their outputs in their home countries. Especially in terms of high-grade activities such as strategic decision-making and higher-end R&D, they remain firmly centred at their home countries. The talk of a borderless world is highly exaggerated.

 

Why is there a home-country bias in this globalized world? The free-market view is that nationality of capital does not – and should not – matter, because companies have to maximize profit in order to survive and therefore that patriotism is a luxury they can ill afford. Interestingly, many Marxists would agree. They also believe that capital willingly destroys national borders for greater profits and for the expanded reproduction of itself. The language is radically different, but the message is the same – money is money, so why should a company do less profitable things simply because they are good for its home country?

However, there are good reasons why companies act with home-country biases. To begin with, like most of us, top business managers feel some personal obligations to the society they come from. They may frame such obligations in many different ways – patriotism, community spirit, noblesse oblige, or wanting to ‘return something to the society that has made them what they are today’ – and may feel them to different degrees. But the point is that they do feel them. And insofar as most top decision-makers in most companies are home-country nationals, there is bound to be some home-country bias in their decisions. Although free-market economists dismiss any motive other than pure self-seeking, ‘moral’ motives are real and are much more important than they lead us to believe (see Thing 5).

On top of those personal feelings of managers, a company often has real historical obligations to the country in which it has ‘grown up’. Companies, especially (although not exclusively) in the early stages of their development, are often supported with public money, directly and indirectly (see Thing 7). Many of them receive direct subsidies for particular types of activities, such as equipment investment or worker training. They sometimes even get bailed out with public money, as Toyota was in 1949, Volkswagen in 1974 and GM in 2009. Or they may get indirect subsidies in the form of tariff protection or statutory monopoly rights.

Of course, companies often fail to mention, and even actively hide, such history, but there is an unspoken understanding among the relevant parties that companies do have some moral obligations to their home countries because of these historical debts. This is why national companies are much more open to moral suasion by the government and the public than foreign companies are, when they are expected, although cannot be legally obliged, to do something for the country against their (at least short-term) interests. For example, it was reported in October 2009 that South Korea’s financial supervisory agency was finding it impossible to persuade foreign-owned banks to lend more to small and medium-sized companies, even though they, like the nationally owned banks, had already signed an MOU (memorandum of understanding) about that with the agency, when the global financial crisis broke out in the autumn of 2008.

Important though the moral and historical reasons are, by far the most important reason for home-country bias is economic – the fact that the core capabilities of a company cannot be easily taken across the border.

Usually, a company becomes transnational and sets up activities in foreign countries because it possesses some technological and/or organizational competences that the firms operating in the host countries do not possess. These competences are usually embodied in people (e.g., managers, engineers, skilled workers), organizations (e.g., internal company rules, organizational routines, ‘institutional memory’) and networks of related firms (e.g., suppliers, financiers, industrial associations or even old-boy networks that cut across company boundaries), all of which cannot be easily transported to another country.

Most machines may be moved abroad easily, but it is much more costly to move skilled workers or managers. It is even more difficult to transplant organizational routines or business networks on to another country. For example, when Japanese automobile companies started setting up subsidiaries in Southeast Asia in the 1980s, they asked their subcontractors also to set up their own subsidiaries, as they needed reliable subcontractors. Moreover, these intangible capabilities embodied in people, organizations and networks often need to have the right institutional environment (the legal system, informal rules, business culture) in order to function well. However powerful it may be, a company cannot transport its institutional surroundings to another country.

For all these reasons, the most sophisticated activities that require high levels of human and organizational competences and a conducive institutional environment tend to stay at home. Home biases do not exist simply because of emotional attachments or historical reasons. Their existence has good economic bases.

 

Lord Peter Mandelson, the de facto deputy prime minister of the UK government at the time of writing (early 2010), has a bit of a reputation for his Machiavellian politics. A grandson of the highly respected Labour politician Herbert Morrison, and a TV producer by profession, Mandelson was the chief spin doctor behind the rise of the so-called New Labour under Tony Blair. His famous ability to sense and exploit shifts in political moods and accordingly organize an effective media campaign, combined with his ruthlessness, earned him the nickname ‘prince of darkness’.

After a high-profile but turbulent cabinet career, marred by two resignations due to suspected corruption scandals, Mandelson quit British politics and moved to Brussels to become European Commissioner for Trade in 2004. Building on the image of a pro-business politician, gained during his brief spell as the UK’s Secretary of State for Trade and Industry back in 1998, Mandelson established a firm reputation as one of the world’s leading advocates of free trade and investment.

So it sent out a shockwave, when Mandelson, who had made a surprise comeback to British politics and become Business Secretary in early 2009, said in an interview with the Wall Street Journal in September 2009 that, thanks to Britain’s permissive attitude towards foreign ownership, ‘UK manufacturing could be a loser’, even though he added the proviso that this was ‘over a lengthy period of time, certainly not overnight’.

Was it a typical Mandelson antic, with his instinct telling him that this was the time to play the nationalist card? Or did he finally cotton on to something that he and other British policy-makers should have realized a long time ago – that excessive foreign ownership of a national economy can be harmful?

Now, it may be argued, the fact that firms have a home-country bias does not necessarily mean that countries should put restrictions on foreign investment. True, given the home bias, investment by a foreign company may not be in the most desirable activities, but an investment is an investment and it will still increase output and create jobs. If you put restrictions on what foreign investors can do – for example, by telling them that they cannot invest in certain ‘strategic’ industries, by forbidding them from holding a majority share or demanding that they transfer technologies – foreign investors will simply go somewhere else and you will lose the jobs and the wealth that they would have created. Especially for developing countries, which do not have many national firms that can make similar investments, rejecting foreign investment because it is foreign many people believe is frankly irrational. Even if they get only lower-grade activities such as assembly operation, they are still better off with the investment than without it.

This reasoning is correct in its own terms, but there are more issues that need to be considered before we conclude that there should be no restriction on foreign investment (here, we put aside portfolio investment, which is investment in company shares for financial gains without involvement in direct management, and focus on foreign direct investment, which is usually defined as acquisition of more than 10 per cent of a company’s shares with an intent to get involved in management).

First of all, we need to remember that a lot of foreign investment is what is known as ‘brownfield investment,’ that is, acquisition of existing firms by a foreign firm, rather than ‘greenfield investment’, which involves a foreign firm setting up new production facilities. Since the 1990s, brownfield investment has accounted for over half of total world foreign direct investment (FDI), even reaching 80 per cent in 2001, at the height of the international mergers and acquisitions (M&A) boom. This means that the majority of FDI involves taking control of existing firms, rather than the creation of new output and jobs. Of course, the new owners may inject better managerial and technological capabilities and revive an ailing company – as seen in the case of Nissan under Carlos Ghosn – but very often such an acquisition is made with a view to utilizing capabilities that already exist in the acquired company rather than creating new ones. And, more importantly, once your national firm is acquired by a foreign firm, the home bias of the acquiring company will in the long run impose a ceiling on how far it progresses in the internal pecking order of the acquiring company.

Even in the case of greenfield investment, home-country bias is a factor to consider. Yes, greenfield investment creates new productive capabilities, so it is by definition better than the alternative, that is, no investment. However, the question that policy-makers need to consider before accepting it is how it is going to affect the future trajectory of their national economy. Different activities have different potentials for technological innovation and productivity growth, and therefore what you do today influences what you will be doing in the future and what you will get out of it. As a popular saying among American industrial policy experts in the 1980s went, we cannot pretend that it does not matter whether you produce potato chips, wood chips or microchips. And the chance is that a foreign company is more likely to produce potato chips or wood chips than microchips in your country.

Given this, especially for a developing country, whose national firms are still underdeveloped, it may be better to restrict FDI at least in some industries and try to raise national firms so that they become credible alternative investors to foreign companies. This will make the country lose some investment in the short run, but it may enable it to have more higher-end activities within its borders in the long run. Or, even better, the developing country government can allow foreign investment under conditions that will help the country upgrade the capabilities of national firms faster – for example, by requiring joint ventures (which will promote the transfer of managerial techniques), demanding more active technology transfer, or mandating worker training.

Now, saying that foreign capital is likely to be less good for your country than your own national capital is not to say that we should always prefer national capital to foreign capital. This is because its nationality is not the only thing that determines the behaviour of capital. The intention and the capability of the capital in question also matter.

Suppose that you are thinking of selling a struggling nationally owned car company. Ideally, you want the new owner to have the willingness and the ability to upgrade the company in the long run. The prospective buyer is more likely to have the technological capabilities to do so when it is an already established automobile producer, whether national or foreign, rather than when it is finance capital, such as a private equity fund.

In recent years, private equity funds have played an increasingly important role in corporate acquisitions. Even though they have no in-house expertise in particular industries, they may, in theory, acquire a company for the long term and hire industry experts as managers and ask them to upgrade its capabilities. However, in practice, these funds usually have no intention to upgrade the acquired company for the long term. They acquire firms with a view to selling them on in three to five years after restructuring them into profitability. Such restructuring, given the time horizon, usually involves cutting costs (especially sacking workers and refraining from long-term investments), rather than raising capabilities. Such restructuring is likely to hurt the long-term prospects of the company by weakening its ability to generate productivity growth. In the worst cases, private equity funds may acquire companies with the explicit intention to engage in asset-stripping, selling the valuable assets of a company without regard to its long-term future. What the now-notorious Phoenix Venture Holdings did to the British car-maker Rover, which they had bought from BMW, is a classic example of this (the so-called ‘Phoenix Four’ became particularly notorious for paying themselves huge salaries and their friends exorbitant consultancy fees).

Of course, this is not to say that firms that are already operating in the industry will always have the intention to upgrade the acquired company for the long term either. When GM acquired a series of smaller foreign car companies – such as Sweden’s Saab and Korea’s Daewoo – during the decade before its bankruptcy in 2009, the intention was to live off the technologies accumulated by these companies, rather than to upgrade them (see Thing 18). Moreover, recently the distinction between industrial capital and finance capital has come to be blurred, with industrial companies such as GM and GE making more profits in finance than in industry (see Thing 22), so the fact that the acquiring firm operates in a particular industry is not a guarantee of a long-term commitment to that industry.

So, if a foreign company operating in the same industry is buying up your national company with a serious long-term commitment, selling it to that company may be better than selling it to your own national private equity fund. However, other things being equal, the chance is that your national company is going to act in a way that is more favourable to your national economy.

Thus, despite the globalization rhetoric, the nationality of a firm is still a key to deciding where its high-grade activities, such as R&D and strategizing, are going to be located. Nationality is not the only determinant of firm behaviour, so we need to take into account other factors, such as whether the investor has a track record in the industry concerned and how strong its long-term commitment to the acquired company really is. While a blind rejection of foreign capital is wrong, it would be very naïve to design economic policies on the myth that capital does not have national roots any more. After all, Lord Mandelson’s belatedly found reservations turn out to have a serious basis in reality.

 

 

Our economy has been fundamentally transformed during the last few decades. Especially in the rich countries, manufacturing industry, once the driving force of capitalism, is not important any more. With the natural tendency for the (relative) demand for services to rise with prosperity and with the rise of high-productivity knowledge-based services (such as banking and management consulting), manufacturing industries have gone into decline in all rich countries. These countries have entered the ‘post-industrial’ age, where most people work in services and most outputs are services. The decline of manufacturing is not only something natural that we needn’t worry about but something that we should really celebrate. With the rise of knowledge-based services, it may be better even for some developing countries to skip those doomed manufacturing activities altogether and leapfrog straight to a service-based post-industrial economy.

 

We may be living in a post-industrial society in the sense that most of us work in shops and offices rather than in factories. But we have not entered a post-industrial stage of development in the sense that industry has become unimportant. Most (although not all) of the shrinkage in the share of manufacturing in total output is not due to the fall in the absolute quantity of manufactured goods produced but due to the fall in their prices relative to those for services, which is caused by their faster growth in productivity (output per unit of input). Now, even though de-industrialization is mainly due to this differential productivity growth across sectors, and thus may not be something negative in itself, it has negative consequences for economy-wide productivity growth and for the balance of payments, which cannot be ignored. As for the idea that developing countries can largely skip industrialization and enter the post-industrial phase directly, it is a fantasy. Their limited scope for productivity growth makes services a poor engine of growth. The low tradability of services means that a more service-based economy will have a lower ability to export. Lower export earnings means a weaker ability to buy advanced technologies from abroad, which in turn leads to a slower growth.

 

One day, Jin-Gyu, my nine-year-old son (yes, that’s the one who appeared as ‘my six-year-old son’ in my earlier book Bad Samaritans – really quite a versatile actor, he is) came and asked me: ‘Daddy, is there anything that is not made in China?’ I told him that, yes, it may not look that way, but other countries still make things. I then struggled to come up with an example. I was about to mention his ‘Japanese’ Nintendo DSi game console, but then I remembered seeing ‘Made in China’ on it. I managed to tell him that some mobile phones and flat-screen TVs are made in Korea, but I could not think of many other things that a nine-year-old would recognize (he is still too young for things like BMW). No wonder China is now called the ‘workshop of the world’.

It is hard to believe, but the phrase ‘workshop of the world’ was originally coined for Britain, which today, according to Nicolas Sarkozy, the French president, has ‘no industry’. Having successfully launched the Industrial Revolution before other countries, Britain became such a dominant industrial power by the mid nineteenth century that it felt confident enough to completely liberalize its trade (see Thing 7). In 1860, it produced 20 per cent of world manufacturing output. In 1870, it accounted for 46 per cent of world trade in manufactured goods. The current Chinese share in world exports is only around 17 per cent (as of 2007), even though ‘everything’ seems to be made in China, so you can imagine the extent of British dominance then.

However, Britain’s pole position was shortlived. Having liberalized its trade completely around 1860, its relative position started declining from the 1880s, with countries such as the US and Germany rapidly catching up. It lost its leading position in the world’s industrial hierarchy by the time of the First World War, but the dominance of manufacturing in the British economy itself continued for a long time afterwards. Until the early 1970s, together with Germany, Britain had one of the world’s highest shares of manufacturing employment in total employment, at around 35 per cent. At the time, Britain was the quintessential manufacturing economy, exporting manufactured goods and importing food, fuel and raw materials. Its manufacturing trade surplus (manufacturing exports minus manufacturing imports) stayed consistently between 4 per cent and 6 per cent of GDP during the 1960s and 70s.

Since the 1970s, however, the British manufacturing sector has shrunk rapidly in importance. Manufacturing output as a share of Britain’s GDP used to be 37 per cent in 1950. Today, it accounts for only around 13 per cent. Manufacturing’s share in total employment fell from around 35 per cent in the early 1970s to just over 10 per cent. Its position in international trade has also dramatically changed. These days, Britain runs manufacturing trade deficits in the region of 2–4 per cent of GDP per year. What has happened? Should Britain be worried?

The predominant opinion is that there is nothing to worry about. To begin with, it is not as if Britain is the only country in which these things have happened. The declining shares of manufacturing in total output and employment – a phenomenon known as de-industrialization – is a natural occurrence, many commentators argue, common to all rich countries (accelerated in the British case by the finding of North Sea oil). This is widely believed to be because, as they become richer, people begin to demand more services than manufactured goods. With falling demand, it is natural that the manufacturing sector shrinks and the country enters the post-industrial stage. Many people actually celebrate the rise of services. According to them, the recent expansion of knowledge-based services with rapid productivity growth – such as finance, consulting, design, computing and information services, R&D – means that services have replaced manufacturing as the engine of growth, at least in the rich countries. Manufacturing is now a low-grade activity that developing countries such as China perform.

 

Have we really entered the post-industrial age? Is manufacturing irrelevant now? The answers are: ‘only in some ways’, and ‘no’.

It is indisputable that much lower proportions of people in the rich countries work in factories than used to be the case. There was a time in the late nineteenth and early twentieth centuries when in some countries (notably Britain and Belgium) around 40 per cent of those employed worked in the manufacturing industry. Today, the ratio is at most 25 per cent, and in some countries (especially the US, Canada and Britain) barely 15 per cent.

With so much fewer people (in proportional terms) working in factories, the nature of society has changed. We are partly formed by our work experiences (a point which most economists fail to recognize), so where and how we work influences who we are. Compared to factory workers, office workers and shop assistants do much less physical work and, not having to work with conveyor belts and other machines, have more control over their labour process. Factory workers cooperate more closely with their colleagues during work and outside work, especially through trade union activities. In contrast, people working in shops and offices tend to work on more individual bases and are not very unionized. Shop assistants and some office workers interact directly with customers, whereas factory workers never see their customers. I am not enough of a sociologist or a psychologist to say anything profound in this regard, but all this means that people in today’s rich countries not only work differently from but are different from their parents and grandparents. In this way, today’s rich countries have become post-industrial societies in the social sense.

However, they have not become post-industrial in the economic sense. Manufacturing still plays the leading role in their economies. In order to see this point, we first need to understand why de-industrialization has happened in the rich countries.

A small, but not negligible, part of de-industrialization is due to optical illusions, in the sense that it reflects changes in statistical classification rather than changes in real activities. One such illusion is due to the outsourcing of some activities that are really services in their physical nature but used to be provided in-house by manufacturing firms and thus classified as manufacturing output (e.g., catering, cleaning, technical supports). When they are outsourced, recorded service outputs increase without a real increase in service activities. Even though there is no reliable estimate of its magnitude, experts agree that outsourcing has been a significant source of de-industrialization in the US and Britain, especially during the 1980s. In addition to the outsourcing effect, the extent of manufacturing contraction is exaggerated by what is called the ‘reclassification effect’. A UK government report estimates that up to 10 per cent of the fall in manufacturing employment between 1998 and 2006 in the UK may be accounted for by some manufacturing firms, seeing their service activities becoming predominant, applying to the government statistical agency to be reclassified as service firms, even when they are still engaged in some manufacturing activities.

One cause of genuine de-industrialization has recently attracted a lot of attention. It is the rise of manufacturing imports from low-cost developing countries, especially China. However dramatic it may look, it is not the main explanation for de-industrialization in the rich countries. China’s exports did not make a real impact until the late 1990s, but the de-industrialization process had already started in the 1970s in most rich countries. Most estimates show that the rise of China as the new workshop of the world can explain only around 20 per cent of de-industrialization in the rich countries that has happened so far.

Many people think that the remaining 80 per cent or so can be largely explained by the natural tendency of the (relative) demand for manufactured goods to fall with rising prosperity. However, a closer look reveals that this demand effect is actually very small. It looks as if we are spending ever higher shares of our income on services not because we are consuming ever more services in absolute terms but mainly because services are becoming ever more expensive in relative terms.

With the (inflation-adjusted) amount of money you paid to get a PC ten years ago, today you can probably buy three, if not four, computers of equal or even greater computing power (and certainly smaller size). As a result, you probably have two, rather than just one, computers. But, even with two computers, the portion of your income that you spend on computers has gone down quite a lot (for the sake of argument, I am assuming that your income, after adjusting for inflation, is the same). In contrast, you are probably getting the same number of haircuts as you did ten years ago (if you haven’t gone thin on top, that is). The price of haircuts has probably gone up somewhat, so the proportion of your income that goes to your haircuts is greater than it was ten years ago. The result is that it looks as if you are spending a greater (smaller) portion of your income on haircuts (computers) than before, but the reality is that you are actually consuming more computers than before, while your consumption of haircuts is the same.

Indeed, if you adjust for the changes in relative prices (or, to use technical jargon, if you measure things in constant prices), the decline of manufacturing in the rich countries has been far less steep than it appears to be. For example, in the case of Britain, the share of manufacturing in total output, without counting the relative price effects (to use the jargon, in current prices), fell by over 40 per cent between 1955 and 1990 (from 37 per cent to 21 per cent). However, when taking the relative price effects into account, the fall was only by just over 10 per cent (from 27 per cent to 24 per cent). In other words, the real demand effect – that is the demand effect after taking relative price changes into account – is small.

Then why are the relative prices of manufactured goods falling? It is because manufacturing industries tend to have faster productivity growth than services. As the output of the manufacturing sector increases faster than the output of the service sector, the prices of the manufactured goods relative to those of services fall. In manufacturing, where mechanization and the use of chemical processes are much easier, it is easier to raise productivity than in services. In contrast, by their very nature, many service activities are inherently impervious to productivity increase without diluting the quality of the product.

In some cases, the very attempt to increase productivity will destroy the product itself. If a string quartet trots through a twenty-seven-minute piece in nine minutes, would you say that its productivity has trebled?

For some other services, the apparent higher productivity is due to the debasement of the product. A teacher can raise her apparent productivity by four times by having four times as many pupils in her classroom, but the quality of her ‘product’ has been diluted by the fact that she cannot pay as much individual attention as before. A lot of the increases in retail service productivity in countries such as the US and Britain has been bought by lowering the quality of the retail service itself while ostensibly offering cheaper shoes, sofas and apples: there are fewer sales assistants at shoe stores, so you wait twenty minutes instead of five; you have to wait four weeks, rather than two, for the delivery of your new sofa and probably also have to take a day off work because they will only deliver ‘sometime between 8 a.m. and 6 p.m.’; you spend much more time than before driving to the new supermarket and walking through the now longer aisles when you get there, because those apples are cheaper than in the old supermarket only because the new supermarket is in the middle of nowhere and thus can have more floor space.

There are some service activities, such as banking, which have greater scope for productivity increase than other services. However, as revealed by the 2008 financial crisis, much of the productivity growth in those activities was due not to a real rise in their productivity (e.g., reduction in trading costs due to better computers) but to financial innovations that obscured (rather than genuinely reduced) the riskiness of financial assets, thereby allowing the financial sector to grow at an unsustainably rapid rate (see Thing 22).

To sum up, the fall in the share of manufacturing in total output in the rich countries is not largely due to the fall in (relative) demand for manufactured goods, as many people think. Nor is it due mainly to the rise of manufactured exports from China and other developing countries, although that has had big impacts on some sectors. It is instead the falling relative prices of the manufactured goods due to faster growth in productivity in the manufacturing sector that is the main driver of the de-industrialization process. Thus, while the citizens of the rich countries may be living in post-industrial societies in terms of their employment, the importance of manufacturing in terms of production in those economies has not been diminished to the extent that we can declare a post-industrial age.

 

But if de-industrialization is due to the very dynamism of a country’s manufacturing sector, isn’t it a good thing?

Not necessarily. The fact that de-industrialization is mainly caused by the comparative dynamism of the manufacturing sector vis-à-vis the service sector does not tell us anything about how well it is doing compared to its counterparts in other countries. If a country’s manufacturing sector has slower productivity growth than its counterparts in other countries, it will become internationally uncompetitive, leading to balance of payments problems in the short run and falling standards of living in the long term. In other words, de-industrialization may be accompanied by either economic success or failure. Countries should not be lulled into a false sense of security by the fact that de-industrialization is due to comparative dynamism of the manufacturing sector, as even a manufacturing sector that is very undynamic by international standards can be (and usually is) more dynamic than the service sector of the same country.

Whether or not a country’s manufacturing sector is dynamic by international standards, the shrinkage of the relative weight of the manufacturing sector has a negative impact on productivity growth. As the economy becomes dominated by the service sector, where productivity growth is slower, productivity growth for the whole economy will slow down. Unless we believe (as some do) that the countries experiencing de-industrialization are now rich enough not to need more productivity growth, productivity slowdown is something that countries should get worried about – or at least reconcile themselves to.

De-industrialization also has a negative effect on a country’s balance of payments because services are inherently more difficult to export than manufactured goods. A balance of payments deficit means that the country cannot ‘pay its way’ in the world. Of course, a country can plug the hole through foreign borrowing for a while, but eventually it will have to lower the value of its currency, thereby reducing its ability to import and thus its living standard.

At the root of the low ‘tradability’ of services lies the fact that, unlike manufactured goods that can be shipped anywhere in the world, most services require their providers and consumers to be in the same location. No one has yet invented ways to provide a haircut or house-cleaning long-distance. Obviously, this problem will be solved if the service provider (the hairdresser or the cleaner in the above examples) can move to the customer’s country, but that in most cases means immigration, which most countries restrict heavily (see Thing 3). Given this, a rising share of services in the economy means that the country, other things being equal, will have lower export earnings. Unless the exports of manufactured goods rise disproportionately, the country won’t be able to pay for the same amount of imports as before. If its de-industrialization is of a negative kind accompanied by weakening international competitiveness, the balance of payments problem could be even more serious, as the manufacturing sector then won’t be able to increase its exports.

Not all services are equally non-tradable. The knowledge-based services that I mentioned earlier – banking, consulting, engineering, and so on – are highly tradable. For example, in Britain since the 1990s, exports of knowledge-based services have played a crucial role in plugging the balance of payments gap left behind by de-industrialization (and the fall in North Sea oil exports, which had enabled the country – just – to survive the negative balance of payments consequences of de-industrialization during the 1980s).

However, even in Britain, which is most advanced in the exports of these knowledge-based services, the balance of payments surplus generated by those services is well below 4 per cent of GDP, just enough to cover the country’s manufacturing trade deficits. With the likely strengthening of global financial regulation as a consequence of the 2008 world financial crisis, it is unlikely that Britain can maintain this level of trade surplus in finance and other knowledge-based services in the future. In the case of the US, supposedly another model post-industrial economy, the trade surplus in knowledge-based services is actually less than 1 per cent of GDP – nowhere near enough to make up for its manufacturing trade deficits, which are around 4 per cent of GDP. The US has been able to maintain such a large manufacturing trade deficit only because it could borrow heavily from abroad – an ability that can only shrink in the coming years, given the changes in the world economy – and not because the service sector stepped in to fill the gap, as in the British case. Moreover, it is questionable whether the strengths of the US and Britain in the knowledge-based services can be maintained over time. In services such as engineering and design, where insights gained from the production process are crucial, a continuous shrinkage of the industrial base will lead to a decline in the quality of their (service) products and a consequent loss in export earnings.

If Britain and the US – two countries that are supposed to be the most developed in the knowledge-based services – are unlikely to meet their balance of payments needs in the long run through the exports of these services, it is highly unlikely that other countries can.

 

Believing de-industrialization to be the result of the change of our engine of growth from manufacturing to services, some have argued that developing countries can largely skip industrialization and move directly to the service economy. Especially with the rise of service offshoring, this view has become very popular among some observers of India. Forget all those polluting industries, they say, why not go from agriculture to services directly? If China is the workshop of the world, the argument goes, India should try to become the ‘office of the world’.

However, it is a fantasy to think that a poor country can develop mainly on the basis of the service sector. As pointed out earlier, the manufacturing sector has an inherently faster productivity growth than the service sector. To be sure, there are some service industries that have rapid productivity growth potential, notably the knowledge-based services that I mentioned above. However, these are service activities that mainly serve manufacturing firms, so it is very difficult to develop those industries without first developing a strong manufacturing base. If you base your development largely on services from early on, your long-term productivity growth rate is going to be much slower than when you base it on manufacturing.

Moreover, we have already seen that, given that services are much less tradable, countries specializing in services are likely to face much more serious balance of payments problems than countries that specialize in manufacturing. This is bad enough for a developed country, where balance of payments problems will lower standards of living in the long run. However, it is seriously detrimental for a developing country. The point is that, in order to develop, a developing country has to import superior technologies from abroad (either in the form of machines or in the form of technology licensing). Therefore, when it has a balance of payments problem, its very ability to upgrade and thus develop its economy by deploying superior technologies is hampered.

As I say these negative things about economic development strategies based on services, some of you may say: what about countries like Switzerland and Singapore? Haven’t they developed on the basis of services?

However, these economies are not what they are reported to be either. They are in fact manufacturing success stories. For example, many people think that Switzerland lives off the stolen money deposited in its banks by Third World dictators or by selling cowbells and cuckoo clocks to Japanese and American tourists, but it is actually one of the most industrialized economies in the world. We don’t see many Swiss manufactured products around because the country is small (around 7 million people), which makes the total amount of Swiss manufactured goods rather small, and because its producers specialize in producer goods, such as machinery and industrial chemicals, rather than consumer goods that are more visible. But in per capita terms, Switzerland has the highest industrial output in the world (it could come second after Japan, depending on the year and the data you look at). Singapore is also one of the five most industrialized economies in the world (once again, measured in terms of manufacturing value-added per head). Finland and Sweden make up the rest of the top five. Indeed, except for a few places such as the Seychelles that has a very small population and exceptional resources for tourism (85,000 people with around $9,000 per capita income), no country has so far achieved even a decent (not to speak of high) living standard by relying on services and none will do so in the future.

To sum up, even the rich countries have not become unequivocally post-industrial. While most people in those countries do not work in factories any more, the manufacturing sector’s importance in their production systems has not fallen very much, once we take into account the relative price effects. But even if de-industrialization is not necessarily a symptom of industrial decline (although it often is), it has negative effects for long-term productivity growth and the balance of payments, both of which need reckoning. The myth that we now live in a post-industrial age has made many governments ignore the negative consequences of de-industrialization.

As for the developing countries, it is a fantasy to think that they can skip industrialization and build prosperity on the basis of service industries. Most services have slow productivity growth and most of those services that have high productivity growth are services that cannot be developed without a strong manufacturing sector. Low tradability of services means that a developing country specializing in services will face a bigger balance of payments problem, which for a developing country means a reduction in its ability to upgrade its economy. Post-industrial fantasies are bad enough for the rich countries, but they are positively dangerous for developing countries.

 

 

Despite its recent economic problems, the US still enjoys the highest standard of living in the world. At market exchange rates, there are several countries that have a higher per capita income than the US. However, if we consider the fact that the same dollar (or whatever common currency we choose) can buy more goods and services in the US than in other rich countries, the US turns out to have the highest living standard in the world, barring the mini-city-state of Luxemburg. This is why other countries seek to emulate the US, illustrating the superiority of the free-market system, which the US most closely (if not perfectly) represents.

 

The average US citizen does have greater command over goods and services than his counterpart in any other country in the world except Luxemburg. However, given the country’s high inequality, this average is less accurate in representing how people live than the averages for other countries with a more equal income distribution. Higher inequality is also behind the poorer health indicators and worse crime statistics of the US. Moreover, the same dollar buys more things in the US than in most other rich countries mainly because it has cheaper services than in other comparable countries, thanks to higher immigration and poorer employment conditions. Furthermore, Americans work considerably longer than Europeans. Per hour worked, their command over goods and services is smaller than that of several European countries. While we can debate which is a better lifestyle – more material goods with less leisure time (as in the US) or fewer material goods with more leisure time (as in Europe) – this suggests that the US does not have an unambiguously higher living standard than comparable countries.

 

Between 1880 and 1914, nearly 3 million Italians migrated to the US. When they arrived, many of them were bitterly disappointed. Their new home was not the paradise they had thought it would be. It is said that many of them wrote back home, saying ‘not only are the roads not paved with gold, they are not paved at all; in fact, we are the ones who are supposed to pave them’.

Those Italian immigrants were not alone in thinking that the US is where dreams come true. The US became the richest country in the world only around 1900, but even in the early days of its existence, it had a strong hold on the imagination of poor people elsewhere. In the early nineteenth century, US per capita income was still only around the European average and something like 50 per cent lower than that of Britain and the Netherlands. But poor Europeans still wanted to move there because the country had an almost unlimited supply of land (well, if you were willing to push out a few native Americans) and an acute labour shortage, which meant wages three or four times higher than those in Europe (see Thing 7). Most importantly, the lack of feudal legacy meant that the country had much higher social mobility than the Old World countries, as celebrated in the idea of the American dream.

It is not just prospective immigrants who are attracted to the US. Especially in the last few decades, businessmen and policy-makers around the world have wanted, and often tried, to emulate the US economic model. Its free enterprise system, according to admirers of the US model, lets people compete without limits and rewards the winners without restrictions imposed by the government or by misguided egalitarian culture. The system therefore creates exceptionally strong incentives for entrepreneurship and innovation. Its free labour market, with easy hiring and firing, allows its enterprises to be agile and thus more competitive, as they can redeploy their workers more quickly than their competitors, in response to changing market conditions. With entrepreneurs richly rewarded and workers having to adapt quickly, the system does create high inequality. However, its proponents argue, even the ‘losers’ in this game willingly accept such outcomes because, given the country’s high social mobility, their own children could be the next Thomas Edison, J. P. Morgan or Bill Gates. With such incentives to work hard and exercise ingenuity, no wonder the country has been the richest in the world for the last century.

 

Actually, this is not quite true. The US is not the richest country in the world any more. Now several European countries have higher per capita incomes. The World Bank data tell us that the per capita income of the US in 2007 was $46,040. There were seven countries with higher per capita income in US dollar terms – starting with Norway ($76,450) at the top, through Luxemburg, Switzerland, Denmark, Iceland, Ireland and ending with Sweden ($46,060). Discounting the two mini-states of Iceland (311,000 people) and Luxemburg (480,000 people), this makes the US only the sixth richest country in the world.

But, some of you may say, that cannot be right. When you go to the US, you just see that people there live better than the Norwegians or the Swiss do.

One reason why we get that impression is that the US is much more unequal than the European countries and therefore looks more prosperous to foreign visitors than it really is – foreign visitors to any country rarely get to see the deprived parts, of which the US has many more than Europe. But even ignoring this inequality factor, there is a good reason why most people think that the US has a higher living standard than European countries.

You may have paid 35 Swiss francs, or $35, for a 5-mile (or 8-km) taxi ride in Geneva, when a similar ride in Boston would have cost you around $15. In Oslo, you may have paid 550 kroner, or $100, for a dinner that could not possibly have been more than $50, or 275 kroner, in St Louis. The reverse would have been the case if you had changed your dollars into Thai baht or Mexican pesos on your holidays. Having your sixth back massage of the week or ordering the third margarita before dinner, you would have felt as if your $100 had been stretched into $200, or even $300 (or was that the alcohol?). If market exchange rates accurately reflected differences in living standards between countries, these kinds of things should not happen.

Why are there such huge differences between the things that you can buy in different countries with what should be the same sums of money? Such differences exist basically because market exchange rates are largely determined by the supply and demand for internationally traded goods and services (although in the short run currency speculation can influence market exchange rates), while what a sum of money can buy in a particular country is determined by the prices of all goods and services, and not just those that are internationally traded.

The most important among the non-traded things are person-to-person labour services, such as driving taxis and serving meals in restaurants. Trade in such services requires international migration, but that is severely limited by immigration control, so the prices of such labour services end up being hugely different across countries (see Things 3 and 9). In other words, things such as taxi rides and meals are expensive in countries such as Switzerland and Norway because they have expensive workers. They are cheap in countries with cheap workers, such as Mexico and Thailand. When it comes to internationally traded things such as TVs or mobile phones, their prices are basically the same in all countries, rich and poor.

In order to take into account the differential prices of non-traded goods and services across countries, economists have come up with the idea of an ‘international dollar’. Based on the notion of purchasing power parity (PPP) – that is, measuring the value of a currency according to how much of a common consumption basket it can buy in different countries – this fictitious currency allows us to convert incomes of different countries into a common measure of living standards.

The result of converting the incomes of different countries into the international dollar is that the incomes of rich countries tend to become lower than their incomes at market exchange rates, while those of poor countries tend to become higher. This is because a lot of what we consume is services, which are much more expensive in the rich countries. In some cases, the difference between market exchange rate income and PPP income is not great. According to the World Bank data, the market exchange rate income of the US was $46,040 in 2007, while its PPP income was more or less the same at $45,850. In the case of Germany, the difference between the two was greater, at $38,860 vs. $33,820 (a 15 per cent difference, so to speak, although we cannot really compare the two numbers this directly). In the case of Denmark, the difference was nearly 50 per cent ($54,910 vs. $36,740). In contrast, China’s 2007 income more than doubles from $2,360 to $5,370 and India’s by nearly three times from $950 to $2,740, when calculated in PPP terms.

Now, the calculation of each currency’s exchange rate with the (fictitious) international dollar is not a straightforward affair, not least because we have to assume that all countries consume the same basket of goods and services, which is patently not the case. This makes the PPP incomes extremely sensitive to the methodologies and the data used. For example, when the World Bank changed its method of estimating PPP incomes in 2007, China’s PPP income per capita fell by 44 per cent (from $7,740 to $5,370), while Singapore’s rose by 53 per cent (from $31,710 to $48,520) overnight.

Despite these limits, a country’s income in international dollars probably gives us a better idea of its living standard than does its dollar income at the market exchange rate. And if we calculate incomes of different countries in international dollars, the US (almost) comes back to the top of the world. It depends on the estimate, but Luxemburg is the only country that has a higher PPP income per capita than that of the US in all estimates. So, as long as we set aside the tiny city-state of Luxemburg, with less than half a million people, the average US citizen can buy the largest amount of goods and services in the world with her income.

Does this allow us to say that the US has the highest living standard in the world? Perhaps. But there are quite a few things we have to consider before we jump to that conclusion.

 

To begin with, having a higher average income than other countries does not necessarily mean that all US citizens live better than their foreign counterparts. Whether this is the case depends on the distribution of income. Of course, in no country does the average income give the right picture of how people live, but in a country with higher inequality it is likely to be particularly misleading. Given that the US has by far the most unequal distribution of income among the rich countries, we can safely guess that the US per capita income overstates the actual living standards of more of its citizens than in other countries. And this conjecture is indirectly supported by other indicators of living standards. For example, despite having the highest average PPP income, the US ranks only around thirtieth in the world in health statistics such as life expectancy and infant mortality (OK, the inefficiency of the US healthcare system contributes to it, but let’s not get into that). The much higher crime rate than in Europe or Japan – in per capita terms, the US has eight times more people in prison than Europe and twelve times more than Japan – shows that there is a far bigger underclass in the US.

Second, the very fact that its PPP income is more or less the same as its market exchange rate income is proof that the higher average living standard in the US is built on the poverty of many. What do I mean by this? As I have pointed out earlier, it is normal for a rich country’s PPP income to be lower, sometimes significantly, than its market exchange rate income, because it has expensive service workers. However, this does not happen to the US, because, unlike other rich countries, it has cheap service workers. To begin with, there is a large inflow of low-wage immigrants from poor countries, many of them illegal, which makes them even cheaper. Moreover, even the native workers have much weaker fallback positions in the US than in European countries of comparable income level. Because they have much less job security and weaker welfare supports, US workers, especially the non-unionized ones in the service industries, work for lower wages and under inferior conditions than do their European counterparts. This is why things like taxi rides and meals at restaurants are so much cheaper in the US than in other rich countries. This is great when you are the customer, but not if you are the taxi driver or the waitress. In other words, the higher purchasing power of average US income is bought at the price of lower income and inferior working conditions for many US citizens.

Last but not least, in comparing living standards across countries, we should not ignore the differences in working hours. Even if someone is earning 50 per cent more money than I earn, you wouldn’t say that he has a higher living standard than I do, if that person has to work double the number of hours that I do. The same applies to the US. The Americans, befitting their reputation for workaholism, work longer hours than the citizens of any other country that has a per capita income of more than $30,000 at market exchange rate in 2007 (Greece being the poorest of the lot, at just under $30,000 per capita income). Americans work 10 per cent longer than most Europeans and around 30 per cent longer than the Dutch and the Norwegians. According to a calculation by the Icelandic economist Thorvaldur Gylfason, in terms of income (in PPP terms) per hour worked in 2005, the US ranked only eighth – after Luxemburg, Norway, France (yes, France, that nation of loungers), Ireland, Belgium, Austria, and the Netherlands – and was very closely followed by Germany. In other words, per unit of effort, the Americans are not getting as high a living standard as their counterparts in competitor nations. They make up for this lower productivity through much longer hours.

Now, it is perfectly reasonable for someone to argue that she wants to work longer hours if that is necessary to have a higher income – she would rather have another TV than one more week of holiday. And who am I, or anyone else, to say that the person got her priority wrong?

However, it is still legitimate to ask whether people who work longer hours even at very high levels of income are doing the right thing. Most people would agree that, at a low level of income, an increase in income is likely to improve your quality of life, even if it means longer working hours. At this level, even if you have to work longer in your factory, higher income is likely to bring a higher overall quality of life, by improving your health (through better food, heating, hygiene and healthcare) and by reducing the physical demands of household work (through more household appliances, piped water, gas and electricity – see Thing 4). However, above a certain level of income, the relative value of material consumption vis-à-vis leisure time is diminished, so earning a higher income at the cost of working longer hours may reduce the quality of your life.

More importantly, the fact that the citizens of a country work longer than others in comparable countries does not necessarily mean that they like working longer hours. They may be compelled to work long hours, even if they actually want to take longer holidays. As I pointed out above, how long a person works is affected not only by his own preference regarding work – leisure balance but also by things such as welfare provision, protection of worker rights and union power. Individuals have to take these things as given, but nations have a choice over them. They can rewrite the labour laws, beef up the welfare state and effect other policy changes to make it less necessary for individuals to work long hours.

Much of the support for the American model has been based on the ‘fact’ that the US has the highest living standard in the world. While there is no question that the US has one of the highest living standards in the world, its alleged superiority looks much weaker once we have a broader conception of living standards than what the average income of a country will buy. Higher inequality in the US means that its average income is less indicative of the living standards of its citizens than in other countries. This is reflected in indicators such as health and crime, where the US performs much worse than comparable countries. The higher purchasing power of US citizens (compared to the citizens of other rich countries) is owed in large part to the poverty and insecurity of many of their fellow citizens, especially in service industries. The Americans also work considerably longer than their counterparts in competitor nations. Per hour worked, US income is lower than that of several European countries, even in purchasing power terms. It is debatable that that can be described as having a higher living standard.

There is no simple way to compare living standards across countries. Per capita income, especially in purchasing power terms, is arguably the most reliable indicator. However, by focusing just on how many goods and services our income can buy, we miss out a lot of other things that constitute elements of the ‘good life’, such as the amount of quality leisure time, job security, freedom from crime, access to healthcare, social welfare provisions, and so on. While different individuals and countries will definitely have different views on how to weigh these indicators against each other and against income figures, non-income dimensions should not be ignored, if we are to build societies where people genuinely ‘live well’.

 

 

Africa is destined for underdevelopment. It has a poor climate, which leads to serious tropical disease problems. It has lousy geography, with many of its countries landlocked and surrounded by countries whose small markets offer limited export opportunities and whose violent conflicts spill into neighbouring countries. It has too many natural resources, which make its people lazy, corrupt and conflict-prone. African nations are ethnically divided, which renders them difficult to manage and more likely to experience violent conflicts. They have poor-quality institutions that do not protect investors well. Their culture is bad – people do not work hard, they do not save and they cannot cooperate with each other. All these structural handicaps explain why, unlike other regions of the world, the continent has failed to grow even after it has implemented significant market liberalization since the 1980s. There is no other way forward for Africa than being propped up by foreign aid.

 

Africa has not always been stagnant. In the 1960s and 70s, when all the supposed structural impediments to growth were present and often more binding, it actually posted a decent growth performance. Moreover, all the structural handicaps that are supposed to hold back Africa have been present in most of today’s rich countries – poor climate (arctic and tropical), landlockedness, abundant natural resources, ethnic divisions, poor institutions and bad culture. These structural conditions seem to act as impediments to development in Africa only because its countries do not yet have the necessary technologies, institutions and organizational skills to deal with their adverse consequences. The real cause of African stagnation in the last three decades is free-market policies that the continent has been compelled to implement during the period. Unlike history or geography, policies can be changed. Africa is not destined for underdevelopment.

 

Sarah Palin, the Republican vice-presidential candidate in the 2008 US election, is reported to have thought that Africa was a country, rather than a continent. A lot of people wondered where she got that idea, but I think I know the answer. It was from the 1977 Disney animation The Rescuers.

The Rescuers is about a group of mice called the Rescue Aid Society going around the world, helping animals in trouble. In one scene, there is an international congress of the society, with mouse delegates from all sorts of countries in their traditional costumes and appropriate accents (if they happen to speak). There is the French mouse in his beret, the German mouse in her sombre blue dress and the Turkish mouse in his fez. And then there is the mouse in his fur hat and beard representing Latvia and the female mouse representing, well, Africa.

Perhaps Disney didn’t literally think that Africa was a country, but allocating one delegate each to a country with 2.2 million people and to a continent of more than 900 million people and nearly sixty countries (the exact number depends on whether you recognize entities such as Somaliland and Western Sahara as countries) tells you something about its view of Africa. Like Disney, many people see Africa as an amorphous mass of countries suffering from the same hot weather, tropical diseases, grinding poverty, civil war and corruption.

While we should be careful not to lump all African countries together, there is no denying that most African countries are very poor – especially if we confine our interest to Sub-Saharan Africa (or ‘black’ Africa), which is really what most people mean when they say Africa. According to the World Bank, the average per capita income of Sub-Saharan Africa was estimated to be $952 in 2007. This is somewhat higher than the $880 of South Asia (Afghanistan, Bangladesh, Bhutan, India, Maldives, Nepal, Pakistan and Sri Lanka), but lower than that of any other region of the world.

What is more, many people talk of Africa’s ‘growth tragedy’. Unlike South Asia, whose growth rates have picked up since the 1980s, Africa seems to be suffering from ‘a chronic failure of economic growth’. Sub-Saharan Africa’s per capita income today is more or less the same as what it was in 1980. Even more worrying is the fact that this lack of growth seems to be due not mainly to poor policy choices (after all, like many other developing countries, countries in the region have implemented free-market reforms since the 1980s) but mainly to the handicaps handed down to them by nature and history and thus extremely difficult, if not impossible, to change.

The list of supposed ‘structural’ handicaps that are holding Africa back is impressive.

First, there are all those conditions defined by nature – climate, geography and natural resources. Being too close to the equator, it has rampant tropical diseases, such as malaria, which reduce worker productivity and raise healthcare costs. Being landlocked, many African countries find it difficult to integrate into the global economy. They are in ‘bad neighbourhoods’ in the sense that they are surrounded by other poor countries that have small markets (which restrict their trading opportunities) and, frequently, violent conflicts (which often spill over into neighbouring countries). African countries are also supposed to be ‘cursed’ by their abundant natural resources. It is said that resource abundance makes Africans lazy – because they ‘can lie beneath a coconut tree and wait for the coconut to fall’, as a popular expression of this idea goes (although those who say that obviously have not tried it; you risk having your head smashed). ‘Unearned’ resource wealth is also supposed to encourage corruption and violent conflicts over the spoils. The economic successes of resource-poor East Asian countries, such as Japan and Korea, are often cited as cases of ‘reverse resource curse’.

Not just nature but Africa’s history is also supposed to be holding it back. African nations are ethnically too diverse, which causes people to be distrustful of each other and thus makes market transactions costly. It is argued that ethnic diversity may encourage violent conflicts, especially if there are a few equally strong groups (rather than many small groups, which are more difficult to organize). The history of colonialism is thought to have produced low-quality institutions in most African countries, as the colonizers did not want to settle in countries with too many tropical diseases (so there is an interaction between climate and institutions) and thus installed only the minimal institutions needed for resource extraction, rather than for the development of the local economy. Some even venture that African culture is bad for economic development – Africans do not work hard, do not plan for the future and cannot cooperate with each other.

Given all this, Africa’s future prospects seem bleak. For some of these structural handicaps, any solution seems unachievable or unacceptable. If being landlocked, being too close to the equator and sitting in a bad neighbourhood are holding Uganda back, what should it do? Physically moving a country is not an option, so the only feasible answer is colonialism – that is, Uganda should invade, say, Norway, and move all the Norwegians to Uganda. If having too many ethnic groups is bad for development, should Tanzania, which has one of the greatest ethnic diversities in the world, indulge in a spot of ethnic cleansing? If having too many natural resources hampers growth, should the Democratic Republic of Congo try to sell the portions of its land with mineral deposits to, say, Taiwan so that it can pass on the natural resource curse to someone else? What should Mozambique do if its colonial history has left it with bad institutions? Should it invent a time machine and fix that history? If Cameroon has a culture that is bad for economic development, should it start some mass brain-washing programme or put people in some re-education camp, as the Khmer Rouge did in Cambodia?

All of these policy conclusions are either physically impossible (moving a country, inventing a time machine) or politically and morally unacceptable (invasion of another country, ethnic cleansing, re-education camps). Therefore, those who believe in the power of these structural handicaps but find these extreme solutions unacceptable argue that African countries should be put on some kind of permanent ‘disability benefit’ through foreign aid and extra help with international trade (e.g., rich countries lowering their agricultural protection only for African – and other similarly poor and structurally disadvantaged – countries).

But is there any other way for Africa’s future development beyond accepting its fate or relying on outside help? Do African countries have no hope of standing on their own feet?

 

One question that we need to ask before we try to explain Africa’s growth tragedy and explore possible ways to overcome it is whether there is indeed such a tragedy. And the answer is ‘no’. The lack of growth in the region has not been chronic.

During the 1960s and 70s, per capita income in Sub-Saharan Africa grew at a respectable rate. At around 1.6 per cent, it was nowhere near the ‘miracle’ growth rate of East Asia (5–6 per cent) or even that of Latin America (around 3 per cent) during the period. However, this is not a growth rate to be sniffed at. It compares favourably with the rates of 1–1.5 per cent achieved by today’s rich countries during their Industrial ‘Revolution’ (roughly 1820–1913).

The fact that Africa grew at a respectable rate before the 1980s suggests that the ‘structural’ factors cannot be the main explanation of the region’s (what in fact is recent) growth failure. If they were, African growth should always have been non-existent. It is not as if the African countries suddenly moved to the tropics or some seismic activity suddenly made some of them landlocked. If the structural factors were so crucial, African economic growth should have accelerated over time, as at least some of those factors would have been weakened or eliminated. For example, poor-quality institutions left behind by the colonists could have been abandoned or improved. Even ethnic diversity could have been reduced through compulsory education, military service and mass media, in the same way in which France managed to turn ‘peasants into Frenchmen’, as the title of a classic 1976 book by the American historian Eugen Weber goes. However, this is not what has happened – African growth suddenly collapsed since the 1980s.

So, if the structural factors have always been there and if their influences would have, if anything, diminished over time, those factors cannot explain why Africa used to grow at a decent rate in the 1960s and 70s and then suddenly failed to grow. The sudden collapse in growth must be explained by something that happened around 1980. The prime suspect is the dramatic change in policy direction around the time.

Since the late 1970s (starting with Senegal in 1979), Sub-Saharan African countries were forced to adopt free-market, free-trade policies through the conditions imposed by the so-called Structural Adjustment Programs (SAPs) of the World Bank and the IMF (and the rich countries that ultimately control them). Contrary to conventional wisdom, these policies are not good for economic development (see Thing 7). By suddenly exposing immature producers to international competition, these policies led to the collapse of what little industrial sectors these countries had managed to build up during the 1960s and 70s. Thus, having been forced back into relying on exports of primary commodities, such as cocoa, coffee and copper, African countries have continued to suffer from the wild price fluctuations and stagnant production technologies that characterize most such commodities. Furthermore, when the SAPs demanded a rapid increase in exports, African countries, with technological capabilities only in a limited range of activities, ended up trying to export similar things – be they traditional products such as coffee and cocoa or new products such as cut flowers. The result was often a collapse of prices in those commodities due to a large increase in their supplies, which sometimes meant that these countries were exporting more in quantity but earning less in revenue. The pressure on governments to balance their budgets led to cuts in expenditures whose impacts are slow to show, such as infrastructure. Over time, however, the deteriorating quality of infrastructure disadvantaged African producers even more, making their ‘geographical disadvantages’ loom even larger.

The result of the SAPs – and their various later incarnations, including today’s PRSPs (Poverty Reduction Strategy Papers) – was a stagnant economy that has failed to grow (in per capita terms) for three decades. During the 1980s and 90s, per capita income in Sub-Saharan Africa fell at the rate of 0.7 per cent per year. The region finally started to grow in the 2000s, but the contraction of the preceding two decades meant that the average annual growth rate of per capita income in Sub-Saharan Africa between 1980 and 2009 was 0.2 per cent. So, after nearly thirty years of using ‘better’ (that is, free-market) policies, its per capita income is basically at the same level as it was in 1980.

So, the so-called structural factors are really scapegoats wheeled out by free-market economists. Seeing their favoured policies failing to produce good outcomes, they had to find other explanations for Africa’s stagnation (or retrogression, if you don’t count the last few years of growth spike due to commodity boom, which has come to an end). It was unthinkable for them that such ‘correct’ policies could fail. It is no coincidence that structural factors came to be cited as the main explanations of poor African economic performance only after growth evaporated in the early 1980s.

 

Pointing out that the above-mentioned structural variables were invoked in an attempt to save free-market economics from embarrassment does not mean that they are irrelevant. Many of the theories offered as to how a particular structural variable affects economic outcome do make sense. Poor climate can hamper development. Being surrounded by poor and conflict-ridden countries limits export opportunities and makes cross-border spill-over of conflicts more likely. Ethnic diversity or resource bonanzas can generate perverse political dynamics. However, these outcomes are not inevitable.

To begin with, there are many different ways in which those structural factors can play out. For example, abundant natural resources can create perverse outcomes, but can also promote development. If that weren’t the case, we wouldn’t consider the poor performances of resource-rich countries to be perverse in the first place. Natural resources allow poor countries to earn the foreign exchanges with which they can buy advanced technologies. Saying that those resources are a curse is like saying that all children born into a rich family will fail in life because they will get spoilt by their inherited wealth. Some do so exactly for this reason, but there are many others who take advantage of their inheritance and become even more successful than their parents. The fact that a factor is structural (that is, it is given by nature or history) does not mean that the outcome of its influence is predetermined.

Indeed, the fact that all those structural handicaps are not insurmountable is proven by the fact that most of today’s rich countries have developed despite suffering from similar handicaps.

Let us first take the case of the climate. Tropical climate is supposed to cripple economic growth by creating health burdens due to tropical diseases, especially malaria. This is a terrible problem, but surmountable. Many of today’s rich countries used to have malaria and other tropical diseases, at least during the summer – not just Singapore, which is bang in the middle of the tropics, but also Southern Italy, the Southern US, South Korea and Japan. These diseases do not matter very much any more only because these countries have better sanitation (which has vastly reduced their incidence) and better medical facilities, thanks to economic development. A more serious criticism of the climate argument is that frigid and arctic climates, which affect a number of rich countries, such as Finland, Sweden, Norway, Canada and parts of the US, impose burdens as economically costly as tropical ones – machines seize up, fuel costs skyrocket, and transportation is blocked by snow and ice. There is no a priori reason to believe that cold weather is better than hot weather for economic development. The cold climate does not hold those countries back because they have the money and the technologies to deal with them (the same can be said of Singapore’s tropical climate). So blaming Africa’s underdevelopment on climate is confusing the cause of underdevelopment with its symptoms – poor climate does not cause underdevelopment; a country’s inability to overcome its poor climate is merely a symptom of underdevelopment.

In terms of geography, the landlocked status of many African countries has been much emphasized. But then what about Switzerland and Austria? These are two of the richest economies in the world, and they are landlocked. The reader may respond by saying that these countries could develop because they had good river transport, but many landlocked African countries are potentially in the same position: e.g., Burkina Faso (the Volta), Mali and Niger (the Niger), Zimbabwe (the Limpopo) and Zambia (the Zambezi). So it is the lack of investment in the river transport system, rather than the geography itself, that is the problem. Moreover, due to freezing seas in winter, Scandinavian countries used to be effectively landlocked for half of the year, until they developed the ice-breaking ship in the late nineteenth century. A bad neighbourhood effect may exist, but it need not be binding – look at the recent rapid growth of India, which is located in the poorest region in the world (poorer than Sub-Saharan Africa, as mentioned above), which also has its share of conflicts (the long history of military conflicts between India and Pakistan, the Maoist Naxalite guerrillas in India, the Tamil–Sinhalese civil war in Sri Lanka).

Many people talk of the resource curse, but the development of countries such as the US, Canada and Australia, which are much better endowed with natural resources than all African countries, with the possible exceptions of South Africa and the DRC (Democratic Republic of Congo), show that abundant resources can be a blessing. In fact, most African countries are not that well endowed with natural resources – fewer than a dozen African countries have so far discovered any significant mineral deposits. Most African countries may be abundantly endowed with natural resources in relative terms, but that is only because they have so few man-made resources, such as machines, infrastructure, and skilled labour. Moreover, in the late nineteenth and early twentieth centuries, the fastest-growing regions of the world were resource-rich areas such as North America, Latin America and Scandinavia, suggesting that the resource curse has not always existed.

Ethnic divisions can hamper growth in various ways, but their influence should not be exaggerated. Ethnic diversity is the norm elsewhere too. Even ignoring ethnic diversities in immigration-based societies such as the US, Canada and Australia, many of today’s rich countries in Europe have suffered from linguistic, religious and ideological divides – especially of the ‘medium-degree’ (a few, rather than numerous, groups) that is supposed to be most conducive to violent conflicts. Belgium has two (and a bit, if you count the tiny German-speaking minority) ethnic groups. Switzerland has four languages and two religions, and has experienced a number of mainly religion-based civil wars. Spain has serious minority problems with the Catalans and the Basques, which have even involved terrorism. Due to its 560-year rule over Finland (1249 to 1809, when it was ceded to Russia), Sweden has a significant Finnish minority (around 5 per cent of the population) and Finland a Swedish one of similar scale. And so on.

Even East Asian countries that are supposed to have particularly benefited from their ethnic homogeneity have serious problems with internal divisions. You may think Taiwan is ethnically homogeneous as its citizens are all ‘Chinese’, but the population consists of two (or four, if you divide them up more finely) linguistic groups (the ‘mainlanders’ vs. the Taiwanese) that are hostile to each other. Japan has serious minority problems with the Koreans, the Okinawans, the Ainus and the Burakumins. South Korea may be one of the most ethno-linguistically homogeneous countries in the world, but that has not prevented my fellow countrymen from hating each other. For example, there are two regions in South Korea that particularly hate each other (Southeast and Southwest), so much so that some people from those regions would not allow their children to get married to someone from ‘the other place’. Very interestingly, Rwanda is nearly as homogeneous in ethno-linguistic terms as Korea, but that did not prevent the ethnic cleansing of the formerly dominant minority Tutsis by the majority Hutus – an example that proves that ‘ethnicity’ is a political, rather than a natural, construction. In other words, rich countries do not suffer from ethnic heterogeneity not because they do not have it but because they have succeeded in nation-building (which, we should note, was often an unpleasant and even violent process).

People say that bad institutions are holding back Africa (and they are), but when the rich countries were at similar levels of material development to those we find in Africa currently, their institutions were in a far worse state. Despite that, they grew continuously and have reached high levels of development. They built the good institutions largely after, or at least in tandem with, their economic development. This shows that institutional quality is as much an outcome as the causal factor of economic development. Given this, bad institutions cannot be the explanation of growth failure in Africa.

People talk about ‘bad’ cultures in Africa, but most of today’s rich countries had once been argued to have comparably bad cultures, as I documented in the chapter ‘Lazy Japanese and thieving Germans’ in my earlier book Bad Samaritans. Until the early twentieth century, Australians and Americans would go to Japan and say the Japanese were lazy. Until the mid nineteenth century, the British would go to Germany and say that the Germans were too stupid, too individualistic and too emotional to develop their economies (Germany was not unified then) – the exact opposite of the stereotypical image that they have of the Germans today and exactly the sort of things that people now say about Africans. The Japanese and German cultures were transformed with economic development, as the demands of a highly organized industrial society made people behave in more disciplined, calculating and cooperative ways. In that sense, culture is more of an outcome, rather than a cause, of economic development. It is wrong to blame Africa’s (or any region’s or any country’s) underdevelopment on its culture.

Thus seen, what appear to be unalterable structural impediments to economic development in Africa (and indeed elsewhere) are usually things that can be, and have been, overcome with better technologies, superior organizational skills and improved political institutions. The fact that most of today’s rich countries themselves used to suffer (and still suffer to an extent) from these conditions is an indirect proof of this point. Moreover, despite having these impediments (often in more severe forms), African countries themselves did not have a problem growing in the 1960s and 70s. The main reason for Africa’s recent growth failure lies in policy – namely, the free-trade, free-market policy that has been imposed on the continent through the SAP. Nature and history do not condemn a country to a particular future. If it is policy that is causing the problem, the future can be changed even more easily. The fact that we have failed to see this, and not its allegedly chronic growth failure, is the real tragedy of Africa.

 

 

Governments do not have the necessary information and expertise to make informed business decisions and ‘pick winners’ through industrial policy. If anything, government decision-makers are likely to pick some spectacular losers, given that they are motivated by power rather than profit and that they do not have to bear the financial consequences of their decisions. Especially if government tries to go against market logic and promote industries that go beyond a country’s given resources and competences, the results are disastrous, as proven by the ‘white elephant’ projects that litter developing countries.

 

Governments can pick winners, sometimes spectacularly well. When we look around with an open mind, there are many examples of successful winner-picking by governments from all over the world. The argument that government decisions affecting business firms are bound to be inferior to the decisions made by the firms themselves is unwarranted. Having more detailed information does not guarantee better decisions – it may actually be more difficult to make the right decision, if one is ‘in the thick of it’. Also, there are ways for the government to acquire better information and improve the quality of its decisions. Moreover, decisions that are good for individual firms may not be good for the national economy as a whole. Therefore, the government picking winners against market signals can improve national economic performance, especially if it is done in close (but not too close) collaboration with the private sector.

 

Eugene Black, the longest-serving president in the history of the World Bank (1949–63), is reported to have criticized developing countries for being fixated on three totems – the highway, the integrated steel mill and the monument to the head of the state.

Mr Black’s remark on the monument may have been unfair (many political leaders in developing countries at the time were not self-aggrandizing), but he was right to be worried about the then widespread tendency to go for prestige projects, such as highways and steel mills, regardless of their economic viability. At the time, too many developing countries built highways that remained empty and steel mills that survived only because of massive government subsidies and tariff protection. Expressions like ‘white elephant’ or ‘castle in the desert’ were invented during this period to describe such projects.

But of all the then potential castles in the desert, South Korea’s plan to build an integrated steel mill, hatched in 1965, was one of the most outlandish.

At the time, Korea was one of the poorest countries in the world, relying on natural resource-based exports (e.g., fish, tungsten ore) or labour-intensive manufactured exports (e.g., wigs made with human hair, cheap garments). According to the received theory of international trade, known as the ‘theory of comparative advantage’, a country like Korea, with a lot of labour and very little capital, should not be making capital-intensive products, like steel.

Worse, Korea did not even produce the necessary raw materials. Sweden developed an iron and steel industry quite naturally because it has a lot of iron ore deposits. Korea produced virtually no iron ore or coking coal, the two key ingredients of modern steel-making. Today, these could have been imported from China, but this was the time of the Cold War when there was no trade between China and South Korea. So the raw materials had to be imported from countries such as Australia, Canada and the US – all of them five or six thousand miles away – thereby significantly adding to the cost of production.

No wonder the Korean government was finding it difficult to convince potential foreign donors and lenders of its plan, even though it proposed to subsidize the steel mill left, right and centre – free infrastructure (ports, roads, railroads), tax breaks, accelerated depreciation of its capital equipment (so that tax liabilities would be minimized in the early years), reduced utility rates, and what not.

While the negotiations with potential donors – such as the World Bank and the governments of the US, UK, West Germany, France and Italy – were going on, the Korean government did things to make the project look even less appealing. When the company to run the steel mill – the Pohang Iron and Steel Company (POSCO) – was set up in 1968, it was as a state-owned enterprise (SOE), despite widespread concerns about the inefficiencies of SOEs in developing countries. And to cap it all, the company was to be led by Mr Park Tae-Joon, a former army general with minimal business experience as the head of a state-owned tungsten-mining company for a few years. Even for a military dictatorship, this was going too far. The country was about to start the biggest business venture in its history, and the man put in charge was not even a professional businessman!

Thus, the potential donors faced arguably the worst business proposal in human history – a state-owned company, run by a politically appointed soldier, making a product that all received economic theories said was not suitable to the country. Naturally, the World Bank advised the other potential donors not to support the project, and every one of them officially pulled out of the negotiations in April 1969.

Undeterred, the Korean government managed to persuade the Japanese government to channel a large chunk of the reparation payments it was paying for its colonial rule (1910–45) into the steel-mill project and to provide the machines and the technical advice necessary for the mill.

The company started production in 1973 and established its presence remarkably quickly. By the mid 1980s, it was considered one of the most cost-efficient producers of low-grade steel in the world. By the 1990s, it was one of the world’s leading steel companies. It was privatized in 2001, not for poor performance but for political reasons, and today is the fourth-largest steel producer in the world (by quantity of output).

So we have a great puzzle on our hands. How did one of the worst business proposals in history produce one of the most successful businesses in history? Actually, the puzzle is even greater, because POSCO is not the only successful Korean company that was set up through government initiative.

Throughout the 1960s and 70s, the Korean government pushed many private sector firms into industries that they would not have entered of their own accord. This was often done through carrots, such as subsidies or tariff protection from imports (although the carrots were also sticks in the sense that they would be denied to under-performers). However, even when all those carrots were not enough to convince the businessmen concerned, sticks – big sticks – were pulled out, such as threats to cut off loans from the then wholly state-owned banks or even a ‘quiet chat’ with the secret police.

Interestingly, many of the businesses thus promoted by the government turned out to be great successes. In the 1960s, the LG Group, the electronics giant, was banned by the government from entering its desired textile industry and was forced to enter the electric cable industry. Ironically, the cable company became the foundation of its electronics business, for which LG is currently world-famous (you would know, if you have ever wanted the latest Chocolate mobile phone). In the 1970s, the Korean government put enormous pressure on Mr Chung Ju-Yung, the legendary founder of the Hyundai Group, famous for his risk appetite, to start a shipbuilding company. Even Chung is said to have initially baulked at the idea but relented when General Park Chung-Hee, the country’s then dictator and the architect of Korea’s economic miracle, personally threatened his business group with bankruptcy. Today, the Hyundai shipbuilding company is one of the biggest shipbuilders in the world.

 

Now, according to the dominant free-market economic theory, things like the successes of POSCO, LG and Hyundai described above simply shouldn’t happen. The theory tells us that capitalism works best when people are allowed to take care of their own businesses without any government interference. Government decisions are bound to be inferior to the decisions made by those who are directly concerned with the matter in question, it is argued. This is because the government does not possess as much information about the business at hand as the firm directly concerned with it. So, for example, if a company prefers to enter Industry A over Industry B, it must be because it knows that A would be more profitable than B, given its competences and market conditions. It would be totally presumptuous of some government official, however clever she may be by some absolute standard, to tell the company’s managers that they should invest in Industry B, when she simply does not have those managers’ business acumen and experiences. In other words, they argue, the government cannot pick winners.

The situation is actually more extreme than that, free-market economists say. Not only are government decision-makers unable to pick winners, they are likely to pick losers. Most importantly, government decision-makers – politicians and bureaucrats – are driven by the desire to maximize power, rather than profits. Therefore, they are bound to go for white elephant projects that have high visibility and political symbolism, regardless of their economic feasibility. Moreover, since government officials play with ‘other people’s money’, they do not really have to worry about the economic viability of the project that they are promoting (on the subject of ‘other people’s money’, see Thing 2). Between the wrong goals (prestige over profit) and the wrong incentives (not personally bearing the consequences of their decisions), these officials are almost certain to pick losers, were they to intervene in business affairs. Business should not be the business of government, it is said.

The best-known example of government picking a loser because of the wrong goals and incentives is the Concorde project, jointly financed by the British and the French governments in the 1960s. Concorde certainly remains one of the most impressive feats of engineering in human history. I still remember seeing one of the most memorable advertising slogans I’ve ever encountered, on a British Airways billboard in New York – it urged people to ‘arrive before you leave’ by flying Concorde (it took around three hours to cross the Atlantic on a Concorde, while the time difference between New York and London is five hours). However, considering all the money spent on its development and the subsidies that the two governments had to give to British Airways and Air France even to buy the aircrafts, Concorde was a resounding business failure.

An even more outrageous example of a government picking a loser because it is divorced from market logic is the case of the Indonesian aircraft industry. The industry was started in the 1970s, when the country was one of the poorest in the world. This decision was made only because Dr Bacharuddin Habibie, number two to President Mohammed Suharto for over twenty years (and the country’s president for just over a year, after his fall), happened to be an aerospace engineer who had trained and worked in Germany.

But if all received economic theories and the evidence from other countries suggest that governments are likely to pick losers rather than winners, how could the Korean government succeed in picking so many winners?

One possible explanation is that Korea is an exception. For whatever reasons, Korean government officials were so exceptionally capable, the argument might run, that they could pick winners in a way that no one else could. But that must mean that we Koreans are the smartest people in history. As a good Korean, I would not mind an explanation that portrays us in such glorious light, but I doubt whether non-Koreans would be convinced by it (and they are right – see Thing 23).

Indeed, as I discuss in some detail elsewhere in the book (most notably, see Things 7 and 19), Korea is not the only country in which the government has had success in picking winners. Other East Asian miracle economies did the same. The Korean strategy of picking winners, while involving more aggressive means, was copied from the one practised by the Japanese government. And the Taiwanese and Singaporean governments were no worse at the job than their Korean counterpart, although the policy tools they used were somewhat different.

More importantly, it isn’t just East Asian governments that have successfully picked winners. In the second half of the twentieth century, the governments of countries such as France, Finland, Norway and Austria shaped and directed industrial development with great success through protection, subsidies and investments by SOEs. Even while it pretends that it does not, the US government has picked most of the country’s industrial winners since the Second World War through massive support for research and development (R&D). The computer, semi-conductors, aircraft, internet and biotechnology industries have all been developed thanks to subsidized R&D from the US government. Even in the nineteenth and early twentieth centuries, when government industrial policies were much less organized and effective than in the late twentieth century, virtually all of today’s rich countries used tariffs, subsidies, licensing, regulation and other policy measures to promote particular industries over others, with considerable degrees of success (see Thing 7).

If governments can and do pick winners with such regularity, sometimes with spectacular results, you may wonder whether there is something wrong with the dominant economic theory that says that it cannot be done. Yes, I would say that there are many things wrong with the theory.

First of all, the theory implicitly assumes that those who are closest to the situation will have the best information and thus make the best decision. This may sound plausible but, if proximity to the situation guaranteed a better decision, no business would ever make a wrong decision. Sometimes being too close to the situation can actually make it more, rather than less, difficult to see the situation objectively. This is why there are so many business decisions that the decision-makers themselves believe to be works of genius that others view with scepticism, if not downright contempt. For example, in 2000, AOL, the internet company, acquired Time Warner media group. Despite the deep scepticism of many outsiders, Steve Case, AOL’s then chairman, called it a ‘historic merger’ that would transform ‘the landscape of media and the internet’. Subsequently the merger turned out to be a spectacular failure, prompting Jerry Levin, the Time Warner chief at the time of the merger, to admit in January 2010 that it was ‘the worst deal of the century’.

Of course, by saying that we cannot necessarily assume a government’s decision concerning a firm will be worse than a decision by the firm itself, I am not denying the importance of having good information. However, insofar as such information is needed for its industrial policy, the government can make sure that it has such information. And indeed, the governments that have been more successful at picking winners tend to have more effective channels of information exchange with the business sector.

One obvious way for a government to ensure that it has good business information is to set up an SOE and run the business itself. Countries such as Singapore, France, Austria, Norway and Finland relied heavily on this solution. Second, a government can legally require that firms in industries that receive state support regularly report on some key aspects of their businesses. The Korean government did this very thoroughly in the 1970s, when it was providing a lot of financial support for several new industries, such as shipbuilding, steel and electronics. Yet another method is to rely on informal networks between government officials and business elites so that the officials develop a good understanding of business situations, although an exclusive reliance on this channel can lead to excessive ‘clubbiness’ or downright corruption. The French policy network, built around the graduates of ENA (École Nationale d’Administration), is the most famous example of this, showing both its positive and negative sides. Somewhere in between the two extremes of legal requirement and personal networks, the Japanese have developed the ‘deliberation councils’, where government officials and business leaders regularly exchange information through formal channels, in the presence of third-party observers from academia and the media.

Moreover, dominant economic theory fails to recognize that there could be a clash between business interests and national interests. Even though businessmen may generally (but not necessarily, as I argued above) know their own affairs better than government officials and therefore be able to make decisions that best serve their companies’ interests, there is no guarantee that their decisions are going to be good for the national economy. So, for example, when it wanted to enter the textile industry in the 1960s, the managers of LG were doing the right thing for their company, but in pushing them to enter the electric cable industry, which enabled LG to become an electronics company, the Korean government was serving Korea’s national interest – and LG’s interest in the long run – better. In other words, the government picking winners may hurt some business interests but it may produce a better outcome from a social point of view (see Thing 18).

 

So far, I have listed many successful examples of government picking winners and explained why the free-market theory that denies the very possibility of government picking winners is full of holes.

By doing this, I am not trying to blind you to cases of government failure. I have already mentioned the series of castles in the desert built in many developing countries in the 1960s and 70s, including Indonesia’s aircraft industry. However, it is more than that. Government attempts to pick winners have failed even in countries that are famous for being good at it, such as Japan, France or Korea. I’ve already mentioned the French government’s ill-fated foray into Concorde. In the 1960s, the Japanese government tried in vain to arrange a takeover of Honda, which it considered to be too small and weak, by Nissan, but it later turned out that Honda was a much more successful firm than Nissan. The Korean government tried to promote the aluminium-smelting industry in the late 1970s, only to see the industry whacked by a massive increase in energy prices, which account for a particularly high proportion of aluminium production costs. And they are just the most prominent examples.

However, in the same way that the success stories do not allow us to support governments picking winners under all circumstances, the failures, however many there are, do not invalidate all government attempts to pick winners.

When you think about it, it is natural that governments fail in picking winners. It is in the very nature of risk-taking entrepreneurial decisions in this uncertain world that they often fail. After all, private sector firms try to pick winners all the time, by betting on uncertain technologies and entering activities that others think are hopeless, and often fail. Indeed, in exactly the same way that even those governments that have the best track records at picking winners do not pick winners all the time, even the most successful firms do not make the right decisions all the time – just think about Microsoft’s disastrous Windows Vista operating system (with which I am very unhappily writing this book) and Nokia’s embarrassing failure with the N-Gage phone/game console.

The question is not then whether governments can pick winners, as they obviously can, but how to improve their ‘batting average’. And contrary to popular perception, governmental batting averages can be quite dramatically improved, if there is sufficient political will. The countries that are frequently associated with success in picking winners prove the point. The Taiwanese miracle was engineered by the Nationalist Party government, which had been a byword for corruption and incompetence until it was forced to move to Taiwan after losing the Chinese mainland to the Communists in 1949. The Korean government in the 1950s was famously inept at economic management, so much so that the country was described as a bottomless pit by USAID, the US government aid agency. In the late nineteenth and early twentieth centuries, the French government was famous for its unwillingness and inability to pick winners, but it became the champion of picking winners in Europe after the Second World War.

The reality is that winners are being picked all the time both by the government and by the private sector, but the most successful ones tend to be done in joint efforts between the two. In all types of winner-picking – private, public, joint – there are successes and failures, sometimes spectacular ones. If we remain blinded by the free-market ideology that tells us only winner-picking by the private sector can succeed, we will end up ignoring a huge range of possibilities for economic development through public leadership or public–private joint efforts.

 

 

We have to create wealth before we can share it out. Like it or not, it is the rich people who are going to invest and create jobs. The rich are vital to both spotting market opportunities and exploiting them. In many countries, the politics of envy and populist policies of the past have put restrictions on wealth creation by imposing high taxes on the rich. This has to stop. It may sound harsh, but in the long run poor people can become richer only by making the rich even richer. When you give the rich a bigger slice of the pie, the slices of the others may become smaller in the short run, but the poor will enjoy bigger slices in absolute terms in the long run, because the pie will get bigger.

 

The above idea, known as ‘trickle-down economics’, stumbles on its first hurdle. Despite the usual dichotomy of ‘growth-enhancing pro-rich policy’ and ‘growth-reducing pro-poor policy’, pro-rich policies have failed to accelerate growth in the last three decades. So the first step in this argument – that is, the view that giving a bigger slice of pie to the rich will make the pie bigger – does not hold. The second part of the argument – the view that greater wealth created at the top will eventually trickle down to the poor – does not work either. Trickle down does happen, but usually its impact is meagre if we leave it to the market.

 

With the devastation of the First World War, the Soviet economy was in dire straits in 1919. Realizing that the new regime had no chance of surviving without reviving food production, Lenin launched the New Economic Policy (NEP), allowing market transactions in agriculture and letting the peasants keep the profits from those transactions.

The Bolshevik party was split. On the left of the party, arguing that the NEP was no more than a regression to capitalism, was Leon Trotsky. He was supported by the brilliant self-taught economist Yevgeni Preobrazhensky. Preobrazhensky argued that if the Soviet economy was to develop it needed to increase investment in industries. However, Preobrazhensky argued, it was very difficult to increase such investment because virtually all the surplus the economy generated (that is, over and above what was absolutely necessary for the physical survival of its population) was controlled by the farmers, as the economy was mostly agricultural. Therefore, he reasoned, private property and the market should be abolished in the countryside, so that all investible surplus could be squeezed out of it by the government suppressing agricultural prices. Such surplus was then to be shifted to the industrial sector, where the planning authority could make sure that all of it was invested. In the short run, this would suppress living standards, especially for the peasantry, but in the long run it would make everyone better off, because it would maximize investment and therefore the growth potential of the economy.

Those on the right of the party, such as Josef Stalin and Nikolai Bukharin, Preobrazhensky’s erstwhile friend and intellectual rival, called for realism. They argued that, even if it was not very ‘communist’ to allow private property in land and livestock in the countryside, they could not afford to alienate the peasantry, given its predominance. According to Bukharin, there was no other choice than ‘riding into socialism on a peasant nag’. Throughout most of the 1920s, the right had the upper hand. Preobrazhensky was increasingly marginalized and forced into exile in 1927.

However, in 1928, it all changed. Upon becoming the sole dictator, Stalin filched his rivals’ ideas and implemented the strategy advocated by Preobrazhensky. He confiscated land from the kulaks, the rich farmers, and brought the entire countryside under state control through collectivization of agriculture. The lands confiscated from the kulaks were turned into state farms (sovkhoz), while small farmers were forced to join cooperatives or collective farms (kolkhoz), with a nominal share ownership.

Stalin did not follow Preobrazhensky’s recommendation exactly. Actually, he went rather soft on the countryside and did not squeeze the peasants to the maximum. Instead, he imposed lower-than-subsistence wages on industrial workers, which in turn forced urban women to join the industrial workforce in order to enable their families to survive.

Stalin’s strategy had huge costs. Millions of people resisting, or being accused of resisisting, agricultural collectivization ended up in labour camps. There was a collapse in agricultural output, following the dramatic fall in the number of traction animals, partly due to the slaughtering by their owners in anticipation of confiscation and partly due to the shortage of grains to feed them thanks to forced grain shipments to the cities. This agricultural breakdown resulted in the severe famine of 1932–3 in which millions of people perished.

The irony is that, without Stalin adopting Preobrazhensky’s strategy, the Soviet Union would not have been able to build the industrial base at such a speed that it was able to repel the Nazi invasion on the Eastern Front in the Second World War. Without the Nazi defeat on the Eastern Front, Western Europe would not have been able to beat the Nazis. Thus, ironically, Western Europeans owe their freedom today to an ultra-left-wing Soviet economist called Preobrazhensky.

Why am I nattering on about some forgotten Russian Marxist economist from nearly a century ago? It is because there is a striking parallel between Stalin’s (or rather Preobrazhensky’s) strategy and today’s pro-rich policies advocated by free-market economists.

 

From the eighteenth century, the feudal order, whereby people were born into certain ‘stations’ and remained there for the rest of their lives, came under attack from liberals throughout Europe. They argued that people should be rewarded according to their achievements rather than their births (see Thing 20).

Of course, these were liberals of nineteenth-century vintage, so they had views that today’s liberals (least of all American liberals, who would be called ‘left of centre’, rather than liberal, in Europe) would find objectionable. Above all, they were against democracy. They believed that giving votes to poor men – women were not even considered, as they were believed to lack full mental faculty – would destroy capitalism. Why was that?

The nineteenth-century liberals believed that abstinence was the key to wealth accumulation and thus economic development. Having acquired the fruits of their labour, people need to abstain from instant gratification and invest it, if they were to accumulate wealth. In this world view, the poor were poor because they did not have the character to exercise such abstinence. Therefore, if you gave the poor voting rights, they would want to maximize their current consumption, rather than investment, by imposing taxes on the rich and spending them. This might make the poor better off in the short run, but it would make them worse off in the long run by reducing investment and thus growth.

In their anti-poor politics, the liberals were intellectually supported by the Classical economists, with David Ricardo, the nineteenth-century British economist, as the most brilliant of them all. Unlike today’s liberal economists, the Classical economists did not see the capitalist economy as being made up of individuals. They believed that people belonged to different classes – capitalists, workers and landlords – and behaved differently according to their classes. The most important inter-class behavioural difference was considered to be the fact that capitalists invested (virtually) all of their incomes while the other classes – the working class and the landlord class – consumed them. On the landlord class, opinion was split. Some, like Ricardo, saw it as a consuming class that hampered capital accumulation, while others, such as Thomas Malthus, thought that its consumption helped the capitalist class by offering extra demands for their products. However, on the workers, there was a consensus. They spent all of their income, so if the workers got a higher share of the national income, investment and thus economic growth would fall.

This is where ardent free-marketeers like Ricardo meet ultra-left wing communists like Preobrazhensky. Despite their apparent differences, both of them believed that the investible surplus should be concentrated in the hands of the investor, the capitalist class in the case of the former and the planning authority in the case of the latter, in order to maximize economic growth in the long run. This is ultimately what people today have in mind when they say that ‘you first have to create wealth before you can redistribute it’.

 

Between the late nineteenth and early twentieth centuries, the worst fears of liberals were realized, and most countries in Europe and the so-called ‘Western offshoots’ (the US, Canada, Australia and New Zealand) extended suffrage to the poor (naturally only to the males). However, the dreaded over-taxation of the rich and the resulting destruction of capitalism did not happen. In the decades that followed the introduction of universal male suffrage, taxation on the rich and social spending did not increase by much. So, the poor were not that impatient after all.

Moreover, when the dreaded over-taxation of the rich started in earnest, it did not destroy capitalism. In fact, it made it even stronger. Following the Second World War, there was a rapid growth in progressive taxation and social welfare spending in most of the rich capitalist countries. Despite this (or rather partly because of this – see Thing 21), the period between 1950 and 1973 saw the highest-ever growth rates in these countries – known as the ‘Golden Age of Capitalism’. Before the Golden Age, per capita income in the rich capitalist economies used to grow at 1–1.5 per cent per year. During the Golden Age, it grew at 2–3 per cent in the US and Britain, 4–5 per cent in Western Europe, and 8 per cent in Japan. Since then, these countries have never managed to grow faster than that.

When growth slowed down in the rich capitalist economies from the mid 1970s, however, the free-marketeers dusted off their nineteenth-century rhetoric and managed to convince others that the reduction in the share of the income going to the investing class was the reason for the slowdown.

Since the 1980s, in many (although not all) of these countries, governments that espouse upward income redistribution have ruled most of the time. Even some so-called left-wing parties, such as Britain’s New Labour under Tony Blair and the American Democratic Party under Bill Clinton, openly advocated such a strategy – the high point being Bill Clinton introducing his welfare reform in 1996, declaring that he wanted to ‘end welfare as we know it’.

In the event, trimming the welfare state down proved more difficult than initially thought (see Thing 21). However, its growth has been moderated, despite the structural pressure for greater welfare spending due to the ageing of the population, which increases the need for pensions, disability allowances, healthcare and other spending directed to the elderly.

More importantly, in most countries there were also many policies that ended up redistributing income from the poor to the rich. There have been tax cuts for the rich – top income-tax rates were brought down. Financial deregulation has created huge opportunities for speculative gains as well as astronomical paycheques for top managers and financiers (see Things 2 and 22). Deregulation in other areas has also allowed companies to make bigger profits, not least because they were more able to exploit their monopoly powers, more freely pollute the environment and more readily sack workers. Increased trade liberalization and increased foreign investment – or at least the threat of them – have also put downward pressure on wages.

As a result, income inequality has increased in most rich countries. For example, according to the ILO (International Labour Organization) report The World of Work 2008, of the twenty advanced economies for which data was available, between 1990 and 2000 income inequality rose in sixteen countries, with only Switzerland among the remaining four experiencing a significant fall. During this period, income inequality in the US, already by far the highest in the rich world, rose to a level comparable to that of some Latin American countries such as Uruguay and Venezuela. The relative increase in income inequality was also high in countries such as Finland, Sweden and Belgium, but these were countries that previously had very low levels of inequality – perhaps too low in the case of Finland, which had an even more equal income distribution than many of the former socialist countries.

According to the Economic Policy Institute (EPI), the centre-left think-tank in Washington, DC, between 1979 and 2006 (the latest year of available data), the top 1 per cent of earners in the US more than doubled their share of national income, from 10 per cent to 22.9 per cent. The top 0.1 per cent did even better, increasing their share by more than three times, from 3.5 per cent in 1979 to 11.6 per cent in 2006. This was mainly because of the astronomical increase in executive pay in the country, whose lack of justification is increasingly becoming obvious in the aftermath of the 2008 financial crisis (see Thing 14).

Of the sixty-five developing and former socialist countries covered in the above-mentioned ILO study, income inequality rose in forty-one countries during the same period. While the proportion of countries experiencing rising inequality among them was smaller than for the rich countries, many of these countries already had very high inequality, so the impacts of rising inequality were even worse than in the rich countries.

 

All this upward redistribution of income might have been justified, had it led to accelerated growth. But the fact is that economic growth has actually slowed down since the start of the neo-liberal pro-rich reform in the 1980s. According to World Bank data, the world economy used to grow in per capita terms at over 3 per cent during the 1960s and 70s, while since the 1980s it has been growing at the rate of 1.4 per cent per year (1980–2009).

In short, since the 1980s, we have given the rich a bigger slice of our pie in the belief that they would create more wealth, making the pie bigger than otherwise possible in the long run. The rich got the bigger slice of the pie all right, but they have actually reduced the pace at which the pie is growing.

The problem is that concentrating income in the hands of the supposed investor, be it the capitalist class or Stalin’s central planning authority, does not lead to higher growth if the investor fails to invest more. When Stalin concentrated income in Gosplan, the planning authority, there was at least a guarantee that the concentrated income would be turned into investment (even though the productivity of the investment may have been adversely affected by factors such as the difficulty of planning and work incentive problems – see Thing 19). Capitalist economies do not have such a mechanism. Indeed, despite rising inequality since the 1980s, investment as a ratio of national output has fallen in all G7 economies (the US, Japan, Germany, the UK, Italy, France and Canada) and in most developing countries (see Things 2 and 6).

Even when upward income redistribution creates more wealth than otherwise possible (which has not happened, I repeat), there is no guarantee that the poor will benefit from those extra incomes. Increasing prosperity at the top might eventually trickle down and benefit the poor, but this is not a foregone conclusion.

Of course, trickle down is not a completely stupid idea. We cannot judge the impact of income redistribution only by its immediate effects, however good or bad they may look. When rich people have more money, they may use it to increase investment and growth, in which case the long-run effect of upward income redistribution may be the growth in the absolute size, although not necessarily the relative share, of income that everyone gets.

However, the trouble is that trickle down usually does not happen very much if left to the market. For example, once again according to the EPI, the top 10 per cent of the US population appropriated 91 per cent of income growth between 1989 and 2006, while the top 1 per cent took 59 per cent. In contrast, in countries with a strong welfare state it is a lot easier to spread the benefits of extra growth that follows upward income redistribution (if it happens) through taxes and transfers. Indeed, before taxes and transfers, income distribution is actually more unequal in Belgium and Germany than in the US, while in Sweden and the Netherlands it is more or less the same as in the US. In other words, we need the electric pump of the welfare state to make the water at the top trickle down in any significant quantity.

Last but not least, there are many reasons to believe that downward income redistribution can help growth, if done in the right way at the right time. For example, in an economic downturn like today’s, the best way to boost the economy is to redistribute wealth downward, as poorer people tend to spend a higher proportion of their incomes. The economy-boosting effect of the extra billion dollar given to the lower-income households through increased welfare spending will be bigger than the same amount given to the rich through tax cuts. Moreover, if wages are not stuck at or below subsistence levels, additional income may encourage workers’ investment in education and health, which may raise their productivity and thus economic growth. In addition, greater income equality may promote social peace by reducing industrial strikes and crime, which may in turn encourage investment, as it reduces the danger of disruption to the production process and thus to the process of generating wealth. Many scholars believe that such a mechanism was at work during the Golden Age of Capitalism, when low income inequality coexisted with rapid growth.

Thus seen, there is no reason to presume that upward income redistribution will accelerate investment and growth. This has not happened in general. Even when there is more growth, the trickle down that occurs through the market mechanism is very limited, as seen in the above comparison of the US with other rich countries with a good welfare state.

Simply making the rich richer does not make the rest of us richer. If giving more to the rich is going to benefit the rest of the society, the rich have to be made to deliver higher investment and thus higher growth through policy measures (e.g., tax cuts for the rich individuals and corporations, conditional on investment), and then share the fruits of such growth through a mechanism such as the welfare state.

 

 

Some people are paid a lot more than others. Especially in the US, companies pay their top managers what some people consider to be obscene amounts. However, this is what market forces demand. Given that the pool of talent is limited, you simply have to pay large sums of money if you are to attract the best talents. From the point of view of a giant corporation with billions of dollars of turnover, it is definitely worth paying extra millions, or even tens of millions, of dollars to get the best talent, as her ability to make better decisions than her counterparts in competitor companies can bring in extra hundreds of millions of dollars in revenue. However unjust these levels of compensation may appear, we should not engage in acts of envy and spite and try to artificially suppress them. Such attempts would be simply counterproductive.

 

US managers are over-priced in more than one sense. First, they are over-priced compared to their predecessors. In relative terms (that is, as a proportion of average worker compensation), American CEOs today are paid around ten times more than their predecessors of the 1960s, despite the fact that the latter ran companies that were much more successful, in relative terms, than today’s American companies. US managers are also over-priced compared to their counterparts in other rich countries. In absolute terms, they are paid, depending on the measure we use and the country we compare with, up to twenty times more than their competitors running similarly large and successful companies. American managers are not only over-priced but also overly protected in the sense that they do not get punished for poor performance. And all this is not, unlike what many people argue, purely dictated by market forces. The managerial class in the US has gained such economic, political and ideological power that it has been able to manipulate the forces that determine its pay.

 

The average CEO compensation (salaries, bonuses, pensions and stock options) in the US is 300–400 times the average worker compensation (wages and benefits). Some people are terribly upset about this. For example, Mr Barack Obama, the US president, is frequently quoted criticizing what he sees as excessive executive pay.

Free-market economists see no problem in this pay disparity. If the CEOs are paid 300 times more than the average worker, they say, it must be because they add 300 times more value to the company. If someone does not have the productivity to justify her high pay, market forces will soon ensure that she is sacked (see Thing 3). Those who raise issues with executive pay, like Mr Obama, are populists who engage in the politics of class envy. Unless those who are less productive accept, they argue, that people need to be paid according to their productivity, capitalism cannot function properly.

One could almost believe in the above arguments, if one made a small concession – ignoring the facts.

I am not disputing that some people are more productive than others and that they need to be paid more – sometimes a lot more (although they should not be too smug about it – see Thing 3). The real question is whether the current degree of difference is justified.

Now, accurately totting up executive pay is very difficult. To begin with, the disclosure of executive pay is not very good in many countries. When we look at compensation as a whole, rather than just salaries, we need to include stock options. Stock options give the recipient the right to buy a certain number of the company’s stocks in the future, so they do not have an exact value in the present and their value needs to be estimated. Depending on the methodology used for the estimation, the valuation can vary a lot.

As mentioned earlier, bearing these caveats in mind, the ratio of CEO compensation to average worker compensation in the US used to be in the region of 30 to 40 to 1 in the 1960s and 70s. This ratio has grown at a rapid rate since the early 1980s, reaching around 100 to 1 in the early 1990s and rising to 300–400 to 1 by the 2000s.

Contrast this to the changes in what the American workers get. According to the Economic Policy Institute (EPI), the Washington-based centre-left think-tank, the average hourly wage for the US workers in 2007 dollars (that is, adjusted for inflation) rose from $18.90 in 1973 to $21.34 in 2006. That is a 13 per cent increase in thirty-three years, which is around 0.4 per cent growth per year. The picture is even bleaker when we look at overall compensation (wages plus benefits) and not just wages. Even if we look at only the recovery periods (given that worker compensation falls during recessions), median worker compensation rose at the rate of 0.2 per cent per year during 1983–9, at the rate of 0.1 per cent per year between 1992 and 2000 and did not grow at all during 2002–7.

In other words, worker pay in the US has been virtually stagnant since the mid 1970s. Of course, this is not to say that Americans have not seen any rise in living standards since the 1970s. Family income, as opposed to individual worker compensation, has risen, but that is only because more and more families have both partners working.

Now, if we believed in the free-market logic that people are paid according to their contribution, the increase in the relative compensation of the CEOs from 30–40 times that of average worker compensation (which has not changed very much) to 300–400 times must mean that the American CEOs have become ten times more productive (in relative terms) than they were in the 1960s and 70s. Is this true?

The average quality of US managers may have been rising due to better education and training, but is it really plausible that they are ten times better than their equivalents were one generation ago? Even looking back at only the last twenty years, during which time I have been teaching in Cambridge, I sincerely doubt whether the American students we get (who are potential CEO material) are three to four times better today than when I started teaching in the early 1990s. But that should be the case, if American CEO pay had risen in relative terms purely because of the rising quality of the CEOs: during this period, the average CEO compensation in the US rose from 100 times the average worker compensation to 300–400 times.

A common explanation of this recent steep rise in relative pay is that companies have become bigger and therefore the difference that the CEO can make has become bigger. According to a popular example used by Professor Robert H. Frank of Cornell University in his widely cited New York Times column, if a company has $10 billion earnings, a few better decisions made by a better CEO can easily increase the company’s earnings by $30 million. So, the implicit message goes, what is an extra $5 million for the CEO, when she has given an extra $30 million to the company?

There is some logic to this argument, but if the growing size of the company is the main explanation for CEO pay inflation, why did it suddenly take off in the 1980s, when US company size has been growing all the time?

Also, the same argument should apply to the workers as well, at least to some extent. Modern corporations work on the basis of complex divisions of labour and cooperation, so the view that what the CEO does is the only thing that matters for company performance is highly misleading (see Things 3 and 15). As companies grow bigger, the potential for workers benefiting or damaging the company grows bigger as well and therefore it becomes more and more important to hire better workers. If that were not the case, why do companies bother with human resources departments?

Moreover, if the increasing importance of top managerial decisions is the main reason for CEO salary inflation, why are CEOs in Japan and Europe running similarly large companies paid only a fraction of what the American CEOs are paid? According to the EPI, as of 2005, Swiss and German CEOs were paid respectively 64 per cent and 55 per cent of what their American counterparts received. The Swedish and the Dutch were paid only around 44 per cent and 40 per cent of the American CEOs’ pay; Japanese CEOs only a paltry 25 per cent. The average CEO pay for thirteen rich countries other than the US was only 44 per cent of the US level.

The above figures actually vastly understate the international differences in CEO remuneration as they do not include stock options, which tend to be much higher in the US than in other countries. Other data from the EPI suggest that, in the US, CEO pay including stock options could be easily three to four times, and possibly five to six times, that of their pay excluding stock options, although it is difficult to know exactly the magnitude involved. This means that, if we include stock options, the Japanese CEO compensation (with only a small stock option component, if at all) could be as low as 5 per cent, instead of 25 per cent, that of US CEO compensation.

Now, if the American CEOs are worth anything between twice (compared to the Swiss CEOs, excluding stock options) and twenty times (compared to the Japanese CEOs, including stock options), their counterparts abroad, how come the companies they run have been losing out to their Japanese and European rivals in many industries?

You may suggest that the Japanese and European CEOs can work at much lower absolute pay than the American CEOs because their countries’ general wage levels are lower. However, wages in Japan and the European countries are basically at the same level as those in the US. The average worker pay in the thirteen countries studied by the EPI was 85 per cent of the US worker pay in 2005. The Japanese workers get paid 91per cent the American wages, but their CEOs get paid only 25 per cent of what the American CEOs get (excluding stock options). The Swiss workers and the German workers get higher wages than the US workers (130 per cent and 106 per cent of the US wage, respectively), while their CEOs get paid only 55 per cent and 64 per cent of the US salaries (once again, excluding share options, which are much higher in the US).

Thus seen, US managers are over-priced. The American workers get paid only 15 per cent or so more than their counterparts in competitor nations, while the American CEOs are paid at least twice (compared to the Swiss managers, excluding stock options) and possibly up to twenty times (compared to the Japanese managers, including stock options) that of what their counterparts in comparable countries are paid. Despite this, the American CEOs are running companies that are no better, and frequently worse, than their Japanese or European competitors.

 

In the US (and the UK, which has the second highest CEO– worker pay ratio after the US), the compensation packages for top managers are loaded in one way. Apart from being paid excessive amounts, these managers do not get punished for bad management. The most that will happen to them is to be kicked out of their current job, but that will almost always be accompanied by a fat severance payment cheque. Sometimes the expelled CEO will get even more than what is required in the contract. According to two economists, Bebchuk and Fried, ‘when Mattel CEO Jill Barad resigned under fire [in 2000], the board forgave a $4.2 million loan, gave her an additional $3.3 million in cash to cover the taxes for forgiveness of another loan and allowed her unvested options to vest automatically. These gratuitous benefits were in addition to the considerable benefits that she received under her employment agreement, which included a termination payment of $26.4 million and a stream of retirement benefits exceeding $700,000 per year.’

Should we care? Not really, free-market economists would argue. If some companies are stupid enough to pay gratuitous benefits to failed CEOs, they would say, let them do it. They will be outcompeted by more hard-nosed competitors that do not engage in such nonsense. So, even though there may be some poorly designed compensation schemes around, they will eventually be eliminated through competitive pressures of the market.

This seems plausible. The competitive process works to eliminate inefficient practices, be they obsolete textile technologies or biased executive pay schemes. And the fact that American and British companies have been losing to foreign companies, which on the whole have better managerial incentives, is a proof of it.

However, it will take a long time for this process to eliminate wrong managerial compensation practices (after all, this has been going on for decades). Before its recent bankruptcy, people had known for at least three decades that GM was on a decline, but no one did anything to stop the top managers from receiving compensation packages more fitting to their predecessors in the mid twentieth century, when the company had absolute dominance worldwide (see Thing 18).

Despite this, little is done to check excessive and biased (in that failures are hardly punished) executive pay packages because the managerial classes in the US and Britain have become so powerful, not least because of the fat paycheques they have been getting over the last few decades. They have come to control the boardrooms, through interlocking directorship and manipulation of information that they provide to independent directors, and as a result few boards of directors question the level and the structure of executive pay set by the CEO. High and rising dividend payments also keep the shareholders happy (see Thing 2). By flexing their economic muscle, the managerial classes have gained enormous influence over the political sphere, including the supposedly centre-left parties such as Britain’s New Labour and America’s Democratic Party. Especially in the US, many private sector CEOs end up running government departments. Most importantly, they have used their economic and political influence to spread the free-market ideology that says that whatever exists must be there because it is the most efficient.

The power of this managerial class has been most vividly demonstrated by the aftermath of the 2008 financial crisis. When the American and the British governments injected astronomical sums of taxpayers’ money into troubled financial institutions in the autumn of 2008, few of the managers who were responsible for their institution’s failure were punished. Yes, a small number of CEOs have lost their jobs, but few of those who have remained in their jobs have taken a serious pay cut and there has been an enormous, and effective, resistance to the attempt by the US Congress to put a cap on pay of the managers of financial firms receiving taxpayers’ money. The British government refused to do anything about the £15–20 million pensions payout (which gives him around £700,000 yearly income) to the disgraced former boss of the RBS (Royal Bank of Scotland), Sir Fred Goodwin, although the intense negative publicity forced him subsequently to return £4 million. The fact that the British and the American taxpayers, who have become the shareholders of the bailed-out financial institutions, cannot even punish their now-employees for poor performance and force them to accept a more efficient compensation scheme shows the extent of power that the managerial class now possesses in these countries.

Markets weed out inefficient practices, but only when no one has sufficient power to manipulate them. Moreover, even if they are eventually weeded out, one-sided managerial compensation packages impose huge costs on the rest of the economy while they last. The workers have to be constantly squeezed through downward pressure on wages, casualization of employment and permanent downsizing, so that the managers can generate enough extra profits to distribute to the shareholders and keep them from raising issues with high executive pay (for more on this, see Thing 2). Having to maximize dividends to keep the shareholders quiet, investment is minimized, weakening the company’s long-term productive capabilities. When combined with excessive managerial pay, this puts the American and British firms at a disadvantage in international competition, eventually costing the workers their jobs. Finally, when things go wrong on a large scale, as in the 2008 financial crisis, taxpayers are forced to bail out the failed companies, while the managers who created the failure get off almost scot-free.

When the managerial classes in the US and, to a lesser extent Britain, possess such economic, political and ideological power that they can manipulate the market and pass on the negative consequences of their actions to other people, it is an illusion to think that executive pay is something whose optimal levels and structures are going to be, and should be, determined by the market.

 

 

Entrepreneurship is at the heart of economic dynamism. Unless there are entrepreneurs who seek out new money-making opportunities by generating new products and meeting unmet demands, the economy cannot develop. Indeed, one of the reasons behind the lack of economic dynamism in a range of countries, from France to all those states in the developing world, is the lack of entrepreneurship. Unless all those people who aimlessly loiter around in poor countries change their attitudes and actively seek out profit-making opportunities, their countries are not going to develop.

 

People who live in poor countries have to be very entrepreneurial even just to survive. For every loiterer in a developing country, you have two or three children shining shoes and four or five people hawking things. What makes the poor countries poor is not the absence of entrepreneurial energy at the personal level, but the absence of productive technologies and developed social organizations, especially modern firms. The increasingly apparent problems with microcredit – very small loans given to poor people in developing countries with the pronounced aim of helping them set up businesses – shows the limitations of individual entrepreneurship. Especially in the last century, entrepreneurship has become a collective activity, so the poverty of collective organization has become an even bigger obstacle to economic development rather than the deficient entrepreneurial spirits of individuals.

 

George W. Bush, the former US president, is reputed to have complained that the problem with the French is that they do not have a word for entrepreneurship in their language. His French may not have been up to scratch, but Mr Bush was articulating a fairly common Anglo-American prejudice against France as an un-dynamic and backward-looking country full of lazy workers, sheep-burning farmers, pretentious left-wing intellectuals, meddling bureaucrats and, last but not least, pompous waiters.

Whether or not Mr Bush’s conception of France is right (more on this later, and see Thing 10), the perspective behind his statement is widely accepted – you need entrepreneurial people to have a successful economy. In this view, the poverty of the developing countries is also attributed to the lack of entrepreneurship in those countries. Look at all those men sitting around having their eleventh cup of mint tea of the day, observers from the rich countries say, these countries really need more go-getters and movers-and-shakers in order to pull themselves out of poverty.

However, anyone who is from or has lived for a period in a developing country will know that it is teeming with entrepreneurs. On the streets of poor countries, you will meet men, women and children of all ages selling everything you can think of, and things that you did not even know could be bought. In many poor countries, you can buy a place in the queue for the visa section of the American embassy (sold to you by professional queuers), the service to ‘watch your car’ (meaning ‘refrain from damaging your car’) in street-parking slots, the right to set up a food stall on a particular corner (perhaps sold by the corrupt local police boss) or even a patch of land to beg from (sold to you by the local thugs). These are all products of human ingenuity and entrepreneurship.

In contrast, most citizens of rich countries have not even come near to becoming entrepreneurs. They mostly work for a company, some of them employing tens of thousands, doing highly specialized and narrowly specified jobs. Even though some of them dream of, or at least idly talk about, setting up their own businesses and ‘becoming my own boss’, few put it into practice because it is a difficult and risky thing to do. As a result, most people from rich countries spend their working lives implementing someone else’s entrepreneurial vision, and not their own.

The upshot is that people are far more entrepreneurial in the developing countries than in the developed countries. According to an OECD study, in most developing countries 30–50 per cent of the non-agricultural workforce is self-employed (the ratio tends to be even higher in agriculture). In some of the poorest countries the ratio of people working as one-person entrepreneurs can be way above that: 66.9 per cent in Ghana, 75.4 per cent in Bangladesh and a staggering 88.7 per cent in Benin. In contrast, only 12.8 per cent of the non-agricultural workforce in developed countries is self-employed. In some countries the ratio does not even reach one in ten: 6.7 per cent in Norway, 7.5 per cent in the US and 8.6 per cent in France (it turns out that Mr Bush’s complaint about the French was a classic case of the pot calling the kettle black). So, even excluding the farmers (which would make the ratio even higher), the chance of an average developing-country person being an entrepreneur is more than twice that for a developed-country person (30 per cent vs. 12.8 per cent). The difference is ten times, if we compare Bangladesh with the US (7.5 per cent vs. 75.4 per cent). And in the most extreme case, the chance of someone from Benin being an entrepreneur is a whopping thirteen times higher than the equivalent chance for a Norwegian (88.7 per cent vs. 6.7 per cent).

Moreover, even those people who are running businesses in the rich countries need not be as entrepreneurial as their counterparts in the poor countries. For developing-country entrepreneurs, things go wrong all the time. There are power cuts that screw up the production schedule. Customs won’t clear the spare parts needed to fix a machine, which has been delayed anyway due to problems with the permit to buy US dollars. Inputs are not delivered at the right time, as the delivery truck broke down – yet again – due to potholes on the road. And the petty local officials are bending, and even inventing, rules all the time in order to extract bribes. Coping with all these obstacles requires agile thinking and the ability to improvise. An average American businessman would not last a week in the face of these problems, if he were made to manage a small company in Maputo or Phnom Penh.

So we are faced with an apparent puzzle. Compared to the rich countries, we have far more people in developing countries (in proportional terms) engaged in entrepreneurial activities. On top of that, their entrepreneurial skills are much more frequently and severely tested than those of their counterparts in the rich countries. Then how is it that these more entrepreneurial countries are the poorer ones?

 

The seemingly boundless entrepreneurial energy of poor people in poor countries has, of course, not gone unnoticed. There is an increasingly influential view that the engine of development for poor countries should be the so-called ‘informal sector’, made up of small businesses that are not registered with the government.

The entrepreneurs in the informal sector, it is argued, are struggling not because they lack the necessary vision and skills but because they cannot get the money to realize their visions. The regular banks discriminate against them, while the local money-lenders charge prohibitive rates of interest. If they are given a small amount of credit (known as a ‘microcredit’) at a reasonable interest rate to set up a food stall, buy a mobile phone to rent out, or get some chickens to sell their eggs, they will be able to pull themselves out of poverty. With these small enterprises making up the bulk of the developing country’s economy, their successes would translate into overall economic development.

The invention of microcredit is commonly attributed to Muhammad Yunus, the economics professor who has been the public face of the microcredit industry since he set up the pioneering Grameen Bank in his native Bangladesh in 1983, although there were similar attempts before. Despite lending to poor people, especially poor women, who were traditionally considered to be high-risk cases, the Grameen Bank boasted a very high repayment ratio (95 per cent or more), showing that the poor are highly bankable. By the early 1990s, the success of the Grameen Bank, and of some similar banks in countries such as Bolivia, was noticed, and the idea of microcredit – or more broadly microfinance, which includes savings and insurance, and not just credit – spread fast.

The recipe sounds perfect. Microcredit allows the poor to get out of poverty through their own efforts, by providing them with the financial means to realize their entrepreneurial potential. In the process, they gain independence and self-respect, as they are no longer relying on handouts from the government and foreign aid agencies for their survival. Poor women are particularly empowered by microcredit, as it gives them the ability to earn an income and thus improve their bargaining positions vis-à-vis their male partners. Not having to subsidize the poor, the government feels less pressure on its budget. The wealth created in the process, naturally, makes the overall economy, and not just the informal sector entrepreneurs, richer. Given all this, it is not a surprise that Professor Yunus believes that, with the help of microfinance, we can create ‘a poverty-free world [where the] only place you can see poverty is in the museum’.

By the mid 2000s, the popularity of microfinance reached fever pitch. The year 2005 was designated the International Year of Microcredit by the United Nations, with endorsements from royalty, like Queen Rania of Jordan, and celebrities, like the actresses Natalie Portman and Aishwarya Rai. The ascendancy of microfinance reached its peak in 2006, when the Nobel Peace Prize was awarded jointly to Professor Yunus and his Grameen Bank.

 

Unfortunately, the hype about microfinance is, well, just that – hype. There are growing criticisms of microfinance, even by some of its early ‘priests’. For example, in a recent paper with David Roodman, Jonathan Morduch, a long-time advocate of microfinance, confesses that ‘[s]trikingly, 30 years into the microfinance movement we have little solid evidence that it improves the lives of clients in measurable ways’. The problems are too numerous even to list here; anyone who is interested can read the fascinating recent book by Milford Bateman, Why Doesn’t Microfinance Work? But those most relevant to our discussion are as follows.

The microfinance industry has always boasted that its operations remain profitable without government subsidies or contributions from international donors, except perhaps in the initial teething phase. Some have used this as evidence that the poor are as good at playing the market as anyone else, if you will just let them. However, it turns out that, without subsidies from governments or international donors, microfinance institutions have to charge, and have been charging, near-usurious rates. It has been revealed that the Grameen Bank could initially charge reasonable interest rates only because of the (hushed-up) subsidies it was getting from the Bangladeshi government and international donors. If they are not subsidized, microfinance institutions have to charge interest rates of typically 40–50 per cent for their loans, with rates as high as 80–100 per cent in countries such as Mexico. When, in the late 1990s, it came under pressure to give up the subsidies, the Grameen Bank had to relaunch itself (in 2001) and start charging interest rates of 40–50 per cent.

With interest rates running up to 100 per cent, few businesses can make the necessary profits to repay the loans, so most of the loans made by microfinance institutions (in some cases as high as 90 per cent) have been used for the purpose of ‘consumption smoothing’ – people taking out loans to pay for their daughter’s wedding or to make up for a temporary fall in income due to the illness of a working family member. In other words, the vast bulk of microcredit is not used to fuel entrepreneurship by the poor, the alleged goal of the exercise, but to finance consumption.

More importantly, even the small portion of microcredit that goes into business activities is not pulling people out of poverty. At first, this sounds inexplicable. Those poor people who take out microcredit know what they are doing. Unlike their counterparts in rich countries, most of them have run businesses of one kind or another. Their business wits are sharpened to the limit by their desperation to survive and sheer desire to get out of poverty. They have to generate very high profits because they have to pay the market rate of interest. So what is going wrong? Why are all these people – highly motivated, in possession of relevant skills and strongly pressured by the market – making huge efforts with their business ventures, producing such meagre results?

When a microfinance institution first starts its operation in a locality, the first posse of its clients may see their income rising – sometimes quite dramatically. For example, when in 1997 the Grameen Bank teamed up with Telenor, the Norwegian phone company, and gave out microloans to women to buy a mobile phone and rent it out to their villagers, these ‘telephone ladies’ made handsome profits – $750–$1,200 in a country whose annual average per capita income was around $300. However, over time, the businesses financed by microcredit become crowded and their earnings fall. To go back to the Grameen phone case, by 2005 there were so many telephone ladies that their income was estimated to be around only $70 per year, even though the national average income had gone up to over $450. This problem is known as the ‘fallacy of composition’ – the fact that some people can succeed with a particular business does not mean that everyone can succeed with it.

Of course, this problem would not exist if new business lines could be constantly developed – if one line of activity becomes unprofitable due to overcrowding, you simply open up another. So, for example, if phone renting becomes less profitable, you could maintain your level of income by manufacturing mobile phones or writing the software for mobile phone games. You will obviously have noticed the absurdity of these suggestions – the telephone ladies of Bangladesh simply do not have the wherewithal to move into phone manufacturing or software design. The problem is that there is only a limited range of (simple) businesses that the poor in developing countries can take on, given their limited skills, the narrow range of technologies available, and the limited amount of finance that they can mobilize through microfinance. So, you, a Croatian farmer who bought one more milk cow with a microcredit, stick to selling milk even as you watch the bottom falling out of your local milk market thanks to the 300 other farmers like you selling more milk, because turning yourself into an exporter of butter to Germany or cheese to Britain simply isn’t possible with the technologies, the organizational skills and the capital you have.

 

Our discussion so far shows that what makes the poor countries poor is not the lack of raw individual entrepreneurial energy, which they in fact have in abundance. The point is that what really makes the rich countries rich is their ability to channel the individual entrepreneurial energy into collective entrepreneurship.

Very much influenced by capitalist folklore, with characters such as Thomas Edison and Bill Gates, and by the pioneering work of Joseph Schumpeter, the Austrian-born Harvard economics professor, our view of entrepreneurship is too much tinged by the individualistic perspective – entrepreneurship is what those heroic individuals with exceptional vision and determination do. By extension, we believe that any individual, if they try hard enough, can become successful in business. However, if it ever was true, this individualistic view of entrepreneurship is becoming increasingly obsolete. In the course of capitalist development, entrepreneurship has become an increasingly collective endeavour.

To begin with, even exceptional individuals like Edison and Gates have become what they have only because they were supported by a whole host of collective institutions (see Thing 3): the whole scientific infrastructure that enabled them to acquire their knowledge and also experiment with it; the company law and other commercial laws that made it possible for them subsequently to build companies with large and complex organizations; the educational system that supplied highly trained scientists, engineers, managers and workers that manned those companies; the financial system that enabled them to raise a huge amount of capital when they wanted to expand; the patent and copyright laws that protected their inventions; the easily accessible market for their products; and so on.

Furthermore, in the rich countries, enterprises cooperate with each other a lot more than do their counterparts in poor countries, even if they operate in similar industries. For example, the dairy sectors in countries such as Denmark, the Netherlands and Germany have become what they are today only because their farmers organized themselves, with state help, into cooperatives and jointly invested in processing facilities (e.g., creaming machines) and overseas marketing. In contrast, the dairy sectors in the Balkan countries have failed to develop despite quite a large amount of microcredit channelled into them, because all their dairy farmers tried to make it on their own. For another example, many small firms in Italy and Germany jointly invest in R&D and export marketing, which are beyond their individual means, through industry associations (helped by government subsidies), whereas typical developing country firms do not invest in these areas because they do not have such a collective mechanism.

Even at the firm level, entrepreneurship has become highly collective in the rich countries. Today, few companies are managed by charismatic visionaries like Edison and Gates, but by professional managers. Writing in the mid twentieth century, Schumpeter was already aware of this trend, although he was none too happy about it. He observed that the increasing scale of modern technologies was making it increasingly impossible for a large company to be established and run by a visionary individual entrepreneur. Schumpeter predicted that the displacement of heroic entrepreneurs with what he called ‘executive types’ would sap the dynamism from capitalism and eventually lead to its demise (see Thing 2).

Schumpeter has been proven wrong in this regard. Over the last century, the heroic entrepreneur has increasingly become a rarity and the process of innovation in products, processes and marketing – the key elements of Schumpeter’s entrepreneurship – has become increasingly ‘collectivist’ in its nature. Yet, despite this, the world economy has grown much faster since the Second World War, compared to the period before it. In the case of Japan, the firms have even developed institutional mechanisms to exploit the creativity of even the lowliest production-line workers. Many attribute the success of the Japanese firms, at least partly, to this characteristic (see Thing 5).

If effective entrepreneurship ever was a purely individual thing, it has stopped being so at least for the last century. The collective ability to build and manage effective organizations and institutions is now far more important than the drives or even the talents of a nation’s individual members in determining its prosperity (see Thing 17). Unless we reject the myth of heroic individual entrepreneurs and help them build institutions and organizations of collective entrepreneurship, we will never see the poor countries grow out of poverty on a sustainable basis.

 

 

We should leave markets alone, because, essentially, market participants know what they are doing – that is, they are rational. Since individuals (and firms as collections of individuals who share the same interests) have their own best interests in mind and since they know their own circumstances best, attempts by outsiders, especially the government, to restrict the freedom of their actions can only produce inferior results. It is presumptuous of any government to prevent market agents from doing things they find profitable or to force them to do things they do not want to do, when it possesses inferior information.

 

People do not necessarily know what they are doing, because our ability to comprehend even matters that concern us directly is limited – or, in the jargon, we have ‘bounded rationality’. The world is very complex and our ability to deal with it is severely limited. Therefore, we need to, and usually do, deliberately restrict our freedom of choice in order to reduce the complexity of problems we have to face. Often, government regulation works, especially in complex areas like the modern financial market, not because the government has superior knowledge but because it restricts choices and thus the complexity of the problems at hand, thereby reducing the possibility that things may go wrong.

 

As expressed by Adam Smith in the idea of the invisible hand, free-market economists argue that the beauty of the free market is that the decisions of isolated individuals (and firms) get reconciled without anybody consciously trying to do so. What makes this possible is that economic actors are rational, in the sense that they know best their own situations and the ways to improve them. It is possible, it is admitted, that certain individuals are irrational or even that a generally rational individual behaves irrationally on occasion. However, in the long run, the market will weed out irrational behaviours by punishing them – for example, investors who ‘irrationally’ invest in over-priced assets will reap low returns, which forces them either to adjust their behaviour or be wiped out. Given this, free-market economists argue, leaving it up to the individuals to decide what to do is the best way to manage the market economy.

Of course, few people would argue that markets are perfect. Even Milton Friedman admitted that there are instances in which markets fail. Pollution is a classic example. People ‘over-produce’ pollution because they are not paying for the costs of dealing with it. So what are optimal levels of pollution for individuals (or individual firms) add up to a sub-optimal level from the social point of view. However, free-market economists are quick to point out that market failures, while theoretically possible, are rare in reality. Moreover, they argue, often the best solution to market failures is to introduce more market forces. For example, they argue that the way to reduce pollution is to create a market for it – by creating ‘tradable emission rights’, which allow people to sell and buy the rights to pollute according to their needs within a socially optimal maximum. On top of that, free-market economists add, governments also fail (see Thing 12). Governments may lack the necessary information to correct market failures. Or they may be run by politicians and bureaucrats who promote their own interests rather than national interests (see Thing 5). All this means that usually the costs of government failure are greater than the costs of market failure that it is (allegedly) trying to fix. Therefore, free-market economists point out, the presence of market failure does not justify government intervention.

The debate on the relative importance of market failures and government failures still rages on, and I am not going to be able to conclude that debate here. However, in this Thing, I can at least point out that the problem with the free market does not end with the fact that individually rational actions can lead to a collective irrational outcome (that is, market failure). The problem is that we are not even rational to begin with. And when the rationality assumption does not hold, we need to think about the role of the market and of the government in a very different way even from the market failure framework, which after all also assumes that we are rational. Let me explain.

 

In 1997, Robert Merton and Myron Scholes were awarded the Nobel Prize in economics for their ‘new method to determine the value of derivatives’. Incidentally, the prize is not a real Nobel prize but a prize given by the Swedish central bank ‘in memory of Alfred Nobel’. As a matter of fact, several years ago the Nobel family even threatened to deny the prize the use of their ancestor’s name, as it had been mostly given to free-market economists of whom Alfred Nobel would not have approved, but that is another story.

In 1998, a huge hedge fund called Long-Term Capital Management (LTCM) was on the verge of bankruptcy, following the Russian financial crisis. The fund was so large that its bankruptcy was expected to bring everyone else down with it. The US financial system avoided a collapse only because the Federal Reserve Board, the US central bank, twisted the arms of the dozen or so creditor banks to inject money into the company and become reluctant shareholders, gaining control over 90 per cent of the shares. LTCM was eventually folded in 2000.

LTCM, founded in 1994 by the famous (now infamous) financier John Merriwether, had on its board of directors – would you believe it? – Merton and Scholes. Merton and Scholes were not just lending their names to the company for a fat cheque: they were working partners and the company was actively using their asset-pricing model.

Undeterred by the LTCM débâcle, Scholes went on to set up another hedge fund in 1999, Platinum Grove Asset Management (PGAM). The new backers, one can only surmise, thought that the Merton–Scholes model must have failed back in 1998 due to a totally unpredictable sui generis event – the Russian crisis. After all, wasn’t it still the best asset-pricing model available in the history of humanity, approved by the Nobel committee?

The investors in PGAM were, unfortunately, proven wrong. In November 2008, it practically went bust, temporarily freezing investor withdrawal. The only comfort they could take was probably that they were not alone in being failed by a Nobel laureate. The Trinsum Group, for which Scholes’s former partner, Merton, was the chief science officer, also went bankrupt in January 2009.

There is a saying in Korea that even a monkey can fall from a tree. Yes, we all make mistakes, and one failure – even if it is a gigantic one like LTCM – we can accept as a mistake. But the same mistake twice? Then you know that the first mistake was not really a mistake. Merton and Scholes did not know what they were doing.

When Nobel Prize-winners in economics, especially those who got the prize for their work on asset pricing, cannot read the financial market, how can we run the world according to an economic principle that assumes people always know what they are doing and therefore should be left alone? As Alan Greenspan, former chairman of the Federal Reserve Board, had to admit in a Congressional hearing, it was a ‘mistake’ to ‘presume that the self-interest of organisations, specifically banks, is such that they were best capable of protecting shareholders and equity in the firms’. Self-interest will protect people only when they know what is going on and how to deal with it.

There are many stories coming out of the 2008 financial crisis that show how the supposedly smartest people did not truly understand what they were doing. We are not talking about the Hollywood big shots, such as Steven Spielberg and John Malkovich, or the legendary baseball pitcher Sandy Koufax, depositing their money with the fraudster Bernie Madoff. While these people are among the world’s best in what they do, they may not necessarily understand finance. We are talking about the expert fund managers, top bankers (including some of the world’s largest banks, such as the British HSBC and the Spanish Santander), and world-class colleges (New York University and Bard College, which had access to some of the world’s most reputed economics faculty members) falling for the same trick by Madoff.

Worse, it isn’t just a matter of being deceived by fraudsters like Madoff or Alan Stanford. The failure by the bankers and other supposed experts in the field to understand what was going on has been pervasive, even when it comes to legitimate finance. One of them apparently shocked Alistair Darling, then British Chancellor of the Exchequer, by telling him in the summer of 2008 that ‘from now on we will only lend when we understand the risks involved’. For another, even more astonishing, example, only six months before the collapse of AIG, the American insurance company bailed out by the US government in the autumn of 2008, its chief financial officer, Joe Cassano, is reported to have said that ‘[i]t is hard for us, without being flippant, to even see a scenario within any kind of realm of reason that would see us losing one dollar in any of the [credit default swap, or CDS] transactions’. Most of you – especially if you are an American taxpayer cleaning up Mr Cassano’s mess – might find that supposed lack of flippancy less than amusing, given that AIG went bust because of its failure in its $441 billion portfolio of CDS, rather than its core insurance business.

When the Nobel Prize-winners in financial economics, top bankers, high-flying fund managers, prestigious colleges and the smartest celebrities have shown that they do not understand what they are doing, how can we accept economic theories that work only because they assume that people are fully rational? The upshot is that we are simply not smart enough to leave the market alone.

But where do we go from there? Is it possible to think about regulating the market when we are not even smart enough to leave it alone? The answer is yes. Actually it is more than that. Very often, we need regulation exactly because we are not smart enough. Let me show why.

 

Herbert Simon, the winner of the 1978 Nobel Prize in economics, was arguably the last Renaissance Man on earth. He started out as a political scientist and moved on to the study of public administration, writing the classic book in the field, Administrative Behaviour. Throwing in a couple of papers in physics along the way, he moved into the study of organizational behaviour, business administration, economics, cognitive psychology and artificial intelligence (AI). If anyone understood how people think and organize themselves, it was Simon.

Simon argued that our rationality is ‘bounded’. He did not believe that we are entirely irrational, although he himself and many other economists of the behaviouralist school (as well as many cognitive psychologists) have convincingly documented how much of our behaviour is irrational. According to Simon, we try to be rational, but our ability to be so is severely limited. The world is too complex, Simon argued, for our limited intelligence to understand fully. This means that very often the main problem we face in making a good decision is not the lack of information but our limited capability to process that information – a point nicely illustrated by the fact that the celebrated advent of the internet age does not seem to have improved the quality of our decisions, judging by the mess we are in today.

To put it another way, the world is full of uncertainty. Uncertainty here is not just not knowing exactly what is going to happen in the future. For certain things, we can reasonably calculate the probability of each possible contingency, even though we cannot predict the exact outcome – economists call this ‘risk’. Indeed, our ability to calculate the risk involved in many aspects of human life – the likelihoods of death, disease, fire, injury, crop failure, and so on – is the very foundation of the insurance industry. However, for many other aspects of our life, we do not even know all the possible contingencies, not to speak of their respective likelihoods, as emphasized, among others, by the insightful American economist Frank Knight and the great British economist John Maynard Keynes in the early twentieth century. Knight and Keynes argued that the kind of rational behaviour that forms the foundation of much of modern economics is impossible under this kind of uncertainty.

The best explanation of the concept of uncertainty – or the complexity of the world, to put it another way – was given by, perhaps surprisingly, Donald Rumsfeld, the Defense Secretary in the first government of George W. Bush. In a press briefing regarding the situation in Afghanistan in 2002, Rumsfeld opined: ‘There are known knowns. There are things we know that we know. There are known unknowns. That is to say, there are things that we now know we don’t know. But there are also unknown unknowns. There are things we do not know we don’t know.’ I don’t think those at the Plain English Campaign that awarded the 2003 Foot in Mouth award to the statement quite understood the significance of this statement for our understanding of human rationality.

So what do we do, when the world is so complex and our ability to understand it so limited? Simon’s answer was that we deliberately restrict our freedom of choice in order to reduce the range and the complexity of the problems that we have to deal with.

This sounds esoteric, but when you think about it, this is exactly what we do all the time. Most of us create routines in our life so that we don’t have to make too many decisions too often. The optimal amount of sleep and the optimal breakfast menu differ every day, depending on our physical conditions and the tasks ahead. Yet most of us go to bed at the same time, wake up at the same time and eat similar things for breakfast, at least during the weekdays.

Simon’s favourite example of how we need some rules in order to cope with our bounded rationality was chess. With only thirty-two pieces and sixty-four squares, chess may seem to be a relatively simple affair, but in fact involves a huge amount of calculation. If you were one of those ‘hyper-rational’ beings (as Simon calls them) that populate standard economics textbooks, you would, of course, figure out all the possible moves and calculate their likelihoods before you make a move. But, Simon points out, there being around 10 (yes, that is 120 zeroes) possibilities in an average game of chess, this ‘rational’ approach requires mental capacity that no human being possesses. Indeed, studying chess masters, Simon realized that they use rules of thumb (heuristics) to focus on a small number of possible moves, in order to reduce the number of scenarios that need to be analysed, even though the excluded moves may have brought better results.

If chess is this complicated, you can imagine how complicated things are in our economy, which involves billions of people and millions of products. Therefore, in the same way in which individuals create routines in their daily lives or chess games, companies operate with ‘productive routines’, which simplify their options and search paths. They build certain decision-making structures, formal rules and conventions that automatically restrict the range of possible avenues that they explore, even when the avenues thus excluded outright may have been more profitable. But they still do it because otherwise they may drown in a sea of information and never make a decision. Similarly, societies create informal rules that deliberately restrict people’s freedom of choice so that they don’t have to make fresh choices constantly. So, they develop a convention for queuing so that people do not have to, for example, constantly calculate and recalculate their positions at a crowded bus stop in order to ensure that they get on the next bus.

 

So far so good, you may think, but what does Simon’s theory of bounded rationality really have to say about regulation?

Free-market economists have argued against government regulation on the (apparently reasonable) ground that the government does not know better than those whose actions are regulated by it. By definition, the government cannot know someone’s situation as well as the individual or firm concerned. Given this, they argue, it is impossible that government officials can improve upon the decisions made by the economic agents.

However, Simon’s theory shows that many regulations work not because the government necessarily knows better than the regulated (although it may sometimes do – see Thing 12) but because they limit the complexity of the activities, which enables the regulated to make better decisions. The 2008 world financial crisis illustrates this point very nicely.

In the run-up to the crisis, our ability to make good decisions was simply overwhelmed because things were allowed to evolve in too complex a manner through financial innovation. So many complex financial instruments were created that even financial experts themselves did not fully understand them, unless they specialized in them – and sometimes not even then (see Thing 22). The top decision-makers of the financial firms certainly did not grasp much of what their businesses were doing. Nor could the regulatory authorities fully figure out what was going on. As discussed above, now we are seeing a flood of confessions – some voluntary, others forced – from the key decision-makers.

If we are going to avoid similar financial crises in the future, we need to restrict severely freedom of action in the financial market. Financial instruments need to be banned unless we fully understand their workings and their effects on the rest of the financial sector and, moreover, the rest of the economy. This will mean banning many of the complex financial derivatives whose workings and impacts have been shown to be beyond the comprehension of even the supposed experts.

You may think I am too extreme. However, this is what we do all the time with other products – drugs, cars, electrical products, and many others. When a company invents a new drug, for example, it cannot be sold immediately. The effects of a drug, and the human body’s reaction to it, are complex. So the drug needs to be tested rigorously before we can be sure that it has enough beneficial effects that clearly overwhelm the side-effects and allow it to be sold. There is nothing exceptional about proposing to ascertain the safety of financial products before they can be sold.

Unless we deliberately restrict our choices by creating restrictive rules, thereby simplifying the environment that we have to deal with, our bounded rationality cannot cope with the complexity of the world. It is not because the government necessarily knows better that we need regulations. It is in the humble recognition of our limited mental capability that we do.

 

 

A well-educated workforce is absolutely necessary for economic development. The best proof of this is the contrast between the economic successes of the East Asian countries, with their famously high educational achievements, and the economic stagnation of Sub-Saharan African countries, which have some of the lowest educational records in the world. Moreover, with the rise of the so-called ‘knowledge economy’, in which knowledge has become the main source of wealth, education, especially higher education, has become the absolute key to prosperity.

 

There is remarkably little evidence showing that more education leads to greater national prosperity. Much of the knowledge gained in education is actually not relevant for productivity enhancement, even though it enables people to lead a more fulfilling and independent life. Also, the view that the rise of the knowledge economy has critically increased the importance of education is misleading. To begin with, the idea of the knowledge economy itself is problematic, as knowledge has always been the main source of wealth. Moreover, with increasing de-industrialization and mechanization, the knowledge requirements may even have fallen for most jobs in the rich countries. Even when it comes to higher education, which is supposed to matter more in the knowledge economy, there is no simple relationship between it and economic growth. What really matters in the determination of national prosperity is not the educational levels of individuals but the nation’s ability to organize individuals into enterprises with high productivity.

 

‘Education, education, education’ – this is how the former British Prime Minister Tony Blair summed up his prospective government’s top three policy priorities during the 1997 election campaign, which brought his ‘New’ Labour party to power after nearly two decades in the wilderness.

The subsequent success or otherwise of New Labour’s education policy may be disputed, but what is indisputable is that the comment perfectly captured Mr Blair’s exceptional ability to say the right thing at the right time (that is, before he lost his head over Iraq). Many a politician before Mr Blair had talked about and pushed for better education, but he was speaking at a time when, having witnessed the rise of the knowledge economy since the 1980s, the whole world was becoming convinced that education was the key to economic prosperity. If education had been important for economic success in the days of smoke-stack industries, more and more people were becoming convinced, it would be the be-all and end-all in the information age, when brains, and not brawn, are the main source of wealth.

The argument seems straightforward. More educated people are more productive – as evidenced by the higher salaries they get. So it is a matter of mathematical logic that an economy with more educated people will be more productive. The fact that poorer countries have a lower stock of educated people – or ‘human capital’ in some economists’ jargon – also proves the point. The average duration of schooling is around nine years in OECD countries, while it is not even three in Sub-Saharan African countries. Also well known are the exceptionally high educational achievements of the ‘miracle’ economies in East Asia – such as Japan, South Korea, Taiwan, Hong Kong and Singapore. Their educational achievements are manifested not just in quantitative terms such as high literacy rates or enrolment rates at various levels of education. The quality of their education is very high as well. They rank right at the top of the league in internationally standardized tests such as the Trends in International Mathematics and Science Study (TIMSS) for fourth and eighth graders, and the Program for International Student Assessment (PISA), which measures fifteen-year-olds’ ability to apply maths knowledge to real-world problems. Need we say more?

 

Self-evident though the importance of education in raising an economy’s productivity may seem, there is actually a lot of evidence that questions this piece of conventional wisdom.

Let’s first take the case of the East Asian miracle economies, in whose development education is supposed to have played a critical role. In 1960, Taiwan had a literacy rate of only 54 per cent, while the Philippines’ was 72 per cent. Despite its lower education level, Taiwan has since then notched up one of the best economic growth performances in human history, while the Philippines has done rather poorly. In 1960, the Philippines had almost double the per capita income of Taiwan ($200 vs. $122), but today Taiwan’s per capita income is around ten times that of the Philippines ($18,000 vs. $1,800). In the same year, Korea had a 71 per cent literacy rate – comparable to that of the Philippines but still well below Argentina’s 91 per cent. Despite the significantly lower literacy rate, Korea has since grown much faster than Argentina. Korea’s per capita income was just over one-fifth that of Argentina’s in 1960 ($82 vs. $378). Today it is three times higher (around $21,000 vs. around $7,000).

Obviously, there are many more things than education that determine a country’s economic growth performance. But these examples undermine the common myth that education was the key to the East Asian miracle. The East Asian economies did not have unusually high educational achievement at the start of their economic miracles, while countries like the Philippines and Argentina did very poorly despite having significantly better-educated populations.

At the other end of the spectrum, the experience of Sub-Saharan Africa also shows that investing more in education is no guarantee of better economic performance. Between 1980 and 2004, literacy rates in Sub-Saharan African countries rose quite substantially from 40 per cent to 61 per cent. Despite such rises, per capita income in the region actually fell by 0.3 per cent per year during this period. If education is so important for economic development, as most of us believe, something like this should not happen.

The apparent lack of positive effects of education on growth is not found only in the extreme cases that I have chosen – East Asia at one end and Sub-Saharan Africa at the other. It is a more general phenomenon. In a widely cited 2004 article, ‘Where has all the education gone?’, Lant Pritchett, a Harvard economist who worked at the World Bank for a long time, analysed the data from dozens of rich and developing countries during the 1960–87 period and conducted an extensive review of similar studies, in order to establish whether education positively influences growth. His conclusion is that there is very little evidence to support the view that increased education leads to higher economic growth.

 

Why is there so little evidence to support what seems to be such an obvious proposition that more education should make a country richer? It is because, to put it simply, education is not as important in raising the productivity of an economy as we believe.

To begin with, not all education is even meant to raise productivity. There are many subjects that have no impact, even indirectly, on most workers’ productivity – literature, history, philosophy and music, for example (see Thing 3). From a strictly economic point of view, teaching these subjects is a waste of time. We teach our children those subjects because we believe that they will eventually enrich their lives and also make them good citizens. Even though this justification for educational spending is increasingly under attack in an age in which everything is supposed to justify its existence in terms of its contribution to productivity growth, it remains a very important – in my view, the most important – reason to invest in education.

Moreover, even subjects like mathematics or sciences, which are supposed to be important for raising productivity, are not relevant for most workers – investment bankers do not need biology or fashion designers mathematics in order to be good at what they do. Even for those jobs for which these subjects are relevant, much of what you learn at school or even university is often not directly relevant for practical work. For example, the link between what a production line worker in a car factory learned in school physics and his productivity is rather tenuous. The importance of apprenticeship and on-the-job training in many professions testifies to the limited relevance of school education for worker productivity. So, even the supposedly productivity-oriented parts of education are not as relevant for raising productivity as we think.

Cross-country statistical analyses have failed to find any relationship between a country’s maths scores and its economic performance. But let me give you more concrete examples. In the mathematical part of the 2007 TIMSS, US fourth-graders were behind not only the famously mathematical children of the East Asian countries but also their counterparts from countries such as Kazakhstan, Latvia, Russia and Lithuania. Children in all other rich European economies included in the test, except England and the Netherlands, scored lower than the US children. Eighth-graders from Norway, the richest country in the world (in terms of per capita income at market exchange rate – see Thing 10), were behind their counterparts not only in all other rich countries but also in much poorer countries, including Lithuania, Czech Republic, Slovenia, Armenia and Serbia (it is interesting to note that all these countries are former socialist countries). Eighth-graders from Israel, a country famous for its educational zeal and exceptional performance in high-end research, scored behind Norway, falling behind Bulgaria as well. Similar stories were observed in science tests.

 

Even if education’s impact on growth has been meagre so far, you may wonder whether the recent rise of the knowledge economy may have changed all that. With ideas becoming the main source of wealth, it may be argued, education will from now on become much more important in determining a country’s prosperity.

Against this, I must first of all point out that the knowledge economy is nothing new. We have always lived in one in the sense that it has always been a country’s command over knowledge (or lack of it) that made it rich (or poor). China was the richest country in the world during the first millennium because it possessed technical knowledge that others did not – paper, movable type, gunpowder and the compass being the most famous, but by no means the only, examples. Britain became the world’s economic hegemon in the nineteenth century because it came to lead the world in technological innovation. When Germany became as poor as Peru and Mexico right after the Second World War, no one suggested that it should be reclassified as a developing country, because people knew that it still had command over technological, organizational and institutional knowledge that had made it one of the most formidable industrial powers before the war. In that sense, the importance (or otherwise) of education has not changed in the recent period.

Of course, the knowledge stock that the humanity collectively commands today is much bigger than in the past, but that does not mean that everyone, or even the majority of the people, has to be better educated than in the past. If anything, the amount of productivity-related knowledge that an average worker needs to possess has fallen for many jobs, especially in rich countries. This may sound absurd, but let me explain.

To begin with, with the continuous rise in manufacturing productivity, a greater proportion of the workforce in rich countries now works in low-skilled service jobs that do not require much education – stacking shelves in supermarkets, frying burgers in fast food restaurants and cleaning offices (see Things 3 and 9). Insofar as the proportion of people in such professions increases, we may actually do with an increasingly less, not more, educated labour force, if we are only interested in the productivity effects of education.

Moreover, with economic development, a higher proportion of knowledge becomes embodied in machines. This means that the economy-wide productivity increases despite individual workers having less understanding of what they do than their counterparts in the past. For the most striking example, these days most shop assistants in rich countries do not even need to know how to add – a skill that their counterparts in earlier times definitely needed – as bar-code machines do that for them. For another example, blacksmiths in poor countries probably know more about the nature of metals in relation to tool-making than do most employees of Bosch or Black & Decker. For yet another example, those who work at the small electronics shops littering the streets of poor countries can fix many more things than can individual workers at Samsung or Sony.

A large part of this is due to the simple fact that mechanization is the most important way to increase productivity. But an influential Marxist school of thought argues that capitalists deliberately ‘de-skill’ their workers by using the most mechanized production technologies possible, even if they are not the most economical, in order to make the workers more easily replaceable and thus easier to control. Whatever the exact cause of the mechanization process, the upshot is that more technologically developed economies may actually need fewer educated people.

 

Now, it may be argued that, even though economic development may not necessarily require the average worker to be more educated, it needs more educated people at the higher end. After all, as I have pointed out above, the ability to generate more productive knowledge than others is what makes a country richer than others. Thus seen, it may be argued, it is the quality of universities, rather than that of primary schools, that determines a nation’s prosperity.

However, even in this supposedly knowledge-driven era, the relationship between higher education and prosperity is not straightforward. Let us take the striking example of Switzerland. The country is one of the top few richest and most industrialized countries in the world (see Things 9 and 10), but it has, surprisingly, the lowest – actually by far the lowest – university enrolment rate in the rich world; until the early 1990s, only around one-third of the average for other rich countries. Until as late as 1996, the Swiss university enrolment rate was still less than half the OECD average (16 per cent vs. 34 per cent). Since then, Switzerland increased its rate considerably, bringing it up to 47 per cent by 2007, according to UNESCO data. However, the Swiss rate still remains the lowest in the rich world and is way below what we find in the most university-heavy countries, such as Finland (94 per cent), the US (82 per cent) and Denmark (80 per cent). It is, interestingly, also far lower than that of many considerably poorer economies, such as Korea (96 per cent), Greece (91 per cent), Lithuania (76 per cent) and Argentina (68 per cent).

How is it possible that Switzerland has stayed at the very top of the international productivity league despite providing much less higher education than not just its main competitors but also many economies that are much poorer?

One possible explanation is that universities in different countries have different qualities. So, if Korean or Lithuanian universities are not as good as Swiss universities, it may be possible for Switzerland to be richer than Korea or Lithuania, even if a much lower proportion of the Swiss have university education than do the Koreans or the Lithuanians. However, this argument loses much of its force when we compare Switzerland with Finland or the US. We cannot in all seriousness suggest that Swiss universities are so much better than Finnish or American ones that Switzerland can get away with university enrolment rates half theirs.

The main explanation for the ‘Swiss paradox’ should be found, once again, in the low productivity content of education. However, in the case of higher education, the non-productivity component is not so much about teaching people subjects that will help them with things such as personal fulfilment, good citizenship and national identity, as in the case of primary and secondary education. It is about what economists call the ‘sorting’ function.

Higher education, of course, imparts certain productivity-related knowledge to its recipients, but another important function of it is to establish each individual’s ranking in the hierarchy of employability. In many lines of work, what counts is general intelligence, discipline and the ability to organize oneself, rather than specialist knowledge, much of which you can, and have to, actually pick up on-the-job. So, even if what you learn in a university as a history major or a chemist may not be relevant to your work as a prospective manager in an insurance company or as a government official in the Department of Transport, the fact that you have graduated from a university tells your potential employers that you are likely to be smarter, more self-disciplined and better organized than those who have not. By hiring you as a university graduate, your employer is then hiring you for those general qualities, not for your specialist knowledge, which is often irrelevant to the job you will be performing.

Now, with the increasing emphasis on higher education in the recent period, an unhealthy dynamic has been established for higher education in many high-income and upper-middle-income countries that can afford to expand universities (Switzerland has not been immune to this, as figures above suggest). Once the proportion of people going to university goes over a critical threshold, people have to go to university in order to get a decent job. When, say, 50 per cent of the population goes to university, not going to university is implicitly declaring that you are in the bottom half of the ability distribution, which is not the greatest way to start your job search. So, people go to university, fully knowing that they will ‘waste time’ studying things that they will never need for their work. With everyone wanting to go to university, the demand for higher education increases, which then leads to the supply of more university places, which raises university enrolment rate further, increasing the pressure to go to university even more. Over time, this leads to a process of degree inflation. Now that ‘everyone’ has a university degree, you have to do a master’s, or even a PhD, in order to stand out, even if the productivity content of those further degrees may be minimal for your future jobs.

Given that Switzerland was until the mid 1990s able to maintain one of the highest national productivities in the world with a university enrolment of 10–15 per cent, we could say that enrolment rates much higher than that are really unnecessary. Even if we accept that skills requirement has risen so much with the rise of the knowledge economy that the 40-plus per cent enrolment rate that Switzerland now has is the minimum (which I seriously doubt), this still means that at least half of university education in countries such as the US, Korea and Finland is ‘wasted’ in the essentially zero-sum game of sorting. The higher education system in these countries has become like a theatre in which some people decided to stand to get a better view, prompting others behind them to stand. Once enough people stand, everyone has to stand, which means that no one is getting a better view, while everyone has become more uncomfortable.

 

If not just basic education but also higher education does not matter so much in determining a nation’s prosperity, we must seriously rethink the role of education in our economy.

In the case of rich countries, their obsession with higher education has to be tamed. This obsession has led to unhealthy degree inflation and the consequent over-investment of huge scale in higher education in many countries. I am not against countries having a very high – or even 100 per cent – university enrolment rate for other reasons, but they should not delude themselves into believing that it would have a significant productivity effect.

In the case of developing countries, an even more radical change of perspective is needed. While they should expand education in order to prepare their youngsters for a more meaningful life, when it comes to the question of productivity increase, these countries need to look beyond the education of individuals and pay more attention to building the right institutions and organizations for productivity growth.

What really distinguishes the rich countries from the poorer ones is much less how well educated their individual citizens are than how well their citizens are organized into collective entities with high productivity – be that giant firms such as Boeing or Volkswagen or the smaller world-class firms of Switzerland and Italy (see Thing 15). Development of such firms needs to be supported by a range of institutions that encourage investment and risk-taking – a trade regime that protects and nurtures firms in ‘infant industries’ (see Things 7 and 12), a financial system that provides ‘patient capital’ necessary for long-term productivity-enhancing investments (see Thing 2), institutions that provide second chances for both the capitalists (a good bankruptcy law) and for the workers (a good welfare state) (see Thing 21), public subsidies and regulation regarding R&D and training (see Things 18 and 19), and so on.

Education is valuable, but its main value is not in raising productivity. It lies in its ability to help us develop our potentials and live a more fulfilling and independent life. If we expanded education in the belief that it will make our economies richer, we will be sorely disappointed, for the link between education and national productivity is rather tenuous and complicated. Our overenthusiasm with education should be tamed, and, especially in developing countries, far greater attention needs to be paid to the issue of establishing and upgrading productive enterprises and institutions that support them.

 

 

At the heart of the capitalist system is the corporate sector. This is where things are produced, jobs created and new technologies invented. Without a vibrant corporate sector, there is no economic dynamism. What is good for business, therefore, is good for the national economy. Especially given the increasing international competition in a globalizing world, countries that make opening and running businesses difficult or make firms do unwanted things will lose investment and jobs, eventually falling behind. Government needs to give the maximum degree of freedom to business.

 

Despite the importance of the corporate sector, allowing firms the maximum degree of freedom may not even be good for the firms themselves, let alone the national economy. In fact, not all regulations are bad for business. Sometimes, it is in the long-run interest of the business sector to restrict the freedom of individual firms so that they do not destroy the common pool of resources that all of them need, such as natural resources or the labour force. Regulations can also help businesses by making them do things that may be costly to them individually in the short run but raise their collective productivity in the long run – such as the provision of worker training. In the end, what matters is not the quantity but the quality of business regulation.

 

They say that Detroit won the Second World War. Yes, the Soviet Union sacrificed the most people – the estimated death toll in the Great Patriotic War (as it is known in Russia) was upward of 25 million, nearly half of all deaths worldwide. But it – and, of course, the UK – would not have survived the Nazi offensive without the arms sent over from what Franklin Roosevelt called ‘the arsenal of democracy’, that is, the United States. And most of those arms were made in the converted factories of the Detroit car-makers – General Motors (GM), Ford and Chrysler. So, without the industrial might of the US, represented by Detroit, the Nazis would have taken over Europe and at least the western part of the Soviet Union.

Of course, history is never straightforward. What made the early success of Nazi Germany in the war possible was the ability of its army to move quickly – its famous Blitzkrieg, or Lightning War. And what made that high mobility of the German army possible was its high degree of motorization, many technologies for which were supplied by none other than GM (through its Opel subsidiary, acquired in 1929). Moreover, evidence is emerging that, in defiance of the law, throughout the war GM secretly maintained its link with Opel, which built not only military cars but aircraft, landmines and torpedoes. So it seems that GM was arming both sides and profiting from it.

Even among the Detroit car-makers – collectively known as the Big Three – GM by then stood pre-eminent. Under the leadership of Alfred Sloan Jr, who ran it for thirty-five years (1923–58), GM had overtaken Ford as the largest US car-maker by the late 1920s and gone on to become the all-American automobile company, producing, in Sloan’s words, ‘a car for every purse and purpose’, arranged along a ‘ladder of success’, starting with Chevrolet, moving up through Pontiac, Oldsmobile, Buick and finally culminating in Cadillac.

By the end of the Second World War, GM was not just the biggest car-maker in the US, it had become the biggest company in the country (in terms of revenue). It was so important that, when asked in the Congressional hearing for his appointment as US Defense Secretary in 1953 whether he saw any potential conflict between his corporate background and his public duties, Mr Charlie Wilson, who used to be the CEO of General Motors, famously replied that what is good for the United States is good for General Motors and vice versa.

The logic behind this argument seems difficult to dispute. In a capitalist economy, private sector companies play the central role in creating wealth, jobs and tax revenue. If they do well, the whole economy does well by extension. Especially when the enterprise in question is one of the largest and technologically most dynamic enterprises, like GM in the 1950s, its success or otherwise has significant effects on the rest of the economy – the supplier firms, the employees of those firms, the producers of goods that the giant firm’s employees, who can number in the hundreds of thousands, may buy, and so on. Therefore, how these giant firms do is particularly important for the prosperity of the national economy.

Unfortunately, proponents of this logic say, this obvious argument was not widely accepted during much of the twentieth century. One can understand why communist regimes were against the private sector – after all, they believed that private property was the source of all the evils of capitalism. However, between the Great Depression and the 1970s, private business was viewed with suspicion even in most capitalist economies.

Businesses were, so the story goes, seen as anti-social agents whose profit-seeking needed to be restrained for other, supposedly loftier, goals, such as justice, social harmony, protection of the weak and even national glory. As a result, complicated and cumbersome systems of licensing were introduced in the belief that governments need to regulate which firms do what in the interest of wider society. In some countries, governments even pushed firms into unwanted businesses in the name of national development (see Things 7 and 12). Large firms were banned from entering those segments of the market populated by small farms, factories and retail shops, in order to preserve the traditional way of life and protect ‘small men’ against big business. Onerous labour regulations were introduced in the name of protecting worker rights. In many countries, consumer rights were extended to such a degree that it hurt business.

These regulations, pro-business commentators argue, not only harmed the large firms but made everyone else worse off by reducing the overall size of the pie to be shared out. By limiting the ability of firms to experiment with new ways of doing business and enter new areas, these regulations slowed down the growth of overall productivity. In the end, however, the folly of this anti-business logic became too obvious, the argument goes. As a result, since the 1970s, countries from all around the world have come to accept that what is good for business is good for the national economy and have adopted a pro-business policy stance. Even communist countries have given up their attempts to stifle the private sector since the 1990s. Need we ponder upon this issue any more?

 

Five decades after Mr Wilson’s remark, in the summer of 2009, GM went bankrupt. Notwithstanding its well-known aversion to state ownership, the US government took over the company and, after an extensive restructuring, launched it as a new entity. In the process, it spent a staggering $57.6 billion of taxpayers’ money.

It may be argued that the rescue was in the American national interest. Letting a company of GM’s size and inter-linkages collapse suddenly would have had huge negative ripple effects on jobs and demand (e.g., fall in consumer demand from unemployed GM workers, evaporation of GM’s demand for products from its supplier firms), aggravating the financial crisis that was unfolding in the country at the time. The US government chose the lesser of the two evils, on behalf of the taxpayers. What was good for GM was still good for the United States, it may be argued, even though it was not a very good thing in absolute terms.

However, that does not mean that we should not question how GM got into that situation in the first place. When faced with stiff competition from imports from Germany, Japan and then Korea from the 1960s, GM did not respond in the most natural, if difficult, way it should have – producing better cars than those of its competitors. Instead, it tried to take the easy way out.

First, it blamed ‘dumping’ and other unfair trade practices by its competitors and got the US government to impose import quotas on foreign, especially Japanese, cars and force open competitors’ home markets. In the 1990s, when these measures proved insufficient to halt its decline, it had tried to make up for its failings in car-making by developing its financial arm, GMAC (General Motors Acceptance Corporation). GMAC moved beyond its traditional function of financing car purchases and started conducting financial transactions for their own sake. GMAC itself proved quite successful – in 2004, for example, 80 per cent of GM’s profit came from GMAC (see Thing 22). But that could not really hide the fundamental problem – that the company could not make good cars at competitive prices. Around the same time, the company tried to shortcut the need for investing in the development of better technologies by buying up smaller foreign competitors (such as Saab of Sweden and Daewoo of Korea), but these were nowhere near enough to revive the company’s former technological superiority. In other words, in the last four decades, GM has tried everything to halt its decline except making better cars because trying to make better cars itself was, well, too much trouble.

Obviously, all these decisions may have been best from GM’s point of view at the time when they were made – after all, they allowed the company to survive for a few more decades with the least effort – but they have not been good for the rest of the United States. The huge bill that American taxpayers have been landed with through the rescue package is the ultimate proof of that, but along the way, the rest of the US could have done better, had GM been forced to invest in the technologies and machines needed to build better cars, instead of lobbying for protection, buying up smaller competitors and turning itself into a financial company.

More importantly, all those actions that have enabled GM to get out of difficulties with the least effort have ultimately not been good even for GM itself – unless you equate GM with its managers and a constantly changing group of shareholders. These managers drew absurdly high salaries by delivering higher profits by not investing for productivity growth while squeezing other weaker ‘stakeholders’ – their workers, supplier firms and the employees of those firms. They bought the acquiescence of shareholders by offering them dividends and share buybacks to such an extent that the company’s future was jeopardized. The shareholders did not mind, and indeed many of them encouraged such practices, because most of them were floating shareholders who were not really concerned with the long-term future of the company because they could leave at a moment’s notice (see Thing 2).

The story of GM teaches us some salutary lessons about the potential conflicts between corporate and national interests – what is good for a company, however important it may be, may not be good for the country. Moreover, it highlights the conflicts between different stakeholders that make up the firm – what is good for some stakeholders of a company, such as managers and short-term shareholders, may not be good for others, such as workers and suppliers. Ultimately, it also tells us that what is good for a company in the short run may not even be good for it in the long run – what is good for GM today may not be good for GM tomorrow.

Now, some readers, even ones who were already persuaded by this argument, may still wonder whether the US is just an exception that proves the rule. Under-regulation may be a problem for the US, but in most other countries, isn’t the problem over-regulation?

 

In the early 1990s, the Hong Kong-based English-language business magazine, Far Eastern Economic Review, ran a special issue on South Korea. In one article the magazine expressed puzzlement at the fact that, even though it needed up to 299 permits from up to 199 agencies to open a factory in the country, South Korea had grown at over 6 per cent in per capita terms for the previous three decades. How was this possible? How can a country with such an oppressive regulatory regime grow so fast?

Before trying to make sense of this puzzle, I must point out that it was not just Korea before the 1990s in which seemingly onerous regulations coexisted with a vibrant economy. The situation was similar in Japan and Taiwan throughout their ‘miracle’ years between the 1950s and the 1980s. The Chinese economy has been heavily regulated in a similar manner during the last three decades of rapid growth. In contrast, over the last three decades, many developing countries in Latin America and Sub-Saharan Africa have de-regulated their economies in the hope that it would stimulate business activities and accelerate their growth. However, puzzlingly, since the 1980s, they have grown far more slowly than in the 1960s and 70s, when they were supposedly held back by excessive regulations (see Things 7 and 11).

The first explanation for the puzzle is that, strange as it may seem to most people without business experience, businesspeople will get 299 permits (with some circumvented along the way with bribes, if they can get away with it), if there is enough money to be made at the end of the process. So, in a country that is growing fast and where good business opportunities are cropping up all the time, even the hassle of acquiring 299 permits would not deter business people from opening a new line of business. In contrast, if there is little money to be made at the end of the process, even twenty-nine permits may look too onerous.

More importantly, the reason why some countries that have heavily regulated business have done economically well is that many regulations are actually good for business.

Sometimes regulations help business by limiting the ability of firms to engage in activities that bring them greater profits in the short run but ultimately destroy the common resource that all business firms need. For example, regulating the intensity of fish farming may reduce the profits of individual fish farms but help the fish-farming industry as a whole by preserving the quality of water that all the fish farms have to use. For another example, it may be in the interest of individual firms to employ children and lower their wage bills. However, a widespread use of child labour will lower the quality of the labour force in the longer run by stunting the physical and mental development of children. In such a case, child labour regulation can actually benefit the entire business sector in the long run. For yet another example, individual banks may benefit from lending more aggressively. But when all of them do the same, they may all suffer in the end, as such lending behaviours may increase the chance of systemic collapse, as we have seen in the 2008 global financial crisis. Restricting what banks can do, then, may actually help them in the long run, even if it does not immediately benefit them (see Thing 22).

It is not just that regulation can help firms by preventing them from undermining the basis of their long-term sustainability. Sometimes, regulations can help businesses by forcing firms to do things that may not be in their individual interests but raise their collective productivity in the long run. For example, firms often do not invest enough in training their workers. This is because they are worried about their workers being poached by other firms ‘free-riding’ on their training efforts. In such a situation, the government imposing a requirement for worker training on all firms could actually raise the quality of the labour force, thereby ultimately benefiting all firms. For another example, in a developing country that needs to import technologies from abroad, the government can help business achieve higher productivity in the long run by banning the importation of overly obsolete foreign technologies that may enable their importers to undermine competitors in the short run but will lock them into dead-end technologies.

Karl Marx described the government restriction of business freedom for the sake of the collective interest of the capitalist class as it acting as ‘the executive committee of the bourgeoisie’. But you don’t need to be a Marxist to see that regulations restricting freedom for individual firms may promote the collective interest of the entire business sector, not to speak of the nation as a whole. In other words, there are many regulations that are pro- rather than anti-business. Many regulations help preserve the common-pool resources that all firms share, while others help business by making firms do things that raise their collective productivity in the long run. Only when we recognize this will we be able to see that what matters is not the absolute amount of regulation, but the aims and contents of those regulations.

 

 

The limits of economic planning have been resoundingly demonstrated by the fall of communism. In complex modern economies, planning is neither possible nor desirable. Only decentralized decisions through the market mechanism, based on individuals and firms being always on the lookout for a profitable opportunity, are capable of sustaining a complex modern economy. We should do away with the delusion that we can plan anything in this complex and ever-changing world. The less planning there is, the better.

 

Capitalist economies are in large part planned. Governments in capitalist economies practise planning too, albeit on a more limited basis than under communist central planning. All of them finance a significant share of investment in R&D and infrastructure. Most of them plan a significant chunk of the economy through the planning of the activities of state-owned enterprises. Many capitalist governments plan the future shape of individual industrial sectors through sectoral industrial policy or even that of the national economy through indicative planning. More importantly, modern capitalist economies are made up of large, hierarchical corporations that plan their activities in great detail, even across national borders. Therefore, the question is not whether you plan or not. It is about planning the right things at the right levels.

 

In the 1970s, many Western diplomats called the Soviet Union ‘Upper Volta with rockets’. What an insult – that is, to Upper Volta (renamed Burkina Faso in 1984), which was being branded the quintessential poor country, when it wasn’t even near the bottom of the world poverty league. The nickname, however, succinctly summarized what was wrong with the Soviet economy.

Here was a country that could send men into space but had people queuing up for basic foodstuffs such as bread and sugar. The country had no problem churning out intercontinental ballistic missiles and nuclear submarines, but could not manufacture a decent TV. It is reported that in the 1980s the second-biggest cause of fires in Moscow was – believe it or not – exploding TVs. The top Russian scientists were as inventive as their counterparts in capitalist countries, but the rest of the country did not seem able to live up to the same standard. What was going on?

In pursuit of the communist vision of a classless society based on collective ownership of the ‘means of production’ (e.g., machines, factory buildings, roads), the Soviet Union and its communist allies aimed for full employment and a high degree of equality. Since no one was allowed to own any means of production, virtually all enterprises were run by professional managers (with minor exceptions such as small restaurants and hairdressers), preventing the emergence of visionary entrepreneurs, like Henry Ford or Bill Gates. Given the political commitment to high equality, there was a clear cap on how much a business manager, however successful, could get. This meant that there was only a limited incentive for business managers to turn the advanced technologies that the system was clearly capable of producing into products that consumers actually wanted. The policy of full employment at all costs meant that managers could not use the ultimate threat – that of sacking – to discipline workers. This contributed to sloppy work and absenteeism; when he was trying to reform the Soviet economy, Gorbachev frequently spoke of the problem of labour discipline.

Of course, all this did not mean that no one in communist countries was motivated to work hard or to run a good business. Even in capitalist economies, we don’t do things just for the money (see Thing 5), but communist countries relied, with some success, much more on the less selfish sides of human nature. Especially in the early days of communism, there was a lot of idealism about building a new society. In the Soviet Union, there was also a huge surge of patriotism during and shortly after the Second World War. In all communist countries there were many dedicated managers and workers who did things well out of professionalism and self-respect. Moreover, by the 1960s, the ideal egalitarianism of early communism had given way to realism and performance-related pay had become the norm, mitigating (although by no means eliminating) the incentive problem.

Despite this, the system still failed to function well because of the inefficiency of the communist central planning system, which was supposed to be a more efficient alternative to the market system.

The communist justification of central planning was based on some quite sound logic. Karl Marx and his followers argued that the fundamental problem with capitalism was the contradiction between the social nature of the production process and the private nature of ownership of the means of production. With economic development – or the development of productive forces, in Marxist jargon – the division of labour between firms develops further and as a result the firms become increasingly more dependent on each other – or the social nature of the production process is intensified. However, despite the growing interdependence among firms, the Marxists argued, ownership of the firms firmly remains in separate private hands, making it impossible to coordinate the actions of those interdependent firms. Of course, price changes ensure that there is some ex post coordination of firm decisions, but its extent is limited and the imbalance between demand and supply, created by such (in non-Marxist terms) ‘coordination failures’, accumulates into periodic economic crises. During an economic crisis, the argument went, a lot of valuable resources are wasted. Many unsold products are thrown away, machines that used to produce now-unwanted things are scrapped, and workers who are capable and willing to work are laid off due to the lack of demand. With the development of capitalism, the Marxists predicted, this systemic contradiction would become larger and consequently economic crises would become more and more violent, finally bringing the whole system down.

In contrast, under central planning, the Marxist argued, all means of production are owned by the whole of society and as a result the activities of interdependent production units can be coordinated ex ante through a unified plan. As any potential coordination failure is resolved before it happens, the economy does not have to go through those periodic crises in order to balance supply and demand. Under central planning, the economy will produce only exactly what is needed. No resource will lie idle at any time, since there will be no economic crisis. Therefore, the central planning system, it was argued, will manage the economy much more efficiently than the market system.

That, at least, was the theory. Unfortunately, central planning did not work very well in practice. The main problem was that of complexity. The Marxists may have been right in thinking that the development in productive forces, by increasing interdependence among different segments of capital, makes it more necessary to plan centrally. However, they failed to recognize that it also makes the economy more complex, making it more difficult to plan centrally.

Central planning worked well when the targets were relatively simple and clear, as seen in the success of early Soviet industrialization, where the main task was to produce a relatively small number of key products in large quantities (steel, tractors, wheat, potatoes, etc.). However, as the economy developed, central planning became increasingly difficult, with a growing number of (actual and potential) diverse products. Of course, with economic development, the ability to plan also increased thanks to improvements in managerial skills, mathematical techniques of planning and computers. However, the increase in the ability to plan was not sufficient to deal with the increase in the complexity of the economy.

One obvious solution was to limit the variety of products, but that created huge consumer dissatisfaction. Moreover, even with reduced varieties, the economy was still too complex to plan. Many unwanted things were produced and remained unsold, while there were shortages of other things, resulting in the ubiquitous queues. By the time communism started unravelling in the 1980s, there was so much cynicism about the system that was increasingly incapable of delivering its promises that the joke was that in the communist countries, ‘we pretend to work and they pretend to pay us’.

No wonder central planning was abandoned across the board when the ruling communist parties were ousted across the Soviet bloc, following the fall of the Berlin Wall. Even countries such as China and Vietnam, which ostensibly maintained communism, have gradually abandoned central planning, although their states still hold high degrees of control over the economy. So, we all now live in market economies (well, unless you live in North Korea or Cuba). Planning is gone. Or is it?

 

The fact that communism has disappeared for all practical purposes does not mean that planning has ceased to exist. Governments in capitalist economies also plan, albeit not in the same comprehensive way that the central planning authorities in communist countries did.

Even in a capitalist economy, there are situations – a war, for example – in which central planning is more effective. For example, during the Second World War, the economies of the major capitalist belligerents, the US, the UK and Germany, were all centrally planned in everything but name.

But, more importantly, many capitalist countries have successfully used what is known as ‘indicative planning’. This is planning that involves the government in a capitalist country setting some broad targets concerning key economic variables (e.g., investments in strategic industries, infrastructure development, exports) and working with, not against, the private sector to achieve them. Unlike under central planning, these targets are not legally binding; hence the adjective ‘indicative’. However, the government will do its best to achieve them by mobilizing various carrots (e.g., subsidies, granting of monopoly rights) and sticks (e.g., regulations, influence through state-owned banks) at its disposal.

France had great success in promoting investment and technological innovation through indicative planning in the 1950s and 60s, thereby overtaking the British economy as Europe’s second industrial power. Other European countries, such as Finland, Norway and Austria, also successfully used indicative planning to upgrade their economies between the 1950s and the 1970s. The East Asian miracle economies of Japan, Korea and Taiwan used indicative planning too between the 1950s and the 1980s. This is not to say that all indicative planning exercises have been successful; in India, for example, it has not. Nevertheless, the European and East Asian examples show that planning in certain forms is not incompatible with capitalism and may even promote capitalist development very well.

Moreover, even when they do not explicitly plan the entire economy, even in an indicative way, governments in most capitalist economies make and implement plans for certain key activities, which can have economy-wide implications (see Thing 12).

Most capitalist governments plan and shape the future of some key industries through what is known as ‘sectoral industrial policy’. The European and East Asian countries which practised indicative planning all also practised active sectoral industrial policy. Even countries that have not practised indicative planning, such as Sweden and Germany, have practised sectoral industrial policy.

In most capitalist countries, the government owns, and often also operates, a sizeable chunk of the national economy through state-owned enterprises (SOEs). SOEs are frequently found in the key infrastructure sectors (e.g., railways, roads, ports, airports) or essential services (e.g., water, electricity, postal service), but also exist in manufacturing or finance (more stories about SOEs can be found in the chapter ‘Man Exploits Man’ of my book Bad Samaritans). The share of SOEs in national output could be as high as 20 per cent-plus, in the case of Singapore, or as low as 1 per cent, in the case of the US, but the international average is around 10 per cent. As the government plans the activities of SOEs, this means that a significant part of the average capitalist economy is directly planned. When we consider the fact that SOEs usually operate in sectors with disproportionate impacts on the rest of the economy, the indirect effect of planning through SOEs is even greater than what is suggested by the share of SOEs in national output.

Moreover, in all capitalist economies, the government plans the national technological future by funding a very high proportion (20–50 per cent) of research and development. Interestingly, the US is one of the most planned capitalist economies in this regard. Between the 1950s and the 1980s, the share of government funding in total R&D in the supposedly free-market US accounted for, depending on the year, between 47 per cent and 65 per cent, as against around 20 per cent in Japan and Korea and less than 40 per cent in several European countries (e.g., Belgium, Finland, Germany, Sweden). The ratio has come down since the 1990s, as military R&D funding was reduced with the end of the Cold War. However, even so, the share of government in R&D in the US is still higher than in many other capitalist economies. It is notable that most of the industries where the US has an international technological lead are the industries that have been receiving major government R&D funding through military programmes (e.g., computers, semiconductors, aircraft) and health projects (e.g., pharmaceuticals, biotechnology).

Of course, since the 1980s the extent of government planning in most capitalist economies has declined, not least because of the rise of pro-market ideology during this period. Indicative planning has been phased out in most countries, including in the ones where it had been successful. In many, although not all, countries, privatization has resulted in a falling share of SOEs in national output and investment. The share of government funding in total R&D funding has also fallen in virtually all capitalist countries, although not by very much in most cases. However, I would argue, despite the relative decline of government planning in the recent period, there is still extensive, and increasing, planning in the capitalist economies. Why do I say that?

 

Suppose that a new CEO arrived in a company and said: ‘I am a great believer in market forces. In this fast-changing world, we should not have a fixed strategy and should maintain maximum possible flexibility. So, from now on, everyone in this company is going to be guided by ever-changing market prices, and not by some rigid plan.’ What do you think would happen? Would his employees welcome a leader with a vision fit for the twenty-first century? Would the shareholders applaud his market-friendly approach and award him with a pay rise?

He wouldn’t last a week. People would say he does not have leadership qualities. He would be accused of lacking the ‘vision thing’ (as George Bush Sr once put it). The top decision-maker, it would be pointed out, should be willing to shape the future of the company, rather than letting it just happen. Blindly following market signals, they would say, is not how you run a business.

People would expect a new CEO to say something like: ‘This is where our company is today. That is where I want to take it in ten years’ time. In order to get there, we will develop new industries A, B and C, while winding down D and E. Our subsidiary in industry D will be sold off. We will shut down our subsidiary in industry E at home, but some production may be shifted to China. In order to develop our subsidiary in industry A, we will have to cross-subsidize it with the profits from existing businesses. In order to establish a presence in industry B, we have to go into strategic alliance with Kaisha Corporation of Japan, which may involve supplying it with some inputs that we produce at below-market prices. In order to expand our business in industry C, we will need to increase our R&D investment in the next five years. All this may mean the company as a whole making losses in the foreseeable future. If that is the case, so be it. Because that is the price we have to pay in order to have a brighter future.’ In other words, a CEO is expected to be a ‘man (or a woman) with a plan’.

Businesses plan their activities – often down to the last detail. Indeed, that is where Marx got the idea of centrally planning the whole economy. When he talked about planning, there was in fact no real-life government that was practising planning. At the time, only firms planned. What Marx predicted was that the ‘rational’ planning approach of the capitalist firms would eventually prove superior to the wasteful anarchy of the market and thus eventually be extended to the whole economy. To be sure, he criticized planning within the firm as despotism by capitalists, but he believed that, once private property was abolished and the capitalists eliminated, the rational elements of such despotism could be isolated and harnessed for the social good.

With the development of capitalism, more and more areas of the economy have become dominated by large corporations. This means that the area of the capitalist economy that is covered by planning has in fact grown. To give you a concrete example, these days, depending on the estimate, between one third and one half of international trade consists of transfers among different units within transnational corporations.

Herbert Simon, the 1978 Nobel laureate in economics who was a pioneer of the study of business organizations (see Thing 16), put this point succinctly in 1991 in ‘Organisations and Markets’, one of the last articles he wrote. If a Martian, with no preconceptions, came to Earth and observed our economy, Simon mused, would he conclude that Earthlings live in a market economy? No, Simon said, he would almost certainly have concluded that Earthlings live in an organizational economy in the sense that the bulk of earth’s economic activities is coordinated within the boundaries of firms (organizations), rather than through market transactions between those firms. If firms were represented by green and markets by red, Simon argued, the Martian would see ‘large green areas interconnected by red lines’, rather than ‘a network of red lines connecting green spots’. And we think planning is dead.

Simon did not talk much about government planning, but if we add government planning, modern capitalist economies are even more planned than his Martian example suggests. Between the planning that is going on within corporations and various types of planning by the government, modern capitalist economies are planned to a very high degree. One interesting point that follows from these observations is that rich countries are more planned than poor countries, owing to the more widespread existence of large corporations and often more pervasive (albeit often less visible, on account of its more subtle approach) presence of the government.

The question, then, is not whether to plan or not. It is what the appropriate levels and forms of planning are for different activities. The prejudice against planning, while understandable given the failures of communist central planning, makes us misunderstand the true nature of the modern economy in which government policy, corporate planning and market relationships are all vital and interact in a complex way. Without markets we will end up with the inefficiencies of the Soviet system. However, thinking that we can live by the market alone is like believing that we can live by eating only salt, because salt is vital for our survival.

 

 

Many people get upset by inequality. However, there is equality and there is equality. When you reward people the same way regardless of their efforts and achievements, the more talented and the harder-working lose the incentive to perform. This is equality of outcome. It’s a bad idea, as proven by the fall of communism. The equality we seek should be the equality of opportunity. For example, it was not only unjust but also inefficient for a black student in apartheid South Africa not to be able to go to better, ‘white’, universities, even if he was a better student. People should be given equal opportunities. However, it is equally unjust and inefficient to introduce affirmative action and begin to admit students of lower quality simply because they are black or from a deprived background. In trying to equalize outcomes, we not only misallocate talents but also penalize those who have the best talent and make the greatest efforts.

 

Equality of opportunity is the starting point for a fair society. But it’s not enough. Of course, individuals should be rewarded for better performance, but the question is whether they are actually competing under the same conditions as their competitors. If a child does not perform well in school because he is hungry and cannot concentrate in class, it cannot be said that the child does not do well because he is inherently less capable. Fair competition can be achieved only when the child is given enough food – at home through family income support and at school through a free school meals programme. Unless there is some equality of outcome (i.e., the incomes of all the parents are above a certain minimum threshold, allowing their children not to go hungry), equal opportunities (i.e., free schooling) are not truly meaningful.

 

In Latin America, people frequently use the expression that someone is ‘more Catholic than the Pope’ (mas Papista que el Papa). This refers to the tendency of societies in the intellectual periphery to apply doctrines – religious, economic and social – more rigidly than do their source countries.

Koreans, my own people, are probably the world champions at being more Catholic than the Pope (not quite in the literal sense – only around 10 per cent of them are Catholics). Korea is not exactly a small country. The combined population of North and South Koreas, which for nearly a millennium until 1945 used to be one country, is about 70 million today. But it happens to be bang in the middle of a zone where the interests of the giants – China, Japan, Russia and the US – clash. So we have become very adept at adopting the ideology of one of the big boys and being more orthodox about it than he is. When we do communism (up in North Korea), we are more communist than the Russians. When we practised Japanese-style state capitalism (in the South) between the 1960s and the 1980s, we were more state-capitalist than the Japanese. Now that we have switched over to US-style capitalism, we lecture the Americans on the virtues of free trade and shame them by deregulating financial and labour markets left, right and centre.

So it was natural that until the nineteenth century, when we were under the Chinese sphere of influence, we were more Confucian than the Chinese. Confucianism, for those who are not familiar with it, is a cultural system based on the teachings of Confucius – the Latinized name of the Chinese political philosopher, Kong Tze, who lived in the fifth century BC. Today, having seen the economic successes of some Confucian countries, many people think it is a culture particularly well suited to economic development, but it was a typical feudal ideology until it came to be adapted to the requirements of modern capitalism in the second half of the twentieth century.

Like most other feudal ideologies, Confucianism espoused a rigid social hierarchy which restricted people’s choice of occupation according to their births. This prevented talented men from lower castes from rising above their station. In Confucianism, there was a crucial divide between the farmers (who were considered to be the bedrock of society) and other working classes. The sons of farmers could sit for the (incredibly difficult) government civil service examination and get incorporated into the ruling class, although this happened rarely in practice, while the sons of artisans and merchants were not even permitted to sit for the exam, however clever they might be.

China, being the birthplace of Confucianism, had the confidence to take a more pragmatic approach in interpreting the classical doctrines and allowed people from merchant and artisanal classes to sit for the civil service examination. Korea – being more Confucian than Confucius – adamantly stuck to this doctrine and refused to hire talented people simply because they were born to the ‘wrong’ parents. It was only after our liberation from Japanese colonial rule (1910–45) that the traditional caste system was fully abolished and Korea became a country where birth does not set a ceiling to individual achievement (although the prejudice against artisans – engineers in modern terms – and merchants – business managers in modern terms – lingered on for another few decades until economic development made these attractive professions).

Obviously feudal Korea was not alone in refusing to give people equality of opportunity. European feudal societies operated with similar systems, and in India the caste system still operates, albeit informally. Nor was it only along the caste lines that people were refused equality of opportunity. Until the Second World War, most societies refused to let women be elected to public office; in fact they were refused political citizenship altogether and not even allowed to vote. Until recently, many countries used to restrict people’s access to education and jobs along racial lines. In the late nineteenth and the early twentieth centuries, the USA prohibited the immigration of ‘undesirable’ races, especially Asians. South Africa, during the apartheid regime, had separate universities for whites and for the rest (the ‘coloureds’ and the blacks), which were very poorly funded.

So it has not been long since the majority of the world emerged from a situation where people were banned from self-advancement due to their race, gender or caste. Equality of opportunity is something to be highly cherished.

 

Many of the formal rules restricting equality of opportunity have been abolished in the last few generations. This was in large part because of political struggles by the discriminated against – such as the Chartist demand for universal (male) suffrage in Britain in the mid nineteenth century, the Civil Rights movement by blacks in the US in the 1960s, the anti-apartheid struggle in South Africa in the second half of the twentieth century and the fight by low caste people in India today. Without these and countless other campaigns by women, oppressed races and lower caste people, we would still be living in a world where restricting people’s rights according to ‘birth lottery’ would be considered natural.

In this struggle against inequality of opportunity, the market has been a great help. When only efficiency ensures survival, free-market economists point out, there is no room for racial or political prejudices to creep into market transactions. Milton Friedman put it succinctly in his Capitalism and Freedom: ‘No one who buys bread knows whether the wheat from which it was made was grown by a Communist or a Republican … by a Negro or a white.’ Therefore, Friedman argued, the market will eventually drive racism out, or at least reduce it significantly, because those racist employers insisting on employing only white people would be driven out by more open-minded ones who hire the best available talents, regardless of race.

This point is powerfully illustrated by the fact that even the notoriously racist apartheid regime in South Africa had to designate the Japanese ‘honorary whites’. There was no way the Japanese executives running the local Toyota and Nissan factories could go and live in townships like Soweto, where non-whites were forced to live under apartheid law. Therefore, the white-supremacist South Africans had to swallow their pride and pretend that the Japanese were whites, if they wanted to drive around in Japanese cars. That is the power of the market.

The power of the market as a ‘leveller’ is more widespread than we think. As the British writer Alan Bennett’s play-turned-movie, History Boys, so poignantly shows, students from disadvantaged groups tend to lack intellectual and social confidence and are thus disadvantaged in getting into elite universities – and by extension, better-paying jobs. Obviously, universities do not have to respond to market pressures as quickly as firms have to. However, if some university consistently discriminated against ethnic minorities or working-class kids and took in only people from the ‘right’ backgrounds despite their inferior quality, potential employers would come to prefer the graduates from non-racist universities. The narrow-minded university, if it is to recruit the best possible students, would have to abandon its prejudices sooner or later.

Given all this, it is tempting to argue that, once you ensure equality of opportunity, free from any formal discrimination other than according to merit, the market will eliminate any residual prejudices through the competitive mechanism. However, this is only the start. A lot more has to be done to build a genuinely fair society.

 

While there are still too many people with prejudices against certain races, poor people, lower castes and women, today few would openly object to the principle of equality of opportunity. But at this point, opinions divide sharply. Some argue that equality should end with that of opportunity. Others, including myself, believe that it is not enough to have mere formal equality of opportunity.

Free-market economists warn that, if we try to equalize the outcomes of people’s actions and not just their opportunities to take certain actions, that will create huge disincentives against hard work and innovation. Would you work hard if you knew that, whatever you do, you will get paid the same as the next guy who is goofing off? Isn’t that exactly why the Chinese agricultural communes under Mao Zedong were such failures? If you tax the rich disproportionately and use the proceeds to finance the welfare state, won’t the rich lose the incentive to create wealth, while the poor lose the incentive to work, as they are guaranteed a minimum standard of living whether they work hard or not – or whether they work at all? (see Thing 21.) This way, free-market economists argue, everyone becomes worse off by the attempt to reduce inequality of outcome (see Thing 13).

It is absolutely true that excessive attempts to equalize outcomes – say, the Maoist commune, where there was virtually no link between someone’s effort and the reward that she got – will have an adverse impact on people’s work effort. It is also unfair. But I believe that a certain degree of equalization of outcomes is necessary, if we are to build a genuinely fair society.

The point is that, in order to benefit from the equal opportunities provided to them, people require the capabilities to make use of them. It is no use that black South Africans now have the same opportunities as whites to get a highly paid job, if they do not have the education to qualify for those jobs. It is no good that blacks now can enter better (former white-only) universities, if they still have to attend poorly funded schools with underqualified teachers, some of whom can barely read and write themselves.

For most black kids in South Africa, the newly acquired equality of opportunity to enter good universities does not mean that they can attend such universities. Their schools are still poor and poorly run. It is not as if their underqualified teachers have suddenly become smart with the end of apartheid. Their parents are still unemployed (even the official unemployment rate, which vastly underestimates true unemployment in a developing country, is, at 26–28 per cent, one of the highest in the world). For them, the right to enter better universities is pie in the sky. For this reason, post-apartheid South Africa has turned into what some South Africans call a ‘cappuccino society’: a mass of brown at the bottom, a thin layer of white froth above it, and a sprinkling of cocoa at the top.

Now, free-market economists will tell you that those who do not have the education, the determination and the entrepreneurial energy to take advantage of market opportunities have only themselves to blame. Why should people who have worked hard and obtained a university degree against all odds be rewarded in the same way as someone, coming from the same poor background, who goes into a life of petty crime?

This argument is correct. We cannot, and should not, explain someone’s performance only by the environment in which he has grown up. Individuals do have responsibilities for what they have made out of their lives.

However, while correct, this argument is only part of the story. Individuals are not born into a vacuum. The socio-economic environment they operate in puts serious restrictions on what they can do. Or even on what they want to do. Your environment can make you give up certain things even without trying. For example, many academically talented British working-class children do not even try to go to universities because universities are ‘not for them’. This attitude is slowly changing, but I still remember seeing a BBC documentary in the late 1980s in which an old miner and his wife were criticizing one of their sons, who had gone to a university and become a teacher, as a ‘class traitor’.

While it is silly to blame everything on the socio-economic environment, it is equally unacceptable to believe that people can achieve anything if they only ‘believe in themselves’ and try hard enough, as Hollywood movies love to tell you. Equality of opportunity is meaningless for those who do not have the capabilities to take advantage of it.

 

Today, no country deliberately keeps poor children from going to school, but many children in poor countries cannot go to school because they do not have the money to pay for the tuition. Moreover, even in countries with free public education, poor children are bound to perform poorly in school, whatever their innate ability may be. Some of them go hungry at home and also skip lunch at school. This makes it impossible for them to concentrate, with predictable results for their academic performance. In extreme cases, their intellectual development may have already been stunted because of a lack of food in their early years. These kids may also suffer more frequently from illness, which makes them skip school more often. If their parents are illiterate and/or have to work long hours, children will have no one to help them with their homework, while middle-class children will be helped by their parents and rich kids may have private tutors. Helped or not, they may not even have enough time for homework, if they have to take care of younger siblings or tend the family goats.

Given all this, as far as we accept that we should not punish children for having poor parents, we should take action to ensure that all children have some minimum amounts of food, healthcare and help with their homework. Much of this can be provided through public policy, as happens in some countries – free school lunches, vaccinations, basic health checks and some help with homework after school by teachers or tutors hired by the school. However, some of this still needs to be provided at home. Schools can provide only so much.

This means that there has to be some minimum equality of outcome in terms of parental income, if poor children are to have anything approaching a fair chance. Without this, even free schooling, free school meals, free vaccinations, and so on, cannot provide real equality of opportunity for children.

Even in adult life, there has to be some equality of outcome. It is well known that, once someone has been unemployed for a long time, it becomes extremely difficult for that person to get back into the labour market. But whether someone loses her job is not entirely determined by the person’s ‘worth’. For example, many people lose their jobs because they chose to join an industry that looked like a good prospect when they first started but since has been hit hard by a sudden increase in foreign competition. Few American steelworkers or British shipbuilding workers who joined their industries in the 1960s, or for that matter anyone else, could have predicted that by the early 1990s their industries would be virtually wiped out by Japanese and Korean competition. Is it really fair that these people have to suffer disproportionately and be consigned to the scrapheap of history?

Of course, in an idealized free market, this should not be a problem because the American steelworkers and the British shipbuilders can get jobs in expanding industries. But how many former American steelworkers do you know who have become computer engineers or former British shipbuilders who have turned themselves into investment bankers? Such conversion rarely, if ever, happens.

A more equitable approach would have been to help the displaced workers find a new career through decent unemployment benefits, health insurance even when out of a job, retraining schemes and help with job searches, as they do particularly well in Scandinavian countries. As I discuss elsewhere in the book (see Thing 21), this can also be a more productive approach for the economy as a whole.

Yes, in theory, a shoeshine boy from a poor provincial town in Peru can go to Stanford and do a PhD, as the former Peruvian President Alejandro Toledo has done, but for one Toledo we have millions of Peruvian children who did not even make it to high school. Of course, we could argue that all those millions of poor Peruvian children are lazy good-for-nothings, since Mr Toledo has proven that they too could have gone to Stanford if they had tried hard enough. But I think it is much more plausible to say that Mr Toledo is the exception. Without some equality of outcome (of parental income), poor people cannot take full advantage of equality of opportunity.

Indeed, international comparison of social mobility corroborates this reasoning. According to a careful study by a group of researchers in Scandinavia and the UK, the Scandinavian countries have higher social mobility than the UK, which in turn has higher mobility than the US. It is no coincidence that the stronger the welfare state, the higher the mobility. Particularly in the case of the US, the fact that low overall mobility is largely accounted for by low mobility at the bottom suggests that it is the lack of a basic income guarantee that is preventing poor kids from making use of the equality of opportunity.

Excessive equalization of outcomes is harmful, although what exactly is excessive is debatable. Nevertheless, equality of opportunity is not enough. Unless we create an environment where everyone is guaranteed some minimum capabilities through some guarantee of minimum income, education and healthcare, we cannot say that we have fair competition. When some people have to run a 100 metre race with sandbags on their legs, the fact that no one is allowed to have a head start does not make the race fair. Equality of opportunity is absolutely necessary but not sufficient in building a genuinely fair and efficient society.

 

 

Big government is bad for the economy. The welfare state has emerged because of the desire by the poor to have an easier life by making the rich pay for the costs of adjustments that are constantly demanded by market forces. When the rich are taxed to pay for unemployment insurance, healthcare and other welfare measures for the poor, this not only makes the poor lazy and deprives the rich of an incentive to create wealth, it also makes the economy less dynamic. With the protection of the welfare state, people do not feel the need to adjust to new market realities, thereby delaying the changes in their professions and working patterns that are needed for dynamic economic adjustments. We don’t even have to invoke the failures of the communist economies. Just look at the lack of dynamism in Europe with its bloated welfare state, compared to the vitality of the US.

 

A well-designed welfare state can actually encourage people to take chances with their jobs and be more, not less, open to changes. This is one reason why there is less demand for trade protectionism in Europe than in the US. Europeans know that, even if their industries shut down due to foreign competition, they will be able to protect their living standards (through unemployment benefits) and get re-trained for another job (with government subsidies), whereas Americans know that losing their current jobs may mean a huge fall in their living standards and may even be the end of their productive lives. This is why the European countries with the biggest welfare states, such as Sweden, Norway and Finland, were able to grow faster than, or at least as fast as, the US, even during the post-1990 ‘American Renaissance’.

 

Representatives of different professions in a Christian country were debating which profession is the oldest.

The medical doctor said: ‘What was the first thing that God did with humans? He performed an operation – he made Eve with Adam’s rib. The medical profession is the oldest.’

‘No, that is not true,’ the architect said. ‘The first thing he did was to build the world out of chaos. That’s what architects do – creating order out of chaos. We are the oldest profession.’

The politician, who was patiently listening, grinned and asked: ‘Who created that chaos?’

Medicine may or may not be the oldest profession in the world, but it is one of the most popular all over the world. However, in no country is it more popular than in my native South Korea.

A survey done in 2003 revealed that nearly four out of five ‘top-scoring university applicants’ (defined as those within the top 2 per cent of the distribution) in the science stream wanted to study medicine. According to unofficial data, during the last few years, even the least competitive of the country’s twenty-seven medical departments (at undergraduate level) has become more difficult to enter than the best engineering departments in the country. It cannot get more popular than that.

The interesting thing is that, even though medicine has always been a popular subject in Korea, this kind of hyper-popularity is new. It is basically a twenty-first-century phenomenon. What has changed?

An obvious possibility is that, for whatever reason (e.g., an ageing population), the relative earnings of medical doctors have risen and the youngsters are merely responding to changes in the incentives – the market wants more able doctors, so more and more able people are going into the profession. However, the relative incomes of medical doctors in Korea have been falling, with the continuous increase in their supply. And it is not as if some new government regulation was introduced that makes it difficult to get jobs as engineers or scientists (the obvious alternative choices for would-be medical doctors). So what is really going on?

What is driving this is the dramatic fall in job security over the last decade or so. After the 1997 financial crisis that ended the country’s ‘miracle years’, Korea abandoned its interventionist, paternalistic economic system and embraced market liberalism that emphasizes maximum competition. Job security has been drastically reduced in the name of greater labour market flexibility. Millions of workers have been forced into temporary jobs. Ironically enough, even before the crisis, the country had one of the most flexible labour markets in the rich world, with one of the highest ratios of workers without a permanent contract at around 50 per cent. The recent liberalization has pushed the ratio up even higher – to around 60 per cent. Moreover, even those with permanent contracts now suffer from heightened job insecurity. Before the 1997 crisis, most workers with a permanent contract could expect, de facto if not de jure, lifetime employment (as many of their Japanese counterparts still do). Not any more. Now older workers in their forties and fifties, even if they have a permanent contract, are encouraged to make way for the younger generation at the earliest possible chance. Companies cannot fire them at will, but we all know that there are ways to let people know that they are not wanted and thus to make them ‘voluntarily’ leave.

Given this, Korean youngsters are, understandably, playing safe. If they become a scientist or an engineer, they reckon, there is a high chance that they will be out of their jobs in their forties, even if they join major companies like Samsung or Hyundai. This is a horrendous prospect, since the welfare state in Korea is so weak – the smallest among the rich countries (measured by public social spending as a share of GDP). A weak welfare state was not such a big problem before, because many people had lifetime employment. With lifetime employment gone, it has become lethal. Once you lose your job, your living standard falls dramatically and, more importantly, you don’t have much of a second chance. Thus, bright Korean youngsters figure, and are advised by their parents, that with a licence to practise medicine they can work until they choose to retire. If the worst comes to the worst, they can set up their own clinics, even if they do not make much money (well, for a medical doctor). No wonder every Korean kid with a brain wants to study medicine (or law – another profession with a licence – if they are in the humanities stream).

Don’t get me wrong. I revere medical doctors. I owe my life to them – I have had a couple of life-saving operations and been cured of countless infections thanks to antibiotics they have prescribed for me. But even I know that it is impossible for 80 per cent of the brainiest Korean kids in the science stream all to be cut out to be medical doctors.

So, one of the freest labour markets in the rich world, that is, the Korean labour market, is spectacularly failing to allocate talent in the most efficient manner. The reason? Heightened job insecurity.

 

Job security is a thorny issue. Free-market economists believe that any labour market regulation that makes firing more difficult makes the economy less efficient and dynamic. To start with, it weakens the incentive for workers to work hard. On top of that, it discourages wealth creation by making employers more reluctant to hire additional people (for fear of not being able to fire them when necessary).

Labour market regulations are bad enough, it is argued, but the welfare state has made things even worse. By providing unemployment benefits, health insurance, free education and even minimum income support, the welfare state has effectively given everyone a guarantee to be hired by the government – as an ‘unemployed worker’, if you like – with a minimum wage. Therefore, workers do not have enough incentive to work hard. To make things worse, these welfare states are financed by taxing the rich, reducing their incentives to work hard, create jobs and generate wealth.

Given this, the reasoning goes, a country with a bigger welfare state is going to be less dynamic – its workers are less compelled to work, while its entrepreneurs are less motivated to create wealth.

This argument has been very influential. In the 1970s, a popular explanation of Britain’s then lacklustre economic performance was that its welfare state had become bloated and its trade unions overly powerful (which is also partly due to the welfare state, insofar as the latter dulls the threat of unemployment). In this reading of British history, Margaret Thatcher saved Britain by putting unions in their place and reducing the welfare state, even though what actually happened is more complicated. Since the 1990s, this view of the welfare state has become even more popular with the (allegedly) superior growth performance of the US to those of other rich countries with bigger welfare states. When governments in other countries try to cut their welfare spending, they frequently cite Mrs Thatcher’s curing of the so-called ‘British Disease’ or the superior dynamism of the US economy.

But is it true that greater job security and a bigger welfare state make an economy less productive and dynamic?

As in our Korean example, a lack of job security can lead youngsters to make conservative choices with their career, favouring secure jobs in medicine or the law. This may be the right choice for them individually, but it leads to a misallocation of talents and thus reduces economic efficiency and dynamism.

The weaker welfare state in the US has been one important reason why trade protectionism is much stronger there than in Europe, despite a greater acceptance of government intervention in the latter. In Europe (of course, I am ignoring national differences in the details), if your industry declines and you lose your job, it is a big blow but not the end of the world. You will still keep your health insurance and public housing (or housing subsidies), while receiving unemployment benefits (up to 80 per cent of your last pay), government-subsidized retraining and government help in your job search. In contrast, if you are a worker in the US, you’d better make sure you hold on to your current job, if necessary through protectionism, because losing your job means losing almost everything. Unemployment insurance coverage is patchy and of shorter duration than in Europe. There is little public help with retraining and job search. More frighteningly, losing your job means losing your health insurance and probably your home, as there is little public housing or public subsidies for your rent. As a result, worker resistance to any industrial restructuring that involves job cuts is much greater in the US than in Europe. Most US workers are unable to put up an organized resistance, but those who can – unionized workers – will, understandably, do everything they can to preserve the current job distribution.

As the above examples show, greater insecurity may make people work harder, but it makes them work harder in the wrong jobs. All those talented Korean youngsters who could be brilliant scientists and engineers are labouring over human anatomy. Many US workers who could – after appropriate retraining – be working in ‘sunrise’ industries (e.g., bio-engineering) are grimly holding on to their jobs in ‘sunset’ industries (e.g., automobiles), only delaying the inevitable.

The point of all the above examples is that, when people know they will have a second (or third or even fourth) chance, they will be much more open to risk-taking when it comes to choosing their first job (as in the Korean example) or letting go of their existing jobs (as in the US– Europe comparison).

Do you find this logic strange? You shouldn’t. Because this is exactly the logic behind bankruptcy law, which most people accept as ‘obvious’.

Before the mid nineteenth century, no country had a bankruptcy law in the modern sense. What was then called bankruptcy law did not give bankrupt businessmen much protection from creditors while they restructured their business – in the US, ‘Chapter 11’ now gives such protection for six months. More importantly, it did not give them a second chance, as they were required to pay back all debts, however long it took, unless the creditors gave them a ‘discharge’ from the duty. This meant that, even if the bankrupt businessman somehow managed to start a new business, he had to use all his new profits to repay the old debts, which hampered the growth of the new business. All this made it extremely risky to start a business venture in the first place.

Over time, people came to realize that the lack of a second chance was hugely discouraging risk-taking by businessmen. Starting with Britain in 1849, countries have introduced modern bankruptcy laws with court-granted protection from creditors during initial restructuring and, more importantly, the power for courts to impose permanent reductions in debts, even against the wishes of the creditors. When combined with institutions like limited liability, which was introduced around the same time (see Thing 2), this new bankruptcy law reduced the danger of any business undertaking and thus encouraged risk-taking, which has made modern capitalism possible.

Insofar as it gives workers second chances, we can say that the welfare state is like a bankruptcy law for them. In the same way that bankruptcy laws encourage risk-taking by entrepreneurs, the welfare state encourages workers to be more open to change (and the resulting risks) in their attitudes. Because they know that there is going to be a second chance, people can be bolder in their initial career choices and more open to changing jobs later in their careers.

 

What about the evidence? What are the relative economic performances of countries that differ in terms of the sizes of their welfare states? As mentioned, the conventional wisdom is that countries with smaller welfare states are more dynamic. However, the evidence does not support this view.

Until the 1980s, the US grew much more slowly than Europe despite the fact that it had a much smaller welfare state. For example, in 1980, public social expenditure as a share of GDP was only 13.3 per cent in the US, compared to 19.9 per cent for the EU’s fifteen countries. The ratio was as high as 28.6 per cent in Sweden, 24.1 per cent in the Netherlands and 23 per cent in (West) Germany. Despite this, between 1950 and 1987, the US grew more slowly than any European country. Per capita income grew at 3.8 per cent in Germany, 2.7 per cent in Sweden, 2.5 per cent in the Netherlands and 1.9 per cent in the US during this period. Obviously, the size of the welfare state is only one factor in determining a country’s economic performance, but this shows that a large welfare state is not incompatible with high growth.

Even since 1990, when the relative growth performance of the US has improved, some countries with large welfare states have grown faster. For example, between 1990 and 2008, per capita income in the US grew at 1.8 per cent. This is basically the same as in the previous period, but given the slowdown in the European economies, this made the US one of the fastest-growing economies in the ‘core’ OECD group (that is, excluding the not-fully-rich-yet countries, such as Korea and Turkey).

The interesting thing, however, is that the two fastest-growing economies in the core OECD group during the post-1990 period are Finland (2.6 per cent) and Norway (2.5 per cent), both with a large welfare state. In 2003, the share of public social spending in GDP was 22.5 per cent in Finland and 25.1 per cent in Norway, compared to the OECD average of 20.7 per cent and 16.2 per cent in the US. Sweden, which has literally the largest welfare state in the world (31.3 per cent, or twice as large as that of the US), at 1.8 per cent, recorded a growth rate that was only a shade below the US rate. If you count only the 2000s (2000–8), the growth rates of Sweden (2.4 per cent) and Finland (2.8 per cent) were far superior to that of the US (1.8 per cent). Were the free-market economists right about the detrimental effects of the welfare state on work ethic and the incentives for wealth creation, this kind of thing should not happen.

Of course, by all this I am not suggesting that the welfare state is necessarily good. Like all other institutions, it has its upsides and downsides. Especially if it is based on targeted, rather than universal, programmes (as in the US), it can stigmatize welfare recipients. The welfare state raises people’s ‘reservation wages’ and deters them from taking low-paying jobs with poor working conditions, although whether this is a bad thing is a matter of opinion (personally I think the existence of a large number of ‘working poor’, as in the US, is as much of a problem as the generally higher unemployment rates we see in Europe). However, if it is well designed, with a view to giving workers a second chance, as it is in Scandinavian countries, it can encourage economic growth by making people be more open to changes and thus making industrial restructuring easier.

We can drive our cars fast only because we have brakes. If cars had no brakes, even the most skilful drivers would not dare to drive at more than 20–30 miles per hour for fear of fatal accidents. In the same way, people can accept the risk of unemployment and the need for occasional re-tooling of their skills more willingly when they know that those experiences are not going to destroy their lives. This is why a bigger government can make people more open to change and thus make the economy more dynamic.

 

 

The rapid development of the financial markets has enabled us to allocate and reallocate resources swiftly. This is why the US, the UK, Ireland and some other capitalist economies that have liberalized and opened up their financial markets have done so well in the last three decades. Liberal financial markets give an economy the ability to respond quickly to changing opportunities, thereby allowing it to grow faster. True, some of the excesses of the recent period have given finance a bad name, not least in the above-mentioned countries. However, we should not rush into restraining financial markets simply because of this once-in-a-century financial crisis that no one could have predicted, however big it may be, as the efficiency of its financial market is the key to a nation’s prosperity.

 

The problem with financial markets today is that they are too efficient. With recent financial ‘innovations’ that have produced so many new financial instruments, the financial sector has become more efficient in generating profits for itself in the short run. However, as seen in the 2008 global crisis, these new financial assets have made the overall economy, as well as the financial system itself, much more unstable. Moreover, given the liquidity of their assets, the holders of financial assets are too quick to respond to change, which makes it difficult for real-sector companies to secure the ‘patient capital’ that they need for long-term development. The speed gap between the financial sector and the real sector needs to be reduced, which means that the financial market needs to be deliberately made less efficient.

 

Visitors to Iceland in the 1990s reported that the official tourist guide handed out at Reykjavik airport had, like all other such guides, a ‘useful phrases’ section. Unlike them, I was told, the Icelandic guide also had a ‘useless phrases’ section. Apparently it contained three phrases, which were, in English: ‘Where is the railway station?’, ‘It’s a nice day today’, and ‘Is there anything cheaper?’

The railways thing is, surprising though it may be, true – Iceland does not have any railways. About the weather, the guide was perhaps being overly harsh. I haven’t lived there, but by all accounts Iceland does seem to have at least a few sunny days a year. As for everything being so expensive, this was also pretty accurate and a consequence of the country’s economic success. Labour services are expensive in high-income countries (unless they have a constant supply of low-wage immigrants, as the US or Australia), making everything more expensive than what the official exchange rate should suggest (see Thing 10). Once one of the poorest economies in Europe, by 1995 Iceland had developed into the eleventh richest economy in the world (after Luxemburg, Switzerland, Japan, Norway, Denmark, Germany, the United States, Austria, Singapore and France).

Rich as it already was, the Icelandic economy got a turbo-charged boost in the late 1990s, thanks to the then government’s decision to privatize and liberalize the financial sector. Between 1998 and 2003, the country privatized state-owned banks and investment funds, while abolishing even the most basic regulations on their activities, such as reserve requirements for the banks. Following this, the Icelandic banks expanded at an astonishing speed, seeking customers abroad as well. Their internet banking facilities made big inroads in Britain, the Netherlands and Germany. And Icelandic investors took advantage of the aggressive lending by their banks and went on corporate shopping sprees, especially in Britain, its former adversary in the famous ‘Cod Wars’ of the 1950s to 1970s. These investors, dubbed the ‘Viking raiders’, were best represented by Baugur, the investment company owned by Jón Jóhanneson, the young business tycoon. Bursting on to the scene only in the early 2000s, by 2007 Baugur had become a major force in the British retail industry, with major stakes in businesses employing about 65,000 people, turning over £10 billion across 3,800 stores, including Hamleys, Debenhams, Oasis and Iceland (the temptingly named British frozen-food chain).

For a while, the financial expansion seemed to work wonders for Iceland. Once a financial backwater with a reputation for excessive regulation (its stock market was only set up in 1985), the country was transformed into a vibrant new hub in the emerging global financial system. From the late 1990s, Iceland grew at an extraordinary rate and became the fifth richest country in the world by 2007 (after Norway, Luxemburg, Switzerland and Denmark). The sky seemed to be the limit.

Unfortunately, after the global financial crisis of 2008, the Icelandic economy went into meltdown. That summer, all three of its biggest banks went bankrupt and had to be taken over by the government. Things got so bad that, in October 2009, McDonald’s decided to withdraw from Iceland, relegating it to the borderland of globalization. At the time of writing (early 2010), the IMF estimate was that its economy shrank at the rate of 8.5 per cent in 2009, the fastest rate of contraction among the rich countries.

The risky nature of Iceland’s financial drive since the late 1990s is increasingly coming to light. Banking assets had reached the equivalent of 1,000 per cent of GDP in 2007, which was double that of the UK, a country with one of the most developed banking sectors in the world. Moreover, Iceland’s financial expansion had been fuelled by foreign borrowing. By 2007, net foreign debt (foreign debts minus foreign lending) reached nearly 250 per cent of GDP, up from 50 per cent of GDP in 1997. Countries have gone to pieces with far less exposure – foreign debts were equivalent to 25 per cent of GDP in Korea and 35 per cent of GDP in Indonesia on the eve of the Asian financial crisis in 1997. On top of that, the shady nature of the financial deals behind the Icelandic economic miracle was revealed – very often the main borrowers from the banks were key shareholders of those same banks.

 

Why am I spending so much time talking about a small island with just over 300,000 people that does not even have a train station or a McDonald’s, however dramatic its rise and fall may have been? It is because Iceland epitomizes what is wrong with the dominant view of finance today.

Extraordinary though Iceland’s story may sound, it was not alone in fuelling growth by privatizing, liberalizing and opening up the financial sector during the last three decades. Ireland tried to become another financial hub through the same strategy, with its financial assets reaching the equivalent of 900 per cent of GDP in 2007. Like Iceland, Ireland also had a bad fall in the 2008 global financial crisis. At the time of writing, the IMF estimate was that its economy contracted by 7.5 per cent in 2009. Latvia, another aspiring financial hub, has had it even worse. Following the collapse of its finance-driven boom, its economy was estimated by the IMF to have shrunk by 16 per cent in 2009. Dubai, the self-appointed financial hub of the Middle East, seemed to hold on a bit longer than its European rivals, but threw in the towel by declaring a debt moratorium for its main state-owned conglomerate in November 2009.

Before their recent falls from grace, these economies were touted as examples of a new finance-led business model for countries that want to get ahead in the era of globalization. As late as November 2007, when the storm clouds were rapidly gathering in the international financial markets, Richard Portes, a prominent British policy economist, and Fridrik Baldursson, an Icelandic professor, solemnly declared in a report for the Iceland Chamber of Commerce that ‘[o]verall, the internationalisation of the Icelandic financial sector is a remarkable success story that the markets should better acknowledge’. For some, even the recent collapses of Iceland, Ireland and Latvia have not been enough reason to abandon a finance-led economic strategy. In September 2009, Turkey announced that it will implement a series of policies that will turn itself into (yet another) financial hub of the Middle East. Even the government of Korea, a traditional manufacturing powerhouse, is implementing policies aimed at turning itself into the financial hub of Northeast Asia, although its enthusiasm has been dented since the collapse of Ireland and Dubai, after which it was hoping to model the country.

Now, the real trouble is that what countries like Iceland and Ireland were implementing were only more extreme forms of the economic strategy being pursued by many countries – a growth strategy based on financial deregulation, first adopted by the US and the UK in the early 1980s. The UK put its financial deregulation programme into a higher gear in the late 1980s, with the so-called ‘Big Bang’ deregulation and since then has prided itself on ‘light-touch’ regulation. The US matched it by abolishing the 1933 Glass-Steagall Act in 1999, thereby tearing down the wall between investment banking and commercial banking, which had defined the US financial industry since the Great Depression. Many other countries followed suit.

What was encouraging more and more countries to adopt a growth strategy based on deregulated finance was the fact that in such a system it is easier to make money in financial activities than through other economic activities – or so it seemed until the 2008 crisis. A study by two French economists, Gérard Duménil and Dominique Lévy – one of the few studies separately estimating the profit rate of the financial sector and that of the non-financial sector – shows that the former has been much higher than the latter in the US and in France during the last two or three decades. According to this study, in the US the rate of profit for financial firms was lower than that of the non-financial firms between the mid 1960s and the late 1970s. But, following financial deregulation in the early 1980s, the profit rate of financial firms has been on a rising trend, and ranged between 4 per cent and 12 per cent. Since the 1980s, it has always been significantly higher than that of non-financial firms, which ranged between 2 per cent and 5 per cent. In France, the profit rate of financial corporations was negative between the early 1970s and the mid 1980s (no data is available for the 1960s). However, with the financial deregulation of the late 1980s, it started rising and overtook that of non-financial firms in the early 1990s, when both were about 5 per cent, and rose to over 10 per cent by 2001. In contrast, the profit rate of French non-financial firms declined from the early 1990s, to reach around 3 per cent in 2001.

In the US, the financial sector became so attractive that even many manufacturing companies have turned themselves essentially into finance companies. Jim Crotty, the distinguished American economist, has calculated that the ratio of financial assets to non-financial assets owned by non-financial corporations in the US rose from around 0.4 in the 1970s to nearly 1 in the early 2000s. Even companies such as GE, GM and Ford – once the symbols of American manufacturing prowess – have been ‘financialized’ through a continuous expansion of their financial arms, coupled with the decline of their core manufacturing activities. By the early twenty-first century, these manufacturing firms were making most of their profits through financial activities, rather than their core manufacturing businesses (see Thing 18). For example, in 2003, 45 per cent of GE’s profit came from GE Capital. In 2004, 80 per cent of profits of GM were from its financial arm, GMAC, while Ford made all its profits from Ford Finance between 2001 and 2003.

 

The result of all this was an extraordinary growth in the financial sector across the world, especially in the rich countries. The growth was not simply in absolute terms. The more significant point is that the financial sector has grown much faster – no, much, much faster – than the underlying economy.

According to a calculation based on IMF data by Gabriel Palma, my colleague at Cambridge and a leading authority on financial crises, the ratio of the stock of financial assets to world output rose from 1.2 to 4.4 between 1980 and 2007. The relative size of the financial sector was even greater in many rich countries. According to his calculation, the ratio of financial assets to GDP in the UK reached 700 per cent in 2007. France, which often styles itself as a counterpoint to Anglo-American finance capitalism, has not lagged far behind the UK in this respect – the ratio of its financial assets to GDP is only marginally lower than that of the UK. In the study cited above, Crotty, using American government data, calculates that the ratio of financial assets to GDP in the US fluctuated between 400 and 500 per cent between the 1950s and the 1970s, but started shooting up from the early 1980s with financial deregulation, to break through the 900 per cent mark by the early 2000s.

This meant that more and more financial claims were being created for each underlying real asset and economic activity. The creation of financial derivatives in the housing market, which was one of the main causes of the 2008 crisis, illustrates this point very well.

In the old days, when someone borrowed money from a bank and bought a house, the lending bank used to own the resulting financial product (mortgage) and that was that. However, financial innovations created mortgage-backed securities (MBSs), which bundle together up to several thousand mortgages. In turn, these MBSs, sometimes as many as 150 of them, were packed into a collateralized debt obligation (CDO). Then CDOs-squared were created by using other CDOs as collateral. And then CDOs-cubed were created by combining CDOs and CDOs-squared. Even higher-powered CDOs were created. Credit default swaps (CDSs) were created to protect you from default on the CDOs. And there are many more financial derivatives that make up the alphabet soup that is modern finance.

By now even I am getting confused (and, as it turns out, so were the people dealing with them), but the point is that the same underlying assets (that is, the houses that were in the original mortgages) and economic activities (the income-earning activities of those mortgage-holders) were being used again and again to ‘derive’ new assets. But, whatever you do in terms of financial alchemy, whether these assets deliver the expected returns depends ultimately on whether those hundreds of thousands of workers and small-scale business-owners who hold the original mortgages fall behind their mortgage payments or not.

The result was an increasingly tall structure of financial assets teetering on the same foundation of real assets (of course, the base itself was growing, in part fuelled by this activity, but let us abstract from that for the moment, since what matters here is that the size of the superstructure relative to the base was growing). If you make an existing building taller without widening the base, you increase the chance of it toppling over. It is actually a lot worse than that. As the degree of ‘derivation’ – or the distance from the underlying assets – increases, it becomes harder and harder to price the asset accurately. So, you are not only adding floors to an existing building without broadening its base, but you are using materials of increasingly uncertain quality for the higher floors. No wonder Warren Buffet, the American financier known for his down-to-earth approach to investment, called financial derivatives ‘weapons of financial mass destruction’ – well before the 2008 crisis proved their destructiveness.

 

All my criticisms so far about the overdevelopment of the financial sector in the last two or three decades are not to say that all finance is a bad thing. Had we listened to Adam Smith, who opposed limited liability companies (see Thing 2) or Thomas Jefferson, who considered banking to be ‘more dangerous than standing armies’, our economies would still be made up of the ‘Satanic mills’ of the Victorian age, if not necessarily Adam Smith’s pin factories.

However, the fact that financial development has been crucial in developing capitalism does not mean that all forms of financial development are good.

What makes financial capital necessary for economic development but potentially counterproductive or even destructive is the fact that it is much more liquid than industrial capital. Suppose that you are a factory owner who suddenly needs money to buy raw materials or machines to fulfil unexpected extra orders. Suppose also that you have already invested everything you have in building the factory and buying the machines and the inputs needed, for the initial orders. You will be grateful that there are banks that are willing to lend you the money (using your factory as collateral) in the knowledge that you will be able to generate extra income with those new inputs. Or suppose that you want to sell half of your factory (say, to start another line of business), but that no one will buy half a building and half a production line. In this case, you will be relieved to know that you can issue shares and sell half your shares. In other words, the financial sector helps companies to expand and diversify through its ability to turn illiquid assets such as buildings and machines into liquid assets such as loans and shares.

However, the very liquidity of financial assets makes them potentially negative for the rest of the economy. Building a factory takes at least months, if not years, while accumulating the technological and organizational know-how needed to build a world-class company takes decades. In contrast, financial assets can be moved around and rearranged in minutes, if not seconds. This enormous gap has created huge problems, because finance capital is ‘impatient’ and seeks short-term gains (see Thing 2). In the short run, this creates economic instability, as liquid capital sloshes around the world at very short notice and in ‘irrational’ ways, as we have recently seen. More importantly, in the long run, it leads to weak productivity growth, because long-term investments are cut down to satisfy impatient capital. The result has been that, despite enormous progress in ‘financial deepening’ (that is, the increase in the ratio between financial assets and GDP), growth has actually slowed down in recent years (see Things 7 and 13).

Thus, exactly because finance is efficient at responding to changing profit opportunities, it can become harmful for the rest of the economy. And this is why James Tobin, the 1981 Nobel laureate in economics, talked of the need to ‘throw some sand in the wheels of our excessively efficient international money markets’. For this purpose, Tobin proposed a financial transaction tax, deliberately intended to slow down financial flows. A taboo in polite circles until recently, the so-called Tobin Tax has recently been advocated by Gordon Brown, the former British prime minister. But the Tobin Tax is not the only way in which we can reduce the speed gap between finance and the real economy. Other means include making hostile takeovers difficult (thereby reducing the gains from speculative investment in stocks), banning short-selling (the practice of selling shares that you do not own today), increasing margin requirements (that is, the proportion of the money that has to be paid upfront when buying shares) or putting restrictions on cross-border capital movements, especially for developing countries.

All this is not to say that the speed gap between finance and the real economy should be reduced to zero. A financial system perfectly synchronized with the real economy would be useless. The whole point of finance is that it can move faster than the real economy. However, if the financial sector moves too fast, it can derail the real economy. In the present circumstances, we need to rewire our financial system so that it allows firms to make those long-term investments in physical capital, human skills and organizations that are ultimately the source of economic development, while supplying them with the necessary liquidity.

 

 

Whatever the theoretical justifications may be for government intervention, the success or otherwise of government policies depends in large part on the competence of those who design and execute them. Especially, albeit not exclusively, in developing countries, government officials are not very well trained in economics, which they need to be if they are to implement good economic policies. Those officials should recognize their limits and should refrain from implementing ‘difficult’ policies, such as selective industrial policy, and stick to less-demanding free-market policies, which minimize the role of the government. Thus seen, free-market policies are doubly good, because not only are they the best policies but they are also the lightest in their demands for bureaucratic capabilities.

 

Good economists are not required to run good economic policies. The economic bureaucrats that have been most successful are usually not economists. During their ‘miracle’ years, economic policies in Japan and (to a lesser extent) Korea were run by lawyers. In Taiwan and China, economic policies have been run by engineers. This demonstrates that economic success does not need people well trained in economics – especially if it is of the free-market kind. Indeed, during the last three decades, the increasing influence of free-market economics has resulted in poorer economic performances all over the world, as I have shown throughout this book – lower economic growth, greater economic instability, increased inequality and finally culminating in the disaster of the 2008 global financial crisis. Insofar as we need economics, we need different kinds of economics from free-market economics.

 

The East Asian economies of Japan, Taiwan, South Korea, Singapore, Hong Kong and China are often called ‘miracle’ economies. This is, of course, hyperbole, but as far as hyperboles go, it is not too outlandish.

During their Industrial ‘Revolution’ in the nineteenth century, per capita income in the economies of Western Europe and its offshoots (North America, Australia and New Zealand) grew between 1 per cent and 1.5 per cent per year (the exact number depending on the exact time period and the country you look at). During the so-called ‘Golden Age’ of capitalism between the early 1950s and the mid 1970s, per capita income in Western Europe and its offshoots grew at around 3.5–4 per cent per year.

In contrast, during their miracle years, roughly between the 1950s and the mid 1990s (and between the 1980s and today in the case of China), per capita incomes grew at something like 6–7 per cent per year in the East Asian economies mentioned above. If growth rates of 1–1.5 per cent describe a ‘revolution’ and 3.5–4 per cent a ‘golden age’, 6–7 per cent deserves to be called a ‘miracle’.

Given these economic records, one would naturally surmise that these countries must have had a lot of good economists. In the same way in which Germany excels in engineering because of the quality of its engineers and France leads the world in designer goods because of the talents of its designers, it seems obvious the East Asian countries must have achieved economic miracles because of the capability of their economists. Especially in Japan, Taiwan, South Korea and China – countries in which the government played a very active role during the miracle years – there must have been many first-rate economists working for the government, one would reason.

Not so. Economists were in fact conspicuous by their absence in the governments of the East Asian miracle economies. Japanese economic bureaucrats were mostly lawyers by training. In Taiwan, most key economic officials were engineers and scientists, rather than economists, as is the case in China today. Korea also had a high proportion of lawyers in its economic bureaucracy, especially before the 1980s. Oh Won-Chul, the brains behind the country’s heavy and chemical industrialization programme in the 1970s – which transformed its economy from an efficient exporter of low-grade manufacturing products into a world-class player in electronics, steel and shipbuilding – was an engineer by training.

If we don’t need economists to have good economic performance, as in the East Asian cases, what use is economics? Have the IMF, the World Bank and other international organizations been wasting money when they provided economics training courses for developing-country government officials and scholarships for bright young things from those countries to study in American or British universities renowned for their excellence in economics?

A possible explanation of the East Asian experience is that what is needed in those who are running economic policy is general intelligence, rather than specialist knowledge in economics. It may be that the economics taught in university classrooms is too detached from reality to be of practical use. If this is the case, the government will acquire more able economic policy-makers by recruiting those who have studied what happens to be the most prestigious subject in the country (which could be law, engineering or even economics, depending on the country), rather than a subject that is notionally most relevant for economic policy-making (that is, economics) (see Thing 17). This conjecture is indirectly supported by the fact that although economic policies in many Latin American countries have been run by economists, and very highly trained ones at that (the ‘Chicago Boys’ of General Pinochet being the most prominent example), their economic performance has been much inferior to that of the East Asian countries. India and Pakistan also have many world-class economists, but their economic performance is no match for the East Asian one.

John Kenneth Galbraith, the wittiest economist in history, was certainly exaggerating when he said that ‘economics is extremely useful as a form of employment for economists’, but he may not have been far off the mark. Economics does not seem very relevant for economic management in the real world.

Actually, it is worse than that. There are reasons to think that economics may be positively harmful for the economy.

 

In November 2008, Queen Elizabeth II visited the London School of Economics, which has one of the most highly regarded economics departments in the world. When given a presentation by one of the professors there, Professor Luis Garicano, on the financial crisis that had just engulfed the world, the Queen asked: ‘How come nobody could foresee it?’ Her Majesty asked a question that had been in most people’s minds since the outbreak of the crisis in the autumn of 2008.

During the last couple of decades, we were repeatedly told by all those highly qualified experts – from Nobel Prize-winning economists through world-class financial regulators to frighteningly bright young investment bankers with economics degrees from the world’s top universities – that all was well with the world economy. We were told that economists had finally found the magic formula that allowed our economies to grow rapidly with low inflation. People talked of the ‘Goldilocks’ economy, in which things are just right – not too hot, not too cold. Alan Greenspan, the former chairman of the Federal Reserve Board, who presided over the world’s biggest and (financially and ideologically) most influential economy for two decades, was hailed as a ‘maestro’, as the title of the book on him by the journalist Bob Woodward of Watergate fame had it. His successor, Ben Bernanke, talked of a ‘great moderation’, which came with the taming of inflation and disappearance of violent economic cycles (see Thing 6).

So it was a real puzzle to most people, including the Queen, that things could go so spectacularly wrong in a world where clever economists were supposed to have sorted out all the major problems. How could all those clever guys with degrees from some of the best universities, with hyper-mathematical equations coming out of their ears, have been so wrong?

Learning of the sovereign’s concern, the British Academy convened a meeting of some of the top economists from academia, the financial sector and the government on 17 June 2009. The result of this meeting was conveyed to the Queen in a letter, dated 22 July 2009, written by Professor Tim Besley, a prominent economics professor at the LSE, and Professor Peter Hennessy, a renowned historian of British government at Queen Mary, University of London.

In the letter, Professors Besley and Hennessy said that individual economists were competent and ‘doing their job properly on its own merit, but that they lost sight of the wood for the trees’ in the run-up to the crisis. There was, according to them, ‘a failure of the collective imagination of many bright people, both in this country and internationally, to understand the risks to the system as a whole’.

A failure of the collective imagination? Hadn’t most economists, including most (although not all) of those who were at the British Academy meeting, told the rest of us that free markets work best because we are rational and individualistic and thus know what we want for ourselves (and no one else, possibly except for our immediate families) and how to get it most efficiently? (See Things 5 and 16.) I don’t remember seeing much discussion in economics about imagination, especially of the collective kind, and I’ve been in the economics profession for the last two decades. I am not even sure whether a concept like imagination, collective or otherwise, has a place in the dominant rationalist discourse in economics. The great and the good of the economics world of Britain, then, were basically admitting that they don’t know what has gone wrong.

But this understates it. Economists are not some innocent technicians who did a decent job within the narrow confines of their expertise until they were collectively wrong-footed by a once-in-a-century disaster that no one could have predicted.

Over the last three decades, economists played an important role in creating the conditions of the 2008 crisis (and dozens of smaller financial crises that came before it since the early 1980s, such as the 1982 Third World debt crisis, the 1995 Mexican peso crisis, the 1997 Asian crisis and the 1998 Russian crisis) by providing theoretical justifications for financial deregulation and the unrestrained pursuit of short-term profits. More broadly, they advanced theories that justified the policies that have led to slower growth, higher inequality, heightened job insecurity and more frequent financial crises that have dogged the world in the last three decades (see Things 2, 6, 13 and 21). On top of that, they pushed for policies that weakened the prospects for long-term development in developing countries (see Things 7 and 11). In the rich countries, these economists encouraged people to overestimate the power of new technologies (see Thing 4), made people’s lives more and more unstable (see Thing 6), made them ignore the loss of national control over the economy (see Thing 8) and rendered them complacent about de-industrialization (see Thing 9). Moreover, they supplied arguments that insist that all those economic outcomes that many people find objectionable in this world – such as rising inequality (see Thing 13), sky-high executive salaries (see Thing 14) or extreme poverty in poor countries (see Thing 3) – are really inevitable, given (selfish and rational) human nature and the need to reward people according to their productive contributions.

In other words, economics has been worse than irrelevant. Economics, as it has been practised in the last three decades, has been positively harmful for most people.

 

If economics is as bad as I say it is, what am I doing working as an economist? If irrelevance is the most benign social consequence of my professional actions and harm the more likely one, should I not change my profession to something more socially beneficial, such as electronic engineering or plumbing?

I stick to economics because I believe that it does not have to be useless or harmful. After all, throughout this book I have myself used economics in trying to explain how capitalism really works. It is a particular type of economics – that is, free-market economics as it has been practised in the last few decades – that is dangerous. Throughout history, there have been many schools of economic thinking that have helped us better manage and develop our economies.

To start from where we are today, what has saved the world economy from a total meltdown in the autumn of 2008 is the economics of John Maynard Keynes, Charles Kindleberger (the author of the classic book on financial crises, Manias, Panics, and Crashes) and Hyman Minsky (the greatly undervalued American scholar of financial crises). The world economy has not descended into a rerun of the 1929 Great Depression because we absorbed their insights and bailed out key financial institutions (although we have not properly punished the bankers responsible for the mess or reformed the industry yet), increased government spending, provided stronger deposit insurance, maintained the welfare state (that props up the incomes of those who are unemployed) and flushed the financial market with liquidity on an unprecedented scale. As explained in earlier Things, many of these actions that have saved the world are ones opposed by free-market economists of earlier generations and of today.

Even though they were not trained as economists, the economic officials of East Asia knew some economics. However, especially until the 1970s, the economics they knew was mostly not of the free-market variety. The economics they happened to know was the economics of Karl Marx, Friedrich List, Joseph Schumpeter, Nicholas Kaldor and Albert Hirschman. Of course, these economists lived in different times, contended with different problems and had radically differing political views (ranging from the very right-wing List to very left-wing Marx). However, there was a commonality between their economics. It was the recognition that capitalism develops through long-term investments and technological innovations that transform the productive structure, and not merely an expansion of existing structures, like inflating a balloon. Many of the things that the East Asian government officials did in the miracle years – protecting infant industries, forcefully mobilizing resources away from technologically stagnant agriculture into the dynamic industrial sector and exploiting what Hirschman called the ‘linkages’ across different sectors – derive from such economic views, rather than the free-market view (see Thing 7). Had the East Asian countries, and indeed most of the rich countries in Europe and North America before them, run their economies according to the principles of free-market economics, they would not have developed their economies in the way they have.

The economics of Herbert Simon and his followers has really changed the way we understand modern firms and, more broadly, the modern economy. It helps us break away from the myth that our economy is exclusively populated by rational self-seekers interacting through the market mechanism. When we understand that the modern economy is populated by people with limited rationality and complex motives, who are organized in a complex way, combining markets, (public and private) bureaucracies and networks, we begin to understand that our economy cannot be run according to free-market economics. When we more closely observe the more successful firms, governments and countries, we see they are the ones that have this kind of nuanced view of capitalism, not the simplistic free-market view.

Even within the dominant school of economics, that is, the neo-classical school, which provides much of the foundation for free-market economics, there are theories that explain why free markets are likely to produce sub-optimal results. These are theories of ‘market failure’ or ‘welfare economics’, first proposed by the early twentieth-century Cambridge professor Arthur Pigou, and later developed by modern-day economists such as Amartya Sen, William Baumol and Joseph Stiglitz, to name just a few of the most important ones.

Free-market economists, of course, have either ignored these other economists or, worse, dismissed them as false prophets. These days, few of the above-mentioned economists, except those belonging to the market-failure school, are even mentioned in the leading economics textbooks, let alone properly taught. But the events that have been unfolding for the last three decades have shown that we actually have a lot more positive things to learn from these other economists than from free-market economists. The relative successes and failures of different firms, economies and policies during this period suggest that the views of these economists who are now ignored, or even forgotten, have important lessons to teach us. Economics does not have to be useless or harmful. We just have to learn right kinds of economics.

 

The daunting task ahead of us is to completely rebuild the world economy. Things are not as bad as they were during the Great Depression only because governments have propped up demand through huge deficit spending and unprecedented easing of money supply (the Bank of England has never had a lower interest rate since it was founded in 1644), while preventing bank runs through expansion of deposit insurance and the bailing-out of many financial firms. Without these measures, and the substantial automatic increase in welfare spending (e.g., unemployment benefit), we could be living through a much worse economic crisis than that of the 1930s.

There are people who believe the currently dominant free-market system to be fundamentally sound. They assume that tinkering on the margins will be a sufficient solution to our condition – a bit more transparency here, a tad more regulation there, and a modicum of restraints on executive pay over there. However, as I have tried to show, the fundamental theoretical and empirical assumptions behind free-market economics are highly questionable. Nothing short of a total re-envisioning of the way we organize our economy and society will do.

So what is to be done?

This is not a place to spell out all the detailed proposals required for the reconstruction of the world economy, many of which have been discussed in the foregoing 23 Things anyway. Here I will only outline some principles – eight of them – that I think we need to have in mind in redesigning our economic system.

*

 

To begin with: paraphrasing what Winston Churchill once said about democracy, let me restate my earlier position that capitalism is the worst economic system except for all the others. My criticism is of free-market capitalism, and not all kinds of capitalism.

The profit motive is still the most powerful and effective fuel to power our economy and we should exploit it to the full. But we must remember that letting it loose without any restraint is not the best way to make the most of it, as we have learned at great cost over the last three decades.

Likewise, the market is an exceptionally effective mechanism for coordinating complex economic activities across numerous economic agents, but it is no more than that – a mechanism, a machine. And like all machines, it needs careful regulation and steering. In the same way that a car can be used to kill people when driven by a drunken driver, or to save lives when it helps us deliver an emergency patient to hospital in time, the market can do wonderful things but also deplorable ones. The same car can be made better by putting in improved brakes, more powerful engines or more efficient fuel, and the same market can be made to perform better through appropriate changes to the attitudes of the participants, their motives and the rules that govern it.

There are different ways to organize capitalism. Free-market capitalism is only one of them – and not a very good one at that. The last three decades have shown that, contrary to the claims of its proponents, it slows down the economy, increases inequality and insecurity, and leads to more frequent (and sometimes massive) financial crashes.

There is no one ideal model. American capitalism is very different from Scandinavian capitalism, which in turn differs from the German or French varieties, not to speak of the Japanese form. For example, countries which find American-style economic inequality unacceptable (which some may not) may reduce it through a welfare state financed by high progressive income taxes (as in Sweden) or through restrictions on money-making opportunities themselves by, say, making the opening of large retail stores difficult (as in Japan). There is no simple way to choose between the two, even though I personally think that the Swedish model is better than the Japanese one, at least in this respect.

So capitalism, yes, but we need to end our love affair with unrestrained free-market capitalism, which has served humanity so poorly, and install a better-regulated variety. What that variety would be depends on our goals, values and beliefs.

Second: we should build our new economic system on the recognition that human rationality is severely limited. The 2008 crisis has revealed how the complexity of the world we have created, especially in the sphere of finance, has vastly outpaced our ability to understand and control it. Our economic system has had a mighty fall because it was rewired following the advice of economists who believe the human ability to deal with complexity is essentially unlimited.

The new world should be formed with a clear recognition that we have only limited powers of objective reasoning. It is suggested that we can prevent another major financial crisis by enhancing transparency. This is wrong. The fundamental problem is not our lack of information but our limited ability to process it. Indeed, if lack of transparency was the problem, the Scandinavian countries – famously transparent – would not have experienced a financial crisis in the early 1990s. As long as we continue to allow unlimited ‘financial innovations’, our ability to regulate will always be outstripped by our ability to innovate.

If we are really serious about preventing another crisis like the 2008 meltdown, we should simply ban complex financial instruments, unless they can be unambiguously shown to benefit society in the long run. This idea will be dismissed by some as outrageous. It’s not. We do that all the time with other products – think about the safety standards for food, drugs, automobiles and aeroplanes. What would result is an approval process whereby the impact of each new financial instrument, concocted by ‘rocket scientists’ within financial firms, is assessed in terms of risks and rewards to our system as a whole in the long run, and not just in terms of short-term profits for those firms.

Third: while acknowledging that we are not selfless angels, we should build a system that brings out the best, rather than worst, in people.

Free-market ideology is built on the belief that people won’t do anything ‘good’ unless they are paid for it or punished for not doing it. This belief is then applied asymmetrically and reconceived as the view that rich people need to be motivated to work by further riches, while poor people must fear poverty for their motivation.

Material self-interest is a powerful motive. The communist system turned out to be unviable because it ignored, or rather wanted to deny, this human driver. This does not, however, prove that material self-interest is our only motive. People are not as much propelled by material self-interest as free-market textbooks claim. If the real world were as full of rational self-seeking agents as the one depicted in those textbooks, it would collapse under the weight of continuous cheating, monitoring, punishment and bargaining.

Moreover, by glorifying the pursuit of material self-interest by individuals and corporations, we have created a world where material enrichment absolves individuals and corporations of other responsibilities to society. In the process, we have allowed our bankers and fund managers, directly and indirectly, to destroy jobs, shut down factories, damage our environment and ruin the financial system itself in the pursuit of individual enrichment.

If we are to prevent this kind of thing happening again, we should build a system where material enrichment is taken seriously but is not allowed to become the only goal. Organizations – be they corporations or government departments – should be designed to reward trust, solidarity, honesty and cooperation among their members. The financial system needs to be reformed to reduce the influence of short-term shareholders so that companies can afford to pursue goals other than short-term profit maximization. We should better reward behaviour with public benefits (e.g., reducing energy consumption, investment in training), not simply through government subsidies but also by bestowing it with a higher social status.

This is not just a moral argument. It is also an appeal to enlightened self-interest. By letting short-term self-interest rule everything we risk destroying the entire system, which serves no one’s interest in the long run.

Fourth: we should stop believing that people are always paid what they ‘deserve’.

People from poor countries are, individually, often more productive and entrepreneurial than their counterparts in rich countries. Should they be given equal opportunity through free immigration, these people can, and will, replace the bulk of the workforce in rich countries, even though that would be politically unacceptable and undesirable. Thus seen, it is the national economic systems and immigration control of the rich countries, rather than their lack of personal qualities, that keep poor people in poor countries poor.

Emphasizing that many people stay poor because they do not have true equal opportunity is not to say that they deserve to remain poor insofar as they have had equal opportunity. Unless there is some equalizing in outcome, especially (although not exclusively) so that all children can have more than minimum nutrition and parental attention, the equality of opportunity provided by the market mechanism will not guarantee truly fair competition. It will be like a race where no one has a head start but some people run with weights on their legs.

At the other end of the spectrum, executive pay in the US has gone into the stratosphere in the last few decades. US managers have increased their relative pay by at least ten times between the 1950s and today (an average CEO used to get paid thirty-five times an average worker’s salary then, while today he is paid 300–400 times that), but that is not because their productivity has risen ten times faster than that of their workers. Even excluding stock options, US managers are paid two and a half times what their Dutch counterparts are or four times what their Japanese counterparts are, despite no apparent superiority in their productivity.

Only when we are free to question the hand of cards that the market has dealt us will we be able to find ways to establish a more just society. We can, and should, change the rules of the stock market and the corporate governance system in order to restrain excessive executive pay in limited liability companies. We should not only provide equal opportunity but also equalize, to an extent, the starting points for all children for a truly meritocratic society. People should be given a real, not superficial, second chance through unemployment benefits and publicly subsidized retraining. Poor people in poor countries should not be blamed for their poverty, when the bigger explanations lie in the poverty of their national economic systems and immigration control in the rich countries. Market outcomes are not ‘natural’ phenomena. They can be changed.

Fifth: we need to take ‘making things’ more seriously. The post-industrial knowledge economy is a myth. The manufacturing sector remains vital.

Especially in the US and the UK, but also in many other countries, industrial decline in the last few decades has been treated as an inevitability of a post-industrial age, if not actively welcomed as a sign of post-industrial success.

But we are material beings and cannot live on ideas, however great the knowledge economy may sound. Moreover, we have always lived in a knowledge economy in the sense that it has always been a command over superior knowledge, rather than the physical nature of activities, that has ultimately decided which country is rich or poor. Indeed, most societies are still making more and more things. It is mainly because those who make things have become so much more productive that things have become cheaper, in relative terms, than services that we think we don’t consume as many things as before.

Unless you are a tiny tax haven (a status that is going to become more and more difficult to maintain, following the 2008 crisis), such as Luxemburg and Monaco, or a small country floating on oil, such as Brunei or Kuwait, you have to become better at making things in order to raise your living standard. Switzerland and Singapore, which are often touted as post-industrial success stories, are in fact two of the most industrialized economies in the world. Moreover, most high-value services are dependent (sometimes even parasitic) on the manufacturing sector (e.g., finance, technical consulting). And services are not very tradable, so an overly large service sector makes your balance of payments situation more precarious and thus your economic growth more difficult to sustain.

The myth of the post-industrial knowledge economy has also misdirected our investments. It has encouraged excessive emphasis on, for example, formal education, whose impact on economic growth turns out to be highly complex and uncertain, and on the spread of the internet, whose productivity impacts are actually quite modest.

Investment in ‘boring’ things like machinery, infrastructure and worker training needs to be encouraged through appropriate changes in tax rules (e.g., accelerated depreciation for machinery), subsidies (e.g., to worker training) or public investment (e.g., redirection into infrastructural development). Industrial policy needs to be redesigned to promote key manufacturing sectors with high scope for productivity growth.

Sixth: we need to strike a better balance between finance and ‘real’ activities.

A productive modern economy cannot exist without a healthy financial sector. Finance plays, among other things, the crucial role of resolving the mismatch between the act of investment and the bearing of its fruits. By ‘liquidizing’ physical assets whose characteristics cannot be changed quickly, finance also helps us to reallocate resources quickly.

However, in the last three decades, finance has become the proverbial tail that wags the dog. Financial liberalization has made it easier for money to move around, even across national borders, allowing financial investors to become more impatient for instant results. As a consequence, both corporations and governments have been forced to implement policies that produce quick profits, regardless of their long-term implications. Financial investors have utilized their greater mobility as a bargaining chip in extracting a bigger share of national income. Easier movement of finance has also resulted in greater financial instability and greater job insecurity (which is needed for delivering quick profits).

Finance needs to be slowed down. Not to put us back to the days of debtors’ prison and small workshops financed by personal savings. But, unless we vastly reduce the speed gap between finance and the real economy, we will not encourage long-term investment and real growth, because productive investments often take a long time to bear fruit. It took Japan forty years of protection and government subsidies before its automobile industry could be an international success, even at the lower end of the market. It took Nokia seventeen years before it made any profit in the electronics business, where it is one of the world leaders today. However, following the increasing degree of financial deregulation, the world has operated with increasingly shorter time horizons.

Financial transaction taxes, restrictions on cross-border movement of capital (especially movements in and out of developing countries), greater restrictions on mergers and acquisitions are some of the measures that will slow down finance to the speed at which it helps, rather than weakens or even derails, the real economy.

Seventh: government needs to become bigger and more active.

In the last three decades, we have been constantly told by free-market ideologues that the government is part of the problem, not a solution to the ills of our society. True, there are instances of government failure – sometimes spectacular ones – but markets and corporations fail too and, more importantly, there are many examples of impressive government success. The role of the government needs to be thoroughly reassessed.

This is not just about crisis management, evident since 2008, even in the avowedly free-market economies, such as the US. It is more about creating a prosperous, equitable and stable society. Despite its limitations and despite numerous attempts to weaken it, democratic government is, at least so far, the best vehicle we have for reconciling conflicting demands in our society and, more importantly, improving our collective well-being. In considering how we can make the best out of the government, we need to abandon some of the standard ‘trade-offs’ bandied about by free-market economists.

We have been told that a big government, which collects high income taxes from the wealthy and redistributes them to the poor, is bad for growth, as it discourages wealth creation by the rich and makes lower classes lazy. However, if having a small government is good for economic growth, many developing countries that have such a government should do well. Evidently this is not the case. At the same time, the Scandinavian examples, where a large welfare state has coexisted with (or even encouraged) good growth performance, should also expose the limits to the belief that smaller governments are always better for growth.

Free-market economists have also told us that active (or intrusive, as they put it) governments are bad for economic growth. However, contrary to common perception, virtually all of today’s rich countries used government intervention to get rich (if you are still not convinced about this point, see my earlier book, Bad Samaritans). If designed and implemented appropriately, government intervention can increase economic dynamism by augmenting the supply of inputs that markets are bad at supplying (e.g., R&D, worker training), sharing risk for projects with high social returns but low private returns, and, in developing countries, providing the space in which nascent firms in ‘infant’ industries can develop their productive capabilities.

We need to think more creatively how the government becomes an essential element in an economic system where there is more dynamism, greater stability and more acceptable levels of equity. This means building a better welfare state, a better regulatory system (especially for finance) and better industrial policy.

Eighth: the world economic system needs to ‘unfairly’ favour developing countries.

Because of the constraints imposed by their democratic checks, the free-market advocates in most rich countries have actually found it difficult to implement full-blown free-market reform. Even Margaret Thatcher found it impossible to consider dismantling the National Health Service. As a result, it was actually developing countries that have been the main subjects of free-market policy experiments.

Many poorer countries, especially in Africa and Latin America, have been forced to adopt free-market policies in order to borrow money from free-market-loving international financial organizations (such as the IMF and the World Bank) and rich-country governments (that also ultimately control the IMF and the World Bank). The weakness of their democracies meant that free-market policies could be implemented more ruthlessly in developing countries, even when they hurt a lot of people. This is the ultimate irony of all – people needing most help were worst hit. This tendency was reinforced by the strengthening of global rules over the last couple of decades on what governments can do to protect and develop their economies (more necessary in the poor countries) through the establishment and/or strengthening of organizations such as the WTO, the BIS and various bilateral and regional free-trade and investment agreements. The result has been a much more thorough implementation of free-market policies and much worse performance in terms of growth, stability and inequality than in developed countries.

The world economic system needs to be completely overhauled in order to provide greater ‘policy space’ for the developing countries to pursue policies that are more suitable to them (the rich countries have much greater scope to bend, or even ignore, international rules). The developing countries need a more permissive regime regarding the use of protectionism, regulation of foreign investment and intellectual property rights, among others. These are policies that the rich countries actually used when they were developing countries themselves. All this requires a reform of the WTO, abolition and/or reform of existing bilateral trade and investment agreements between rich and poor countries, and changes in the policy conditions attached to loans from international financial organizations and to foreign aid from the rich countries.

Of course, these things are ‘unfairly favourable’ to the developing countries, as some rich countries would argue. However, developing countries already suffer from so many disadvantages in the international system that they need these breaks to have a hope of catching up.

The eight principles all directly go against the received economic wisdom of the last three decades. This will have made some readers uncomfortable. But unless we now abandon the principles that have failed us and that are continuing to hold us back, we will meet similar disasters down the road. And we will have done nothing to alleviate the conditions of billions suffering poverty and insecurity, especially, but not exclusively, in the developing world. It is time to get uncomfortable.

 